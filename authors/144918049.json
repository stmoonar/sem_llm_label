{
    "authorId": "144918049",
    "papers": [
        {
            "paperId": "513d947c064694ecb781d6b1cbe51dacee7bb379",
            "title": "Machine learning approaches for electronic health records phenotyping: A methodical review",
            "abstract": "Objective: Accurate and rapid methods for phenotyping are a prerequisite to realizing the potential of electronic health records (EHRs) data for clinical and translational research. This study reviews the literature on machine learning (ML) approaches for phenotyping with respect to the phenotypes considered, the data sources and methods used, and the contributions within the wider context of EHR-based research. Materials and Methods: We searched for relevant articles in PubMed and Web of Science published between January 1, 2018 and April 14, 2022. After screening, we collected data on 52 variables across 106 selected articles. Results: ML-based methods were developed for 156 unique phenotypes, primarily using EHR data from a single institution or health system. 72 of 106 articles leveraged unstructured data in clinical notes. In terms of methodology, supervised learning is the most prevalent ML paradigm (n = 64, 60.4%), with half of the articles employing deep learning. Semi-supervised and weakly-supervised approaches were applied to reduce the burden of obtaining gold-standard labeled data (n = 21, 19.8%), while unsupervised learning was used for phenotype discovery (n = 20, 18.9%). Federated learning has been applied to develop algorithms across multiple institutions while preserving data privacy (n = 2, 1.9%). Discussion While the use of ML for phenotyping is growing, most articles applied traditional supervised ML to characterize the presence of common, chronic conditions. Conclusion: Continued research in ML-based methods is warranted, with particular attention to the development of advanced methods for complex phenotypes and standards for reporting and evaluating phenotyping algorithms.",
            "fieldsOfStudy": [
                "Medicine",
                "Computer Science"
            ],
            "authors": [
                {
                    "authorId": "2108974994",
                    "name": "Siyue Yang"
                },
                {
                    "authorId": "2171475909",
                    "name": "Paul Varghese"
                },
                {
                    "authorId": "47486926",
                    "name": "E. Stephenson"
                },
                {
                    "authorId": "144918049",
                    "name": "K. Tu"
                },
                {
                    "authorId": "14929566",
                    "name": "Jessica L. Gronsbell"
                }
            ]
        },
        {
            "paperId": "8f4abf265c274dacb1e2d282cb813fad7586b23b",
            "title": "Using Biomedical Text as Data and Representation Learning for Identifying Patients with an Osteoarthritis Phenotype in the Electronic Medical Record",
            "abstract": "IntroductionElectronic medical records (EMRs) are increasingly used in health services research. Accurate/efficient identification of a target population with a specific disease phenotype is a necessary precursor to studying the health of these individuals. \nObjectives and ApproachWe explored the use of biomedical text as inputs to supervised phenotype identification algorithms. We employed a two-stage classification approach to map the discrete, sparse high-dimensional biomedical text data to a dense low dimensional vector space using methods from unsupervised machine learning. Next we used these learned vectors as inputs to supervised machine learning algorithms for phenotype identification. \nWe were able to demonstrate the applicability of the approach to identifying patients with an osteoarthritis (OA) phenotype using primary care data from the Electronic Medical Record Administrative data Linked Database (EMRALD) held at ICES. \nResultsEMRALD contains approximately 20Gb of biomedical text data on approximately 500,000 patients. The unit of analysis for this study is the patient. We were interested in identifying OA patients using solely text data as features. \nLabelled outcome information wass available from a random sample of 7,500 patients. We divided patients into training (N=6000), validation (N=750) and test (N=750) cohorts. We learned low dimensional representations of the input text data on the entire EMRALD corpus (N=500,000). We used learned numeric vectors as inputs to supervised machine learning models for OA classification (N=6,000 training set patients). \nWe compared models in terms of accuracy, sensitivity, specificity, PPV and NPV. The best learned models achieved approximately 90\\% sensitivity and 80\\% specificity. Classification accuracy varied as a function of learned inputs. \nConclusion/ImplicationsWe developed an approach to phenotype identification using solely biomedical text as an input. Preliminary results suggest our two-stage ML approach has improved operating characteristics compared to existing clinically derived decision rules for OA classification. Future work will explore the generalizability of this methodology to other disease phenotypes.",
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "authors": [
                {
                    "authorId": "4888158",
                    "name": "C. Meaney"
                },
                {
                    "authorId": "6515227",
                    "name": "J. Widdifield"
                },
                {
                    "authorId": "3866520",
                    "name": "L. Jaakkimainen"
                },
                {
                    "authorId": "2057385717",
                    "name": "Michael Escobar"
                },
                {
                    "authorId": "2479037",
                    "name": "Frank Rudzicz"
                },
                {
                    "authorId": "144918049",
                    "name": "K. Tu"
                }
            ]
        },
        {
            "paperId": "a2a7ad9ed5db4d2faf9c28c40558af55973fc3eb",
            "title": "Linkage of whole genome sequencing with administrative health, and electronic medical record data for the study of autism spectrum disorder: Feasibility, Opportunities and Challenges",
            "abstract": "IntroductionAutism Spectrum Disorder (ASD) is a neurodevelopmental disorder (NDD) that presents with a high degree of heterogeneity (e.g., co-occurrence of other NDDs and other co-morbid conditions), contributing to differential health system needs. Genetics are known to play an important role in ASD and may be associated with different disease trajectories. \nObjectives and ApproachIn this proof of principle project, our objective is to link >2,200 children with a confirmed diagnosis of a NDD from the Province of Ontario Neurodevelopmental (POND) Study to administrative health data and electronic medical record (EMR) data in order to identify subgroups of ASD with unique health system trajectories. POND includes detailed phenotype and whole genome sequencing (WGS) data. Identified subgroups will be characterized based on clinical phenotype and genetics. To meet this goal, consideration of WGS-specific privacy and data issues is needed to implement processes which are above and beyond traditional requirements for analyzing individual-level administrative health data. \nResultsLinkage of WGS data with administrative health data is an emerging area of research. As such it has presented a number of initial challenges for our study of ASD. Privacy concerns surrounding the use of WGS data and rare-variant analysis are of particular importance. Practical issues required the need for analysts with expertise in administrative data, EMR data and genetic analyses, and specialized software and sufficient processing power to analyze WGS data. Transdisciplinary discussions of the scope and significance of research questions addressed through this linkage were crucial. The identification of genetic determinants of phenotypes and trajectories in ASD could support targeted early interventions; EMR linkage may inform algorithms to identify ASD in broader populations. These approaches could improve both patient outcome and family experience. \nConclusion/ImplicationsAs the cost of genetic sequencing decreases, WGS data will become part of the routine clinical management of patients. Linkage of WGS, EMR and administrative data has tremendous potential that has largely not been realized; including population-level ASD research to improve our ability to predict long-term outcomes associated with ASD.",
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "authors": [
                {
                    "authorId": "7353807",
                    "name": "Jennifer D. Brooks"
                },
                {
                    "authorId": "2122023",
                    "name": "E. Anagnostou"
                },
                {
                    "authorId": "2674478",
                    "name": "F. Rahman"
                },
                {
                    "authorId": "144918049",
                    "name": "K. Tu"
                },
                {
                    "authorId": "52567566",
                    "name": "Lavnaya Uruthiramoorthy"
                },
                {
                    "authorId": "1400693974",
                    "name": "Kirk Nylen"
                },
                {
                    "authorId": "2263595850",
                    "name": "J. McLaughlin"
                },
                {
                    "authorId": "2780549",
                    "name": "M. Schull"
                },
                {
                    "authorId": "4518944",
                    "name": "S. Bronskill"
                }
            ]
        },
        {
            "paperId": "b4ed03f5f7cf204aa5360d214085746305fd76b2",
            "title": "Identify Patients with Congestive Heart Failure through Analyzing Free-Text Clinical Notes",
            "abstract": "IntroductionA number of challenges exist in analyzing unstructured free text data in electronic medical records (EMRs). EMR text are difficult to represent and model due to their high dimensionality, heterogeneity, sparsity, incompleteness, random errors and the presence of noise. \nObjectives and ApproachStandard Natural Language Processing (NLP) tools make errors when applied to clinical notes due to physician use of unconventional language, involving polysemy, abbreviations, ambiguity, misspelling, variations, and negation. \nThis paper presents a novel NLP framework, \u201cClinical Learning On Natural Expression\u201d (CLONE), to automatically learn from a large primary care EMR database, analyzing free text clinical notes from primary care practices. CLONE\u2019s predictive clinical models using text mining and neural network approach to extract features to identify patterns. To demonstrate effectiveness, we evaluate CLONE\u2019s ability in a case study to identify patients with a specific chronic condition: congestive heart failure (CHF). \nResultsA random selected sample of 7500 patients from Electronic Medical Record Administrative data Linked Database (EMRALD) is used. In this dataset, each patient\u2019s medical chart includes a reference standard, manually reviewed by medical practitioners. Prevalence of CHF is approximately 2%. The low prevalence leads to another challenging problem in machine learning: imbalanced datasets. After pre-processing, we build deep learning models to represent and extract important medical information from free text to identify CHF patients through analyzing patient charts. We evaluated the effectiveness of CLONE by comparing the predicted labels with the standard references on a holdout test dataset. Comparing it with a number of alternative algorithms, we improve the overall accuracy to over 90% on a test dataset. \nConclusion/ImplicationsAs the role of NLP in EMR data expands, the CLONE natural language processing framework can lead to substantial reduction in manual processing, while improving predictive accuracy.",
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "authors": [
                {
                    "authorId": "3386650",
                    "name": "M. Yann"
                },
                {
                    "authorId": "3890732",
                    "name": "T. Stukel"
                },
                {
                    "authorId": "3866520",
                    "name": "L. Jaakkimainen"
                },
                {
                    "authorId": "144918049",
                    "name": "K. Tu"
                }
            ]
        },
        {
            "paperId": "e3badb3ba44ba5485e538411a93498026244cb97",
            "title": "Learning Unsupervised Representations from Biomedical Text",
            "abstract": "IntroductionHealthcare settings are becoming increasingly technological. Interactions/events involving healthcare providers and the patients they service are captured as digital text. Healthcare organizations are amassing increasingly large/complex collections of biomedical text data. Researchers and policy makers are beginning to explore these text data holdings for structure, patterns, and meaning. \nObjectives and ApproachEMRALD is a primary care electronic medical record (EMR) database, comprised of over 40 family medicine clinics, nearly 400 primary care physicians and over 500,000 patients. EMRALD includes full-chart extractions, including all clinical narrative information/data in a variety of fields. \nThe input data (raw text strings) are discrete, sparse and high dimensional. We assessed scalable statistical models for high dimensional discrete data, including fitting, assessing and exploring models from three broad statistical areas: i) matrix factorization/decomposition models ii) probabilistic topic models and iii) word-vector embedding models. \nResultsEMRALD is comprised of 12 text data streams. EMRALD text data is structured into 84 million clinical notes (3.5 billion word/language tokens) and is approximately 18Gb in storage size. We employ a \u201ctext as data\u201d pipeline, i) mapping raw strings to sequences of word/language tokens, ii) mapping token sequences to numeric arrays, and finally iii) using numeric arrays as inputs to statistical models. \nFitted topic models yield useful thematic summaries of the EMRALD corpora. Topics discovered reflect core responsibilities of primary care physicians (e.g. women\u2019s health, pain management, nutrition/diet, etc.). \nFitted vector embedding models capture structure of discourse/syntax. Related words are mapped to similar locations of vector spaces. Analogical reasoning is possible in the embedding space. \nConclusion/Implications\u201cText as data\u201d requires an understanding of statistical models for discrete, sparse, high dimensional data. We fit a variety of unsupervised statistical models to biomedical text data. Preliminary results suggest that the learned low dimensional representations of the biomedical text data are effective at uncovering meaningful patterns/structure.",
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "authors": [
                {
                    "authorId": "4888158",
                    "name": "C. Meaney"
                },
                {
                    "authorId": "144918049",
                    "name": "K. Tu"
                },
                {
                    "authorId": "3866520",
                    "name": "L. Jaakkimainen"
                },
                {
                    "authorId": "2057385717",
                    "name": "Michael Escobar"
                },
                {
                    "authorId": "2479037",
                    "name": "Frank Rudzicz"
                },
                {
                    "authorId": "6515227",
                    "name": "J. Widdifield"
                }
            ]
        },
        {
            "paperId": "c8aedde57cecb3cdcad99322f276bbe1d63535a8",
            "title": "Capture of Osteoporosis and Fracture Information in an Electronic Medical Record Database from Primary Care",
            "abstract": "In a large database of EMR records, we explore: 1) completeness in capture of bone mineral density (BMD) T-scores required for diagnosis of osteoporosis; 2) concordance of BMD exam information with other osteoporosis information; and 3) evidence of osteoporosis screening among fracture patients. To explore completeness of exam capture, BMD exams in the EMR were related to a provincial billing database. To explore concordance of information and screening rates, 7500 EMR records were reviewed for osteoporosis and fracture details. Results show that 98% of exams billed to the province for EMR patients were found in the EMR. However, documented osteoporosis was substantiated with BMD results only 55.8% of the time. Of 151 charts for fragility fracture patients, 1 in 4 contained no evidence of osteoporosis investigation. In summary, while EMR information about osteoporosis is of variable quality, EMR records shed light on osteoporosis management indicators and completely capture BMD results.",
            "fieldsOfStudy": [
                "Medicine",
                "Computer Science"
            ],
            "authors": [
                {
                    "authorId": "2430826",
                    "name": "S. Allin"
                },
                {
                    "authorId": "46588978",
                    "name": "S. Munce"
                },
                {
                    "authorId": "3463161",
                    "name": "S. Jaglal"
                },
                {
                    "authorId": "37724752",
                    "name": "D. Butt"
                },
                {
                    "authorId": "3463151",
                    "name": "Jacqueline Young"
                },
                {
                    "authorId": "144918049",
                    "name": "K. Tu"
                }
            ]
        },
        {
            "paperId": "cae3ae0901a08d6dfdc31584ed619ec96ff2541b",
            "title": "User Manuals for a Primary Care Electronic Medical Record System: A Mixed-Methods Study of User- and Vendor-Generated Documents",
            "abstract": "Research problem: Tutorials and user manuals are important forms of impersonal support for using software applications, including electronic medical records (EMRs). Differences between user- and vendor-generated documentation may indicate support needs, which are not sufficiently addressed by the official documentation, and reveal new elements that may inform the design of tutorials and user manuals. Research question: What are the differences between user-generated tutorials and manuals for an EMR and the official user manual from the software vendor? Literature review: Effective design of tutorials and user manuals requires careful packaging of information, balance between declarative and procedural texts, an action and task-oriented approach, support for error recognition and recovery, and effective use of visual elements. No previous research compared these elements between formal and informal documents. Methodology: We conducted a mixed-methods study. Seven tutorials and two manuals for an EMR were collected from three family health teams and compared with the official user manual from the software vendor. Documents were qualitatively analyzed using a framework analysis approach in relation to the principles of technical documentation described before. Subsets of the data were quantitatively analyzed using cross-tabulation to compare the types of error information and visual cues in screen captures between user- and vendor-generated manuals. Results and discussion: The user-developed tutorials and manuals differed from the vendor-developed manual in that they contained mostly procedural and not declarative information; were customized to the specific workflow, user roles, and patient characteristics; contained more error information related to work processes than software usage; and used explicit visual cues on screen captures to help users identify window elements. These findings imply that to support EMR implementation, tutorials and manuals need to be customized and adapted to specific organizational contexts and workflows. The main limitation of the study is its generalizability. Future research should address this limitation and may explore alternative approaches to software documentation, such as modular manuals or participatory design.",
            "fieldsOfStudy": [
                "Computer Science",
                "Medicine"
            ],
            "authors": [
                {
                    "authorId": "47934706",
                    "name": "A. Shachak"
                },
                {
                    "authorId": "33634816",
                    "name": "Rustam Dow"
                },
                {
                    "authorId": "2154645",
                    "name": "J. Barnsley"
                },
                {
                    "authorId": "144918049",
                    "name": "K. Tu"
                },
                {
                    "authorId": "3224934",
                    "name": "S. Domb"
                },
                {
                    "authorId": "2879684",
                    "name": "A. Jadad"
                },
                {
                    "authorId": "1411459690",
                    "name": "L. Lemieux-Charles"
                }
            ]
        },
        {
            "paperId": "aa66e6c8e72ae823d5cb9b032b0fa894f9c40cd0",
            "title": "Understanding end-user support for health information technology: a theoretical framework.",
            "abstract": "BACKGROUND\nSupport is often considered an important factor for successful implementation and realising the benefits of health information technology (HIT); however, there is a dearth of research on support and theoretical frameworks to characterise it.\n\n\nOBJECTIVE\nTo develop and present a comprehensive, holistic, framework for characterising enduser support that can be applied to various settings and types of information systems.\n\n\nMETHOD\nScoping review of the medical informatics and information systems literature.\n\n\nRESULTS\nA theoretical framework of end-user support is presented. It includes the following facets: support source, location of support, support activities, and perceived characteristics of support and support personnel.\n\n\nCONCLUSION\nThe proposed framework may be a useful tool for describing and characterising enduser support for HIT. it may also be used by decision makers and implementation leaders for planning purposes.",
            "fieldsOfStudy": [
                "Computer Science",
                "Medicine"
            ],
            "authors": [
                {
                    "authorId": "47934706",
                    "name": "A. Shachak"
                },
                {
                    "authorId": "2154645",
                    "name": "J. Barnsley"
                },
                {
                    "authorId": "144918049",
                    "name": "K. Tu"
                },
                {
                    "authorId": "2879684",
                    "name": "A. Jadad"
                },
                {
                    "authorId": "1411459690",
                    "name": "L. Lemieux-Charles"
                }
            ]
        },
        {
            "paperId": "50fd709fbfe0ff97a4a887c7a4f1de908b0cc7d0",
            "title": "Medical text analytics tools for search and classification.",
            "abstract": "A text-analytic tool has been developed that accepts clinical medical data as input in order to produce patient details. The integrated tool has the following four characteristics. 1) It has a graphical user interface. 2) It has a free-text search tool that is designed to retrieve records using keywords such as \"MI\" for myocardial infarction. The result set is a display of those sentences in the medical records that contain the keywords. 3) It has three tools to classify patients based on the likelihood of being diagnosed for myocardial infarction, hypertension, or their smoking status. 4) A summary is generated for each patient selected. Large medical data sets provided by the Institute for Clinical Evaluative Sciences were used during the project.",
            "fieldsOfStudy": [
                "Computer Science",
                "Medicine"
            ],
            "authors": [
                {
                    "authorId": "1683391",
                    "name": "J. Huang"
                },
                {
                    "authorId": "144081368",
                    "name": "Aijun An"
                },
                {
                    "authorId": "50161308",
                    "name": "Vivian Hu"
                },
                {
                    "authorId": "144918049",
                    "name": "K. Tu"
                }
            ]
        }
    ]
}