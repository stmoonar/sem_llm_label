{
    "authorId": "1860612",
    "papers": [
        {
            "paperId": "083189e9680d13390797ed5b45da6d23b189e12c",
            "title": "Hierarchical Skip Decoding for Efficient Autoregressive Text Generation",
            "abstract": "Autoregressive decoding strategy is a commonly used method for text generation tasks with pre-trained language models, while early-exiting is an effective approach to speedup the inference stage. In this work, we propose a novel decoding strategy named Hierarchical Skip Decoding (HSD) for efficient autoregressive text generation. Different from existing methods that require additional trainable components, HSD is a plug-and-play method applicable to autoregressive text generation models, it adaptively skips decoding layers in a hierarchical manner based on the current sequence length, thereby reducing computational workload and allocating computation resources. Comprehensive experiments on five text generation datasets with pre-trained language models demonstrate HSD's advantages in balancing efficiency and text quality. With almost half of the layers skipped, HSD can sustain 90% of the text quality compared to vanilla autoregressive decoding, outperforming the competitive approaches.",
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "authors": [
                {
                    "authorId": "2293320991",
                    "name": "Yunqi Zhu"
                },
                {
                    "authorId": "1860612",
                    "name": "Xuebing Yang"
                },
                {
                    "authorId": "2204743673",
                    "name": "Yuanyuan Wu"
                },
                {
                    "authorId": "2271172648",
                    "name": "Wensheng Zhang"
                }
            ]
        },
        {
            "paperId": "4a25db8b5ea36935c28e90fbdbfd4fb184fdebea",
            "title": "Super Resolution Graph With Conditional Normalizing Flows for Temporal Link Prediction",
            "abstract": "Temporal link prediction on dynamic graphs has attracted considerable attention. Most methods focus on the graph at each timestamp and extract features for prediction. As graphs are directly compressed into feature matrices, the important latent information at each timestamp has not been well revealed. Eventually, the acquisition of dynamic evolution-related patterns is rendered inadequately. In this paper, inspired by the process of Super-Resolution (SR), a novel deep generative model SRG (Super Resolution Graph) is proposed. We innovatively introduce the concepts of the Low-Resolution (LR) graph, which is a single adjacent matrix at a timestamp, and the High-Resolution (HR) graph, which includes the link status of surrounding snapshots. Specifically, two major aspects are considered regarding the construction of the HR graph. For edges, we endeavor to obtain an extensive information transmission description that affects the current link status. For nodes, similar to the SR process, the neighbor relationship among nodes is maintained. In this form, we could predict the link status from a new perspective: Under the supervision of the graph moving average strategy, the conditional normalizing flow effectively realizes the transformation between LR and HR graphs. Extensive experiments on six real-world datasets from different applications demonstrate the effectiveness of our proposal.",
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "authors": [
                {
                    "authorId": "2223554832",
                    "name": "Yanting Yin"
                },
                {
                    "authorId": "2107922909",
                    "name": "Yajing Wu"
                },
                {
                    "authorId": "1860612",
                    "name": "Xuebing Yang"
                },
                {
                    "authorId": "2108167911",
                    "name": "Wensheng Zhang"
                },
                {
                    "authorId": "1721029",
                    "name": "Xiaojie Yuan"
                }
            ]
        },
        {
            "paperId": "1000914d5584e25fe241b9f4edbd9e5faa615e95",
            "title": "PmcaNet: Pyramid multiscale channel attention network for electron microscopy image segmentation",
            "abstract": "Recent advances in high-throughput electron microscopy (EM) have revolutionized the examination of microstructures by enabling fast EM image generation. However, accurately segmenting EM images remains challenging due to inherent characteristics, including low contrast and subtle grayscale variations. Moreover, as manually annotated EM images are limited, it is usually impractical to utilize deep learning techniques for EM image segmentation. To address these challenges, the pyramid multiscale channel attention network (PmcaNet) is specifically designed. PmcaNet employs a convolutional neural network-based architecture and a multiscale feature pyramid to effectively capture global context information, enhancing its ability to comprehend the intricate structures within EM images. To enable the rapid extraction of channel-wise dependencies, a novel attention module is introduced to enhance the representation of intricate nonlinear features within the images. The performance of PmcaNet is evaluated on two general EM image segmentation datasets as well as a homemade dataset of superalloy materials, regarding pixel-wise accuracy and mean intersection over union (mIoU) as evaluation metrics. Extensive experiments demonstrate that PmcaNet outperforms other models on the ISBI 2012 dataset, achieving 87.85% pixel-wise accuracy and 73.11% mean intersection over union (mIoU), while also advancing results on the Kathuri and SEM-material datasets.",
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "authors": [
                {
                    "authorId": "2278093413",
                    "name": "Kaihan Gao"
                },
                {
                    "authorId": "2278049089",
                    "name": "Yiwei Ju"
                },
                {
                    "authorId": "2279021877",
                    "name": "Shuai Li"
                },
                {
                    "authorId": "1860612",
                    "name": "Xuebing Yang"
                },
                {
                    "authorId": "2108167911",
                    "name": "Wensheng Zhang"
                },
                {
                    "authorId": "2278235829",
                    "name": "Guoqing Li"
                }
            ]
        },
        {
            "paperId": "17330c07a59b9dfb6cb01612c4b8be8841735396",
            "title": "Leveraging Summary Guidance on Medical Report Summarization",
            "abstract": "This study presents three deidentified large medical text datasets, named DISCHARGE, ECHO and RADIOLOGY, which contain 50 K, 16 K and 378 K pairs of report and summary that are derived from MIMIC-III, respectively. We implement convincing baselines of automated abstractive summarization on the created datasets with pre-trained encoder-decoder language models, including BERT2BERT, BERTShare, RoBERTaShare, Pegasus, ProphetNet, T5-large, BART and GSUM. Further, based on the BART model, we leverage the sampled summaries from the training set as prior knowledge guidance, for encoding additional contextual representations of the guidance with the encoder and enhancing the decoding representations in the decoder. The experimental results confirm the improvement of ROUGE scores and BERTScore made by the proposed method.",
            "fieldsOfStudy": [
                "Computer Science",
                "Medicine"
            ],
            "authors": [
                {
                    "authorId": "5878432",
                    "name": "Yunqi Zhu"
                },
                {
                    "authorId": "1860612",
                    "name": "Xuebing Yang"
                },
                {
                    "authorId": "2204743673",
                    "name": "Yuanyuan Wu"
                },
                {
                    "authorId": "2108167911",
                    "name": "Wensheng Zhang"
                }
            ]
        },
        {
            "paperId": "6178c99328984452551b0356b64d048d341b9a9e",
            "title": "Parameter-Efficient Fine-Tuning with Layer Pruning on Free-Text Sequence-to-Sequence Modeling",
            "abstract": "The increasing size of language models raises great research interests in parameter-efficient fine-tuning such as LoRA that freezes the pre-trained model, and injects small-scale trainable parameters for multiple downstream tasks (e.g., summarization, question answering and translation). To further enhance the efficiency of fine-tuning, we propose a framework that integrates LoRA and structured layer pruning. The integrated framework is validated on two created deidentified medical report summarization datasets based on MIMIC-IV-Note and two public medical dialogue datasets. By tuning 0.6% parameters of the original model and pruning over 30% Transformer-layers, our framework can reduce 50% of GPU memory usage and speed up 100% of the training phase, while preserving over 92% generation qualities on free-text sequence-to-sequence tasks.",
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "authors": [
                {
                    "authorId": "145350978",
                    "name": "Y. Zhu"
                },
                {
                    "authorId": "1860612",
                    "name": "Xuebing Yang"
                },
                {
                    "authorId": "2204743673",
                    "name": "Yuanyuan Wu"
                },
                {
                    "authorId": "2108167911",
                    "name": "Wensheng Zhang"
                }
            ]
        },
        {
            "paperId": "0ebd08e4922082723816cbf34269367301d1ec08",
            "title": "SE-GRU: Structure Embedded Gated Recurrent Unit Neural Networks for Temporal Link Prediction",
            "abstract": "Temporal link prediction on dynamic graphs is essential to various areas such as recommendation systems, social networks, and citation analysis, and thus attracts great attention in both research and industry fields. For complex graphs in real-world applications, although recent temporal link prediction methods perform well in predicting high-frequency and nearby connections, it becomes more challenging when considering low-frequency and earlier connections. In this work, we introduce a novel and elegant prediction architecture called Structure Embedded Gated Recurrent Unit (SE-GRU) neural networks, to strengthen the prediction robustness against frequency variation and occurrence delay of connections. The established SE-GRU embeds the structure for local topological characteristics to emphasize the different connection frequencies between nodes and captures the temporal dependencies to avoid losing valuable information caused by long-term changes. We realize neural network optimization considering three terms concerning reconstruction, structure, and evolution. The extensive experiments performed on three public datasets demonstrate the significant superiority of SE-GRU compared with 5 representative and state-of-the-art competitors under three evaluation metrics. The results validate the effectiveness and robustness of our proposed method, by showing that the frequencies and timestamps of connections have a little-to-no negative impact on prediction accuracy.",
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "authors": [
                {
                    "authorId": "49545927",
                    "name": "Yanting Yin"
                },
                {
                    "authorId": "2107922909",
                    "name": "Yajing Wu"
                },
                {
                    "authorId": "1860612",
                    "name": "Xuebing Yang"
                },
                {
                    "authorId": "2108167911",
                    "name": "Wensheng Zhang"
                },
                {
                    "authorId": "1721029",
                    "name": "Xiaojie Yuan"
                }
            ]
        },
        {
            "paperId": "4b76cea17ef785f319a453722f202f12e5f47e12",
            "title": "Active Learning with Effective Scoring Functions for Semi-Supervised Temporal Action Localization",
            "abstract": "Temporal Action Localization (TAL) aims to predict both action category and temporal boundary of action instances in untrimmed videos, i.e., start and end time. Fully-supervised solutions are usually adopted in most existing works, and proven to be effective. One of the practical bottlenecks in these solutions is the large amount of labeled training data required. To reduce expensive human label cost, this paper focuses on a rarely investigated yet practical task named semi-supervised TAL and proposes an effective active learning method, named AL-STAL. We leverage four steps for actively selecting video samples with high informativeness and training the localization model, named \\emph{Train, Query, Annotate, Append}. Two scoring functions that consider the uncertainty of localization model are equipped in AL-STAL, thus facilitating the video sample rank and selection. One takes entropy of predicted label distribution as measure of uncertainty, named Temporal Proposal Entropy (TPE). And the other introduces a new metric based on mutual information between adjacent action proposals and evaluates the informativeness of video samples, named Temporal Context Inconsistency (TCI). To validate the effectiveness of proposed method, we conduct extensive experiments on two benchmark datasets THUMOS'14 and ActivityNet 1.3. Experiment results show that AL-STAL outperforms the existing competitors and achieves satisfying performance compared with fully-supervised learning.",
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "authors": [
                {
                    "authorId": "2109153420",
                    "name": "Ding Li"
                },
                {
                    "authorId": "1860612",
                    "name": "Xuebing Yang"
                },
                {
                    "authorId": "2111321753",
                    "name": "Yongqiang Tang"
                },
                {
                    "authorId": "2124944872",
                    "name": "Chenyang Zhang"
                },
                {
                    "authorId": "2108167911",
                    "name": "Wensheng Zhang"
                },
                {
                    "authorId": "2149343311",
                    "name": "Lizhuang Ma"
                }
            ]
        },
        {
            "paperId": "9d0660d76b3fc5a278d2bfa71855b99f13395f19",
            "title": "Inductive Spatiotemporal Graph Convolutional Networks for Short-term Quantitative Precipitation Forecasting",
            "abstract": "Short-term Quantitative Precipitation Forecasting (SQPF) using weather radar is an important but challenging problem as one must cope with inherent nonlinearity and spatiotemporal correlation in the data. In this paper, we propose a novel deep learning model, named Inductive spatiotemporal Graph Convolutional Networks (InstGCN), to overcome these issues in SQPF. The proposed InstGCN can learn a nonlinear mapping from historical radar reflectivity to future rainfall amounts, and extract informative spatiotemporal representations simultaneously. Specifically, we first provide a formal definition for formulating the SQPF problem from a graph perspective. Then, based on radar reflectivity and rain gauge observation, we propose a novel graph construction approach which utilizes a special elliptic structure to model the spatial dependency of precipitation area. Additionally, a new Node level Differential Block (Node-DB) is introduced to tackle the non-stationary temporal dependency. To execute inductive graph learning for unseen nodes, we design to decompose a whole graph into sub-graphs. We conduct extensive experiments on three real-world datasets in East China and a public weather radar dataset in the south-eastern parts of France. The experimental results confirm the advantages of InstGCN compared with several state-of-the-arts.",
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "authors": [
                {
                    "authorId": "2107922909",
                    "name": "Yajing Wu"
                },
                {
                    "authorId": "1860612",
                    "name": "Xuebing Yang"
                },
                {
                    "authorId": "2111321753",
                    "name": "Yongqiang Tang"
                },
                {
                    "authorId": "2124944872",
                    "name": "Chenyang Zhang"
                },
                {
                    "authorId": "2127722396",
                    "name": "Guoping Zhang"
                },
                {
                    "authorId": "2108167911",
                    "name": "Wensheng Zhang"
                }
            ]
        },
        {
            "paperId": "a7706692ae449169230df1f34cdc9b4d33a54897",
            "title": "Classifying Clear Air Echoes via Static and Motion Streams Network",
            "abstract": "Classification of nonprecipitation echoes of radar is an inevitable step in radar-based precipitation estimation. Among nonprecipitation echoes, clear air echoes are specifically difficult to distinguish for their similarity to precipitation echoes. This letter aims to conduct a pixelwise classification of clear air echoes for image sequences of the radar reflectivity. We propose the Static and Motion streams Network (SMNet) to simultaneously utilize the static and motion features. SMNet realizes capturing the spatiotemporal characteristics while maintaining the details of the current frame via a fusion structure and a novel training method. For feature fusion, the static and motion streams are concatenated. Then, for model training, we adopt a dynamic weight assignment strategy to further extract rich information. Finally, we validate our method on an S-band single-polarization radar in Beijing, China, from May to September 2018. The results demonstrate that the overall performance of SMNet is superior to other competitors.",
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "authors": [
                {
                    "authorId": "2147288303",
                    "name": "Yuxun Qu"
                },
                {
                    "authorId": "2124944872",
                    "name": "Chenyang Zhang"
                },
                {
                    "authorId": "1860612",
                    "name": "Xuebing Yang"
                },
                {
                    "authorId": "2107922909",
                    "name": "Yajing Wu"
                },
                {
                    "authorId": "39123575",
                    "name": "Wensheng Zhang"
                },
                {
                    "authorId": "46266468",
                    "name": "Guoping Zhang"
                }
            ]
        },
        {
            "paperId": "237c6c9c28d14365688067f97c6499c356e42aef",
            "title": "Graph Convolutional Regression Networks for Quantitative Precipitation Estimation",
            "abstract": "Accurate and high-resolution quantitative precipitation estimation (QPE) plays a crucial role in meteorology and hydrology. However, for acquiring a more accurate QPE, how to depict the complex nonlinear relationship between the radar reflectivity and the true rain rates, as well as adaptively explore the spatial dependencies of precipitation, remains extremely challenging. In this letter, we propose to incorporate the merits of graph convolutional regression networks (GCRNs) and address the aforementioned issues simultaneously in the GCRNs framework. Furthermore, in order to tolerate the variabilities of spatial correlation in the practical precipitation, we expand GCRNs with a multiconvolutional mechanism between the center node and its neighbor rain gauges. Thus, the ability to capture more complicated spatial characteristics of precipitation can be enhanced, and the phenomenon of overwhelming by the neighbor nodes can be released. Extensive experiments were implemented on 12 rainfall processes in Hangzhou, China, 2015. The experimental results confirm that our proposal consistently outperforms the state-of-the-art QPE models.",
            "fieldsOfStudy": [
                "Mathematics",
                "Computer Science"
            ],
            "authors": [
                {
                    "authorId": "2107922909",
                    "name": "Yajing Wu"
                },
                {
                    "authorId": "2111321753",
                    "name": "Yongqiang Tang"
                },
                {
                    "authorId": "1860612",
                    "name": "Xuebing Yang"
                },
                {
                    "authorId": "39123575",
                    "name": "Wensheng Zhang"
                },
                {
                    "authorId": "46266468",
                    "name": "Guoping Zhang"
                }
            ]
        }
    ]
}