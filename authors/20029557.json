{
    "authorId": "20029557",
    "papers": [
        {
            "paperId": "13cc7cb462d3146cbc35ccb128f66609c788a96a",
            "title": "Multi-Task Recommendations with Reinforcement Learning",
            "abstract": "In recent years, Multi-task Learning (MTL) has yielded immense success in Recommender System (RS) applications [40]. However, current MTL-based recommendation models tend to disregard the session-wise patterns of user-item interactions because they are predominantly constructed based on item-wise datasets. Moreover, balancing multiple objectives has always been a challenge in this field, which is typically avoided via linear estimations in existing works. To address these issues, in this paper, we propose a Reinforcement Learning (RL) enhanced MTL framework, namely RMTL, to combine the losses of different recommendation tasks using dynamic weights. To be specific, the RMTL structure can address the two aforementioned issues by (i) constructing an MTL environment from session-wise interactions and (ii) training multi-task actor-critic network structure, which is compatible with most existing MTL-based recommendation models, and (iii) optimizing and fine-tuning the MTL loss function using the weights generated by critic networks. Experiments on two real-world public datasets demonstrate the effectiveness of RMTL with a higher AUC against state-of-the-art MTL-based recommendation models. Additionally, we evaluate and validate RMTL\u2019s compatibility and transferability across various MTL models.",
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "authors": [
                {
                    "authorId": "2204700561",
                    "name": "Ziru Liu"
                },
                {
                    "authorId": "2204719513",
                    "name": "Jiejie Tian"
                },
                {
                    "authorId": "144994208",
                    "name": "Qingpeng Cai"
                },
                {
                    "authorId": "2116711669",
                    "name": "Xiangyu Zhao"
                },
                {
                    "authorId": "2161309826",
                    "name": "Jingtong Gao"
                },
                {
                    "authorId": "50152132",
                    "name": "Shuchang Liu"
                },
                {
                    "authorId": "2113596993",
                    "name": "Da Chen"
                },
                {
                    "authorId": "2204642544",
                    "name": "Tonghao He"
                },
                {
                    "authorId": "2153430224",
                    "name": "Dong Zheng"
                },
                {
                    "authorId": "2061280682",
                    "name": "Peng Jiang"
                },
                {
                    "authorId": "20029557",
                    "name": "Kun Gai"
                }
            ]
        },
        {
            "paperId": "19f57c712d0a5dd47fb499aef9f76374dd5acea9",
            "title": "A Large Language Model Enhanced Conversational Recommender System",
            "abstract": "Conversational recommender systems (CRSs) aim to recommend high-quality items to users through a dialogue interface. It usually contains multiple sub-tasks, such as user preference elicitation, recommendation, explanation, and item information search. To develop effective CRSs, there are some challenges: 1) how to properly manage sub-tasks; 2) how to effectively solve different sub-tasks; and 3) how to correctly generate responses that interact with users. Recently, Large Language Models (LLMs) have exhibited an unprecedented ability to reason and generate, presenting a new opportunity to develop more powerful CRSs. In this work, we propose a new LLM-based CRS, referred to as LLMCRS, to address the above challenges. For sub-task management, we leverage the reasoning ability of LLM to effectively manage sub-task. For sub-task solving, we collaborate LLM with expert models of different sub-tasks to achieve the enhanced performance. For response generation, we utilize the generation ability of LLM as a language interface to better interact with users. Specifically, LLMCRS divides the workflow into four stages: sub-task detection, model matching, sub-task execution, and response generation. LLMCRS also designs schema-based instruction, demonstration-based instruction, dynamic sub-task and model matching, and summary-based generation to instruct LLM to generate desired results in the workflow. Finally, to adapt LLM to conversational recommendations, we also propose to fine-tune LLM with reinforcement learning from CRSs performance feedback, referred to as RLPF. Experimental results on benchmark datasets show that LLMCRS with RLPF outperforms the existing methods.",
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "authors": [
                {
                    "authorId": "2047904135",
                    "name": "Yue Feng"
                },
                {
                    "authorId": "50152132",
                    "name": "Shuchang Liu"
                },
                {
                    "authorId": "2093481204",
                    "name": "Zhenghai Xue"
                },
                {
                    "authorId": "144994208",
                    "name": "Qingpeng Cai"
                },
                {
                    "authorId": "2191842",
                    "name": "Lantao Hu"
                },
                {
                    "authorId": "2061280682",
                    "name": "Peng Jiang"
                },
                {
                    "authorId": "20029557",
                    "name": "Kun Gai"
                },
                {
                    "authorId": "143770118",
                    "name": "Fei Sun"
                }
            ]
        },
        {
            "paperId": "1b2740ab1d21afb2bb1176c50344cf428f213e2b",
            "title": "Understanding and Modeling Passive-Negative Feedback for Short-video Sequential Recommendation",
            "abstract": "Sequential recommendation is one of the most important tasks in recommender systems, which aims to recommend the next interacted item with historical behaviors as input. Traditional sequential recommendation always mainly considers the collected positive feedback such as click, purchase, etc. However, in short-video platforms such as TikTok, video viewing behavior may not always represent positive feedback. Specifically, the videos are played automatically, and users passively receive the recommended videos. In this new scenario, users passively express negative feedback by skipping over videos they do not like, which provides valuable information about their preferences. Different from the negative feedback studied in traditional recommender systems, this passive-negative feedback can reflect users\u2019 interests and serve as an important supervision signal in extracting users\u2019 preferences. Therefore, it is essential to carefully design and utilize it in this novel recommendation scenario. In this work, we first conduct analyses based on a large-scale real-world short-video behavior dataset and illustrate the significance of leveraging passive feedback. We then propose a novel method that deploys the sub-interest encoder, which incorporates positive feedback and passive-negative feedback as supervision signals to learn the user\u2019s current active sub-interest. Moreover, we introduce an adaptive fusion layer to integrate various sub-interests effectively. To enhance the robustness of our model, we then introduce a multi-task learning module to simultaneously optimize two kinds of feedback \u2013 passive-negative feedback and traditional randomly-sampled negative feedback. The experiments on two large-scale datasets verify that the proposed method can significantly outperform state-of-the-art approaches. The code is released at https://github.com/tsinghua-fib-lab/RecSys2023-SINE to benefit the community.",
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "authors": [
                {
                    "authorId": "2111417074",
                    "name": "Yunzhu Pan"
                },
                {
                    "authorId": "49281242",
                    "name": "Chen Gao"
                },
                {
                    "authorId": "2630544",
                    "name": "Jianxin Chang"
                },
                {
                    "authorId": "2056580600",
                    "name": "Yanan Niu"
                },
                {
                    "authorId": "2157996254",
                    "name": "Yang Song"
                },
                {
                    "authorId": "20029557",
                    "name": "Kun Gai"
                },
                {
                    "authorId": "49953590",
                    "name": "Depeng Jin"
                },
                {
                    "authorId": "2154403926",
                    "name": "Yong Li"
                }
            ]
        },
        {
            "paperId": "277797fee15cd21d0db75f00dceb1cf092f83bde",
            "title": "Multi-behavior Self-supervised Learning for Recommendation",
            "abstract": "Modern recommender systems often deal with a variety of user interactions, e.g., click, forward, purchase, etc., which requires the underlying recommender engines to fully understand and leverage multi-behavior data from users. Despite recent efforts towards making use of heterogeneous data, multi-behavior recommendation still faces great challenges. Firstly, sparse target signals and noisy auxiliary interactions remain an issue. Secondly, existing methods utilizing self-supervised learning (SSL) to tackle the data sparsity neglect the serious optimization imbalance between the SSL task and the target task. Hence, we propose a Multi-Behavior Self-Supervised Learning (MBSSL) framework together with an adaptive optimization method. Specifically, we devise a behavior-aware graph neural network incorporating the self-attention mechanism to capture behavior multiplicity and dependencies. To increase the robustness to data sparsity under the target behavior and noisy interactions from auxiliary behaviors, we propose a novel self-supervised learning paradigm to conduct node self-discrimination at both inter-behavior and intra-behavior levels. In addition, we develop a customized optimization strategy through hybrid manipulation on gradients to adaptively balance the self-supervised learning task and the main supervised recommendation task. Extensive experiments on five real-world datasets demonstrate the consistent improvements obtained by MBSSL over ten state-of-the-art (SOTA) baselines. We release our model implementation at: https://github.com/Scofield666/MBSSL.git.",
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "authors": [
                {
                    "authorId": "2180607307",
                    "name": "Jingcao Xu"
                },
                {
                    "authorId": "121900345",
                    "name": "Chaokun Wang"
                },
                {
                    "authorId": "2151102586",
                    "name": "Cheng Wu"
                },
                {
                    "authorId": "2157996254",
                    "name": "Yang Song"
                },
                {
                    "authorId": "2052687617",
                    "name": "Kai Zheng"
                },
                {
                    "authorId": "2218644324",
                    "name": "Xiaowei Wang"
                },
                {
                    "authorId": "35656765",
                    "name": "Changping Wang"
                },
                {
                    "authorId": "35066946",
                    "name": "Guorui Zhou"
                },
                {
                    "authorId": "20029557",
                    "name": "Kun Gai"
                }
            ]
        },
        {
            "paperId": "5197996cb586157dc7f5a7a8bd12c2f0b1377228",
            "title": "Reinforcing User Retention in a Billion Scale Short Video Recommender System",
            "abstract": "Recently, short video platforms have achieved rapid user growth by recommending interesting content to users. The objective of the recommendation is to optimize user retention, thereby driving the growth of DAU (Daily Active Users). Retention is a long-term feedback after multiple interactions of users and the system, and it is hard to decompose retention reward to each item or a list of items. Thus traditional point-wise and list-wise models are not able to optimize retention. In this paper, we choose reinforcement learning methods to optimize the retention as they are designed to maximize the long-term performance. We formulate the problem as an infinite-horizon request-based Markov Decision Process, and our objective is to minimize the accumulated time interval of multiple sessions, which is equal to improving the app open frequency and user retention. However, current reinforcement learning algorithms can not be directly applied in this setting due to uncertainty, bias, and long delay time incurred by the properties of user retention. We propose a novel method, dubbed RLUR, to address the aforementioned challenges. Both offline and live experiments show that RLUR can significantly improve user retention. RLUR has been fully launched in Kuaishou app for a long time, and achieves consistent performance improvement on user retention and DAU.",
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "authors": [
                {
                    "authorId": "144994208",
                    "name": "Qingpeng Cai"
                },
                {
                    "authorId": "50152132",
                    "name": "Shuchang Liu"
                },
                {
                    "authorId": "2170467924",
                    "name": "Xueliang Wang"
                },
                {
                    "authorId": "2204463122",
                    "name": "Tianyou Zuo"
                },
                {
                    "authorId": "2204463602",
                    "name": "Wentao Xie"
                },
                {
                    "authorId": "2118582559",
                    "name": "Bin Yang"
                },
                {
                    "authorId": "2153430224",
                    "name": "Dong Zheng"
                },
                {
                    "authorId": "2061280682",
                    "name": "Peng Jiang"
                },
                {
                    "authorId": "20029557",
                    "name": "Kun Gai"
                }
            ]
        },
        {
            "paperId": "5b9d865f2e8b1e421f42b0d8ca9c85538744bc2d",
            "title": "Exploration and Regularization of the Latent Action Space in Recommendation",
            "abstract": "In recommender systems, reinforcement learning solutions have effectively boosted recommendation performance because of their ability to capture long-term user-system interaction. However, the action space of the recommendation policy is a list of items, which could be extremely large with a dynamic candidate item pool. To overcome this challenge, we propose a hyper-actor and critic learning framework where the policy decomposes the item list generation process into a hyper-action inference step and an effect-action selection step. The first step maps the given state space into a vectorized hyper-action space, and the second step selects the item list based on the hyper-action. In order to regulate the discrepancy between the two action spaces, we design an alignment module along with a kernel mapping function for items to ensure inference accuracy and include a supervision module to stabilize the learning process. We build simulated environments on public datasets and empirically show that our framework is superior in recommendation compared to standard RL baselines.",
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "authors": [
                {
                    "authorId": "50152132",
                    "name": "Shuchang Liu"
                },
                {
                    "authorId": "144994208",
                    "name": "Qingpeng Cai"
                },
                {
                    "authorId": "2020121737",
                    "name": "Bowen Sun"
                },
                {
                    "authorId": "2185248657",
                    "name": "Yuhao Wang"
                },
                {
                    "authorId": "2218282111",
                    "name": "Jiadi Jiang"
                },
                {
                    "authorId": "2153430224",
                    "name": "Dong Zheng"
                },
                {
                    "authorId": "20029557",
                    "name": "Kun Gai"
                },
                {
                    "authorId": "2061280682",
                    "name": "Peng Jiang"
                },
                {
                    "authorId": "2116711312",
                    "name": "Xiang Zhao"
                },
                {
                    "authorId": "1739818",
                    "name": "Yongfeng Zhang"
                }
            ]
        },
        {
            "paperId": "6ca1057501f8c2ac06d068cf9f1a8a984f87f60f",
            "title": "Two-Stage Constrained Actor-Critic for Short Video Recommendation",
            "abstract": "The wide popularity of short videos on social media poses new opportunities and challenges to optimize recommender systems on the video-sharing platforms. Users sequentially interact with the system and provide complex and multi-faceted responses, including WatchTime and various types of interactions with multiple videos. On the one hand, the platforms aim at optimizing the users\u2019 cumulative WatchTime (main goal) in the long term, which can be effectively optimized by Reinforcement Learning. On the other hand, the platforms also need to satisfy the constraint of accommodating the responses of multiple user interactions (auxiliary goals) such as Like, Follow, Share, etc. In this paper, we formulate the problem of short video recommendation as a Constrained Markov Decision Process (CMDP). We find that traditional constrained reinforcement learning algorithms fail to work well in this setting. We propose a novel two-stage constrained actor-critic method: At stage one, we learn individual policies to optimize each auxiliary signal. In stage two, we learn a policy to (i) optimize the main signal and (ii) stay close to policies learned in the first stage, which effectively guarantees the performance of this main policy on the auxiliaries. Through extensive offline evaluations, we demonstrate the effectiveness of our method over alternatives in both optimizing the main goal as well as balancing the others. We further show the advantage of our method in live experiments of short video recommendations, where it significantly outperforms other baselines in terms of both WatchTime and interactions. Our approach has been fully launched in the production system to optimize user experiences on the platform.",
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "authors": [
                {
                    "authorId": "144994208",
                    "name": "Qingpeng Cai"
                },
                {
                    "authorId": "2093481204",
                    "name": "Zhenghai Xue"
                },
                {
                    "authorId": "2117835555",
                    "name": "Chi Zhang"
                },
                {
                    "authorId": "2052308113",
                    "name": "Wanqi Xue"
                },
                {
                    "authorId": "50152132",
                    "name": "Shuchang Liu"
                },
                {
                    "authorId": "2088873890",
                    "name": "Ruohan Zhan"
                },
                {
                    "authorId": "2170467924",
                    "name": "Xueliang Wang"
                },
                {
                    "authorId": "2204463122",
                    "name": "Tianyou Zuo"
                },
                {
                    "authorId": "2204463602",
                    "name": "Wentao Xie"
                },
                {
                    "authorId": "2153430224",
                    "name": "Dong Zheng"
                },
                {
                    "authorId": "2061280682",
                    "name": "Peng Jiang"
                },
                {
                    "authorId": "20029557",
                    "name": "Kun Gai"
                }
            ]
        },
        {
            "paperId": "7d9185004276381ab00bb08fd25bac16fc53736a",
            "title": "Divide and Conquer: Towards Better Embedding-based Retrieval for Recommender Systems from a Multi-task Perspective",
            "abstract": "Embedding-based retrieval (EBR) methods are widely used in modern recommender systems thanks to its simplicity and effectiveness. However, along the journey of deploying and iterating on EBR in production, we still identify some fundamental issues in existing methods. First, when dealing with large corpus of candidate items, EBR models often have difficulties in balancing the performance on distinguishing highly relevant items (positives) from both irrelevant ones (easy negatives) and from somewhat related yet not competitive ones (hard negatives). Also, we have little control in the diversity and fairness of the retrieval results because of the \u201cgreedy\u201d nature of nearest vector search. These issues compromise the performance of EBR methods in large-scale industrial scenarios. This paper introduces a simple and proven-in-production solution to overcome these issues. The proposed solution takes a divide-and-conquer approach: the whole set of candidate items are divided into multiple clusters and we run EBR to retrieve relevant candidates from each cluster in parallel; top candidates from each cluster are then combined by some controllable merging strategies. This approach allows our EBR models to only concentrate on discriminating positives from mostly hard negatives. It also enables further improvement from a multi-tasking learning (MTL) perspective: retrieval problems within each cluster can be regarded as individual tasks; inspired by recent successes in prompting and prefix-tuning, we propose an efficient task adaption technique further boosting the retrieval performance within each cluster with negligible overheads. The presented solution has been deployed in Kuaishou, one of the most popular short-video streaming platforms in China with hundreds of millions of active users.",
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "authors": [
                {
                    "authorId": "49889831",
                    "name": "Yuan Zhang"
                },
                {
                    "authorId": "2204669948",
                    "name": "Xue Dong"
                },
                {
                    "authorId": "2051321269",
                    "name": "Wei Ding"
                },
                {
                    "authorId": "2156072391",
                    "name": "Biao Li"
                },
                {
                    "authorId": "2061280682",
                    "name": "Peng Jiang"
                },
                {
                    "authorId": "20029557",
                    "name": "Kun Gai"
                }
            ]
        },
        {
            "paperId": "81cc2738cf574b015e6bf7b1129dfdc7a748b453",
            "title": "Disentangled Causal Embedding With Contrastive Learning For Recommender System",
            "abstract": "Recommender systems usually rely on observed user interaction data to build personalized recommendation models, assuming that the observed data reflect user interest. However, user interacting with an item may also due to conformity, the need to follow popular items. Most previous studies neglect user\u2019s conformity and entangle interest with it, which may cause the recommender systems fail to provide satisfying results. Therefore, from the cause-effect view, disentangling these interaction causes is a crucial issue. It also contributes to OOD problems, where training and test data are out-of-distribution. Nevertheless, it is quite challenging as we lack the signal to differentiate interest and conformity. The data sparsity of pure cause and the items\u2019 long-tail problem hinder disentangled causal embedding. In this paper, we propose DCCL, a framework that adopts contrastive learning to disentangle these two causes by sample augmentation for interest and conformity respectively. Futhermore, DCCL is model-agnostic, which can be easily deployed in any industrial online system. Extensive experiments are conducted over two real-world datasets and DCCL outperforms state-of-the-art baselines on top of various backbone models in various OOD environments. We also demonstrate the performance improvements by online A/B testing on Kuaishou, a billion-user scale short-video recommender system.",
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "authors": [
                {
                    "authorId": "49260883",
                    "name": "Weiqi Zhao"
                },
                {
                    "authorId": "51290435",
                    "name": "Dianjuan Tang"
                },
                {
                    "authorId": "2145231152",
                    "name": "Xin Chen"
                },
                {
                    "authorId": "2204646172",
                    "name": "Dawei Lv"
                },
                {
                    "authorId": "2008289004",
                    "name": "Daoli Ou"
                },
                {
                    "authorId": "2156072391",
                    "name": "Biao Li"
                },
                {
                    "authorId": "2061281682",
                    "name": "P. Jiang"
                },
                {
                    "authorId": "20029557",
                    "name": "Kun Gai"
                }
            ]
        },
        {
            "paperId": "8b6a7caa792665e7b383a44188286187270cab20",
            "title": "Graph Contrastive Learning with Generative Adversarial Network",
            "abstract": "Graph Neural Networks (GNNs) have demonstrated promising results on exploiting node representations for many downstream tasks through supervised end-to-end training. To deal with the widespread label scarcity issue in real-world applications, Graph Contrastive Learning (GCL) is leveraged to train GNNs with limited or even no labels by maximizing the mutual information between nodes in its augmented views generated from the original graph. However, the distribution of graphs remains unconsidered in view generation, resulting in the ignorance of unseen edges in most existing literature, which is empirically shown to be able to improve GCL's performance in our experiments. To this end, we propose to incorporate graph generative adversarial networks (GANs) to learn the distribution of views for GCL, in order to i) automatically capture the characteristic of graphs for augmentations, and ii) jointly train the graph GAN model and the GCL model. Specifically, we present GACN, a novel Generative Adversarial Contrastive learning Network for graph representation learning. GACN develops a view generator and a view discriminator to generate augmented views automatically in an adversarial style. Then, GACN leverages these views to train a GNN encoder with two carefully designed self-supervised learning losses, including the graph contrastive loss and the Bayesian personalized ranking Loss. Furthermore, we design an optimization framework to train all GACN modules jointly. Extensive experiments on seven real-world datasets show that GACN is able to generate high-quality augmented views for GCL and is superior to twelve state-of-the-art baseline methods. Noticeably, our proposed GACN surprisingly discovers that the generated views in data augmentation finally conform to the well-known preferential attachment rule in online networks.",
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "authors": [
                {
                    "authorId": "2151102586",
                    "name": "Cheng Wu"
                },
                {
                    "authorId": "2135743383",
                    "name": "Chao-Hong Wang"
                },
                {
                    "authorId": "2180607307",
                    "name": "Jingcao Xu"
                },
                {
                    "authorId": "2117941439",
                    "name": "Ziyang Liu"
                },
                {
                    "authorId": "145487536",
                    "name": "Kai Zheng"
                },
                {
                    "authorId": "2218644324",
                    "name": "Xiaowei Wang"
                },
                {
                    "authorId": "144404428",
                    "name": "Yang Song"
                },
                {
                    "authorId": "20029557",
                    "name": "Kun Gai"
                }
            ]
        }
    ]
}