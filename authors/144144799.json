{
    "authorId": "144144799",
    "papers": [
        {
            "paperId": "5fa230579616993cb25c40aac4ed265f745c2926",
            "title": "Saliency-Aware Interpolative Augmentation for Multimodal Financial Prediction",
            "abstract": "Predicting price variations of financial instruments for risk modeling and stock trading is challenging due to the stochastic nature of the stock market. While recent advancements in the Financial AI realm have expanded the scope of data and methods they use, such as textual and audio cues from financial earnings calls, limitations exist. Most datasets are small, and show domain distribution shifts due to the nature of their source, suggesting the exploration for data augmentation for robust augmentation strategies such as Mixup. To tackle such challenges in the financial domain, we propose SH-Mix: Saliency-guided Hierarchical Mixup augmentation technique for multimodal financial prediction tasks. SH-Mix combines multi-level embedding mixup strategies based on the contribution of each modality and context subsequences. Through extensive quantitative and qualitative experiments on financial earnings and conference call datasets consisting of text and speech, we show that SH-Mix outperforms state-of-the-art methods by 3-7%. Additionally, we show that SH-Mix is generalizable across different modalities and models.",
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "authors": [
                {
                    "authorId": "2302368303",
                    "name": "Samyak Jain"
                },
                {
                    "authorId": "2186676914",
                    "name": "Parth Chhabra"
                },
                {
                    "authorId": "2157860264",
                    "name": "A. Neerkaje"
                },
                {
                    "authorId": "144144799",
                    "name": "Puneet Mathur"
                },
                {
                    "authorId": "51042088",
                    "name": "Ramit Sawhney"
                },
                {
                    "authorId": "1923351",
                    "name": "Shivam Agarwal"
                },
                {
                    "authorId": "2026545715",
                    "name": "Preslav Nakov"
                },
                {
                    "authorId": "2275117",
                    "name": "S. Chava"
                },
                {
                    "authorId": "2273677165",
                    "name": "Dinesh Manocha"
                }
            ]
        },
        {
            "paperId": "846768c90137ecbf08ab6630bb894bb349096bc3",
            "title": "DocSynthv2: A Practical Autoregressive Modeling for Document Generation",
            "abstract": "While the generation of document layouts has been extensively explored, comprehensive document generation encompassing both layout and content presents a more complex challenge. This paper delves into this advanced domain, proposing a novel approach called DocSynthv2 through the development of a simple yet effective autoregressive structured model. Our model, distinct in its integration of both layout and textual cues, marks a step beyond existing layout-generation approaches. By focusing on the relationship between the structural elements and the textual content within documents, we aim to generate cohesive and contextually relevant documents without any reliance on visual components. Through experimental studies on our curated benchmark for the new task, we demonstrate the ability of our model combining layout and textual information in enhancing the generation quality and relevance of documents, opening new pathways for research in document creation and automated design. Our findings emphasize the effectiveness of autoregressive models in handling complex document generation tasks.",
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "authors": [
                {
                    "authorId": "2150473007",
                    "name": "Sanket Biswas"
                },
                {
                    "authorId": "39878379",
                    "name": "R. Jain"
                },
                {
                    "authorId": "2852035",
                    "name": "Vlad I. Morariu"
                },
                {
                    "authorId": "2274190457",
                    "name": "Jiuxiang Gu"
                },
                {
                    "authorId": "144144799",
                    "name": "Puneet Mathur"
                },
                {
                    "authorId": "26360698",
                    "name": "Curtis Wigington"
                },
                {
                    "authorId": "2190051546",
                    "name": "Tongfei Sun"
                },
                {
                    "authorId": "2305681954",
                    "name": "Josep Llad'os"
                }
            ]
        },
        {
            "paperId": "b3795d73cadfacfb6aa0f723978915012070a3d5",
            "title": "DocScript: Document-level Script Event Prediction",
            "abstract": "We present a novel task of document-level script event prediction, which aims to predict the next event given a candidate list of narrative events in long-form documents. To enable this, we introduce DocSEP, a challenging dataset in two new domains - contractual documents and Wikipedia articles, where timeline events may be paragraphs apart and may require multi-hop temporal and causal reasoning. We benchmark existing baselines and present a novel architecture called DocScript to learn sequential ordering between events at the document scale. Our experimental results on the DocSEP dataset demonstrate that learning longer-range dependencies between events is a key challenge and show that contemporary LLMs such as ChatGPT and FlanT5 struggle to solve this task, indicating their lack of reasoning abilities for understanding causal relationships and temporal sequences within long texts.",
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "authors": [
                {
                    "authorId": "144144799",
                    "name": "Puneet Mathur"
                },
                {
                    "authorId": "2852035",
                    "name": "Vlad I. Morariu"
                },
                {
                    "authorId": "31099365",
                    "name": "Aparna Garimella"
                },
                {
                    "authorId": "2301580599",
                    "name": "Franck Dernoncourt"
                },
                {
                    "authorId": "2274190457",
                    "name": "Jiuxiang Gu"
                },
                {
                    "authorId": "51042088",
                    "name": "Ramit Sawhney"
                },
                {
                    "authorId": "2026545715",
                    "name": "Preslav Nakov"
                },
                {
                    "authorId": "2273677165",
                    "name": "Dinesh Manocha"
                },
                {
                    "authorId": "39878379",
                    "name": "R. Jain"
                }
            ]
        },
        {
            "paperId": "db493c98fc87a53f8e74d54f18fb834611af1218",
            "title": "DOC-RAG: ASR Language Model Personalization with Domain-Distributed Co-occurrence Retrieval Augmentation",
            "abstract": "We propose DOC-RAG - Domain-distributed Co-occurrence Retrieval Augmentation for ASR language model personalization aiming to improve the automatic speech recognition of rare word patterns in unseen domains. Our approach involves contrastively training a document retrieval module to rank external knowledge domains based on their semantic similarity with respect to the input query. We further use n-gram co-occurrence distribution to recognize rare word patterns associated with specific domains. We aggregate the next word probability distribution based on the relative importance of different domains. Extensive experiments on three user-specific speech-to-text tasks for meetings, TED talks, and financial earnings calls show that DOC-RAG significantly outperforms strong baselines with an 8-15% improvement in terms of perplexity and a 4-7% reduction in terms of Word Error Rates in various settings.",
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "authors": [
                {
                    "authorId": "144144799",
                    "name": "Puneet Mathur"
                },
                {
                    "authorId": "2273747531",
                    "name": "Zhe Liu"
                },
                {
                    "authorId": "2274075466",
                    "name": "Ke Li"
                },
                {
                    "authorId": "2237981926",
                    "name": "Yingyi Ma"
                },
                {
                    "authorId": "2301578834",
                    "name": "Gil Karen"
                },
                {
                    "authorId": "2237806751",
                    "name": "Zeeshan Ahmed"
                },
                {
                    "authorId": "2273677165",
                    "name": "Dinesh Manocha"
                },
                {
                    "authorId": "2264766048",
                    "name": "Xuedong Zhang"
                }
            ]
        },
        {
            "paperId": "383db93b039c2f7d743a06dc62a8db2ff1ea33f7",
            "title": "DocEdit: Language-Guided Document Editing",
            "abstract": "Professional document editing tools require a certain level of expertise to perform complex edit operations. To make editing tools accessible to increasingly novice users, we investigate intelligent document assistant systems that can make or suggest edits based on a user's natural language request. Such a system should be able to understand the user's ambiguous requests and contextualize them to the visual cues and textual content found in a document image to edit localized unstructured text and structured layouts. To this end, we propose a new task of language-guided localized document editing, where the user provides a document and an open vocabulary editing request, and the intelligent system produces a command that can be used to automate edits in real-world document editing software. In support of this task, we curate the DocEdit dataset, a collection of approximately 28K instances of user edit requests over PDF and design templates along with their corresponding ground truth software executable commands. To our knowledge, this is the first dataset that provides a diverse mix of edit operations with direct and indirect references to the embedded text and visual objects such as paragraphs, lists, tables, etc. We also propose DocEditor, a Transformer-based localization-aware multimodal (textual, spatial, and visual) model that performs the new task. The model attends to both document objects and related text contents which may be referred to in a user edit request, generating a multimodal embedding that is used to predict an edit command and associated bounding box localizing it. Our proposed model empirically outperforms other baseline deep learning approaches by 15-18%, providing a strong starting point for future work.",
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "authors": [
                {
                    "authorId": "144144799",
                    "name": "Puneet Mathur"
                },
                {
                    "authorId": "39878379",
                    "name": "R. Jain"
                },
                {
                    "authorId": "2174964",
                    "name": "Jiuxiang Gu"
                },
                {
                    "authorId": "2301580599",
                    "name": "Franck Dernoncourt"
                },
                {
                    "authorId": "2172597446",
                    "name": "Dinesh Manocha"
                },
                {
                    "authorId": "2852035",
                    "name": "Vlad I. Morariu"
                }
            ]
        },
        {
            "paperId": "91ac4c094a2936c292b5dec56fd44a913f183083",
            "title": "LayerDoc: Layer-wise Extraction of Spatial Hierarchical Structure in Visually-Rich Documents",
            "abstract": "Digital documents often contain images and scanned text. Parsing such visually-rich documents is a core task for work-flow automation, but it remains challenging since most documents do not encode explicit layout information, e.g., how characters and words are grouped into boxes and ordered into larger semantic entities. Current state-of-the-art layout extraction methods are challenged by such documents as they rely on word sequences to have correct reading order and do not exploit their hierarchical structure. We propose LayerDoc, an approach that uses visual features, textual semantics, and spatial coordinates along with constraint inference to extract the hierarchical layout structure of documents in a bottom-up layer-wise fashion. LayerDoc recursively groups smaller regions into larger semantic elements in 2D to infer complex nested hierarchies. Experiments show that our approach outperforms competitive baselines by 10-15% on three diverse datasets of forms and mobile app screen layouts for the tasks of spatial region classification, higher-order group identification, layout hierarchy extraction, reading order detection, and word grouping.",
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "authors": [
                {
                    "authorId": "144144799",
                    "name": "Puneet Mathur"
                },
                {
                    "authorId": "39878379",
                    "name": "R. Jain"
                },
                {
                    "authorId": "2064021145",
                    "name": "Ashutosh Mehra"
                },
                {
                    "authorId": "2174964",
                    "name": "Jiuxiang Gu"
                },
                {
                    "authorId": "2301580599",
                    "name": "Franck Dernoncourt"
                },
                {
                    "authorId": "2101319527",
                    "name": "Anandhavelu N"
                },
                {
                    "authorId": "2536742",
                    "name": "Quan Hung Tran"
                },
                {
                    "authorId": "1419671559",
                    "name": "Verena Kaynig-Fittkau"
                },
                {
                    "authorId": "3115414",
                    "name": "A. Nenkova"
                },
                {
                    "authorId": "2172597446",
                    "name": "Dinesh Manocha"
                },
                {
                    "authorId": "2852035",
                    "name": "Vlad I. Morariu"
                }
            ]
        },
        {
            "paperId": "c2c24a87b4971243323c5887dfb613ed383bbf1f",
            "title": "PersonaLM: Language Model Personalization via Domain-distributed Span Aggregated K-Nearest N-gram Retrieval Augmentation",
            "abstract": ",",
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "authors": [
                {
                    "authorId": "144144799",
                    "name": "Puneet Mathur"
                },
                {
                    "authorId": "2273747531",
                    "name": "Zhe Liu"
                },
                {
                    "authorId": "2274075466",
                    "name": "Ke Li"
                },
                {
                    "authorId": "2237981926",
                    "name": "Yingyi Ma"
                },
                {
                    "authorId": "2273709851",
                    "name": "Gil Keren"
                },
                {
                    "authorId": "2237806751",
                    "name": "Zeeshan Ahmed"
                },
                {
                    "authorId": "2273677165",
                    "name": "Dinesh Manocha"
                },
                {
                    "authorId": "2264766048",
                    "name": "Xuedong Zhang"
                }
            ]
        },
        {
            "paperId": "04134747badf3b6991488b45de4a636d4286af0f",
            "title": "3MASSIV: Multilingual, Multimodal and Multi-Aspect dataset of Social Media Short Videos",
            "abstract": "We present 3MASSIV, a multilingual, multimodal and multi-aspect, expertly-annotated dataset of diverse short videos extracted from short-video social media platform - Moj. 3MASSIV comprises of 50k short videos (20 seconds average duration) and 100K unlabeled videos in 11 different languages and captures popular short video trends like pranks, fails, romance, comedy expressed via unique audio-visual formats like self-shot videos, reaction videos, lip-synching, self-sung songs, etc. 3MASSIV presents an opportunity for multimodal and multilingual semantic understanding on these unique videos by annotating them for concepts, affective states, media types, and audio language. We present a thorough analysis of 3MASSIV and highlight the variety and unique aspects of our dataset compared to other contemporary popular datasets with strong baselines. We also show how the social media content in 3MASSIV is dynamic and temporal in nature, which can be used for semantic understanding tasks and cross-lingual analysis.",
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "authors": [
                {
                    "authorId": "1838218557",
                    "name": "Vikram Gupta"
                },
                {
                    "authorId": "9214782",
                    "name": "Trisha Mittal"
                },
                {
                    "authorId": "144144799",
                    "name": "Puneet Mathur"
                },
                {
                    "authorId": "2057516053",
                    "name": "Vaibhav Mishra"
                },
                {
                    "authorId": "2065570165",
                    "name": "Mayank Maheshwari"
                },
                {
                    "authorId": "2718563",
                    "name": "Aniket Bera"
                },
                {
                    "authorId": "1766159",
                    "name": "Debdoot Mukherjee"
                },
                {
                    "authorId": "1699159",
                    "name": "Dinesh Manocha"
                }
            ]
        },
        {
            "paperId": "1cec3e33185a7c7e4f60cb85278320321facbc7a",
            "title": "PISA: PoIncar\u00e9 Saliency-Aware Interpolative Augmentation",
            "abstract": "Saliency-aware portion-wise mixup has proven to be an effective data augmentation technique for different modalities and tasks. However, it involves calculating the saliency over gradient vectors in the Euclidean space, representations that often possess complicated geometries and inherent hierarchical structure. We propose PISA, saliency-aware interpolative regularization operating in the hyperbolic space, to better capture the complex geometries of representations. To this end, we also formulate a saliency-aware mixup for speech signals. PISA outperforms existing state-of-the-art interpolative augmentation methods on 7 benchmark and low-resource datasets from the domains of speech signal processing and computer vision. PISA results in more stable training than existing data augmentation methods while being robust to adversarial attacks. It can be generalized across modalities, models and downstream tasks.",
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "authors": [
                {
                    "authorId": "51042088",
                    "name": "Ramit Sawhney"
                },
                {
                    "authorId": "71188587",
                    "name": "Megh Thakkar"
                },
                {
                    "authorId": "2069609589",
                    "name": "Vishwa Shah"
                },
                {
                    "authorId": "144144799",
                    "name": "Puneet Mathur"
                },
                {
                    "authorId": "144582538",
                    "name": "Vasu Sharma"
                },
                {
                    "authorId": "1699159",
                    "name": "Dinesh Manocha"
                }
            ]
        },
        {
            "paperId": "2bff94593787c47a240dc438bef1498a1f02fb2f",
            "title": "DocFin: Multimodal Financial Prediction and Bias Mitigation using Semi-structured Documents",
            "abstract": ",",
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "authors": [
                {
                    "authorId": "144144799",
                    "name": "Puneet Mathur"
                },
                {
                    "authorId": "2000936311",
                    "name": "Mihir Goyal"
                },
                {
                    "authorId": "51042088",
                    "name": "Ramit Sawhney"
                },
                {
                    "authorId": "2069834937",
                    "name": "Ritik Mathur"
                },
                {
                    "authorId": "2227049",
                    "name": "Jochen L. Leidner"
                },
                {
                    "authorId": "2301580599",
                    "name": "Franck Dernoncourt"
                },
                {
                    "authorId": "2172597446",
                    "name": "Dinesh Manocha"
                }
            ]
        }
    ]
}