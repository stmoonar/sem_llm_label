{
    "authorId": "2145031333",
    "papers": [
        {
            "paperId": "79f4bf84b817f47fa74a8b183cde7641ccfecc4f",
            "title": "Covariate-Shift Generalization via Random Sample Weighting",
            "abstract": "Shifts in the marginal distribution of covariates from training to the test phase, named covariate-shifts, often lead to unstable prediction performance across agnostic testing data, especially under model misspecification. Recent literature on invariant learning attempts to learn an invariant predictor from heterogeneous environments. However, the performance of the learned predictor depends heavily on the availability and quality of provided environments. In this paper, we propose a simple and effective non-parametric method for generating heterogeneous environments via Random Sample Weighting (RSW). Given the training dataset from a single source environment, we randomly generate a set of covariate-determining sample weights and use each weighted training distribution to simulate an environment. We theoretically show that under appropriate conditions, such random sample weighting can produce sufficient heterogeneity to be exploited by common invariance constraints to find the invariant variables for stable prediction under covariate shifts. Extensive experiments on both simulated and real-world datasets clearly validate the effectiveness of our method.",
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "authors": [
                {
                    "authorId": "2145031333",
                    "name": "Yue He"
                },
                {
                    "authorId": "2111109710",
                    "name": "Xinwei Shen"
                },
                {
                    "authorId": "150287491",
                    "name": "Renzhe Xu"
                },
                {
                    "authorId": "2117882965",
                    "name": "Tong Zhang"
                },
                {
                    "authorId": "2150036614",
                    "name": "Yong Jiang"
                },
                {
                    "authorId": "2181321465",
                    "name": "Wenchao Zou"
                },
                {
                    "authorId": "2153522384",
                    "name": "Peng Cui"
                }
            ]
        },
        {
            "paperId": "b61b1c2e5827548134b64c4095b8c3c3b1b9ed84",
            "title": "Exploring and Exploiting Data Heterogeneity in Recommendation",
            "abstract": "Massive amounts of data are the foundation of data-driven recommendation models. As an inherent nature of big data, data heterogeneity widely exists in real-world recommendation systems. It reflects the differences in the properties among sub-populations. Ignoring the heterogeneity in recommendation data could limit the performance of recommendation models, hurt the sub-populational robustness, and make the models misled by biases. However, data heterogeneity has not attracted substantial attention in the recommendation community. Therefore, it inspires us to adequately explore and exploit heterogeneity for solving the above problems and assisting data analysis. In this work, we focus on exploring two representative categories of heterogeneity in recommendation data that is the heterogeneity of prediction mechanism and covariate distribution and propose an algorithm that explores the heterogeneity through a bilevel clustering method. Furthermore, the uncovered heterogeneity is exploited for two purposes in recommendation scenarios which are prediction with multiple sub-models and supporting debias. Extensive experiments on real-world data validate the existence of heterogeneity in recommendation data and the effectiveness of exploring and exploiting data heterogeneity in recommendation.",
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "authors": [
                {
                    "authorId": "2117418792",
                    "name": "Zimu Wang"
                },
                {
                    "authorId": "2120846500",
                    "name": "Jiashuo Liu"
                },
                {
                    "authorId": "145742335",
                    "name": "Hao Zou"
                },
                {
                    "authorId": "51258901",
                    "name": "Xingxuan Zhang"
                },
                {
                    "authorId": "2145031333",
                    "name": "Yue He"
                },
                {
                    "authorId": "2218202008",
                    "name": "Dongxu Liang"
                },
                {
                    "authorId": "2153522384",
                    "name": "Peng Cui"
                }
            ]
        },
        {
            "paperId": "bd6a324709036d9b53a80a354261a9a976fa5354",
            "title": "Rethinking the Evaluation Protocol of Domain Generalization",
            "abstract": "Domain generalization aims to solve the challenge of Out-of-Distribution (OOD) generalization by leveraging common knowledge learnedfrom multiple training domains to generalize to unseen test domains. To accurately evaluate the OOD generalization ability, it is required that test data information is unavailable. However, the current domain generalization protocol may still have potential test data information leakage. This paper examines the risks of test data information leakage from two aspects of the current evaluation protocol: supervised pretraining on ImageNet and oracle model selection. We propose modifications to the current protocol that we should employ self-supervised pretraining or train from scratch instead of employing the current supervised pretraining, and we should use multiple test domains. These would result in a more precise eval-uation of OOD generalization ability. We also rerun the algorithms with the modified protocol and introduce new leaderboards to encourage future research in domain gen-eralization with a fairer comparison.",
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "authors": [
                {
                    "authorId": "2187083103",
                    "name": "Han Yu"
                },
                {
                    "authorId": "51258901",
                    "name": "Xingxuan Zhang"
                },
                {
                    "authorId": "150287491",
                    "name": "Renzhe Xu"
                },
                {
                    "authorId": "2120846500",
                    "name": "Jiashuo Liu"
                },
                {
                    "authorId": "2145031333",
                    "name": "Yue He"
                },
                {
                    "authorId": "2153522384",
                    "name": "Peng Cui"
                }
            ]
        },
        {
            "paperId": "a4858a92b99166cb8e2ffd390e01042c33f8ae83",
            "title": "Distilling Causal Metaknowledge from Knowledge Graphs",
            "abstract": "In recent years, the explosive increase of information facilitates the massive knowledge graphs, which in turn increase burden of people to understand and leverage the regularity behind these superficial facts. Therefore, the metaknowledge, defined as the knowledge about knowledge, is proposed to identify complex processes of knowledge production and consumption. Unfortunately, even though the current correlation-based rule mining methods in knowledge graph distill the rule-formed metaknowledge, they can not explain the processes of knowledge production. In this paper, we focus on capturing the metaknowledge with causality which is generally regarded as one of the most promising techniques to reveal the interactions between components in the complex system. To the best of our knowledge, this is the first attempt to interpret the knowledge graph from the causal perspective. For this purpose, we propose a causal metaknowledge method for link prediction, which achieves entity-level link prediction by discovering concept-level topological causality. Specifically, we first formalize causal metaknowledge as causal rule, following the form of logical rule. Then, we transform the relational data into propositional data to learn the causal relationships between topological structures. And an efficient algorithm for discovering local causal relationships is proposed using the d -seperation criterion. Eventually, the causal rules generated based on the mined relationships are used for link prediction. Both simulation-based and real data-based experiments demonstrate the effectiveness of the proposed approach, especially under the Out-of-Distribution(OoD) settings.",
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "authors": [
                {
                    "authorId": "2114022137",
                    "name": "Yuan Meng"
                },
                {
                    "authorId": "2153514690",
                    "name": "Yancheng Dong"
                },
                {
                    "authorId": "2208964917",
                    "name": "Shixuan Liu"
                },
                {
                    "authorId": "2208802705",
                    "name": "Chaohao Yuan"
                },
                {
                    "authorId": "2145031333",
                    "name": "Yue He"
                },
                {
                    "authorId": "2188744953",
                    "name": "Jian Pei"
                },
                {
                    "authorId": "2052469774",
                    "name": "P. Cui"
                }
            ]
        },
        {
            "paperId": "d2c6fa8a9abf6157084e1442109abe651874c620",
            "title": "Invariant Preference Learning for General Debiasing in Recommendation",
            "abstract": "Current recommender systems have achieved great successes in online services, such as E-commerce and social media. However, they still suffer from the performance degradation in real scenarios, because various biases always occur in the generation process of user behaviors. Despite the recent development of addressing some specific type of bias, a variety of data bias, some of which are even unknown, are often mixed up in real applications. Although the uniform (or unbiased) data may help for the purpose of general debiasing, such data can either be hardly available or induce high experimental cost. In this paper, we consider a more practical setting where we aim to conduct general debiasing with the biased observational data alone. We assume that the observational user behaviors are determined by invariant preference (i.e. a user's true preference) and the variant preference (affected by some unobserved confounders). We propose a novel recommendation framework called InvPref which iteratively decomposes the invariant preference and variant preference from biased observational user behaviors by estimating heterogeneous environments corresponding to different types of latent bias. Extensive experiments, including the settings of general debiasing and specific debiasing, verify the advantages of our method.",
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "authors": [
                {
                    "authorId": "2117418792",
                    "name": "Zimu Wang"
                },
                {
                    "authorId": "2145031333",
                    "name": "Yue He"
                },
                {
                    "authorId": "2120846500",
                    "name": "Jiashuo Liu"
                },
                {
                    "authorId": "2181321465",
                    "name": "Wenchao Zou"
                },
                {
                    "authorId": "144019071",
                    "name": "Philip S. Yu"
                },
                {
                    "authorId": "2153522384",
                    "name": "Peng Cui"
                }
            ]
        },
        {
            "paperId": "e1b5ca7d17c5b46a0c93c1a4e828ddf2a94f389a",
            "title": "Stable Learning via Sparse Variable Independence",
            "abstract": "The problem of covariate-shift generalization has attracted intensive research attention. Previous stable learning algorithms employ sample reweighting schemes to decorrelate the covariates when there is no explicit domain information about training data. However, with finite samples, it is difficult to achieve the desirable weights that ensure perfect independence to get rid of the unstable variables. Besides, decorrelating within stable variables may bring about high variance of learned models because of the over-reduced effective sample size. A tremendous sample size is required for these algorithms to work. In this paper, with theoretical justification, we propose SVI (Sparse Variable Independence) for the covariate-shift generalization problem. We introduce sparsity constraint to compensate for the imperfectness of sample reweighting under the finite-sample setting in previous methods. Furthermore, we organically combine independence-based sample reweighting and sparsity-based variable selection in an iterative way to avoid decorrelating within stable variables, increasing the effective sample size to alleviate variance inflation. Experiments on both synthetic and real-world datasets demonstrate the improvement of covariate-shift generalization performance brought by SVI.",
            "fieldsOfStudy": [
                "Computer Science",
                "Mathematics"
            ],
            "authors": [
                {
                    "authorId": "2110985120",
                    "name": "Han Yu"
                },
                {
                    "authorId": "2153522384",
                    "name": "Peng Cui"
                },
                {
                    "authorId": "2145031333",
                    "name": "Yue He"
                },
                {
                    "authorId": "24069072",
                    "name": "Zheyan Shen"
                },
                {
                    "authorId": "2154487280",
                    "name": "Yong Lin"
                },
                {
                    "authorId": "150287491",
                    "name": "Renzhe Xu"
                },
                {
                    "authorId": "51258901",
                    "name": "Xingxuan Zhang"
                }
            ]
        },
        {
            "paperId": "6dbddf3d0420d5f8bf9d55164a3c8a987021f503",
            "title": "A Unified Solution to Constrained Bidding in Online Display Advertising",
            "abstract": "In online display advertising, advertisers usually participate in real-time bidding to acquire ad impression opportunities. In most advertising platforms, a typical impression acquiring demand of advertisers is to maximize the sum value of winning impressions under budget and some key performance indicators constraints, (e.g. maximizing clicks with the constraints of budget and cost per click upper bound). The demand can be various in value type (e.g. ad exposure/click), constraint type (e.g. cost per unit value) and constraint number. Existing works usually focus on a specific demand or hardly achieve the optimum. In this paper, we formulate the demand as a constrained bidding problem, and deduce a unified optimal bidding function on behalf of an advertiser. The optimal bidding function facilitates an advertiser calculating bids for all impressions with only m parameters, where m is the constraint number. However, in real application, it is non-trivial to determine the parameters due to the non-stationary auction environment. We further propose a reinforcement learning (RL) method to dynamically adjust parameters to achieve the optimum, whose converging efficiency is significantly boosted by the recursive optimization property in our formulation. We name the formulation and the RL method, together, as Unified Solution to Constrained Bidding (USCB). USCB is verified to be effective on industrial datasets and is deployed in Alibaba display advertising platform.",
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "authors": [
                {
                    "authorId": "2145031333",
                    "name": "Yue He"
                },
                {
                    "authorId": "48282892",
                    "name": "Xiujun Chen"
                },
                {
                    "authorId": "92148538",
                    "name": "Di Wu"
                },
                {
                    "authorId": "12692416",
                    "name": "Junwei Pan"
                },
                {
                    "authorId": "2049010106",
                    "name": "Qing Tan"
                },
                {
                    "authorId": "2117821247",
                    "name": "Chuan Yu"
                },
                {
                    "authorId": "49394850",
                    "name": "Jian Xu"
                },
                {
                    "authorId": "150345697",
                    "name": "Xiaoqiang Zhu"
                }
            ]
        },
        {
            "paperId": "bbd40c4f4e060fa7618544fc54cd20c9ca50b7d9",
            "title": "DARING: Differentiable Causal Discovery with Residual Independence",
            "abstract": "Discovering causal structure among a set of variables is a crucial task in various scientific and industrial scenarios. Given finite i.i.d. samples from a joint distribution, causal discovery is a challenging combinatorial problem in nature. The recent development in functional causal models, especially the NOTEARS provides a differentiable optimization framework for causal discovery. They formulate the structure learning problem as a task of maximum likelihood estimation over observational data (i.e., variable reconstruction) with specified structural constraints such as acyclicity and sparsity. Despite its success in terms of scalability, we find that optimizing the objectives of these differentiable methods is not always consistent with the correctness of learned causal graph especially when the variables carry heterogeneous noises (i.e., different noise types and noise variances) in real data from wild environments. In this paper, we provide the justification that their proneness to erroneous structures is mainly caused by the over-reconstruction problem, i.e., the noises of variables are absorbed into the variable reconstruction process, leading to the dependency among variable reconstruction residuals, and thus raise structure identifiability problems according to FCM theories. To remedy this, we propose a novel differentiable method DARING by imposing explicit residual independence constraint in an adversarial way. Extensive experimental results on both simulation and real data show that our proposed method is insensitive to the heterogeneity of external noise, and thus can significantly improve the causal discovery performances.",
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "authors": [
                {
                    "authorId": "2145031333",
                    "name": "Yue He"
                },
                {
                    "authorId": "143738684",
                    "name": "Peng Cui"
                },
                {
                    "authorId": "24069072",
                    "name": "Zheyan Shen"
                },
                {
                    "authorId": "150287491",
                    "name": "Renzhe Xu"
                },
                {
                    "authorId": "39853706",
                    "name": "Furui Liu"
                },
                {
                    "authorId": "2150036614",
                    "name": "Yong Jiang"
                }
            ]
        },
        {
            "paperId": "c6595a97b70933ff0c1a32282e4b7d8b4defad32",
            "title": "Purify and Generate: Learning Faithful Item-to-Item Graph from Noisy User-Item Interaction Behaviors",
            "abstract": "Matching is almost the first and most fundamental step in recommender systems, that is to quickly select hundreds or thousands of related entities from the whole commodity pool. Among all the matching methods, item-to-item (I2I) graph based matching is a handy and highly effective approach and is widely used in most applications, owing to the essential relationships of entities described in a powerful I2I graph. Yet, the I2I graph is not a ready-made product in a data source. To obtain it from users' behaviors, a common practice in the industry is to construct the graph based on the similarity of item embeddings or co-occurrence frequency directly. However, these methods tend to lose the complicated correlations (high-ordered or nonlinear) inside decision-making actions and cannot achieve the global optimal solution. Moreover, the correlations between items are usually contained in users' short-term actions, which are full of noise information (e.g. spurious association, missing connection). It is vitally important to filter out noise while generating the graph. In this paper, we propose a novel framework called Purified Graph Generation (PGG) dedicated to learn faithful I2I graph from sparse and noisy behavior data. We capture the 'confidence value' between user and item to get rid of exception action during decision making, and leverage it to re-sample purified sets that are fed into an unsupervised I2I graph structure learning framework called GPBG. Extensive experimental results from both simulation and real data demonstrate that our method could significantly benefit the performance of I2I graph compared to the typical baselines.",
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "authors": [
                {
                    "authorId": "2145031333",
                    "name": "Yue He"
                },
                {
                    "authorId": "2153514690",
                    "name": "Yancheng Dong"
                },
                {
                    "authorId": "143738684",
                    "name": "Peng Cui"
                },
                {
                    "authorId": "10796506",
                    "name": "Yuhang Jiao"
                },
                {
                    "authorId": "2108201662",
                    "name": "Xiaowei Wang"
                },
                {
                    "authorId": "40478933",
                    "name": "Ji Liu"
                },
                {
                    "authorId": "152297693",
                    "name": "Philip S. Yu"
                }
            ]
        },
        {
            "paperId": "e5b2e2a284db5ba7c2c011daba9769d2c56b6586",
            "title": "Towards Out-Of-Distribution Generalization: A Survey",
            "abstract": "Traditional machine learning paradigms are based on the assumption that both training and test data follow the same statistical pattern, which is mathematically referred to as Independent and Identically Distributed ($i.i.d.$). However, in real-world applications, this $i.i.d.$ assumption often fails to hold due to unforeseen distributional shifts, leading to considerable degradation in model performance upon deployment. This observed discrepancy indicates the significance of investigating the Out-of-Distribution (OOD) generalization problem. OOD generalization is an emerging topic of machine learning research that focuses on complex scenarios wherein the distributions of the test data differ from those of the training data. This paper represents the first comprehensive, systematic review of OOD generalization, encompassing a spectrum of aspects from problem definition, methodological development, and evaluation procedures, to the implications and future directions of the field. Our discussion begins with a precise, formal characterization of the OOD generalization problem. Following that, we categorize existing methodologies into three segments: unsupervised representation learning, supervised model learning, and optimization, according to their positions within the overarching learning process. We provide an in-depth discussion on representative methodologies for each category, further elucidating the theoretical links between them. Subsequently, we outline the prevailing benchmark datasets employed in OOD generalization studies. To conclude, we overview the existing body of work in this domain and suggest potential avenues for future research on OOD generalization. A summary of the OOD generalization methodologies surveyed in this paper can be accessed at http://out-of-distribution-generalization.com.",
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "authors": [
                {
                    "authorId": "24069072",
                    "name": "Zheyan Shen"
                },
                {
                    "authorId": "2120846500",
                    "name": "Jiashuo Liu"
                },
                {
                    "authorId": "2145031333",
                    "name": "Yue He"
                },
                {
                    "authorId": "51258901",
                    "name": "Xingxuan Zhang"
                },
                {
                    "authorId": "150287491",
                    "name": "Renzhe Xu"
                },
                {
                    "authorId": "2187083103",
                    "name": "Han Yu"
                },
                {
                    "authorId": "143738684",
                    "name": "Peng Cui"
                }
            ]
        }
    ]
}