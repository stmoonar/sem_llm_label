{
    "authorId": "2166262174",
    "papers": [
        {
            "paperId": "1105f0758a5d354a23331bf3a8ab7533ef39be97",
            "title": "Adversarial Style Augmentation via Large Language Model for Robust Fake News Detection",
            "abstract": "The spread of fake news negatively impacts individuals and is regarded as a significant social challenge that needs to be addressed. A number of algorithmic and insightful features have been identified for detecting fake news. However, with the recent LLMs and their advanced generation capabilities, many of the detectable features (e.g., style-conversion attacks) can be altered, making it more challenging to distinguish from real news. This study proposes adversarial style augmentation, AdStyle, to train a fake news detector that remains robust against various style-conversion attacks. Our model's key mechanism is the careful use of LLMs to automatically generate a diverse yet coherent range of style-conversion attack prompts. This improves the generation of prompts that are particularly difficult for the detector to handle. Experiments show that our augmentation strategy improves robustness and detection performance when tested on fake news benchmark datasets.",
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "authors": [
                {
                    "authorId": "2109454735",
                    "name": "Sungwon Park"
                },
                {
                    "authorId": "1444699639",
                    "name": "Sungwon Han"
                },
                {
                    "authorId": "2166262174",
                    "name": "Meeyoung Cha"
                }
            ]
        },
        {
            "paperId": "2797afb30527403ef1769a66e7db9edb750d5a8e",
            "title": "Generalizable Disaster Damage Assessment via Change Detection with Vision Foundation Model",
            "abstract": "The increasing frequency and intensity of natural disasters demand more sophisticated approaches for rapid and precise damage assessment. To tackle this issue, researchers have developed various methods on disaster benchmark datasets from satellite imagery to aid in detecting disaster damage. However, the diverse nature of geographical landscapes and disasters makes it challenging to apply existing methods to regions unseen during training. We present DAVI (Disaster Assessment with VIsion foundation model), which overcomes domain disparities and detects structural damage (e.g., building) without requiring ground-truth labels of the target region. DAVI integrates task-specific knowledge from a model trained on source regions with an image segmentation foundation model to generate pseudo labels of possible damage in the target region. It then employs a two-stage refinement process, targeting both the pixel and overall image, to more accurately pinpoint changes in disaster-struck areas based on before-and-after images. Comprehensive evaluations demonstrate that DAVI achieves exceptional performance across diverse terrains (e.g., USA and Mexico) and disaster types (e.g., wildfires, hurricanes, and earthquakes). This confirms its robustness in assessing disaster impact without dependence on ground-truth labels.",
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "authors": [
                {
                    "authorId": "2305821862",
                    "name": "Kyeongjin Ahn"
                },
                {
                    "authorId": "1444699639",
                    "name": "Sungwon Han"
                },
                {
                    "authorId": "2109454735",
                    "name": "Sungwon Park"
                },
                {
                    "authorId": "2117130220",
                    "name": "Jihee Kim"
                },
                {
                    "authorId": "2238948186",
                    "name": "Sangyoon Park"
                },
                {
                    "authorId": "2166262174",
                    "name": "Meeyoung Cha"
                }
            ]
        },
        {
            "paperId": "3bba4118e7e5e40dd71ba47d69e4101f469b35e9",
            "title": "Uncertainty-Aware Face Embedding With Contrastive Learning for Open-Set Evaluation",
            "abstract": "While advances in deep learning have enabled novel applications in various fields, face recognition in open-set scenarios remains a complex task, owing to the challenges posed by the extensive volume of low-quality face images. We introduce a new approach for recognizing faces in unconstrained open-set settings by leveraging uncertainty-aware embeddings through contrastive learning. Our model, called UCFace, effectively regulates the contribution of each face image based on the face uncertainty derived from image quality as an inverse proxy. Face embeddings are reinterpreted as a probabilistic distribution within the embedding space, where the degree of sharpness (i.e., distribution concentration) reflects the underlying uncertainty and probability density is used as a similarity metric to facilitate contrastive learning. Experiments on a wide range of face datasets, including those with high, mixed, and real-world low-resolution face images, demonstrate that UCFace enhances open-set face recognition performance by integrating the aspect of uncertainty.",
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "authors": [
                {
                    "authorId": "2305821862",
                    "name": "Kyeongjin Ahn"
                },
                {
                    "authorId": "2116971826",
                    "name": "Seungeon Lee"
                },
                {
                    "authorId": "1444699639",
                    "name": "Sungwon Han"
                },
                {
                    "authorId": "2832641",
                    "name": "C. Low"
                },
                {
                    "authorId": "2166262174",
                    "name": "Meeyoung Cha"
                }
            ]
        },
        {
            "paperId": "47f201e6a010aa6bca61fdd4a04be3b877f80f3d",
            "title": "FedMID: A Data-Free Method for Using Intermediate Outputs as a Defense Mechanism Against Poisoning Attacks in Federated Learning",
            "abstract": "Federated learning combines local updates from clients to produce a global model, which is susceptible to poisoning attacks. Most previous defense strategies relied on vectors derived from projections of local updates on a Euclidean space; however, these methods fail to accurately represent the functionality and structure of local models, resulting in inconsistent performance. Here, we present a new paradigm to defend against poisoning attacks in federated learning using functional mappings of local models based on intermediate outputs. Experiments show that our mechanism is robust under a broad range of computing conditions and advanced attack scenarios, enabling safer collaboration among data-sensitive participants via federated learning.",
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "authors": [
                {
                    "authorId": "1444699639",
                    "name": "Sungwon Han"
                },
                {
                    "authorId": "1645918180",
                    "name": "Hyeonho Song"
                },
                {
                    "authorId": "2109454735",
                    "name": "Sungwon Park"
                },
                {
                    "authorId": "2166262174",
                    "name": "Meeyoung Cha"
                }
            ]
        },
        {
            "paperId": "65868b45b6dea04e2f23a2efa9272e333a15cc8f",
            "title": "GeoSEE: Regional Socio-Economic Estimation With a Large Language Model",
            "abstract": "Moving beyond traditional surveys, combining heterogeneous data sources with AI-driven inference models brings new opportunities to measure socio-economic conditions, such as poverty and population, over expansive geographic areas. The current research presents GeoSEE, a method that can estimate various socio-economic indicators using a unified pipeline powered by a large language model (LLM). Presented with a diverse set of information modules, including those pre-constructed from satellite imagery, GeoSEE selects which modules to use in estimation, for each indicator and country. This selection is guided by the LLM's prior socio-geographic knowledge, which functions similarly to the insights of a domain expert. The system then computes target indicators via in-context learning after aggregating results from selected modules in the format of natural language-based texts. Comprehensive evaluation across countries at various stages of development reveals that our method outperforms other predictive models in both unsupervised and low-shot contexts. This reliable performance under data-scarce setting in under-developed or developing countries, combined with its cost-effectiveness, underscores its potential to continuously support and monitor the progress of Sustainable Development Goals, such as poverty alleviation and equitable growth, on a global scale.",
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "authors": [
                {
                    "authorId": "1444699639",
                    "name": "Sungwon Han"
                },
                {
                    "authorId": "2053105001",
                    "name": "Donghyun Ahn"
                },
                {
                    "authorId": "2116971826",
                    "name": "Seungeon Lee"
                },
                {
                    "authorId": "2189870481",
                    "name": "Min-Chae Song"
                },
                {
                    "authorId": "2109454735",
                    "name": "Sungwon Park"
                },
                {
                    "authorId": "2238948186",
                    "name": "Sangyoon Park"
                },
                {
                    "authorId": "2117130220",
                    "name": "Jihee Kim"
                },
                {
                    "authorId": "2166262174",
                    "name": "Meeyoung Cha"
                }
            ]
        },
        {
            "paperId": "e320fb19ac509f6a4b196d5a801ff69779c8f3c5",
            "title": "Self Supervised Vision for Climate Downscaling",
            "abstract": "Climate change is one of the most critical challenges that our planet is facing today. Rising global temperatures are already affecting Earth's weather and climate patterns with an increased frequency of unpredictable and extreme events. Future projections for climate change research are based on computer models like Earth System Models (ESMs). Climate simulations typically run on a coarser grid due to the high computational resources required, and then undergo a lighter downscaling process to obtain data on a finer grid. This work presents a self-supervised deep learning model that does not require high resolution ground truth data for downscaling. This is realized by leveraging salient distribution patterns and the hidden dependencies between weather variables for an individual data point at runtime. We propose three climate-specific components that well represent the patterns of underlying weather variables and learn intricate inter-variable dependencies. Extensive evaluation with 2x, 3x, and 4x scaling factors demonstrates that our model obtains 8% to 47% performance gain over existing baselines while greatly reducing the overall runtime. The improved performance and no dependence on high resolution ground truth data make our method a valuable tool for future climate research.",
            "fieldsOfStudy": [
                "Physics",
                "Computer Science"
            ],
            "authors": [
                {
                    "authorId": "2150725025",
                    "name": "Karandeep Singh"
                },
                {
                    "authorId": "2212076872",
                    "name": "Chaeyoon Jeong"
                },
                {
                    "authorId": "9434857",
                    "name": "Naufal Shidqi"
                },
                {
                    "authorId": "2109454735",
                    "name": "Sungwon Park"
                },
                {
                    "authorId": "2007390496",
                    "name": "A. Nellikkattil"
                },
                {
                    "authorId": "2273652954",
                    "name": "Elke Zeller"
                },
                {
                    "authorId": "2166262174",
                    "name": "Meeyoung Cha"
                }
            ]
        },
        {
            "paperId": "32c3e0419b29e3fffdeacf930a3efc646db3fccc",
            "title": "Neural Classification of Terrestrial Biomes",
            "abstract": "Predicting vegetation changes under climate change is crucial because it will alter the distribution of different plants and have repercussions for ecosystems. To detect changes in vegetation, we employ biome classification that assigns vegetation distributions to specific biomes. Conventional methods have used empirical formulas or simple vegetation models. Based on previous research that showed the use of convolutional neural networks (CNN), this work employs multiple deep models to classify biomes with the goal of predicting future changes. Experiments over multiple datasets demonstrate that Transformer models can be a suitable alternative to the CNN model. In addition, we observe that the use of additional climate variables helps improve the prediction accuracy without overfitting the data, which previous studies have not considered. We discuss the future directions of machine learning for biome classification as a complement to traditional biome classification methods.",
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "authors": [
                {
                    "authorId": "2212409593",
                    "name": "Vyacheslav Shen"
                },
                {
                    "authorId": "2212067752",
                    "name": "Dong-Kyum Kim"
                },
                {
                    "authorId": "51139019",
                    "name": "Elke Zeller"
                },
                {
                    "authorId": "2166262174",
                    "name": "Meeyoung Cha"
                }
            ]
        },
        {
            "paperId": "70580745b7a4c851fa803b1e0275bdf103a12cd5",
            "title": "GraphFC: Customs Fraud Detection with Label Scarcity",
            "abstract": "Customs officials across the world encounter huge volumes of transactions. Associated with customs transactions is customs fraud-the intentional manipulation of goods declarations to avoid taxes and duties. Due to limited manpower, the customs offices can only manually inspect a small number of declarations, necessitating the automation of customs fraud detection by machine learning techniques. The limited availability of manually inspected ground truth data makes it essential for the ML approach to generalize well on unseen data. However, current customs fraud detection models are not well suited or designed for this setting. In this work, we propose GraphFC (Graph Neural networks for Customs Fraud), a model-agnostic, domain-specific, graph neural network based customs fraud detection model that is designed to work in a real-world setting with limited ground truth data. Extensive experimentation using real customs data from two countries demonstrates that GraphFC generalizes well over unseen data and outperforms various baselines and other models by a large margin.",
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "authors": [
                {
                    "authorId": "2150725025",
                    "name": "Karandeep Singh"
                },
                {
                    "authorId": "1896151979",
                    "name": "Yu-Che Tsai"
                },
                {
                    "authorId": "2169355",
                    "name": "Cheng-te Li"
                },
                {
                    "authorId": "2166262174",
                    "name": "Meeyoung Cha"
                },
                {
                    "authorId": "2107904896",
                    "name": "Shou-de Lin"
                }
            ]
        },
        {
            "paperId": "8b2f666288b47438c2993c1008439e452c44e61b",
            "title": "Explainable Product Classification for Customs",
            "abstract": "The task of assigning internationally accepted commodity codes (aka HS codes) to traded goods is a critical function of customs offices. Like court decisions made by judges, this task follows the doctrine of precedent and can be nontrivial even for experienced officers. Together with the Korea Customs Service (KCS), we propose a first-ever explainable decision supporting model that suggests the most likely subheadings (i.e., the first six digits) of the HS code. The model also provides reasoning for its suggestion in the form of a document that is interpretable by customs officers. We evaluated the model using 5,000 cases that recently received a classification request. The results showed that the top-3 suggestions made by our model had an accuracy of 93.9% when classifying 925 challenging subheadings. A user study with 32 customs experts further confirmed that our algorithmic suggestions accompanied by explainable reasonings, can substantially reduce the time and effort taken by customs officers for classification reviews.",
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "authors": [
                {
                    "authorId": "2261952853",
                    "name": "Eunji Lee"
                },
                {
                    "authorId": "2267356820",
                    "name": "Sihyeon Kim"
                },
                {
                    "authorId": "35637055",
                    "name": "Sundong Kim"
                },
                {
                    "authorId": "2149055939",
                    "name": "Soyeon Jung"
                },
                {
                    "authorId": "2144361868",
                    "name": "Heeja Kim"
                },
                {
                    "authorId": "2166262174",
                    "name": "Meeyoung Cha"
                }
            ]
        },
        {
            "paperId": "9df5413e4ee0c2fbb65ee18147e053b429e7046f",
            "title": "Fine-Grained Socioeconomic Prediction from Satellite Images with Distributional Adjustment",
            "abstract": "While measuring socioeconomic indicators is critical for local governments to make informed policy decisions, such measurements are often unavailable at fine-grained levels like municipality. This study employs deep learning-based predictions from satellite images to close the gap. We propose a method that assigns a socioeconomic score to each satellite image by capturing the distributional behavior observed in larger areas based on the ground truth. We train an ordinal regression scoring model and adjust the scores to follow the common power law within and across regions. Evaluation based on official statistics in South Korea shows that our method outperforms previous models in predicting population and employment size at both the municipality and grid levels. Our method also demonstrates robust performance in districts with uneven development, suggesting its potential use in developing countries where reliable, fine-grained data is scarce.",
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "authors": [
                {
                    "authorId": "2053105001",
                    "name": "Donghyun Ahn"
                },
                {
                    "authorId": "2189870481",
                    "name": "Min-Chae Song"
                },
                {
                    "authorId": "2116971826",
                    "name": "Seungeon Lee"
                },
                {
                    "authorId": "2257834342",
                    "name": "Yubin Choi"
                },
                {
                    "authorId": "2117130220",
                    "name": "Jihee Kim"
                },
                {
                    "authorId": "2107908149",
                    "name": "Sangyoon Park"
                },
                {
                    "authorId": "1899292751",
                    "name": "Hyunjoo Yang"
                },
                {
                    "authorId": "2166262174",
                    "name": "Meeyoung Cha"
                }
            ]
        }
    ]
}