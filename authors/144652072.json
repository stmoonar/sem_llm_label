{
    "authorId": "144652072",
    "papers": [
        {
            "paperId": "a64dff274698a5269a5654ddeb6f5e114b37c63d",
            "title": "A Unified Model and Dimension for Interactive Estimation",
            "abstract": "We study an abstract framework for interactive learning called interactive estimation in which the goal is to estimate a target from its\"similarity'' to points queried by the learner. We introduce a combinatorial measure called dissimilarity dimension which largely captures learnability in our model. We present a simple, general, and broadly-applicable algorithm, for which we obtain both regret and PAC generalization bounds that are polynomial in the new dimension. We show that our framework subsumes and thereby unifies two classic learning models: statistical-query learning and structured bandits. We also delineate how the dissimilarity dimension is related to well-known parameters for both frameworks, in some cases yielding significantly improved analyses.",
            "fieldsOfStudy": [
                "Computer Science",
                "Mathematics"
            ],
            "authors": [
                {
                    "authorId": "35889341",
                    "name": "Nataly Brukhim"
                },
                {
                    "authorId": "144652072",
                    "name": "Miroslav Dud\u00edk"
                },
                {
                    "authorId": "3124110",
                    "name": "Aldo Pacchiano"
                },
                {
                    "authorId": "1716301",
                    "name": "R. Schapire"
                }
            ]
        },
        {
            "paperId": "4a9b0378ed59410a5aaee0dd14308c92c0963536",
            "title": "Interdisciplinarity, Gender Diversity, and Network Structure Predict the Centrality of AI Organizations",
            "abstract": "Artificial intelligence (AI) research plays an increasingly important role in society, impacting key aspects of human life. From face recognition algorithms aiding national security in airports, to software that advises judges in criminal cases, and medical staff in healthcare, AI research is shaping critical facets of our experience in the world. But who are the people and institutional bodies behind this influential research? What are the predictors of influence of AI researchers and research organizations? We study this question using social network analysis, in an exploration of the structural characteristics, i.e., network topology, of research organizations that shape modern AI. In a sample of 149 organizations with 9,987 affiliated authors of published papers in a major AI conference (NeurIPS) and two major conferences that specifically focus on societal impacts of AI (FAccT and AIES), we find that both industry and academic research organizations with influential authors are more interdisciplinary, have a greater fraction of women, are more hierarchical, and less clustered, even when controlling for the size of the organizations. The influence is operationalized as betweenness centrality in co-authorship networks, i.e., how often an author is on the shortest path connecting any pair of authors, acting as a bridge connecting otherwise distant (or even disconneted) members of the network, such as their own co-authors who are not each other\u2019s co-author themselves. Using this operationalization, we also find that women have less influence in the AI community, determined as lower betweenness centrality in co-authorship networks. These results suggest that while diverse AI institutions are more influential, the individuals contributing to the increased diversity are marginalized in the AI field. We discuss these results in the context of current events with important societal implications.",
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "authors": [
                {
                    "authorId": "70025889",
                    "name": "Madalina Vlasceanu"
                },
                {
                    "authorId": "144652072",
                    "name": "Miroslav Dud\u00edk"
                },
                {
                    "authorId": "1990422",
                    "name": "I. Momennejad"
                }
            ]
        },
        {
            "paperId": "f195e26dcab4ad2a28f428d97c1d7017d3b82654",
            "title": "Personalization Improves Privacy-Accuracy Tradeoffs in Federated Optimization",
            "abstract": "Large-scale machine learning systems often involve data distributed across a collection of users. Federated optimization algorithms leverage this structure by communicating model updates to a central server, rather than entire datasets. In this paper, we study stochastic optimization algorithms for a personalized federated learning setting involving local and global models subject to user-level (joint) di\ufb00erential privacy. While learning a private global model induces a cost of privacy, local learning is perfectly private. We show that coordinating local learning with private centralized learning yields a generically useful and improved tradeo\ufb00 between accuracy and privacy. We illustrate our theoretical results with experiments on synthetic and real-world datasets",
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "authors": [
                {
                    "authorId": "2269602",
                    "name": "A. Bietti"
                },
                {
                    "authorId": "2144000427",
                    "name": "Chengkun Wei"
                },
                {
                    "authorId": "144652072",
                    "name": "Miroslav Dud\u00edk"
                },
                {
                    "authorId": "144162125",
                    "name": "J. Langford"
                },
                {
                    "authorId": "1768074",
                    "name": "Zhiwei Steven Wu"
                }
            ]
        },
        {
            "paperId": "f26c56e3c202385d1b29716cc7b5f3ba89353207",
            "title": "Personalization Improves Privacy-Accuracy Tradeoffs in Federated Learning",
            "abstract": "Large-scale machine learning systems often involve data distributed across a collection of users. Federated learning algorithms leverage this structure by communicating model updates to a central server, rather than entire datasets. In this paper, we study stochastic optimization algorithms for a personalized federated learning setting involving local and global models subject to user-level (joint) differential privacy. While learning a private global model induces a cost of privacy, local learning is perfectly private. We provide generalization guarantees showing that coordinating local learning with private centralized learning yields a generically useful and improved tradeoff between accuracy and privacy. We illustrate our theoretical results with experiments on synthetic and real-world datasets.",
            "fieldsOfStudy": [
                "Computer Science",
                "Mathematics"
            ],
            "authors": [
                {
                    "authorId": "2269602",
                    "name": "A. Bietti"
                },
                {
                    "authorId": "3431759",
                    "name": "Chen-Yu Wei"
                },
                {
                    "authorId": "144652072",
                    "name": "Miroslav Dud\u00edk"
                },
                {
                    "authorId": "144162125",
                    "name": "J. Langford"
                },
                {
                    "authorId": "1768074",
                    "name": "Zhiwei Steven Wu"
                }
            ]
        },
        {
            "paperId": "5894d57ea49bd5c136ebefb1e6c3986555908ea0",
            "title": "Fairlearn: A toolkit for assessing and improving fairness in AI",
            "abstract": "We introduce Fairlearn, an open source toolkit that empowers data scientists and developers to assess and improve the fairness of their AI systems. Fairlearn has two components: an interactive visualization dashboard and unfairness mitigation algorithms. These components are designed to help with navigating trade-offs between fairness and model performance. We emphasize that prioritizing fairness in AI systems is a sociotechnical challenge. Because there are many complex sources of unfairness\u2014some societal and some technical\u2014it is not possible to fully \u201cdebias\u201d a system or to guarantee fairness; the goal is to mitigate fairness-related harms as much as possible. As Fairlearn grows to include additional fairness metrics, unfairness mitigation algorithms, and visualization capabilities, we hope that it will be shaped by a diverse community of stakeholders, ranging from data scientists, developers, and business decision makers to the people whose lives may be affected by the predictions of AI systems.",
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "authors": [
                {
                    "authorId": "145583374",
                    "name": "Sarah Bird"
                },
                {
                    "authorId": "144652072",
                    "name": "Miroslav Dud\u00edk"
                },
                {
                    "authorId": "113003571",
                    "name": "R. Edgar"
                },
                {
                    "authorId": "2064040799",
                    "name": "Brandon Horn"
                },
                {
                    "authorId": "40451032",
                    "name": "Roman Lutz"
                },
                {
                    "authorId": "1390070911",
                    "name": "Vanessa Milan"
                },
                {
                    "authorId": "2128305",
                    "name": "M. Sameki"
                },
                {
                    "authorId": "1831395",
                    "name": "Hanna M. Wallach"
                },
                {
                    "authorId": "2054043979",
                    "name": "Kathleen Walker"
                }
            ]
        },
        {
            "paperId": "7ed50e8bd030093b78ab1a38567e2d426240b157",
            "title": "Constrained episodic reinforcement learning in concave-convex and knapsack settings",
            "abstract": "We propose an algorithm for tabular episodic reinforcement learning with constraints. We provide a modular analysis with strong theoretical guarantees for settings with concave rewards and convex constraints, and for settings with hard constraints (knapsacks). Most of the previous work in constrained reinforcement learning is limited to linear constraints, and the remaining work focuses on either the feasibility question or settings with a single episode. Our experiments demonstrate that the proposed algorithm significantly outperforms these approaches in existing constrained episodic environments.",
            "fieldsOfStudy": [
                "Computer Science",
                "Mathematics"
            ],
            "authors": [
                {
                    "authorId": "11963742",
                    "name": "Kiant\u00e9 Brantley"
                },
                {
                    "authorId": "144652072",
                    "name": "Miroslav Dud\u00edk"
                },
                {
                    "authorId": "2558458",
                    "name": "Thodoris Lykouris"
                },
                {
                    "authorId": "138875199",
                    "name": "Sobhan Miryoosefi"
                },
                {
                    "authorId": "3385674",
                    "name": "Max Simchowitz"
                },
                {
                    "authorId": "2158559",
                    "name": "Aleksandrs Slivkins"
                },
                {
                    "authorId": "144426657",
                    "name": "Wen Sun"
                }
            ]
        },
        {
            "paperId": "ac18880d3f0102d34364aaddc28711be20ec688c",
            "title": "Log-time Prediction Markets for Interval Securities",
            "abstract": "We design a prediction market to recover a complete and fully general probability distribution over a continuous random variable. Traders buy and sell interval securities, or binary contracts that pay $1 if the outcome falls into an interval and $0 otherwise. We allow traders to express any interval endpoint of arbitrary precision, in service of recovering distributions of any complex shape and number of modes. Our market takes the form of a central automated market maker offering prices for every interval security that traders propose. All market operations can be achieved in time logarithmic in the number of outcomes (that traders distinguish), providing the first computationally efficient market for a continuous variable. We present two designs. The first replicates the popular logarithmic market scoring rule (LMSR) exactly, keeping its bounded-loss guarantee, while utilizing a balanced binary tree to execute all operations exponentially faster than standard LMSR markets. We exploit modularity properties of LMSR to decompose computations along nodes of the tree. The second features two or more parallel LMSR market makers that mediate submarkets with increasingly fine-grained outcome partitions. This design remains computationally efficient for all operations, including arbitrage removal across submarkets, and adds two additional benefits: (1) the ability to flexibly express utility for information at various resolutions by assigning different liquidity values, and (2) the ability to guarantee true constant bounded loss by geometrically decreasing the liquidity in each submarket. We conduct simulation experiments to illustrate the flexibility of our second design, showing that it can converge fast at both coarse and fine resolutions, whereas standard LMSR markets need to pick the preferred outcome resolution ex ante.",
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "authors": [
                {
                    "authorId": "144652072",
                    "name": "Miroslav Dud\u00edk"
                },
                {
                    "authorId": "2108003088",
                    "name": "Xintong Wang"
                },
                {
                    "authorId": "1766638",
                    "name": "David M. Pennock"
                },
                {
                    "authorId": "145792941",
                    "name": "David M. Rothschild"
                }
            ]
        },
        {
            "paperId": "1f868b5839b3126209612f6e2f8c40aa431b46fd",
            "title": "Fair Regression: Quantitative Definitions and Reduction-based Algorithms",
            "abstract": "In this paper, we study the prediction of a real-valued target, such as a risk score or recidivism rate, while guaranteeing a quantitative notion of fairness with respect to a protected attribute such as gender or race. We call this class of problems \\emph{fair regression}. We propose general schemes for fair regression under two notions of fairness: (1) statistical parity, which asks that the prediction be statistically independent of the protected attribute, and (2) bounded group loss, which asks that the prediction error restricted to any protected group remain below some pre-determined level. While we only study these two notions of fairness, our schemes are applicable to arbitrary Lipschitz-continuous losses, and so they encompass least-squares regression, logistic regression, quantile regression, and many other tasks. Our schemes only require access to standard risk minimization algorithms (such as standard classification or least-squares regression) while providing theoretical guarantees on the optimality and fairness of the obtained solutions. In addition to analyzing theoretical properties of our schemes, we empirically demonstrate their ability to uncover fairness--accuracy frontiers on several standard datasets.",
            "fieldsOfStudy": [
                "Computer Science",
                "Mathematics"
            ],
            "authors": [
                {
                    "authorId": "40333747",
                    "name": "Alekh Agarwal"
                },
                {
                    "authorId": "144652072",
                    "name": "Miroslav Dud\u00edk"
                },
                {
                    "authorId": "1768074",
                    "name": "Zhiwei Steven Wu"
                }
            ]
        },
        {
            "paperId": "8ae4f95029bd00508342818f40ae4b0ca53b0192",
            "title": "Doubly robust off-policy evaluation with shrinkage",
            "abstract": "We propose a new framework for designing estimators for off-policy evaluation in contextual bandits. Our approach is based on the asymptotically optimal doubly robust estimator, but we shrink the importance weights to minimize a bound on the mean squared error, which results in a better bias-variance tradeoff in finite samples. We use this optimization-based framework to obtain three estimators: (a) a weight-clipping estimator, (b) a new weight-shrinkage estimator, and (c) the first shrinkage-based estimator for combinatorial action sets. Extensive experiments in both standard and combinatorial bandit benchmark problems show that our estimators are highly adaptive and typically outperform state-of-the-art methods.",
            "fieldsOfStudy": [
                "Computer Science",
                "Mathematics"
            ],
            "authors": [
                {
                    "authorId": "144908640",
                    "name": "Yi-Hsun Su"
                },
                {
                    "authorId": "8472327",
                    "name": "Maria Dimakopoulou"
                },
                {
                    "authorId": "37019006",
                    "name": "A. Krishnamurthy"
                },
                {
                    "authorId": "144652072",
                    "name": "Miroslav Dud\u00edk"
                }
            ]
        },
        {
            "paperId": "9c5ab1e836acdba0c1f91360909e9e81c56d2f15",
            "title": "Reinforcement Learning with Convex Constraints",
            "abstract": "In standard reinforcement learning (RL), a learning agent seeks to optimize the overall reward. However, many key aspects of a desired behavior are more naturally expressed as constraints. For instance, the designer may want to limit the use of unsafe actions, increase the diversity of trajectories to enable exploration, or approximate expert trajectories when rewards are sparse. In this paper, we propose an algorithmic scheme that can handle a wide class of constraints in RL tasks: specifically, any constraints that require expected values of some vector measurements (such as the use of an action) to lie in a convex set. This captures previously studied constraints (such as safety and proximity to an expert), but also enables new classes of constraints (such as diversity). Our approach comes with rigorous theoretical guarantees and only relies on the ability to approximately solve standard RL tasks. As a result, it can be easily adapted to work with any model-free or model-based RL. In our experiments, we show that it matches previous algorithms that enforce safety via constraints, but can also enforce new properties that these algorithms do not incorporate, such as diversity.",
            "fieldsOfStudy": [
                "Computer Science",
                "Mathematics"
            ],
            "authors": [
                {
                    "authorId": "138875199",
                    "name": "Sobhan Miryoosefi"
                },
                {
                    "authorId": "11963742",
                    "name": "Kiant\u00e9 Brantley"
                },
                {
                    "authorId": "1722360",
                    "name": "Hal Daum\u00e9"
                },
                {
                    "authorId": "144652072",
                    "name": "Miroslav Dud\u00edk"
                },
                {
                    "authorId": "1716301",
                    "name": "R. Schapire"
                }
            ]
        }
    ]
}