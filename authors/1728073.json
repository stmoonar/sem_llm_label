{
    "authorId": "1728073",
    "papers": [
        {
            "paperId": "24a10e614ecd19b24bc8a5afc412f151553d20d6",
            "title": "An Empirical Study on Using Large Language Models for Multi-Intent Comment Generation",
            "abstract": "Code comment generation aims at generating natural language descriptions for a code snippet to facilitate developers\u2019 program comprehension activities. Despite being studied for a long time, a bottleneck for existing approaches is that given a code snippet, they can only generate one comment while developers usually need to know information from diverse perspectives such as what is the functionality of this code snippet and how to use it. To tackle this limitation, this study empirically investigates the feasibility of utilizing large language models (LLMs) to generate comments that can fulfill developers\u2019 diverse intents. Our intuition is based on the facts that (1) the code and its pairwise comment are used during the pre-training process of LLMs to build the semantic connection between the natural language and programming language, and (2) comments in the real-world projects, which are collected for the pre-training, usually contain different developers\u2019 intents. We thus postulate that the LLMs can already understand the code from different perspectives after the pre-training. Indeed, experiments on two large-scale datasets demonstrate the rationale of our insights: by adopting the in-context learning paradigm and giving adequate prompts to the LLM (e.g., providing it with ten or more examples), the LLM can significantly outperform a state-of-the-art supervised learning approach on generating comments with multiple intents. Results also show that customized strategies for constructing the prompts and post-processing strategies for reranking the results can both boost the LLM\u2019s performances, which shed light on future research directions for using LLMs to achieve comment generation.",
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "authors": [
                {
                    "authorId": "2141549468",
                    "name": "Mingyang Geng"
                },
                {
                    "authorId": "49184504",
                    "name": "Shangwen Wang"
                },
                {
                    "authorId": "39891717",
                    "name": "Dezun Dong"
                },
                {
                    "authorId": "1728073",
                    "name": "Hao Wang"
                },
                {
                    "authorId": "2154591375",
                    "name": "Ge Li"
                },
                {
                    "authorId": "2152843753",
                    "name": "Zhi Jin"
                },
                {
                    "authorId": "2150465957",
                    "name": "Xiaoguang Mao"
                },
                {
                    "authorId": "144078016",
                    "name": "Xiangke Liao"
                }
            ]
        },
        {
            "paperId": "375a571174ea59b1f4aa62ad2619e9593fc03436",
            "title": "Large Language Models are Few-Shot Summarizers: Multi-Intent Comment Generation via In-Context Learning",
            "abstract": "Code comment generation aims at generating natural language descriptions for a code snippet to facilitate developers' program comprehension activities. Despite being studied for a long time, a bottleneck for existing approaches is that given a code snippet, they can only generate one comment while developers usually need to know information from diverse perspectives such as what is the functionality of this code snippet and how to use it. To tackle this limitation, this study empirically investigates the feasibility of utilizing large language models (LLMs) to generate comments that can fulfill developers' diverse intents. Our intuition is based on the facts that (1) the code and its pairwise comment are used during the pre-training process of LLMs to build the semantic connection between the natural language and programming language, and (2) comments in the real-world projects, which are collected for the pre-training, usually contain different developers' intents. We thus postulate that the LLMs can already understand the code from different perspectives after the pre-training. Indeed, experiments on two large-scale datasets demonstrate the rationale of our insights: by adopting the in-context learning paradigm and giving adequate prompts to the LLM (e.g., providing it with ten or more examples), the LLM can significantly outperform a state-of-the-art supervised learning approach on generating comments with multiple intents. Results also show that customized strategies for constructing the prompts and post-processing strategies for reranking the results can both boost the LLM's performances, which shed light on future research directions for using LLMs to achieve comment generation.",
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "authors": [
                {
                    "authorId": "2141549468",
                    "name": "Mingyang Geng"
                },
                {
                    "authorId": "49184504",
                    "name": "Shangwen Wang"
                },
                {
                    "authorId": "39891717",
                    "name": "Dezun Dong"
                },
                {
                    "authorId": "1728073",
                    "name": "Hao Wang"
                },
                {
                    "authorId": "2154591375",
                    "name": "Ge Li"
                },
                {
                    "authorId": "2152843753",
                    "name": "Zhi Jin"
                },
                {
                    "authorId": "2150465957",
                    "name": "Xiaoguang Mao"
                },
                {
                    "authorId": "144078016",
                    "name": "Xiangke Liao"
                }
            ]
        },
        {
            "paperId": "628219d6db682340eb40bc5122ed62dbccab3f34",
            "title": "Counterfactual Collaborative Reasoning",
            "abstract": "Causal reasoning and logical reasoning are two important types of reasoning abilities for human intelligence. However, their relationship has not been extensively explored under machine intelligence context. In this paper, we explore how the two reasoning abilities can be jointly modeled to enhance both accuracy and explainability of machine learning models. More specifically, by integrating two important types of reasoning ability--counterfactual reasoning and (neural) logical reasoning--we propose Counterfactual Collaborative Reasoning (CCR), which conducts counterfactual logic reasoning to improve the performance. In particular, we use recommender system as an example to show how CCR alleviate data scarcity, improve accuracy and enhance transparency. Technically, we leverage counterfactual reasoning to generate \"difficult\" counterfactual training examples for data augmentation, which--together with the original training examples--can enhance the model performance. Since the augmented data is model irrelevant, they can be used to enhance any model, enabling the wide applicability of the technique. Besides, most of the existing data augmentation methods focus on \"implicit data augmentation\" over users' implicit feedback, while our framework conducts \"explicit data augmentation\" over users explicit feedback based on counterfactual logic reasoning. Experiments on three real-world datasets show that CCR achieves better performance than non-augmented models and implicitly augmented models, and also improves model transparency by generating counterfactual explanations.",
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "authors": [
                {
                    "authorId": "2111810606",
                    "name": "Jianchao Ji"
                },
                {
                    "authorId": "2109968285",
                    "name": "Zelong Li"
                },
                {
                    "authorId": "2111044480",
                    "name": "Shuyuan Xu"
                },
                {
                    "authorId": "2209210425",
                    "name": "Max Xiong"
                },
                {
                    "authorId": "2110449137",
                    "name": "Juntao Tan"
                },
                {
                    "authorId": "152988336",
                    "name": "Yingqiang Ge"
                },
                {
                    "authorId": "1728073",
                    "name": "Hao Wang"
                },
                {
                    "authorId": "2145038716",
                    "name": "Yongfeng Zhang"
                }
            ]
        },
        {
            "paperId": "6e309529556211ed38ba56e90119903e46c2684d",
            "title": "An end-to-end neural framework using coarse-to-fine-grained attention for overlapping relational triple extraction",
            "abstract": "Abstract In recent years, the extraction of overlapping relations has received great attention in the field of natural language processing (NLP). However, most existing approaches treat relational triples in sentences as isolated, without considering the rich semantic correlations implied in the relational hierarchy. Extracting these overlapping relational triples is challenging, given the overlapping types are various and relatively complex. In addition, these approaches do not highlight the semantic information in the sentence from coarse-grained to fine-grained. In this paper, we propose an end-to-end neural framework based on a decomposition model that incorporates multi-granularity relational features for the extraction of overlapping triples. Our approach employs an attention mechanism that combines relational hierarchy information with multiple granularities and pretrained textual representations, where the relational hierarchies are constructed manually or obtained by unsupervised clustering. We found that the different hierarchy construction strategies have little effect on the final extraction results. Experimental results on two public datasets, NYT and WebNLG, show that our mode substantially outperforms the baseline system in extracting overlapping relational triples, especially for long-tailed relations.",
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "authors": [
                {
                    "authorId": "2209213788",
                    "name": "Huizhe Su"
                },
                {
                    "authorId": "1728073",
                    "name": "Hao Wang"
                },
                {
                    "authorId": "33807333",
                    "name": "Xiangfeng Luo"
                },
                {
                    "authorId": "2114081696",
                    "name": "Shaorong Xie"
                }
            ]
        },
        {
            "paperId": "9bbfda47b615c29eb0c567808eabe498e036cc46",
            "title": "Quantifying Representation Reliability in Self-Supervised Learning Models",
            "abstract": "Self-supervised learning models extract general-purpose representations from data. Quantifying the reliability of these representations is crucial, as many downstream models rely on them as input for their own tasks. To this end, we introduce a formal definition of representation reliability: the representation for a given test point is considered to be reliable if the downstream models built on top of that representation can consistently generate accurate predictions for that test point. However, accessing downstream data to quantify the representation reliability is often infeasible or restricted due to privacy concerns. We propose an ensemble-based method for estimating the representation reliability without knowing the downstream tasks a priori. Our method is based on the concept of neighborhood consistency across distinct pre-trained representation spaces. The key insight is to find shared neighboring points as anchors to align these representation spaces before comparing them. We demonstrate through comprehensive numerical experiments that our method effectively captures the representation reliability with a high degree of correlation, achieving robust and favorable performance compared with baseline methods.",
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "authors": [
                {
                    "authorId": "2115210131",
                    "name": "Young-Jin Park"
                },
                {
                    "authorId": "1728073",
                    "name": "Hao Wang"
                },
                {
                    "authorId": "2599451",
                    "name": "Shervin Ardeshir"
                },
                {
                    "authorId": "2082417",
                    "name": "Navid Azizan"
                }
            ]
        },
        {
            "paperId": "f358c4e7903d1cd653bf15d3f1874e27a17e1384",
            "title": "Interpretation-based Code Summarization",
            "abstract": "Code comment, i.e., the natural language text to describe the semantic of a code snippet, is an important way for developers to comprehend the code. Recently, a number of approaches have been proposed to automatically generate the comment given a code snippet, aiming at facilitating the comprehension activities of developers. Despite that state-of-the-art approaches have already utilized advanced machine learning techniques such as the Transformer model, they often ignore critical information of the source code, leading to the inaccuracy of the generated summarization. In this paper, to boost the effectiveness of code summarization, we propose a two-stage paradigm, where in the first stage, we train an off-the-shelf model and then identify its focuses when generating the initial summarization, through a model interpretation approach, and in the second stage, we reinforce the model to generate more qualified summarization based on the source code and its focuses. Our intuition is that in such a manner the model could learn to identify what critical information in the code has been captured and what has been missed in its initial summarization, and thus revise its initial summarization accordingly, just like how a human student learns to write high-quality summarization for a natural language text. Extensive experiments on two large-scale datasets show that our approach can boost the effectiveness of five state-of-the-art code summarization approaches significantly. Specifically, for the well-known code summarizer, DeepCom, utilizing our two-stage paradigm can increase its BLEU-4 values by around 30% and 25% on the two datasets, respectively.",
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "authors": [
                {
                    "authorId": "2141549468",
                    "name": "Mingyang Geng"
                },
                {
                    "authorId": "49184504",
                    "name": "Shangwen Wang"
                },
                {
                    "authorId": "39891717",
                    "name": "Dezun Dong"
                },
                {
                    "authorId": "1728073",
                    "name": "Hao Wang"
                },
                {
                    "authorId": "2223184559",
                    "name": "Shaomeng Cao"
                },
                {
                    "authorId": "2033148496",
                    "name": "Kechi Zhang"
                },
                {
                    "authorId": "1700880",
                    "name": "Zhi Jin"
                }
            ]
        },
        {
            "paperId": "148edfe81457169c24de9d5bbab75dad53567e4b",
            "title": "An empirical study of incorporating syntactic constraints into BERT-based location metonymy resolution",
            "abstract": "Abstract Metonymy resolution (MR) is a challenging task in the field of natural language processing. The task of MR aims to identify the metonymic usage of a word that employs an entity name to refer to another target entity. Recent BERT-based methods yield state-of-the-art performances. However, they neither make full use of the entity information nor explicitly consider syntactic structure. In contrast, in this paper, we argue that the metonymic process should be completed in a collaborative manner, relying on both lexical semantics and syntactic structure (syntax). This paper proposes a novel approach to enhancing BERT-based MR models with hard and soft syntactic constraints by using different types of convolutional neural networks to model dependency parse trees. Experimental results on benchmark datasets (e.g., ReLocaR, SemEval 2007 and WiMCor) confirm that leveraging syntactic information into fine pre-trained language models benefits MR tasks.",
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "authors": [
                {
                    "authorId": "1728073",
                    "name": "Hao Wang"
                },
                {
                    "authorId": "27665305",
                    "name": "Siyuan Du"
                },
                {
                    "authorId": "2157411813",
                    "name": "X. Zheng"
                },
                {
                    "authorId": "2027433366",
                    "name": "Li Meng"
                }
            ]
        },
        {
            "paperId": "224b227f1c4926f8833b27feff767f371fbd860c",
            "title": "MIFAS: Multi\u2010source heterogeneous information fusion with adaptive importance sampling for link prediction",
            "abstract": "Link prediction plays an important role in constructing knowledge graph. Recently, graph representation learning models yield state\u2010of\u2010the\u2010art results. However, existing models concentrate merely on triples or graph structures and mostly ignore textual descriptions, resulting in incomplete or partial information. In this paper, we propose a novel graph representation learning model to address this challenge, namely multi\u2010source heterogeneous information fusion with adaptive importance sampling. Our model leverages multiple sources, such triple, graph structure and textual description, and generate rich\u2010attribute embeddings for entities, encapsulating relations simultaneously. We also propose an adaptive importance sampling algorithm to boost aggregation of useful features from local neighbours. Additionally, we also boost node aggregation of useful features from local neighbours by adaptive importance sampling algorithm in our model. Experimental results on two benchmark datasets show that our proposed model significantly outperforms state\u2010of\u2010the\u2010art methods.",
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "authors": [
                {
                    "authorId": "2114747066",
                    "name": "Tingting Jiang"
                },
                {
                    "authorId": "1728073",
                    "name": "Hao Wang"
                },
                {
                    "authorId": "2167614",
                    "name": "Xiangfeng Luo"
                },
                {
                    "authorId": "2114081696",
                    "name": "Shaorong Xie"
                },
                {
                    "authorId": "2110124127",
                    "name": "Jingchao Wang"
                }
            ]
        },
        {
            "paperId": "96fce4552ab5f1a840bcdf4a2acea0fedb6a7cdb",
            "title": "Causal Event Extraction using Iterated Dilated Convolutions with Semantic Convolutional Filters",
            "abstract": "Causal Event Extraction (CEE) is a joint extraction task of events and causality, which can help text understanding, event prediction and so on. Recent research has achieved state-of-the-art performance in various Natural Language Processing (NLP) tasks by combining pre-trained models with neural networks. However, ambiguity of event description and long-distance dependence of event causality result in the low accuracy of extractors. In this paper, we propose a model to incorporate in-domain knowledge by taking frequent expression of event causality into account, and use iterated dilated convolutions to expand the perception field of event causality. External causal knowledge is modeled as frequent n-grams with different length, which is used as convolution filters during kernel initialization, enhancing the ability of model to capture the boundary of event description. To obtain long-distance dependence of event causality, we use iterated dilated convolutions to aggregate context from the entire sentence. Experimental results show that our method significantly outperform the baselines with faster convergence speed.",
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "authors": [
                {
                    "authorId": "49952430",
                    "name": "Jianqi Gao"
                },
                {
                    "authorId": "2167614",
                    "name": "Xiangfeng Luo"
                },
                {
                    "authorId": "1728073",
                    "name": "Hao Wang"
                },
                {
                    "authorId": "2135787227",
                    "name": "Zijian Wang"
                }
            ]
        },
        {
            "paperId": "cbd4ce270d43605e982ecab2071b2ffc3c965c86",
            "title": "Chinese causal event extraction using causality\u2010associated graph neural network",
            "abstract": "Causal event extraction (CEE) aims to identify and extract cause\u2010effect event pairs from texts, which is a fundamental task in natural language processing. Recent research treat CEE as a sequence labeling problem. However, the linguistic complexity and ambiguity of textual description results in the low accuracy of extractors. To address the above issues, considering the prior knowledge like the causal network constructed based on the causal indicators, which can represent information transition between cause and effect, may helpful for CEE. In this article, we propose causality\u2010associated graph neural network to incorporate in\u2010domain knowledge by taking important causal words into account. External causal knowledge is modeled as causal associated graph (CAG). Then we use graph neural networks (GNN) to capture the complex relationship of intraevent mentions and interevent causality in a sentence based on the relationship obtained from CAG. Finally, sentence sequence and prior causal knowledge of GNN embedding are fed into multiscaled convolution and bidirectional long short\u2010term memory networks. Experimental results on two datasets show that our method outperforms the state\u2010of\u2010the\u2010art baseline.",
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "authors": [
                {
                    "authorId": "49952430",
                    "name": "Jianqi Gao"
                },
                {
                    "authorId": "2167614",
                    "name": "Xiangfeng Luo"
                },
                {
                    "authorId": "1728073",
                    "name": "Hao Wang"
                }
            ]
        }
    ]
}