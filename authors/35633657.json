{
    "authorId": "35633657",
    "papers": [
        {
            "paperId": "b5aad38122c14f4287c5feca20b7017fda50d7c0",
            "title": "Hybrid forecasting of geopolitical events\u2020",
            "abstract": "Sound decision-making relies on accurate prediction for tangible outcomes ranging from military conflict to disease outbreaks. To improve crowdsourced forecasting accuracy, we developed SAGE, a hybrid forecasting system that combines human and machine generated forecasts. The system provides a platform where users can interact with machine models and thus anchor their judgments on an objective",
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "authors": [
                {
                    "authorId": "2052360522",
                    "name": "Daniel M. Benjamin"
                },
                {
                    "authorId": "2775559",
                    "name": "Fred Morstatter"
                },
                {
                    "authorId": "32494669",
                    "name": "A. Abbas"
                },
                {
                    "authorId": "2919118",
                    "name": "A. Abeliuk"
                },
                {
                    "authorId": "2213032239",
                    "name": "Pavel Atanasov"
                },
                {
                    "authorId": "1667696997",
                    "name": "Stephen T. Bennett"
                },
                {
                    "authorId": "52249013",
                    "name": "Andreas Beger"
                },
                {
                    "authorId": "2088006944",
                    "name": "Saurabh Birari"
                },
                {
                    "authorId": "3275470",
                    "name": "D. Budescu"
                },
                {
                    "authorId": "1754926",
                    "name": "Michele Catasta"
                },
                {
                    "authorId": "48898287",
                    "name": "Emilio Ferrara"
                },
                {
                    "authorId": "2213306048",
                    "name": "Lucas Haravitch"
                },
                {
                    "authorId": "115201201",
                    "name": "Mark Himmelstein"
                },
                {
                    "authorId": "144022002",
                    "name": "K. T. Hossain"
                },
                {
                    "authorId": "35633657",
                    "name": "Yuzhong Huang"
                },
                {
                    "authorId": "8844876",
                    "name": "Woojeong Jin"
                },
                {
                    "authorId": "51892568",
                    "name": "R. Joseph"
                },
                {
                    "authorId": "1702139",
                    "name": "J. Leskovec"
                },
                {
                    "authorId": "50390828",
                    "name": "Akira Matsui"
                },
                {
                    "authorId": "35416435",
                    "name": "Mehrnoosh Mirtaheri"
                },
                {
                    "authorId": "145201124",
                    "name": "Xiang Ren"
                },
                {
                    "authorId": "1840215",
                    "name": "Gleb Satyukov"
                },
                {
                    "authorId": "31928125",
                    "name": "Rajiv Sethi"
                },
                {
                    "authorId": "2116288277",
                    "name": "Amandeep Singh"
                },
                {
                    "authorId": "48523334",
                    "name": "R. Sosi\u010d"
                },
                {
                    "authorId": "1804885",
                    "name": "M. Steyvers"
                },
                {
                    "authorId": "2628881",
                    "name": "Pedro A. Szekely"
                },
                {
                    "authorId": "2067815167",
                    "name": "M. D. Ward"
                },
                {
                    "authorId": "143728483",
                    "name": "A. Galstyan"
                }
            ]
        },
        {
            "paperId": "db40c7a2ae4bff0063ef073a4e204c28ea851481",
            "title": "The Unequal Opportunities of Large Language Models: Examining Demographic Biases in Job Recommendations by ChatGPT and LLaMA",
            "abstract": "Warning: This paper discusses and contains content that is offensive or upsetting. Large Language Models (LLMs) have seen widespread deployment in various real-world applications. Understanding these biases is crucial to comprehend the potential downstream consequences when using LLMs to make decisions, particularly for historically disadvantaged groups. In this work, we propose a simple method for analyzing and comparing demographic bias in LLMs, through the lens of job recommendations. We demonstrate the effectiveness of our method by measuring intersectional biases within ChatGPT and LLaMA, two cutting-edge LLMs. Our experiments primarily focus on uncovering gender identity and nationality bias; however, our method can be extended to examine biases associated with any intersection of demographic identities. We identify distinct biases in both models toward various demographic identities, such as both models consistently suggesting low-paying jobs for Mexican workers or preferring to recommend secretarial roles to women. Our study highlights the importance of measuring the bias of LLMs in downstream applications to understand the potential for harm and inequitable outcomes. Our code is available at https://github.com/Abel2Code/Unequal-Opportunities-of-LLMs.",
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "authors": [
                {
                    "authorId": "2071206993",
                    "name": "A. Salinas"
                },
                {
                    "authorId": "2205907589",
                    "name": "Parth Vipul Shah"
                },
                {
                    "authorId": "35633657",
                    "name": "Yuzhong Huang"
                },
                {
                    "authorId": "65960877",
                    "name": "R. McCormack"
                },
                {
                    "authorId": "2775559",
                    "name": "Fred Morstatter"
                }
            ]
        },
        {
            "paperId": "16de1cb7971ca2b0bcd463417e8f780d9b083b31",
            "title": "Assessing Scientific Research Papers with Knowledge Graphs",
            "abstract": "In recent decades, the growing scale of scientific research has led to numerous novel findings. Reproducing these findings is the foundation of future research. However, due to the complexity of experiments, manually assessing scientific research is laborious and time-intensive, especially in social and behavioral sciences. Although increasing reproducibility studies have garnered increased attention in the research community, there is still a lack of systematic ways for evaluating scientific research at scale. In this paper, we propose a novel approach towards automatically assessing scientific publications by constructing a knowledge graph (KG) that captures a holistic view of the research contributions. Specifically, during the KG construction, we combine information from two different perspectives: micro-level features that capture knowledge from published articles such as sample sizes, effect sizes, and experimental models, and macro-level features that comprise relationships between entities such as authorship and reference information. We then learn low-dimensional representations using language models and knowledge graph embeddings for entities (nodes in KGs), which are further used for the assessments. A comprehensive set of experiments on two benchmark datasets shows the usefulness of leveraging KGs for scoring scientific research.",
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "authors": [
                {
                    "authorId": "35329068",
                    "name": "Kexuan Sun"
                },
                {
                    "authorId": "2175275027",
                    "name": "Zhiqiang Qiu"
                },
                {
                    "authorId": "2071206993",
                    "name": "A. Salinas"
                },
                {
                    "authorId": "35633657",
                    "name": "Yuzhong Huang"
                },
                {
                    "authorId": "73037511",
                    "name": "Dong-Ho Lee"
                },
                {
                    "authorId": "2052360522",
                    "name": "Daniel M. Benjamin"
                },
                {
                    "authorId": "2775559",
                    "name": "Fred Morstatter"
                },
                {
                    "authorId": "2149473952",
                    "name": "Xiang Ren"
                },
                {
                    "authorId": "2073018730",
                    "name": "Kristina Lerman"
                },
                {
                    "authorId": "2634786",
                    "name": "J. Pujara"
                }
            ]
        },
        {
            "paperId": "0408b6b8de997aa611b20468aea9417a3b1b9088",
            "title": "Learning Where to Cut from Edited Videos",
            "abstract": "In this work we propose a new approach for accelerating the video editing process by identifying good moments in time to cut unedited videos. We first validate that there is indeed a consensus among human viewers about good and bad cut moments with a user study, and then formulate this problem as a classification task. In order to train for such a task, we propose a self-supervised scheme that only requires pre-existing edited videos for training, of which there is large and diverse data readily available. We then propose a contrastive learning framework to train a 3D ResNet model to predict good regions to cut. We validate our method with a second user study, which indicates that clips generated by our model are preferred over a number of baselines.",
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "authors": [
                {
                    "authorId": "35633657",
                    "name": "Yuzhong Huang"
                },
                {
                    "authorId": "2114140107",
                    "name": "Xue Bai"
                },
                {
                    "authorId": "39231399",
                    "name": "Oliver Wang"
                },
                {
                    "authorId": "1886612407",
                    "name": "Fabian Caba"
                },
                {
                    "authorId": "1696487",
                    "name": "A. Agarwala"
                }
            ]
        },
        {
            "paperId": "5bb3f0356f66ac94cb761795a5a658a1bcbe6add",
            "title": "Graph Embedding with Personalized Context Distribution",
            "abstract": "Graph representation learning embeds graph nodes in a low-dimensional latent space, which allows for mathematical operations on nodes using low-dimensional vectors for downstream tasks, such as link prediction, node classification, and recommendation. Traditional graph embedding methods rely on hyper-parameters to capture the rich variation hidden in the structure of real-world graphs. In many applications, it may not be computationally feasible to search for optimal hyper-parameters. In this work, built on WatchYourStep which a graph embedding method leveraging graph attention, we propose a method that utilizes node-personalized context attention to capture the local variation in a graph structure. Specifically, we replace the shared context distribution among nodes with learnable personalized context distribution for each node. We evaluate our model on seven real-world graphs and show that our method outperforms the state-of-the-art baselines on both link prediction and node classification tasks. We further analyze the learned node context distribution to provide insights into its connection to graph structural properties.",
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "authors": [
                {
                    "authorId": "2110180772",
                    "name": "Di Huang"
                },
                {
                    "authorId": "2116308648",
                    "name": "Zihao He"
                },
                {
                    "authorId": "35633657",
                    "name": "Yuzhong Huang"
                },
                {
                    "authorId": "35329068",
                    "name": "Kexuan Sun"
                },
                {
                    "authorId": "1389570466",
                    "name": "Sami Abu-El-Haija"
                },
                {
                    "authorId": "2271808",
                    "name": "Bryan Perozzi"
                },
                {
                    "authorId": "1782658",
                    "name": "Kristina Lerman"
                },
                {
                    "authorId": "2775559",
                    "name": "Fred Morstatter"
                },
                {
                    "authorId": "143728483",
                    "name": "A. Galstyan"
                }
            ]
        },
        {
            "paperId": "7377982e58702e0f44beff2c00ab2d32825cf557",
            "title": "Fast Retinomorphic Event-Driven Representations for Video Gameplay and Action Recognition",
            "abstract": "Good temporal representations are crucial for video understanding, and the state-of-the-art video recognition framework is based on two-stream networks. In such framework, besides the regular ConvNets responsible for RGB frame inputs, a second network is introduced to handle the temporal representation, usually the optical flow (OF). However, OF or other task-oriented flow is computationally costly, and is thus typically pre-computed. Critically, this prevents the two-stream approach from being applied to reinforcement learning (RL) applications such as video game playing, where the next state depends on current state and action choices. Inspired by the early vision systems of mammals and insects, we propose a fast event-driven representation (EDR) that models several major properties of early retinal circuits: (1) logarithmic input response, (2) multi-timescale temporal smoothing to filter noise, and (3) bipolar (ON/OFF) pathways for primitive event detection. Trading off the directional information for fast speed ($>$9000 fps), EDR enables fast real-time inference/learning in video applications that require interaction between an agent and the world such as game-playing, virtual robotics, and domain adaptation. In this vein, we use EDR to demonstrate performance improvements over state-of-the-art reinforcement learning algorithms for Atari games, something that has not been possible with pre-computed OF. Moreover, with UCF-101 video action recognition experiments, we show that EDR performs near state-of-the-art in accuracy while achieving a \u00a01,500x speedup in input representation processing, as compared to optical flow.",
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "authors": [
                {
                    "authorId": "31586818",
                    "name": "H. G. Chen"
                },
                {
                    "authorId": "8133623",
                    "name": "Wanjia Liu"
                },
                {
                    "authorId": "46186660",
                    "name": "Rishab Goel"
                },
                {
                    "authorId": "2492444",
                    "name": "R. Lua"
                },
                {
                    "authorId": "2073395987",
                    "name": "Siddharth Mittal"
                },
                {
                    "authorId": "35633657",
                    "name": "Yuzhong Huang"
                },
                {
                    "authorId": "145280967",
                    "name": "A. Veeraraghavan"
                },
                {
                    "authorId": "46463998",
                    "name": "Ankit B. Patel"
                }
            ]
        },
        {
            "paperId": "8bf33ce439a1361caa2d09ac9cd9646efdd3984f",
            "title": "Anchor Attention for Hybrid Crowd Forecasts Aggregation",
            "abstract": "Forecasting the future is a notoriously difficult task. To overcome this challenge, state-of-the-art forecasting platforms are \"hybridized\", they gather forecasts from a crowd of humans, as well as one or more machine models. However, an open challenge remains in how to optimally combine forecasts from these pools into a single forecast. We proposed anchor attention for this type of sequence summary problem. Each forecast is represented by a trainable embedding vector, and use computed anchor attention score as the combined weight. We evaluate our approach using data from real-world forecasting tournaments, and show that our method outperforms the current state-of-the-art aggregation approaches.",
            "fieldsOfStudy": [
                "Computer Science",
                "Mathematics"
            ],
            "authors": [
                {
                    "authorId": "35633657",
                    "name": "Yuzhong Huang"
                },
                {
                    "authorId": "2919118",
                    "name": "A. Abeliuk"
                },
                {
                    "authorId": "2775559",
                    "name": "Fred Morstatter"
                },
                {
                    "authorId": "47919380",
                    "name": "P. Atanasov"
                },
                {
                    "authorId": "143728483",
                    "name": "A. Galstyan"
                }
            ]
        },
        {
            "paperId": "9f4f84c1fd1c835ebc02d5674922e9c0701cb95f",
            "title": "Statistical Equity: A Fairness Classification Objective",
            "abstract": "Machine learning systems have been shown to propagate the societal errors of the past. In light of this, a wealth of research focuses on designing solutions that are \"fair.\" Even with this abundance of work, there is no singular definition of fairness, mainly because fairness is subjective and context dependent. We propose a new fairness definition, motivated by the principle of equity, that considers existing biases in the data and attempts to make equitable decisions that account for these previous historical biases. We formalize our definition of fairness, and motivate it with its appropriate contexts. Next, we operationalize it for equitable classification. We perform multiple automatic and human evaluations to show the effectiveness of our definition and demonstrate its utility for aspects of fairness, such as the feedback loop.",
            "fieldsOfStudy": [
                "Computer Science",
                "Mathematics"
            ],
            "authors": [
                {
                    "authorId": "51997673",
                    "name": "Ninareh Mehrabi"
                },
                {
                    "authorId": "35633657",
                    "name": "Yuzhong Huang"
                },
                {
                    "authorId": "2775559",
                    "name": "Fred Morstatter"
                }
            ]
        },
        {
            "paperId": "0b0d2fef55d3b0d39ef19e0086516cfaeef73a76",
            "title": "Efficient Text Classification Using Tree-structured Multi-linear Principal Component Analysis",
            "abstract": "A novel text data dimension reduction technique, called the tree-structured multi-linear principal component analysis (TMPCA), is proposed in this work. Being different from traditional text dimension reduction methods that deal with the word-level representation, the TMPCA technique reduces the dimension of input sequences and sentences to simplify the following text classification tasks. It is shown mathematically and experimentally that the TMPCA tool demands much lower complexity (and, hence, less computing power) than the ordinary principal component analysis (PCA). Furthermore, it is demonstrated by experimental results that the support vector machine (SVM) method applied to the TMPCA-processed data achieves commensurable or better performance than the state-of-the-art recurrent neural network (RNN) approach.",
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "authors": [
                {
                    "authorId": "3368711",
                    "name": "Yuanhang Su"
                },
                {
                    "authorId": "35633657",
                    "name": "Yuzhong Huang"
                },
                {
                    "authorId": "9363144",
                    "name": "C.-C. Jay Kuo"
                }
            ]
        },
        {
            "paperId": "68fe62729939700b470c29326c1057853c000abe",
            "title": "Fast Retinomorphic Event Stream for Video Recognition and Reinforcement Learning",
            "abstract": "Good temporal representations are crucial for video understanding, and the state-of-the-art video recognition framework is based on two-stream networks. In such framework, besides the regular ConvNets responsible for RGB frame inputs, a second network is introduced to handle the temporal representation, usually the optical flow (OF). However, OF or other task-oriented flow is computationally costly, and is thus typically pre-computed. Critically, this prevents the two-stream approach from being applied to reinforcement learning (RL) applications such as video game playing, where the next state depends on current state and action choices. Inspired by the early vision systems of mammals and insects, we propose a fast event-driven representation (EDR) that models several major properties of early retinal circuits: (1) logarithmic input response, (2) multi-timescale temporal smoothing to filter noise, and (3) bipolar (ON/OFF) pathways for primitive event detection[12]. Trading off the directional information for fast speed (> 9000 fps), EDR en-ables fast real-time inference/learning in video applications that require interaction between an agent and the world such as game-playing, virtual robotics, and domain adaptation. In this vein, we use EDR to demonstrate performance improvements over state-of-the-art reinforcement learning algorithms for Atari games, something that has not been possible with pre-computed OF. Moreover, with UCF-101 video action recognition experiments, we show that EDR performs near state-of-the-art in accuracy while achieving a 1,500x speedup in input representation processing, as compared to optical flow.",
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "authors": [
                {
                    "authorId": "8133623",
                    "name": "Wanjia Liu"
                },
                {
                    "authorId": "31586818",
                    "name": "H. G. Chen"
                },
                {
                    "authorId": "46186660",
                    "name": "Rishab Goel"
                },
                {
                    "authorId": "35633657",
                    "name": "Yuzhong Huang"
                },
                {
                    "authorId": "145280967",
                    "name": "A. Veeraraghavan"
                },
                {
                    "authorId": "2115628251",
                    "name": "Ankit B. Patel"
                }
            ]
        }
    ]
}