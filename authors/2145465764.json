{
    "authorId": "2145465764",
    "papers": [
        {
            "paperId": "1fdc07b3152bd0e3213b8122224fc96f3070f2f5",
            "title": "Improved Neural Network with Spatial Pyramid Pooling and Online Datasets Preprocessing for Underwater Target Detection Based on Side Scan Sonar Imagery",
            "abstract": "Fast and high-accuracy detection of underwater targets based on side scan sonar images has great potential for marine fisheries, underwater security, marine mapping, underwater engineering and other applications. The following problems, however, must be addressed when using low-resolution side scan sonar images for underwater target detection: (1) the detection performance is limited due to the restriction on the input of multi-scale images; (2) the widely used deep learning algorithms have a low detection effect due to their complex convolution layer structures; (3) the detection performance is limited due to insufficient model complexity in training process; and (4) the number of samples is not enough because of the bad dataset preprocessing methods. To solve these problems, an improved neural network for underwater target detection\u2014which is based on side scan sonar images and fully utilizes spatial pyramid pooling and online dataset preprocessing based on the You Look Only Once version three (YOLO V3) algorithm\u2014is proposed. The methodology of the proposed approach is as follows: (1) the AlexNet, GoogleNet, VGGNet and the ResNet networks and an adopted YOLO V3 algorithm were the backbone networks. The structure of the YOLO V3 model is more mature and compact and has higher target detection accuracy and better detection efficiency than the other models; (2) spatial pyramid pooling was added at the end of the convolution layer to improve detection performance. Spatial pyramid pooling breaks the scale restrictions when inputting images to improve feature extraction because spatial pyramid pooling enables the backbone network to learn faster at high accuracy; and (3) online dataset preprocessing based on YOLO V3 with spatial pyramid pooling increases the number of samples and improves the complexity of the model to further improve detection process performance. Three-side scan imagery datasets were used for training and were tested in experiments. The quantitative evaluation using Accuracy, Recall, Precision, mAP and F1-Score metrics indicates that: for the AlexNet, GoogleNet, VGGNet and ResNet algorithms, when spatial pyramid pooling is added to their backbone networks, the average detection accuracy of the three sets of data was improved by 2%, 4%, 2% and 2%, respectively, as compared to their original formulations. Compared with the original YOLO V3 model, the proposed ODP+YOLO V3+SPP underwater target detection algorithm model has improved detection performance through the mAP qualitative evaluation index has increased by 6%, the Precision qualitative evaluation index has increased by 13%, and the detection efficiency has increased by 9.34%. These demonstrate that adding spatial pyramid pooling and online dataset preprocessing can improve the target detection accuracy of these commonly used algorithms. The proposed, improved neural network with spatial pyramid pooling and online dataset preprocessing based on the YOLO V3 method achieves the highest scores for underwater target detection results for sunken ships, fish flocks and seafloor topography, with mAP scores of 98%, 91% and 96% for the above three kinds of datasets, respectively.",
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "authors": [
                {
                    "authorId": "2145465764",
                    "name": "Jinrui Li"
                },
                {
                    "authorId": "2122090299",
                    "name": "Libin Chen"
                },
                {
                    "authorId": "2115733546",
                    "name": "Jian Shen"
                },
                {
                    "authorId": "2018051",
                    "name": "Xiongwu Xiao"
                },
                {
                    "authorId": "2110654417",
                    "name": "Xiaosong Liu"
                },
                {
                    "authorId": "2109230283",
                    "name": "Xin Sun"
                },
                {
                    "authorId": "144129720",
                    "name": "Xiao Wang"
                },
                {
                    "authorId": "39598299",
                    "name": "Deren Li"
                }
            ]
        },
        {
            "paperId": "673867133e2f7b96b0ba53c5c7eefc88f8bbb368",
            "title": "Mean Inflection Point Distance: Artificial Intelligence Mapping Accuracy Evaluation Index - An Experimental Case Study of Building Extraction",
            "abstract": "Mapping is a fundamental application of remote sensing images, and the accurate evaluation of remote sensing image information extraction using artificial intelligence is critical. However, the existing evaluation method, based on Intersection over Union (IoU), is limited in evaluating the extracted information\u2019s boundary accuracy. It is insufficient for determining mapping accuracy. Furthermore, traditional remote sensing mapping methods struggle to match the inflection points encountered in artificial intelligence contour extraction. In order to address these issues, we propose the mean inflection point distance (MPD) as a new segmentation evaluation method. MPD can accurately calculate error values and solve the problem of multiple inflection points, which traditional remote sensing mapping cannot match. We tested three algorithms on the Vaihingen dataset: Mask R-CNN, Swin Transformer, and PointRend. The results show that MPD is highly sensitive to mapping accuracy, can calculate error values accurately, and is applicable for different scales of mapping accuracy while maintaining high visual consistency. This study helps to assess the accuracy of automatic mapping using remote sensing artificial intelligence.",
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "authors": [
                {
                    "authorId": "2213807889",
                    "name": "Ding Yu"
                },
                {
                    "authorId": "49779418",
                    "name": "Aihua Li"
                },
                {
                    "authorId": "2145465764",
                    "name": "Jinrui Li"
                },
                {
                    "authorId": "2320711903",
                    "name": "Yan Xu"
                },
                {
                    "authorId": "2212919758",
                    "name": "Yinping Long"
                }
            ]
        },
        {
            "paperId": "5556781cd152c74d539b56d564475d060b081bf4",
            "title": "Functionality Recognition on Binary Code with Neural Representation Learning",
            "abstract": "The functionality recognition of binary code has important application value in malware analysis, software forensics, binary code similarity analysis and other applications. Most of the existing methods are based on source code or machine learning strategies to carry out program similarity analysis, and this similarity analysis is also applied to a pair of programs, there are limitations in detection accuracy and quantity. Inspired by the recent great success of neural networks and representation learning in various program analysis tasks, We propose NPFI to analyze the binary code of the program and identify its functionality from the perspective of assembly instruction sequence. To evaluate the performance of NPFI, we built a large dataset consisting of 39,000 programs from six different categories collected from Google Code Jam. A large number of experiments show that the accuracy of NPFI in binary code function recognition can reach 95.8%, which is much better than the existing methods.",
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "authors": [
                {
                    "authorId": "2475464",
                    "name": "Zhenzhou Tian"
                },
                {
                    "authorId": "2145465764",
                    "name": "Jinrui Li"
                },
                {
                    "authorId": "2156126082",
                    "name": "Peng Xue"
                },
                {
                    "authorId": "2136088366",
                    "name": "Jie Tian"
                },
                {
                    "authorId": "2053590758",
                    "name": "H. Mao"
                },
                {
                    "authorId": "2108605757",
                    "name": "Yaqian Huang"
                }
            ]
        }
    ]
}