{
    "authorId": "1760642",
    "papers": [
        {
            "paperId": "25bc9944aba4a047e7dfea7e5ceb1708d541b87e",
            "title": "Fairness in AI: challenges in bridging the gap between algorithms and law",
            "abstract": "In this paper we examine algorithmic fairness from the perspective of law aiming to identify best practices and strategies for the specification and adoption of fairness definitions and algorithms in real-world systems and use cases. We start by providing a brief introduction of current anti-discrimination law in the European Union and the United States and discussing the concepts of bias and fairness from an legal and ethical viewpoint. We then proceed by presenting a set of algorithmic fairness definitions by example, aiming to communicate their objectives to non-technical audiences. Then, we introduce a set of core criteria that need to be taken into account when selecting a specific fairness definition for real-world use case applications. Finally, we enumerate a set of key considerations and best practices for the design and employment of fairness methods on real-world AI applications.",
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "authors": [
                {
                    "authorId": "40397337",
                    "name": "G. Giannopoulos"
                },
                {
                    "authorId": "2298966484",
                    "name": "Maria Psalla"
                },
                {
                    "authorId": "3434260",
                    "name": "Loukas Kavouras"
                },
                {
                    "authorId": "1760642",
                    "name": "Dimitris Sacharidis"
                },
                {
                    "authorId": "2298966095",
                    "name": "Jakub Marecek"
                },
                {
                    "authorId": "2298966283",
                    "name": "German M Matilla"
                },
                {
                    "authorId": "2298897005",
                    "name": "Ioannis Emiris"
                }
            ]
        },
        {
            "paperId": "4de94c928ad1d7c5b481178dd4f31c3a7570be49",
            "title": "FALE: Fairness-Aware ALE Plots for Auditing Bias in Subgroups",
            "abstract": "Fairness is steadily becoming a crucial requirement of Machine Learning (ML) systems. A particularly important notion is subgroup fairness, i.e., fairness in subgroups of individuals that are defined by more than one attributes. Identifying bias in subgroups can become both computationally challenging, as well as problematic with respect to comprehensibility and intuitiveness of the finding to end users. In this work we focus on the latter aspects; we propose an explainability method tailored to identifying potential bias in subgroups and visualizing the findings in a user friendly manner to end users. In particular, we extend the ALE plots explainability method, proposing FALE (Fairness aware Accumulated Local Effects) plots, a method for measuring the change in fairness for an affected population corresponding to different values of a feature (attribute). We envision FALE to function as an efficient, user friendly, comprehensible and reliable first-stage tool for identifying subgroups with potential bias issues.",
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "authors": [
                {
                    "authorId": "40397337",
                    "name": "G. Giannopoulos"
                },
                {
                    "authorId": "1760642",
                    "name": "Dimitris Sacharidis"
                },
                {
                    "authorId": "2298899402",
                    "name": "Nikolas Theologitis"
                },
                {
                    "authorId": "3434260",
                    "name": "Loukas Kavouras"
                },
                {
                    "authorId": "2298897005",
                    "name": "Ioannis Emiris"
                }
            ]
        },
        {
            "paperId": "7442bc53a1bb7916b33b7ea3323084b836ed04b7",
            "title": "GLANCE: Global Actions in a Nutshell for Counterfactual Explainability",
            "abstract": "Counterfactual explanations have emerged as an important tool to understand, debug, and audit complex machine learning models. To offer global counterfactual explainability, state-of-the-art methods construct summaries of local explanations, offering a trade-off among conciseness, counterfactual effectiveness, and counterfactual cost or burden imposed on instances. In this work, we provide a concise formulation of the problem of identifying global counterfactuals and establish principled criteria for comparing solutions, drawing inspiration from Pareto dominance. We introduce innovative algorithms designed to address the challenge of finding global counterfactuals for either the entire input space or specific partitions, employing clustering and decision trees as key components. Additionally, we conduct a comprehensive experimental evaluation, considering various instances of the problem and comparing our proposed algorithms with state-of-the-art methods. The results highlight the consistent capability of our algorithms to generate meaningful and interpretable global counterfactual explanations.",
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "authors": [
                {
                    "authorId": "2298897005",
                    "name": "Ioannis Emiris"
                },
                {
                    "authorId": "2273195757",
                    "name": "Dimitris Fotakis"
                },
                {
                    "authorId": "40397337",
                    "name": "G. Giannopoulos"
                },
                {
                    "authorId": "2303655763",
                    "name": "Dimitrios Gunopulos"
                },
                {
                    "authorId": "3434260",
                    "name": "Loukas Kavouras"
                },
                {
                    "authorId": "2297771041",
                    "name": "Kleopatra Markou"
                },
                {
                    "authorId": "2139143386",
                    "name": "Eleni Psaroudaki"
                },
                {
                    "authorId": "150081157",
                    "name": "D. Rontogiannis"
                },
                {
                    "authorId": "1760642",
                    "name": "Dimitris Sacharidis"
                },
                {
                    "authorId": "2220631614",
                    "name": "Nikolaos Theologitis"
                },
                {
                    "authorId": "2082489302",
                    "name": "Dimitrios Tomaras"
                },
                {
                    "authorId": "2220631616",
                    "name": "Konstantinos Tsopelas"
                }
            ]
        },
        {
            "paperId": "af034d8aee20d34dc471c00ddb95ca71c2038651",
            "title": "AIDE: Antithetical, Intent-based, and Diverse Example-Based Explanations",
            "abstract": "For many use-cases, it is often important to explain the prediction of a black-box model by identifying the most influential training data samples. Existing approaches lack customization for user intent and often provide a homogeneous set of explanation samples, failing to reveal the model's reasoning from different angles. In this paper, we propose AIDE, an approach for providing antithetical (i.e., contrastive), intent-based, diverse explanations for opaque and complex models. AIDE distinguishes three types of explainability intents: interpreting a correct, investigating a wrong, and clarifying an ambiguous prediction. For each intent, AIDE selects an appropriate set of influential training samples that support or oppose the prediction either directly or by contrast. To provide a succinct summary, AIDE uses diversity-aware sampling to avoid redundancy and increase coverage of the training data. We demonstrate the effectiveness of AIDE on image and text classification tasks, in three ways: quantitatively, assessing correctness and continuity; qualitatively, comparing anecdotal evidence from AIDE and other example-based approaches; and via a user study, evaluating multiple aspects of AIDE. The results show that AIDE addresses the limitations of existing methods and exhibits desirable traits for an explainability method.",
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "authors": [
                {
                    "authorId": "2312397178",
                    "name": "Ikhtiyor Nematov"
                },
                {
                    "authorId": "1760642",
                    "name": "Dimitris Sacharidis"
                },
                {
                    "authorId": "47125649",
                    "name": "Tomer Sagi"
                },
                {
                    "authorId": "47061445",
                    "name": "K. Hose"
                }
            ]
        },
        {
            "paperId": "bb629847e0cedcdc224703376fc50201d1e6c032",
            "title": "Mobility Data Science: Perspectives and Challenges",
            "abstract": "Mobility data captures the locations of moving objects such as humans, animals, and cars. With the availability of Global Positioning System (GPS)\u2013equipped mobile devices and other inexpensive location-tracking technologies, mobility data is collected ubiquitously. In recent years, the use of mobility data has demonstrated a significant impact in various domains, including traffic management, urban planning, and health sciences. In this article, we present the domain of mobility data science. Towards a unified approach to mobility data science, we present a pipeline having the following components: mobility data collection, cleaning, analysis, management, and privacy. For each of these components, we explain how mobility data science differs from general data science, we survey the current state-of-the-art, and describe open challenges for the research community in the coming years.",
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "authors": [
                {
                    "authorId": "1756679",
                    "name": "M. Mokbel"
                },
                {
                    "authorId": "2268766982",
                    "name": "Mahmoud Sakr"
                },
                {
                    "authorId": "2252073675",
                    "name": "Li Xiong"
                },
                {
                    "authorId": "2260704425",
                    "name": "Andreas Z\u00fcfle"
                },
                {
                    "authorId": "2223124284",
                    "name": "Jussara Almeida"
                },
                {
                    "authorId": "2265874763",
                    "name": "Taylor Anderson"
                },
                {
                    "authorId": "1709661",
                    "name": "W. Aref"
                },
                {
                    "authorId": "50663909",
                    "name": "G. Andrienko"
                },
                {
                    "authorId": "1780833",
                    "name": "N. Andrienko"
                },
                {
                    "authorId": "1596101114",
                    "name": "Yang Cao"
                },
                {
                    "authorId": "2290927435",
                    "name": "Sanjay Chawla"
                },
                {
                    "authorId": "2073538844",
                    "name": "R. Cheng"
                },
                {
                    "authorId": "2249901748",
                    "name": "P. Chrysanthis"
                },
                {
                    "authorId": "48055813",
                    "name": "Xiqi Fei"
                },
                {
                    "authorId": "2182067502",
                    "name": "Gabriel Ghinita"
                },
                {
                    "authorId": "2266847299",
                    "name": "Anita Graser"
                },
                {
                    "authorId": "1736832",
                    "name": "D. Gunopulos"
                },
                {
                    "authorId": "2249956546",
                    "name": "C. S. Jensen"
                },
                {
                    "authorId": "2198052325",
                    "name": "Joon-Seok Kim"
                },
                {
                    "authorId": "2290927320",
                    "name": "Peer Kr\u00f6ger Kyoung-Sook Kim"
                },
                {
                    "authorId": "2265841517",
                    "name": "John Krumm"
                },
                {
                    "authorId": "2290917145",
                    "name": "Johannes Lauer"
                },
                {
                    "authorId": "143811079",
                    "name": "A. Magdy"
                },
                {
                    "authorId": "2242562854",
                    "name": "Mario A. Nascimento"
                },
                {
                    "authorId": "1797879",
                    "name": "S. Ravada"
                },
                {
                    "authorId": "2270167726",
                    "name": "Matthias Renz"
                },
                {
                    "authorId": "1760642",
                    "name": "Dimitris Sacharidis"
                },
                {
                    "authorId": "2290927314",
                    "name": "Flora Salim"
                },
                {
                    "authorId": "1769421",
                    "name": "Mohamed Sarwat"
                },
                {
                    "authorId": "2223117689",
                    "name": "M. Schoemans"
                },
                {
                    "authorId": "2258957849",
                    "name": "Cyrus Shahabi"
                },
                {
                    "authorId": "2238220399",
                    "name": "Bettina Speckmann"
                },
                {
                    "authorId": "3346327",
                    "name": "E. Tanin"
                },
                {
                    "authorId": "2061528071",
                    "name": "Xu Teng"
                },
                {
                    "authorId": "2182067387",
                    "name": "Yannis Theodoridis"
                },
                {
                    "authorId": "2275821767",
                    "name": "Kristian Torp"
                },
                {
                    "authorId": "1776969",
                    "name": "Goce Trajcevski"
                },
                {
                    "authorId": "2285578947",
                    "name": "Mar van Kreveld"
                },
                {
                    "authorId": "1711445",
                    "name": "C. Wenk"
                },
                {
                    "authorId": "2183364647",
                    "name": "Martin Werner"
                },
                {
                    "authorId": "2223022273",
                    "name": "Raymond E. Wong"
                },
                {
                    "authorId": "2182962401",
                    "name": "Song Wu"
                },
                {
                    "authorId": "2291049801",
                    "name": "Jianqiu Xu"
                },
                {
                    "authorId": "2290927453",
                    "name": "Moustafa Youssef"
                },
                {
                    "authorId": "66975603",
                    "name": "Demetris Zeinalipour"
                },
                {
                    "authorId": "2291074728",
                    "name": "Mengxuan Zhang"
                }
            ]
        },
        {
            "paperId": "f2c5e65ee7783731490c78ced65d3cbb62ce3d3e",
            "title": "The Susceptibility of Example-Based Explainability Methods to Class Outliers",
            "abstract": "This study explores the impact of class outliers on the effectiveness of example-based explainability methods for black-box machine learning models. We reformulate existing explainability evaluation metrics, such as correctness and relevance, specifically for example-based methods, and introduce a new metric, distinguishability. Using these metrics, we highlight the shortcomings of current example-based explainability methods, including those who attempt to suppress class outliers. We conduct experiments on two datasets, a text classification dataset and an image classification dataset, and evaluate the performance of four state-of-the-art explainability methods. Our findings underscore the need for robust techniques to tackle the challenges posed by class outliers.",
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "authors": [
                {
                    "authorId": "2312397178",
                    "name": "Ikhtiyor Nematov"
                },
                {
                    "authorId": "1760642",
                    "name": "Dimitris Sacharidis"
                },
                {
                    "authorId": "47125649",
                    "name": "Tomer Sagi"
                },
                {
                    "authorId": "47061445",
                    "name": "K. Hose"
                }
            ]
        },
        {
            "paperId": "11c26cfcee4adeb81fd3c0ea81fc27877128352a",
            "title": "Towards Mobility Data Science (Vision Paper)",
            "abstract": "Mobility data captures the locations of moving objects such as humans, animals, and cars. With the availability of GPS-equipped mobile devices and other inexpensive location-tracking technologies, mobility data is collected ubiquitously. In recent years, the use of mobility data has demonstrated significant impact in various domains including traffic management, urban planning, and health sciences. In this paper, we present the emerging domain of mobility data science. Towards a unified approach to mobility data science, we envision a pipeline having the following components: mobility data collection, cleaning, analysis, management, and privacy. For each of these components, we explain how mobility data science differs from general data science, we survey the current state of the art and describe open challenges for the research community in the coming years.",
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "authors": [
                {
                    "authorId": "1756679",
                    "name": "M. Mokbel"
                },
                {
                    "authorId": "152843469",
                    "name": "M. Sakr"
                },
                {
                    "authorId": "47607633",
                    "name": "Li-Qiong Xiong"
                },
                {
                    "authorId": "1393273470",
                    "name": "Andreas Zufle"
                },
                {
                    "authorId": "2223124284",
                    "name": "Jussara Almeida"
                },
                {
                    "authorId": "1709661",
                    "name": "W. Aref"
                },
                {
                    "authorId": "50663909",
                    "name": "G. Andrienko"
                },
                {
                    "authorId": "1780833",
                    "name": "N. Andrienko"
                },
                {
                    "authorId": "1596101114",
                    "name": "Yang Cao"
                },
                {
                    "authorId": "50793091",
                    "name": "S. Chawla"
                },
                {
                    "authorId": "2073538844",
                    "name": "R. Cheng"
                },
                {
                    "authorId": "1728643",
                    "name": "Panos K. Chrysanthis"
                },
                {
                    "authorId": "48055813",
                    "name": "Xiqi Fei"
                },
                {
                    "authorId": "3277872",
                    "name": "Gabriel Ghinita"
                },
                {
                    "authorId": "32324949",
                    "name": "A. Graser"
                },
                {
                    "authorId": "1736832",
                    "name": "D. Gunopulos"
                },
                {
                    "authorId": "144572233",
                    "name": "C. Jensen"
                },
                {
                    "authorId": "2183485901",
                    "name": "Joon-Sook Kim"
                },
                {
                    "authorId": "2144390213",
                    "name": "Kyoung-Sook Kim"
                },
                {
                    "authorId": "152431109",
                    "name": "Peer Kr\u0151ger"
                },
                {
                    "authorId": "79027713",
                    "name": "John Krumm"
                },
                {
                    "authorId": "2381835",
                    "name": "Johannes Lauer"
                },
                {
                    "authorId": "143811079",
                    "name": "A. Magdy"
                },
                {
                    "authorId": "144977963",
                    "name": "M. Nascimento"
                },
                {
                    "authorId": "1797879",
                    "name": "S. Ravada"
                },
                {
                    "authorId": "1723035",
                    "name": "M. Renz"
                },
                {
                    "authorId": "1760642",
                    "name": "Dimitris Sacharidis"
                },
                {
                    "authorId": "1773086",
                    "name": "C. Shahabi"
                },
                {
                    "authorId": "144954586",
                    "name": "Flora D. Salim"
                },
                {
                    "authorId": "1769421",
                    "name": "Mohamed Sarwat"
                },
                {
                    "authorId": "30749282",
                    "name": "Maxime Schoemans"
                },
                {
                    "authorId": "1699605",
                    "name": "B. Speckmann"
                },
                {
                    "authorId": "3346327",
                    "name": "E. Tanin"
                },
                {
                    "authorId": "1714996",
                    "name": "Y. Theodoridis"
                },
                {
                    "authorId": "2380832",
                    "name": "K. Torp"
                },
                {
                    "authorId": "1776969",
                    "name": "Goce Trajcevski"
                },
                {
                    "authorId": "1796774",
                    "name": "M. V. Kreveld"
                },
                {
                    "authorId": "1711445",
                    "name": "C. Wenk"
                },
                {
                    "authorId": "2183364647",
                    "name": "Martin Werner"
                },
                {
                    "authorId": "2223022273",
                    "name": "Raymond E. Wong"
                },
                {
                    "authorId": "2182962401",
                    "name": "Song Wu"
                },
                {
                    "authorId": "46372740",
                    "name": "Jianqiu Xu"
                },
                {
                    "authorId": "144711492",
                    "name": "M. Youssef"
                },
                {
                    "authorId": "66975603",
                    "name": "Demetris Zeinalipour"
                },
                {
                    "authorId": "3451341",
                    "name": "Mengxuan Zhang"
                },
                {
                    "authorId": "2223118920",
                    "name": "Esteban Zim'anyi"
                }
            ]
        },
        {
            "paperId": "463dc7fb9d9ea3e4c14a7595baaa8f184a88f332",
            "title": "3rd International Workshop on Scientific Knowledge Representation, Discovery, and Assessment (Sci-K 2023)",
            "abstract": "The International Workshop on Scientific Knowledge: Representation, Discovery, and Assessment (Sci-K 2023) is now running its third edition. The Sci-K workshop is a venue that brings together researchers and practitioners from different disciplines (including, but not limited to, Digital Libraries, Information Extraction, Machine Learning, Semantic Web, Knowledge Engineering, Natural Language Processing, Scholarly Communication, Science of Science, Scientometrics and Bibliometrics), as well as professionals from the industry, to explore innovative solutions and ideas for the production and consumption of Scientific Knowledge Graphs and assessing the research impact. The workshop has called for high-quality submissions around the three main themes of research, related to scientific knowledge: representation, discovery, and assessment. In response to the call for papers, the workshop has received outstanding submissions from researchers in 15 different countries: United States of America, Germany, United Kingdom, Ireland, Sweden, Canada, India, Brazil, Australia, Italy, Slovenia, Bulgaria, Denmark, Ethiopia, and Norway. Each paper was reviewed at least by three members of the programme committee. Given the quality and the interesting topics covered by the submissions, we accepted 10 papers. Sci-K 2023 builds on two previous successful editions and keeps attracting a combined pool of attendees. The first edition (Sci-K 2021), was held on 13 April 2021 in conjunction with The Web Conference 2021. Its program consisted of two keynote talks, and the presentation of 11 research papers. The second edition (Sci-K 2022) took place on the 26 April 2022 at The Web Conference 2022. The program included the presentation of 5 long papers, 4 short papers, 2 vision papers, 2 keynote speeches and a panel on \u201cWhat\u2019s next after Microsoft Academic Graph?\u201d. The full program as well as the list of accepted papers can be found on the Sci-K website: https://sci-k.github.io/2023/.",
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "authors": [
                {
                    "authorId": "40520756",
                    "name": "Angelo Salatino"
                },
                {
                    "authorId": "80354842",
                    "name": "Yushuai Bu"
                },
                {
                    "authorId": "2111237412",
                    "name": "Ying Ding"
                },
                {
                    "authorId": "2063949950",
                    "name": "\u00c1gnes Horv\u00e1t"
                },
                {
                    "authorId": "2145587478",
                    "name": "Yong Huang"
                },
                {
                    "authorId": "47842495",
                    "name": "Meijun Liu"
                },
                {
                    "authorId": "1799502",
                    "name": "P. Manghi"
                },
                {
                    "authorId": "2043406",
                    "name": "Andrea Mannocci"
                },
                {
                    "authorId": "2052329",
                    "name": "Francesco Osborne"
                },
                {
                    "authorId": "2183689460",
                    "name": "Daniel M. Romero"
                },
                {
                    "authorId": "1760642",
                    "name": "Dimitris Sacharidis"
                },
                {
                    "authorId": "3142706",
                    "name": "M. Teplitskiy"
                },
                {
                    "authorId": "1768540",
                    "name": "Thanasis Vergoulis"
                },
                {
                    "authorId": "2143633281",
                    "name": "Feng Xia"
                },
                {
                    "authorId": "49337746",
                    "name": "Yujia Zhai"
                }
            ]
        },
        {
            "paperId": "4b531e2e65ae2f8e989342fbe8e41d2822584be8",
            "title": "Fairness Aware Counterfactuals for Subgroups",
            "abstract": "In this work, we present Fairness Aware Counterfactuals for Subgroups (FACTS), a framework for auditing subgroup fairness through counterfactual explanations. We start with revisiting (and generalizing) existing notions and introducing new, more refined notions of subgroup fairness. We aim to (a) formulate different aspects of the difficulty of individuals in certain subgroups to achieve recourse, i.e. receive the desired outcome, either at the micro level, considering members of the subgroup individually, or at the macro level, considering the subgroup as a whole, and (b) introduce notions of subgroup fairness that are robust, if not totally oblivious, to the cost of achieving recourse. We accompany these notions with an efficient, model-agnostic, highly parameterizable, and explainable framework for evaluating subgroup fairness. We demonstrate the advantages, the wide applicability, and the efficiency of our approach through a thorough experimental evaluation of different benchmark datasets.",
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "authors": [
                {
                    "authorId": "3434260",
                    "name": "Loukas Kavouras"
                },
                {
                    "authorId": "2220631616",
                    "name": "Konstantinos Tsopelas"
                },
                {
                    "authorId": "40397337",
                    "name": "G. Giannopoulos"
                },
                {
                    "authorId": "1760642",
                    "name": "Dimitris Sacharidis"
                },
                {
                    "authorId": "2139143386",
                    "name": "Eleni Psaroudaki"
                },
                {
                    "authorId": "2220631614",
                    "name": "Nikolaos Theologitis"
                },
                {
                    "authorId": "150081157",
                    "name": "D. Rontogiannis"
                },
                {
                    "authorId": "143995221",
                    "name": "Dimitris Fotakis"
                },
                {
                    "authorId": "1804042",
                    "name": "I. Emiris"
                }
            ]
        },
        {
            "paperId": "4e4eb9408d9b93d542373c560151e97212c700e5",
            "title": "Auditing for Spatial Fairness",
            "abstract": "This paper studies algorithmic fairness when the protected attribute is location. To handle protected attributes that are continuous, such as age or income, the standard approach is to discretize the domain into predefined groups, and compare algorithmic outcomes across groups. However, applying this idea to location raises concerns of gerrymandering and may introduce statistical bias. Prior work addresses these concerns but only for regularly spaced locations, while raising other issues, most notably its inability to discern regions that are likely to exhibit spatial unfairness. Similar to established notions of algorithmic fairness, we define spatial fairness as the statistical independence of outcomes from location. This translates into requiring that for each region of space, the distribution of outcomes is identical inside and outside the region. To allow for localized discrepancies in the distribution of outcomes, we compare how well two competing hypotheses explain the observed outcomes. The null hypothesis assumes spatial fairness, while the alternate allows different distributions inside and outside regions. Their goodness of fit is then assessed by a likelihood ratio test. If there is no significant difference in how well the two hypotheses explain the observed outcomes, we conclude that the algorithm is spatially fair.",
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "authors": [
                {
                    "authorId": "1760642",
                    "name": "Dimitris Sacharidis"
                },
                {
                    "authorId": "40397337",
                    "name": "G. Giannopoulos"
                },
                {
                    "authorId": "2325154",
                    "name": "George Papastefanatos"
                },
                {
                    "authorId": "12619004",
                    "name": "Kostas Stefanidis"
                }
            ]
        }
    ]
}