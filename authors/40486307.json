{
    "authorId": "40486307",
    "papers": [
        {
            "paperId": "72cab1b285d0c3c2e998684ba0fb96c94e739859",
            "title": "Firebolt: Weak Supervision Under Weaker Assumptions",
            "abstract": "Modern machine learning demands a large amount of training data. Weak supervision is a promising approach to meet this demand. It aggregates multiple labeling functions (LFs)\u2014noisy, user-provided labeling heuristics\u2014to rapidly and cheaply curate probabilistic labels for large-scale unlabeled data. However, standard assumptions in weak supervision\u2014such as user-speci\ufb01ed class balance, similar accuracy of an LF in classifying di\ufb00erent classes, and full knowledge of LF dependency at inference time\u2014might be undesirable in practice. In response, we present Fire-bolt, a new weak supervision framework that seeks to operate under weaker assumptions. In particular, Firebolt learns the class balance and class-speci\ufb01c accuracy of LFs jointly from unlabeled data. It carries out inference in an e\ufb03cient and interpretable manner. We analyze the parameter estimation error of Firebolt and characterize its impact on down-stream model performance. Furthermore, we show that on \ufb01ve publicly available datasets, Firebolt outperforms a state-of-the-art weak supervision method by up to 5.8 points in AUC. We also provide a case study in the production setting of a tech company, where a Firebolt-supervised model outperforms the existing weakly-supervised production model by 1.3 points in AUC and speeds up label model training and inference from one hour to three minutes.",
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "authors": [
                {
                    "authorId": null,
                    "name": "Zhaobin Kuang"
                },
                {
                    "authorId": "46256261",
                    "name": "Chidubem Arachie"
                },
                {
                    "authorId": "13674886",
                    "name": "Bangyong Liang"
                },
                {
                    "authorId": "145382418",
                    "name": "P. Narayana"
                },
                {
                    "authorId": "3186812",
                    "name": "Giulia DeSalvo"
                },
                {
                    "authorId": "49819634",
                    "name": "M. Quinn"
                },
                {
                    "authorId": "40486307",
                    "name": "Bert Huang"
                },
                {
                    "authorId": "2165806839",
                    "name": "Geoffrey Downs"
                },
                {
                    "authorId": "46285538",
                    "name": "Yang Yang"
                }
            ]
        },
        {
            "paperId": "b0b20b1bbbc0459508100e11feb6be571e977da5",
            "title": "Interpretable Engagement Models for MOOCs Using Hinge-Loss Markov Random Fields",
            "abstract": "Maintaining and cultivating student engagement is critical for learning. Understanding factors affecting student engagement can help in designing better courses and improving student retention. The large number of participants in massive open online courses (MOOCs) and data collected from their interactions on the MOOC open up avenues for studying student engagement at scale. In this work, we develop an interpretable statistical relational learning model for understanding student engagement in online courses using a complex combination of behavioral, linguistic, structural, and temporal cues. We show how to abstract student engagement types of active, passive, and disengagement as meaningful latent variables using logical rules in our model connecting student behavioral signals with student success in MOOCs. We demonstrate that the latent formulation for engagement helps in predicting two measures of student success: performance, their final grade in the course, and survival, their continued presence in the course till the end, across seven MOOCs. Furthermore in order to initiate better instructor interventions, we need to be able to predict student success early in the course. We demonstrate that we can predict student success early in the course reliably using the latent model. We also demonstrate the utility of our models in predicting student success in new courses, by training our models on one course and testing on another course. We show that the latent abstractions are helpful in predicting student success and engagement reliably in new MOOCs that have not yet gathered student interaction data. We then perform a closer quantitative analysis of different features derived from student interactions on the MOOC and identify student activities that are good indicators of student success at different points in the course. Through a qualitative analysis of the latent engagement variable values, we demonstrate their utility in understanding students\u2019 engagement levels at various points in the course and movement of students across different types of engagement.",
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "authors": [
                {
                    "authorId": "152459641",
                    "name": "Arti Ramesh"
                },
                {
                    "authorId": "2877164",
                    "name": "Dan Goldwasser"
                },
                {
                    "authorId": "40486307",
                    "name": "Bert Huang"
                },
                {
                    "authorId": "1722360",
                    "name": "Hal Daum\u00e9"
                },
                {
                    "authorId": "1746034",
                    "name": "L. Getoor"
                }
            ]
        },
        {
            "paperId": "0a5de1f988745d0b3b1e02ea0ffbd7ca0e0d557e",
            "title": "An Adaptable Framework for Deep Adversarial Label Learning from Weak Supervision",
            "abstract": "In this paper, we propose a general framework for using adversarial label learning (ALL) [1] for multiclass classification when the data is weakly supervised. We introduce a new variant of ALL that incorporates human knowledge through multiple constraint types. Like adversarial label learning, we learn by adversarially finding labels constrained to be partially consistent with the weak supervision. However, we describe a different approach to solve the optimization that enjoys faster convergence when training large deep models. Our framework allows for human knowledge to be encoded into the algorithm as a set of linear constraints. We then solve a two-player game optimization subject to these constraints. We test our method on three data sets by training convolutional neural network models that learn to classify image objects with limited access to training labels. Our approach is able to learn even in settings where the weak supervision confounds state-of-the-art weakly supervised learning methods. The results of our experiments demonstrate the applicability of this approach to general classification tasks.",
            "fieldsOfStudy": [
                "Computer Science",
                "Mathematics"
            ],
            "authors": [
                {
                    "authorId": "46256261",
                    "name": "Chidubem Arachie"
                },
                {
                    "authorId": "40486307",
                    "name": "Bert Huang"
                }
            ]
        },
        {
            "paperId": "5a68c747aacd4a71f2e8d4088d11880fa9a85fe6",
            "title": "Active Learning by Greedy Split and Label Exploration",
            "abstract": "Annotating large unlabeled datasets can be a major bottleneck for machine learning applications. We introduce a scheme for inferring labels of unlabeled data at a fraction of the cost of labeling the entire dataset. We refer to the scheme as greedy split and label exploration (GSAL). GSAL greedily queries an oracle (or human labeler) and partitions a dataset to find data subsets that have mostly the same label. GSAL can then infer labels by majority vote of the known labels in each subset. GSAL makes the decision to split or label from a subset by maximizing a lower bound on the expected number of correctly labeled examples. GSAL improves upon existing hierarchical labeling schemes by using supervised models to partition the data, therefore avoiding reliance on unsupervised clustering methods that may not accurately group data by label. We design GSAL with strategies to avoid bias that could be introduced through this adaptive partitioning. We evaluate GSAL on labeling of three datasets and find that it outperforms existing strategies for adaptive labeling.",
            "fieldsOfStudy": [
                "Computer Science",
                "Mathematics"
            ],
            "authors": [
                {
                    "authorId": "146086646",
                    "name": "Alyssa Herbst"
                },
                {
                    "authorId": "40486307",
                    "name": "Bert Huang"
                }
            ]
        },
        {
            "paperId": "ad221ce6b5e28c30a62cab79c76756f2c247ea77",
            "title": "Stochastic Generalized Adversarial Label Learning",
            "abstract": "The usage of machine learning models has grown substantially and is spreading into several application domains. A common need in using machine learning models is collecting the data required to train these models. In some cases, labeling a massive dataset can be a crippling bottleneck, so there is need to develop models that work when training labels for large amounts of data are not easily obtained. A possible solution is weak supervision, which uses noisy labels that are easily obtained from multiple sources. The challenge is how best to combine these noisy labels and train a model to perform well given a task. In this paper, we propose stochastic generalized adversarial label learning (Stoch-GALL), a framework for training machine learning models that perform well when noisy and possibly correlated labels are provided. Our framework allows users to provide different weak labels and multiple constraints on these labels. Our model then attempts to learn parameters for the data by solving a non-zero sum game optimization. The game is between an adversary that chooses labels for the data and a model that minimizes the error made by the adversarial labels. We test our method on three datasets by training convolutional neural network models that learn to classify image objects with limited access to training labels. Our approach is able to learn even in settings where the weak supervision confounds state-of-the-art weakly supervised learning methods. The results of our experiments demonstrate the applicability of this approach to general classification tasks.",
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "authors": [
                {
                    "authorId": "46256261",
                    "name": "Chidubem Arachie"
                },
                {
                    "authorId": "40486307",
                    "name": "Bert Huang"
                }
            ]
        },
        {
            "paperId": "d2e2be68f6b0c0c604dd2154d32ef12a0cd439d3",
            "title": "Structured Output Learning with Conditional Generative Flows",
            "abstract": "Traditional structured prediction models try to learn the conditional likelihood, i.e., p(y|x), to capture the relationship between the structured output y and the input features x. For many models, computing the likelihood is intractable. These models are therefore hard to train, requiring the use of surrogate objectives or variational inference to approximate likelihood. In this paper, we propose conditional Glow (c-Glow), a conditional generative flow for structured output learning. C-Glow benefits from the ability of flow-based models to compute p(y|x) exactly and efficiently. Learning with c-Glow does not require a surrogate objective or performing inference during training. Once trained, we can directly and efficiently generate conditional samples. We develop a sample-based prediction method, which can use this advantage to do efficient and effective inference. In our experiments, we test c-Glow on five different tasks. C-Glow outperforms the state-of-the-art baselines in some tasks and predicts comparable outputs in the other tasks. The results show that c-Glow is versatile and is applicable to many different structured prediction problems.",
            "fieldsOfStudy": [
                "Computer Science",
                "Mathematics"
            ],
            "authors": [
                {
                    "authorId": "2115728263",
                    "name": "You Lu"
                },
                {
                    "authorId": "40486307",
                    "name": "Bert Huang"
                }
            ]
        },
        {
            "paperId": "f24adbaf86cb763c7fe8f783e5c84a9dc89ddb84",
            "title": "Labeled Graph Generative Adversarial Networks",
            "abstract": "As a new way to train generative models, generative adversarial networks (GANs) have achieved considerable success in image generation, and this framework has also recently been applied to data with graph structures. We identify the drawbacks of existing deep frameworks for generating graphs, and we propose labeled-graph generative adversarial networks (LGGAN) to train deep generative models for graph-structured data with node labels. We test the approach on various types of graph datasets, such as collections of citation networks and protein graphs. Experiment results show that our model can generate diverse labeled graphs that match the structural characteristics of the training data and outperforms all baselines in terms of quality, generality, and scalability. To further evaluate the quality of the generated graphs, we apply it to a downstream task for graph classification, and the results show that LGGAN can better capture the important aspects of the graph structure.",
            "fieldsOfStudy": [
                "Computer Science",
                "Mathematics"
            ],
            "authors": [
                {
                    "authorId": "9294914",
                    "name": "Shuangfei Fan"
                },
                {
                    "authorId": "40486307",
                    "name": "Bert Huang"
                }
            ]
        },
        {
            "paperId": "0a93597acd7c6ff5c365ac1b2df2b80db0ea1294",
            "title": "Adversarial Label Learning",
            "abstract": "We consider the task of training classifiers without labels. We propose a weakly supervised method\u2014adversarial label learning\u2014that trains classifiers to perform well against an adversary that chooses labels for training data. The weak supervision constrains what labels the adversary can choose. The method therefore minimizes an upper bound of the classifier\u2019s error rate using projected primal-dual subgradient descent. Minimizing this bound protects against bias and dependencies in the weak supervision. Experiments on real datasets show that our method can train without labels and outperforms other approaches for weakly supervised learning.",
            "fieldsOfStudy": [
                "Computer Science",
                "Mathematics"
            ],
            "authors": [
                {
                    "authorId": "46256261",
                    "name": "Chidubem Arachie"
                },
                {
                    "authorId": "40486307",
                    "name": "Bert Huang"
                }
            ]
        },
        {
            "paperId": "1ddd1e6df8fb5a90bc2a1cc30b3e7b5e2be80f12",
            "title": "International Workshop on Cybersafety Chairs' Welcome & Organization",
            "abstract": "It is our great pleasure to welcome you to the WWW 2018 Workshop on Computational Methods in Cybersafety, Online Harassment, and Misinformation. The theme of cybersafety is an important emerging research topic on the Internet that manifests itself daily as users navigate the Web and networked applications. After two successful workshops on cybersafety, the main goal of this third edition of this workshop on cybersafety is to build and grow the cybersafety research community by bringing together the leading researchers and practitioners from academia, industry, government, and research labs working in the general area of cybersafety to discuss the unique challenges in addressing various cybersafety issues and to share experiences, solutions, tools, and techniques. The focus is on the detection, prevention, and mitigation of various cybersafety issues, as well as education and promoting safe practices. The focus of this workshop is on computational methods in cybersafety, including new algorithms, tools, data mining techniques, analysis, systems, and applications for the detection, prevention and mitigation of various cybersafety issues, as well as education and promoting safe practices. Our program features two invited keynote speakers. We will have Dr. April Edwards, Vice President for Academic Affairs and Dean of the Faculty at Elmhurst College, speak about Racial and Gender Differences in Cyberbullying Behavior. And we will have Dr. Neil Shah, Research Scientist at Snap Inc., speak about Anomaly Detection on Large Social Graphs. We will also feature four contributed presentations and publications selected from papers submitted to our workshop.",
            "fieldsOfStudy": [
                "Sociology",
                "Computer Science"
            ],
            "authors": [
                {
                    "authorId": "144334335",
                    "name": "Richard O. Han"
                },
                {
                    "authorId": "144728530",
                    "name": "Jeremy Blackburn"
                },
                {
                    "authorId": "2378569",
                    "name": "Homa Hosseinmardi"
                },
                {
                    "authorId": "1569105854",
                    "name": "Q. Lv"
                },
                {
                    "authorId": "40486307",
                    "name": "Bert Huang"
                },
                {
                    "authorId": "1681816",
                    "name": "Shivakant Mishra"
                }
            ]
        },
        {
            "paperId": "9569371f11ef6991105fc2c99946d0c288ef7e12",
            "title": "Adversarial Labeling for Learning without Labels",
            "abstract": "We consider the task of training classifiers without labels. We propose a weakly supervised method---adversarial label learning---that trains classifiers to perform well against an adversary that chooses labels for training data. The weak supervision constrains what labels the adversary can choose. The method therefore minimizes an upper bound of the classifier's error rate using projected primal-dual subgradient descent. Minimizing this bound protects against bias and dependencies in the weak supervision. Experiments on three real datasets show that our method can train without labels and outperforms other approaches for weakly supervised learning.",
            "fieldsOfStudy": [
                "Mathematics",
                "Computer Science"
            ],
            "authors": [
                {
                    "authorId": "46256261",
                    "name": "Chidubem Arachie"
                },
                {
                    "authorId": "40486307",
                    "name": "Bert Huang"
                }
            ]
        }
    ]
}