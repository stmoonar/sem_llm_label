{
    "authorId": "2145038716",
    "papers": [
        {
            "paperId": "1f332772568cb1334451da8e4c7e4ba252c9a09a",
            "title": "AIOS Compiler: LLM as Interpreter for Natural Language Programming and Flow Programming of AI Agents",
            "abstract": "Since their inception, programming languages have trended towards greater readability and lower barriers for programmers. Following this trend, natural language can be a promising type of programming language that provides great flexibility and usability and helps towards the democracy of programming. However, the inherent vagueness, ambiguity, and verbosity of natural language pose significant challenges in developing an interpreter that can accurately understand the programming logic and execute instructions written in natural language. Fortunately, recent advancements in Large Language Models (LLMs) have demonstrated remarkable proficiency in interpreting complex natural language. Inspired by this, we develop a novel system for Code Representation and Execution (CoRE), which employs LLM as interpreter to interpret and execute natural language instructions. The proposed system unifies natural language programming, pseudo-code programming, and flow programming under the same representation for constructing language agents, while LLM serves as the interpreter to interpret and execute the agent programs. In this paper, we begin with defining the programming syntax that structures natural language instructions logically. During the execution, we incorporate external memory to minimize redundancy. Furthermore, we equip the designed interpreter with the capability to invoke external tools, compensating for the limitations of LLM in specialized domains or when accessing real-time information. This work is open-source at https://github.com/agiresearch/CoRE, https://github.com/agiresearch/OpenAGI, and https://github.com/agiresearch/AIOS.",
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "authors": [
                {
                    "authorId": "2111044480",
                    "name": "Shuyuan Xu"
                },
                {
                    "authorId": "2109968285",
                    "name": "Zelong Li"
                },
                {
                    "authorId": "2261740874",
                    "name": "Kai Mei"
                },
                {
                    "authorId": "2145038716",
                    "name": "Yongfeng Zhang"
                }
            ]
        },
        {
            "paperId": "3dd86949c4028ac5d29428acd9e9439e7fc29fa0",
            "title": "PAP-REC: Personalized Automatic Prompt for Recommendation Language Model",
            "abstract": "Recently emerged prompt-based Recommendation Language Models (RLM) can solve multiple recommendation tasks uniformly. The RLMs make full use of the inherited knowledge learned from the abundant pre-training data to solve the downstream recommendation tasks by prompts, without introducing additional parameters or network training. However, handcrafted prompts require significant expertise and human effort since slightly rewriting prompts may cause massive performance changes. In this paper, we propose PAP-REC, a framework to generate the Personalized Automatic Prompt for RECommendation language models to mitigate the inefficiency and ineffectiveness problems derived from manually designed prompts. Specifically, personalized automatic prompts allow different users to have different prompt tokens for the same task, automatically generated using a gradient-based method. One challenge for personalized automatic prompt generation for recommendation language models is the extremely large search space, leading to a long convergence time. To effectively and efficiently address the problem, we develop surrogate metrics and leverage an alternative updating schedule for prompting recommendation language models. Experimental results show that our PAP-REC framework manages to generate personalized prompts, and the automatically generated prompts outperform manually constructed prompts and also outperform various baseline recommendation models. The source code of the work is available at https://github.com/rutgerswiselab/PAP-REC.",
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "authors": [
                {
                    "authorId": "2109968285",
                    "name": "Zelong Li"
                },
                {
                    "authorId": "2111810606",
                    "name": "Jianchao Ji"
                },
                {
                    "authorId": "152988336",
                    "name": "Yingqiang Ge"
                },
                {
                    "authorId": "2007245028",
                    "name": "Wenyue Hua"
                },
                {
                    "authorId": "2145038716",
                    "name": "Yongfeng Zhang"
                }
            ]
        },
        {
            "paperId": "bb16e1cc304fdbf2e5a7e034cb0235fa1aa37a76",
            "title": "IDGenRec: LLM-RecSys Alignment with Textual ID Learning",
            "abstract": "Generative recommendation based on Large Language Models (LLMs) have transformed the traditional ranking-based recommendation style into a text-to-text generation paradigm. However, in contrast to standard NLP tasks that inherently operate on human vocabulary, current research in generative recommendations struggles to effectively encode recommendation items within the text-to-text framework using concise yet meaningful ID representations. To better align LLMs with recommendation needs, we propose IDGen, representing each item as a unique, concise, semantically rich, platform-agnostic textual ID using human language tokens. This is achieved by training a textual ID generator alongside the LLM-based recommender, enabling seamless integration of personalized recommendations into natural language generation. Notably, as user history is expressed in natural language and decoupled from the original dataset, our approach suggests the potential for a foundational generative recommendation model. Experiments show that our framework consistently surpasses existing models in sequential recommendation under standard experimental setting. Then, we explore the possibility of training a foundation recommendation model with the proposed method on data collected from 19 different datasets and tested its recommendation performance on 6 unseen datasets across different platforms under a completely zero-shot setting. The results show that the zero-shot performance of the pre-trained foundation model is comparable to or even better than some traditional recommendation models based on supervised training, showing the potential of the IDGen paradigm serving as the foundation model for generative recommendation. Code and data are open-sourced at https://github.com/agiresearch/IDGenRec.",
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "authors": [
                {
                    "authorId": "2110449137",
                    "name": "Juntao Tan"
                },
                {
                    "authorId": "2111044480",
                    "name": "Shuyuan Xu"
                },
                {
                    "authorId": "2007245028",
                    "name": "Wenyue Hua"
                },
                {
                    "authorId": "152988336",
                    "name": "Yingqiang Ge"
                },
                {
                    "authorId": "2109968285",
                    "name": "Zelong Li"
                },
                {
                    "authorId": "2145038716",
                    "name": "Yongfeng Zhang"
                }
            ]
        },
        {
            "paperId": "d6274dd321da90648a573d202ffef96b5f9d25b0",
            "title": "Formal-LLM: Integrating Formal Language and Natural Language for Controllable LLM-based Agents",
            "abstract": "Recent advancements on Large Language Models (LLMs) enable AI Agents to automatically generate and execute multi-step plans to solve complex tasks. However, since LLM's content generation process is hardly controllable, current LLM-based agents frequently generate invalid or non-executable plans, which jeopardizes the performance of the generated plans and corrupts users' trust in LLM-based agents. In response, this paper proposes a novel\"Formal-LLM\"framework for LLM-based agents by integrating the expressiveness of natural language and the precision of formal language. Specifically, the framework allows agent developers to express their requirements or constraints for the planning process as an automaton. A stack-based LLM plan generation process is then conducted under the supervision of the automaton to ensure that the generated plan satisfies the constraints, making the planning process controllable. We conduct experiments on both benchmark tasks and practical real-life tasks, and our framework achieves over 50% overall performance increase, which validates the feasibility and effectiveness of employing Formal-LLM to guide the plan generation of agents, preventing the agents from generating invalid and unsuccessful plans. Further, more controllable LLM-based agents can facilitate the broader utilization of LLM in application scenarios where high validity of planning is essential. The source code of this work is available at https://github.com/agiresearch/Formal-LLM.",
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "authors": [
                {
                    "authorId": "2109968285",
                    "name": "Zelong Li"
                },
                {
                    "authorId": "2007245028",
                    "name": "Wenyue Hua"
                },
                {
                    "authorId": "2282309329",
                    "name": "Hao Wang"
                },
                {
                    "authorId": "2282352408",
                    "name": "He Zhu"
                },
                {
                    "authorId": "2145038716",
                    "name": "Yongfeng Zhang"
                }
            ]
        },
        {
            "paperId": "f89e85059a55b647c93822aefa7e985376e0ef20",
            "title": "AIOS: LLM Agent Operating System",
            "abstract": "The integration and deployment of large language model (LLM)-based intelligent agents have been fraught with challenges that compromise their efficiency and efficacy. Among these issues are sub-optimal scheduling and resource allocation of agent requests over the LLM, the difficulties in maintaining context during interactions between agent and LLM, and the complexities inherent in integrating heterogeneous agents with different capabilities and specializations. The rapid increase of agent quantity and complexity further exacerbates these issues, often leading to bottlenecks and sub-optimal utilization of resources. Inspired by these challenges, this paper presents AIOS, an LLM agent operating system, which embeds large language model into operating systems (OS) as the brain of the OS, enabling an operating system\"with soul\"-- an important step towards AGI. Specifically, AIOS is designed to optimize resource allocation, facilitate context switch across agents, enable concurrent execution of agents, provide tool service for agents, and maintain access control for agents. We present the architecture of such an operating system, outline the core challenges it aims to resolve, and provide the basic design and implementation of the AIOS. Our experiments on concurrent execution of multiple agents demonstrate the reliability and efficiency of our AIOS modules. Through this, we aim to not only improve the performance and efficiency of LLM agents but also to pioneer for better development and deployment of the AIOS ecosystem in the future. The project is open-source at https://github.com/agiresearch/AIOS.",
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "authors": [
                {
                    "authorId": "2261740874",
                    "name": "Kai Mei"
                },
                {
                    "authorId": "2109968285",
                    "name": "Zelong Li"
                },
                {
                    "authorId": "2111044480",
                    "name": "Shuyuan Xu"
                },
                {
                    "authorId": "2124838724",
                    "name": "Ruosong Ye"
                },
                {
                    "authorId": "152988336",
                    "name": "Yingqiang Ge"
                },
                {
                    "authorId": "2145038716",
                    "name": "Yongfeng Zhang"
                }
            ]
        },
        {
            "paperId": "38179848e2d6a3ad373b1793848816111428ac36",
            "title": "OpenAGI: When LLM Meets Domain Experts",
            "abstract": "Human intelligence excels at combining basic skills to solve complex tasks. This capability is vital for Artificial Intelligence (AI) and should be embedded in comprehensive intelligent models, enabling them to harness expert models for complex task-solving towards Artificial General Intelligence (AGI). Large Language Models (LLMs) show promising learning and reasoning abilities, and can effectively use external models, tools or APIs to tackle complex problems. In this work, we introduce OpenAGI, an open-source AGI research platform designed for multi-step, real-world tasks. Specifically, OpenAGI uses a dual strategy, integrating standard benchmark tasks for benchmarking and evaluation, and open-ended tasks including more expandable models, tools or APIs for creative problem-solving. Tasks are presented as natural language queries to the LLM, which then selects and executes appropriate models. We also propose a Reinforcement Learning from Task Feedback (RLTF) mechanism that uses task results to improve the LLM's ability, which creates a self-improving AI feedback loop. While we acknowledge that AGI is a broad and multifaceted research challenge with no singularly defined solution path, the integration of LLMs with domain-specific expert models, inspired by mirroring the blend of general and specialized intelligence in humans, offers a promising approach towards AGI. We are open-sourcing the OpenAGI project's code, dataset, benchmarks, evaluation methods, and demo to foster community involvement in AGI advancement: https://github.com/agiresearch/OpenAGI.",
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "authors": [
                {
                    "authorId": "152988336",
                    "name": "Yingqiang Ge"
                },
                {
                    "authorId": "2007245028",
                    "name": "Wenyue Hua"
                },
                {
                    "authorId": "2111810606",
                    "name": "Jianchao Ji"
                },
                {
                    "authorId": "2110449137",
                    "name": "Juntao Tan"
                },
                {
                    "authorId": "2111044480",
                    "name": "Shuyuan Xu"
                },
                {
                    "authorId": "2145038716",
                    "name": "Yongfeng Zhang"
                }
            ]
        },
        {
            "paperId": "3e82d12dbce6becdcae94e3ebb01dd569bdb734f",
            "title": "Causal Inference for Recommendation: Foundations, Methods and Applications",
            "abstract": "Recommender systems are important and powerful tools for various personalized services. Traditionally, these systems use data mining and machine learning techniques to make recommendations based on correlations found in the data. However, relying solely on correlation without considering the underlying causal mechanism may lead to various practical issues such as fairness, explainability, robustness, bias, echo chamber and controllability problems. Therefore, researchers in related area have begun incorporating causality into recommendation systems to address these issues. In this survey, we review the existing literature on causal inference in recommender systems. We discuss the fundamental concepts of both recommender systems and causal inference as well as their relationship, and review the existing work on causal methods for different problems in recommender systems. Finally, we discuss open problems and future directions in the field of causal inference for recommendations.",
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "authors": [
                {
                    "authorId": "2111044480",
                    "name": "Shuyuan Xu"
                },
                {
                    "authorId": "2111810606",
                    "name": "Jianchao Ji"
                },
                {
                    "authorId": "48515097",
                    "name": "Yunqi Li"
                },
                {
                    "authorId": "152988336",
                    "name": "Yingqiang Ge"
                },
                {
                    "authorId": "2110449137",
                    "name": "Juntao Tan"
                },
                {
                    "authorId": "2145038716",
                    "name": "Yongfeng Zhang"
                }
            ]
        },
        {
            "paperId": "5b9c89f5b743916c95c88605f02ce78be7699941",
            "title": "ExplainableFold: Understanding AlphaFold Prediction with Explainable AI",
            "abstract": "This paper presents ExplainableFold (xFold), which is an Explainable AI framework for protein structure prediction. Despite the success of AI-based methods such as AlphaFold (\u03b1Fold) in this field, the underlying reasons for their predictions remain unclear due to the black-box nature of deep learning models. To address this, we propose a counterfactual learning framework inspired by biological principles to generate counterfactual explanations for protein structure prediction, enabling a dry-lab experimentation approach. Our experimental results demonstrate the ability of ExplainableFold to generate high-quality explanations for AlphaFold's predictions, providing near-experimental understanding of the effects of amino acids on 3D protein structure. This framework has the potential to facilitate a deeper understanding of protein structures. Source code and data of the ExplainableFold project are available at https://github.com/rutgerswiselab/ExplainableFold.",
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "authors": [
                {
                    "authorId": "2110449137",
                    "name": "Juntao Tan"
                },
                {
                    "authorId": "2145038716",
                    "name": "Yongfeng Zhang"
                }
            ]
        },
        {
            "paperId": "628219d6db682340eb40bc5122ed62dbccab3f34",
            "title": "Counterfactual Collaborative Reasoning",
            "abstract": "Causal reasoning and logical reasoning are two important types of reasoning abilities for human intelligence. However, their relationship has not been extensively explored under machine intelligence context. In this paper, we explore how the two reasoning abilities can be jointly modeled to enhance both accuracy and explainability of machine learning models. More specifically, by integrating two important types of reasoning ability--counterfactual reasoning and (neural) logical reasoning--we propose Counterfactual Collaborative Reasoning (CCR), which conducts counterfactual logic reasoning to improve the performance. In particular, we use recommender system as an example to show how CCR alleviate data scarcity, improve accuracy and enhance transparency. Technically, we leverage counterfactual reasoning to generate \"difficult\" counterfactual training examples for data augmentation, which--together with the original training examples--can enhance the model performance. Since the augmented data is model irrelevant, they can be used to enhance any model, enabling the wide applicability of the technique. Besides, most of the existing data augmentation methods focus on \"implicit data augmentation\" over users' implicit feedback, while our framework conducts \"explicit data augmentation\" over users explicit feedback based on counterfactual logic reasoning. Experiments on three real-world datasets show that CCR achieves better performance than non-augmented models and implicitly augmented models, and also improves model transparency by generating counterfactual explanations.",
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "authors": [
                {
                    "authorId": "2111810606",
                    "name": "Jianchao Ji"
                },
                {
                    "authorId": "2109968285",
                    "name": "Zelong Li"
                },
                {
                    "authorId": "2111044480",
                    "name": "Shuyuan Xu"
                },
                {
                    "authorId": "2209210425",
                    "name": "Max Xiong"
                },
                {
                    "authorId": "2110449137",
                    "name": "Juntao Tan"
                },
                {
                    "authorId": "152988336",
                    "name": "Yingqiang Ge"
                },
                {
                    "authorId": "1728073",
                    "name": "Hao Wang"
                },
                {
                    "authorId": "2145038716",
                    "name": "Yongfeng Zhang"
                }
            ]
        },
        {
            "paperId": "cd200572cb6ef882b8dd9fcf5632f703820b5bc4",
            "title": "User-Controllable Recommendation via Counterfactual Retrospective and Prospective Explanations",
            "abstract": "Modern recommender systems utilize users' historical behaviors to generate personalized recommendations. However, these systems often lack user controllability, leading to diminished user satisfaction and trust in the systems. Acknowledging the recent advancements in explainable recommender systems that enhance users' understanding of recommendation mechanisms, we propose leveraging these advancements to improve user controllability. In this paper, we present a user-controllable recommender system that seamlessly integrates explainability and controllability within a unified framework. By providing both retrospective and prospective explanations through counterfactual reasoning, users can customize their control over the system by interacting with these explanations. Furthermore, we introduce and assess two attributes of controllability in recommendation systems: the complexity of controllability and the accuracy of controllability. Experimental evaluations on MovieLens and Yelp datasets substantiate the effectiveness of our proposed framework. Additionally, our experiments demonstrate that offering users control options can potentially enhance recommendation accuracy in the future. Source code and data are available at \\url{https://github.com/chrisjtan/ucr}.",
            "fieldsOfStudy": [
                "Computer Science",
                "Mathematics"
            ],
            "authors": [
                {
                    "authorId": "2110449137",
                    "name": "Juntao Tan"
                },
                {
                    "authorId": "152988336",
                    "name": "Yingqiang Ge"
                },
                {
                    "authorId": "2153095583",
                    "name": "Yangchun Zhu"
                },
                {
                    "authorId": "35846319",
                    "name": "Yinglong Xia"
                },
                {
                    "authorId": "33642939",
                    "name": "Jiebo Luo"
                },
                {
                    "authorId": "2111810606",
                    "name": "Jianchao Ji"
                },
                {
                    "authorId": "2145038716",
                    "name": "Yongfeng Zhang"
                }
            ]
        }
    ]
}