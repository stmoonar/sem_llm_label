{
    "authorId": "153107187",
    "papers": [
        {
            "paperId": "b451d72b5f3e71afafc6e09167914e99868b6db4",
            "title": "A dual benchmarking study of facial forgery and facial forensics",
            "abstract": "In recent years, visual facial forgery has reached a level of sophistication that humans cannot identify fraud, which poses a significant threat to information security. A wide range of malicious applications have emerged, such as deepfake, fake news, defamation or blackmailing of celebrities, impersonation of politicians in political warfare, and the spreading of rumours to attract views. As a result, a rich body of visual forensic techniques has been proposed in an attempt to stop this dangerous trend. However, there is no comprehensive, fair, and unified performance evaluation to enlighten the community on best performing methods. The authors present a systematic benchmark beyond traditional surveys that provides in\u2010depth insights into facial forgery and facial forensics, grounding on robustness tests such as contrast, brightness, noise, resolution, missing information, and compression. The authors also provide a practical guideline of the benchmarking results, to determine the characteristics of the methods that serve as a comparative reference in this never\u2010ending war between measures and countermeasures. The authors\u2019 source code is open to the public.",
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "authors": [
                {
                    "authorId": "39904789",
                    "name": "Minh Tam Pham"
                },
                {
                    "authorId": "152399820",
                    "name": "T. T. Huynh"
                },
                {
                    "authorId": "153107187",
                    "name": "Vinh Tong"
                },
                {
                    "authorId": "2117824517",
                    "name": "T. Nguyen"
                },
                {
                    "authorId": "2117824154",
                    "name": "T. Nguyen"
                },
                {
                    "authorId": "2416851",
                    "name": "Hongzhi Yin"
                },
                {
                    "authorId": "144133815",
                    "name": "Q. Nguyen"
                }
            ]
        },
        {
            "paperId": "cd9986d773e782d168d5a7abbdb4a0a3d4c5ffc2",
            "title": "Network Alignment with Holistic Embeddings (Extended Abstract)",
            "abstract": "Network alignment is the task of identifying topo-logically and semantically similar nodes across (two) different networks. However, existing alignment models either cannot handle large-scale graphs or fail to leverage different types of network information or modalities. In this paper, we pro-pose a novel end-to-end alignment framework that can lever-age different modalities to compare and align network nodes in an efficient way. A comprehensive evaluation on various datasets shows that our technique outperforms state-of-the-art approaches. Our source code is available at https://github.com/thanhtrunghuynh93/holisticEmbeddingsNA.",
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "authors": [
                {
                    "authorId": "152399820",
                    "name": "T. T. Huynh"
                },
                {
                    "authorId": "2180255488",
                    "name": "Thang Chi Duong"
                },
                {
                    "authorId": "2117824517",
                    "name": "T. Nguyen"
                },
                {
                    "authorId": "153107187",
                    "name": "Vinh Tong"
                },
                {
                    "authorId": "143756261",
                    "name": "A. Sattar"
                },
                {
                    "authorId": "2416851",
                    "name": "Hongzhi Yin"
                },
                {
                    "authorId": "144133815",
                    "name": "Q. Nguyen"
                }
            ]
        },
        {
            "paperId": "3dbf7c825bbda47d8c33d12f39cc22d9de8b1ad0",
            "title": "A War Beyond Deepfake: Benchmarking Facial Counterfeits and Countermeasures",
            "abstract": "In recent years, visual forgery has reached a level of sophistication that humans cannot identify fraud, which poses a signi\ufb01cant threat to information security. A wide range of malicious applications have emerged, such as fake news, defamation or blackmailing of celebrities, impersonation of politicians in political warfare, and the spreading of rumours to attract views. As a result, a rich body of visual forensic techniques has been proposed in an attempt to stop this dangerous trend. In this paper, we present a benchmark that provides in-depth insights into visual forgery and visual forensics, using a comprehensive and empirical approach. More speci\ufb01cally, we develop an independent framework that integrates state-of-the-arts counterfeit generators and detectors, and measure the performance of these techniques using various criteria. We also perform an exhaustive analysis of the benchmarking results, to determine the characteristics of the methods that serve as a comparative reference in this never-ending war between measures and countermeasures.",
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "authors": [
                {
                    "authorId": "39904789",
                    "name": "Minh Tam Pham"
                },
                {
                    "authorId": "152399820",
                    "name": "T. T. Huynh"
                },
                {
                    "authorId": "153107187",
                    "name": "Vinh Tong"
                },
                {
                    "authorId": "2117824517",
                    "name": "T. Nguyen"
                },
                {
                    "authorId": "2117824154",
                    "name": "T. Nguyen"
                },
                {
                    "authorId": "2416851",
                    "name": "Hongzhi Yin"
                },
                {
                    "authorId": "144133815",
                    "name": "Q. Nguyen"
                }
            ]
        },
        {
            "paperId": "3c287e0565dcfbb2e23f588e9992dd67ad448437",
            "title": "Adaptive Network Alignment with Unsupervised and Multi-order Convolutional Networks",
            "abstract": "Network alignment is the problem of pairing nodes between two graphs such that the paired nodes are structurally and semantically similar. A well-known application of network alignment is to identify which accounts in different social networks belong to the same person. Existing alignment techniques, however, lack scalability, cannot incorporate multi-dimensional information without training data, and are limited in the consistency constraints enforced by an alignment. In this paper, we propose a fully unsupervised network alignment framework based on a multi-order embedding model. The model learns the embeddings of each node using a graph convolutional neural representation, which we prove to satisfy consistency constraints. We further design a data augmentation method and a refinement mechanism to make the model adaptive to consistency violations and noise. Extensive experiments on real and synthetic datasets show that our model outperforms state-of-the-art alignment techniques. We also demonstrate the robustness of our model against adversarial conditions, such as structural noises, attribute noises, graph size imbalance, and hyper-parameter sensitivity.",
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "authors": [
                {
                    "authorId": "152399820",
                    "name": "T. T. Huynh"
                },
                {
                    "authorId": "153107187",
                    "name": "Vinh Tong"
                },
                {
                    "authorId": "90631830",
                    "name": "T. Nguyen"
                },
                {
                    "authorId": "2416851",
                    "name": "Hongzhi Yin"
                },
                {
                    "authorId": "2315762",
                    "name": "M. Weidlich"
                },
                {
                    "authorId": "1925773",
                    "name": "Nguyen Quoc Viet Hung"
                }
            ]
        }
    ]
}