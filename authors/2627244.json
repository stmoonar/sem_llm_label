{
    "authorId": "2627244",
    "papers": [
        {
            "paperId": "687885c1c598d2f8424980d60de9b89b60a9599d",
            "title": "Macroeconomic Forecasting with Large Language Models",
            "abstract": "This paper presents a comparative analysis evaluating the accuracy of Large Language Models (LLMs) against traditional macro time series forecasting approaches. In recent times, LLMs have surged in popularity for forecasting due to their ability to capture intricate patterns in data and quickly adapt across very different domains. However, their effectiveness in forecasting macroeconomic time series data compared to conventional methods remains an area of interest. To address this, we conduct a rigorous evaluation of LLMs against traditional macro forecasting methods, using as common ground the FRED-MD database. Our findings provide valuable insights into the strengths and limitations of LLMs in forecasting macroeconomic time series, shedding light on their applicability in real-world scenarios",
            "fieldsOfStudy": [
                "Computer Science",
                "Economics"
            ],
            "authors": [
                {
                    "authorId": "2309179885",
                    "name": "Andrea Carriero"
                },
                {
                    "authorId": "2285672615",
                    "name": "Davide Pettenuzzo"
                },
                {
                    "authorId": "2627244",
                    "name": "Shubhranshu Shekhar"
                }
            ]
        },
        {
            "paperId": "7ea3d737f31f60f6d7a22d6671ddfc3b6341cd23",
            "title": "UltraProp: Principled and Explainable Propagation on Large Graphs",
            "abstract": "Given a large graph with few node labels, how can we (a) identify the mixed network-effect of the graph and (b) predict the unknown labels accurately and efficiently? This work proposes Network Effect Analysis (NEA) and U LTRA P ROP , which are based on two insights: (a) the network-effect (NE) insight: a graph can exhibit not only one of homophily and heterophily, but also both or none in a label-wise manner, and (b) the neighbor-differentiation (ND) insight: neighbors have different degrees of influence on the target node based on the strength of connections. NEA provides a statistical test to check whether a graph exhibits network-effect or not, and surprisingly discovers the absence of NE in many real-world graphs known to have heterophily. U LTRA P ROP solves the node classification problem with notable advantages: (a) Accurate , thanks to the network-effect (NE) and neighbor-differentiation (ND) insights; (b) Explainable , precisely estimating the compatibility matrix; (c) Scalable , being linear with the input size and handling graphs with millions of nodes; and (d) Principled , with closed-form formula and theoretical guarantee. Applied on eight real-world graph datasets, U LTRA P ROP outperforms top competitors in terms of accuracy and run time, requiring only stock CPU servers. On a large real-world graph with 1 . 6 M nodes and 22 . 3 M edges , U LTRA P ROP achieves \u2265 9 \u00d7 speedup (12 minutes vs. 2 hours) compared to most competitors.",
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "authors": [
                {
                    "authorId": "151121638",
                    "name": "Meng-Chieh Lee"
                },
                {
                    "authorId": "2627244",
                    "name": "Shubhranshu Shekhar"
                },
                {
                    "authorId": "2257360769",
                    "name": "Jaemin Yoo"
                },
                {
                    "authorId": "2256724188",
                    "name": "Christos Faloutsos"
                }
            ]
        },
        {
            "paperId": "019cd41cc5833517a3b7cecade69ffde086775ca",
            "title": "Less is More: SlimG for Accurate, Robust, and Interpretable Graph Mining",
            "abstract": "How can we solve semi-supervised node classification in various graphs possibly with noisy features and structures? Graph neural networks (GNNs) have succeeded in many graph mining tasks, but their generalizability to various graph scenarios is limited due to the difficulty of training, hyperparameter tuning, and the selection of a model itself. Einstein said that we should\"make everything as simple as possible, but not simpler.\"We rephrase it into the careful simplicity principle: a carefully-designed simple model can surpass sophisticated ones in real-world graphs. Based on the principle, we propose SlimG for semi-supervised node classification, which exhibits four desirable properties: It is (a) accurate, winning or tying on 10 out of 13 real-world datasets; (b) robust, being the only one that handles all scenarios of graph data (homophily, heterophily, random structure, noisy features, etc.); (c) fast and scalable, showing up to 18 times faster training in million-scale graphs; and (d) interpretable, thanks to the linearity and sparsity. We explain the success of SlimG through a systematic study of the designs of existing GNNs, sanity checks, and comprehensive ablation studies.",
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "authors": [
                {
                    "authorId": "31888223",
                    "name": "Jaemin Yoo"
                },
                {
                    "authorId": "151121638",
                    "name": "Meng-Chieh Lee"
                },
                {
                    "authorId": "2627244",
                    "name": "Shubhranshu Shekhar"
                },
                {
                    "authorId": "1702392",
                    "name": "C. Faloutsos"
                }
            ]
        },
        {
            "paperId": "3fcde37cd3b59e8713af28a127b54629eca350eb",
            "title": "Unsupervised Machine Learning for Explainable Health Care Fraud Detection",
            "abstract": "The US federal government spends more than a trillion dollars per year on health care, largely provided by private third parties and reimbursed by the government. A major concern in this system is overbilling, waste and fraud by providers, who face incentives to misreport on their claims in order to receive higher payments. In this paper, we develop novel machine learning tools to identify providers that overbill Medicare, the US federal health insurance program for elderly adults and the disabled. Using large-scale Medicare claims data, we identify patterns consistent with fraud or overbilling among inpatient hospitalizations. Our proposed approach for Medicare fraud detection is fully unsupervised, not relying on any labeled training data, and is explainable to end users, providing reasoning and interpretable insights into the potentially suspicious behavior of the flagged providers. Data from the Department of Justice on providers facing anti-fraud lawsuits and several case studies validate our approach and findings both quantitatively and qualitatively.",
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "authors": [
                {
                    "authorId": "2627244",
                    "name": "Shubhranshu Shekhar"
                },
                {
                    "authorId": "1403360325",
                    "name": "Jetson Leder-Luis"
                },
                {
                    "authorId": "3255268",
                    "name": "L. Akoglu"
                }
            ]
        },
        {
            "paperId": "54bb6c9607b34c618a4c9c611c965831fa9c7ad1",
            "title": "SlenderGNN: Accurate, Robust, and Interpretable GNN, and the Reasons for its Success",
            "abstract": "dimensionality",
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "authors": [
                {
                    "authorId": "31888223",
                    "name": "Jaemin Yoo"
                },
                {
                    "authorId": "151121638",
                    "name": "Meng-Chieh Lee"
                },
                {
                    "authorId": "2627244",
                    "name": "Shubhranshu Shekhar"
                },
                {
                    "authorId": "1702392",
                    "name": "C. Faloutsos"
                }
            ]
        },
        {
            "paperId": "7a8b8e7f36376fc040e025e7e8c22bc5e1d495d8",
            "title": "Unsupervised Machine Learning for Explainable Medicare Fraud Detection",
            "abstract": "The US federal government spends more than a trillion dollars per year on health care, largely provided by private third parties and reimbursed by the government. A major concern in this system is overbilling, waste and fraud by providers, who face incentives to misreport on their claims in order to receive higher payments. In this paper, we develop novel machine learning tools to identify providers that overbill Medicare, the US federal health insurance program for elderly adults and the disabled. Using large-scale Medicare claims data, we identify patterns consistent with fraud or overbilling among inpatient hospitalizations. Our proposed approach for Medicare fraud detection is fully unsupervised, not relying on any labeled training data, and is explainable to end users, providing reasoning and interpretable insights into the potentially suspicious behavior of the flagged providers. Data from the Department of Justice on providers facing anti-fraud lawsuits and several case studies validate our approach and findings both quantitatively and qualitatively.",
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "authors": [
                {
                    "authorId": "2627244",
                    "name": "Shubhranshu Shekhar"
                },
                {
                    "authorId": "1403360325",
                    "name": "Jetson Leder-Luis"
                },
                {
                    "authorId": "3255268",
                    "name": "L. Akoglu"
                }
            ]
        },
        {
            "paperId": "b646d84714d6b53bb43ab0c4ab92915d7d26e9dc",
            "title": "Gen2Out: Detecting and Ranking Generalized Anomalies",
            "abstract": "In a cloud of m-dimensional data points, how would we spot, as well as rank, both single-point- as well as group-anomalies? We are the first to generalize anomaly detection in two dimensions: The first dimension is that we handle both point-anomalies, as well as group-anomalies, under a unified view - we shall refer to them as generalized anomalies. The second dimension is that Gen2Out not only detects, but also ranks, anomalies in suspiciousness order. Detection, and ranking, of anomalies has numerous applications: For example, in EEG recordings of an epileptic patient, an anomaly may indicate a seizure; in computer network traffic data, it may signify a power failure, or a DoS/DDoS attack.We start by setting some reasonable axioms; surprisingly, none of the earlier methods pass all the axioms. Our main contribution is the Gen2Out algorithm, that has the following desirable properties: (a) Principled and Sound anomaly scoring that obeys the axioms for detectors, (b) Doubly-general in that it detects, as well as ranks generalized anomaly\u2013 both point- and group-anomalies, (c) Scalable, it is fast and scalable, linear on input size. (d) Effective, experiments on real-world epileptic recordings (200GB) demonstrate effectiveness of Gen2Out as confirmed by clinicians. Experiments on 27 real-world benchmark datasets show that Gen2Out detects ground truth groups, matches or outperforms point-anomaly baseline algorithms on accuracy, with no competition for group-anomalies and requires about 2 minutes for 1 million data points on a stock machine.",
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "authors": [
                {
                    "authorId": "151121638",
                    "name": "Meng-Chieh Lee"
                },
                {
                    "authorId": "2627244",
                    "name": "Shubhranshu Shekhar"
                },
                {
                    "authorId": "1702392",
                    "name": "C. Faloutsos"
                },
                {
                    "authorId": "15817147",
                    "name": "T. Hutson"
                },
                {
                    "authorId": "2023105",
                    "name": "L. Iasemidis"
                }
            ]
        },
        {
            "paperId": "16cf947eb1244c28ce4d6ca00affec414382301c",
            "title": "Entity Resolution in Dynamic Heterogeneous Networks",
            "abstract": "Networks evolve continuously over time not only with the addition and deletion of links and nodes but also with changes in the importance of edges. Even though many networks contain this type of temporal weightings, vast majority of research in network representation learning and classification has focused on static snapshots of the graph, while largely ignoring the temporal dynamics. In this work, we describe two approaches for incorporating weighted temporal information into network embedding methods such as Graph Convolutional Networks (GCNs). While the first approach aggregates time-weighted edges and nodes, the second approach uses temporal random walks to find relevant convolution nodes. With experiments on public and proprietary datasets, we demonstrate the effectiveness of the proposed TimeSage for link prediction tasks. By applying these predictions, we show improvements in our task of identifying fraudulent actors on a large e-commerce website selling software as subscriptions.",
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "authors": [
                {
                    "authorId": "2627244",
                    "name": "Shubhranshu Shekhar"
                },
                {
                    "authorId": "33893997",
                    "name": "Deepak Pai"
                },
                {
                    "authorId": "152110895",
                    "name": "S. Ravindran"
                }
            ]
        },
        {
            "paperId": "2324d25fcbeb11d04dd2956026a5c4d68eac54dd",
            "title": "FairOD: Fairness-aware Outlier Detection",
            "abstract": "Fairness and Outlier Detection (OD) are closely related, as it is exactly the goal of OD to spot rare, minority samples in a given population. However, when being a minority (as defined by protected variables, such as race/ethnicity/sex/age) does not reflect positive-class membership (such as criminal/fraud), OD produces unjust outcomes. Surprisingly, fairness-aware OD has been almost untouched in prior work, as fair machine learning literature mainly focuses on supervised settings. Our work aims to bridge this gap. Specifically, we develop desiderata capturing well-motivated fairness criteria for OD, and systematically formalize the fair OD problem. Further, guided by our desiderata, we propose FairOD, a fairness-aware outlier detector that has the following desirable properties: FairOD (1) exhibits treatment parity at test time, (2) aims to flag equal proportions of samples from all groups (i.e. obtain group fairness, via statistical parity), and (3) strives to flag truly high-risk samples within each group. Extensive experiments on a diverse set of synthetic and real world datasets show that FairOD produces outcomes that are fair with respect to protected variables, while performing comparable to (and in some cases, even better than) fairness-agnostic detectors in terms of detection performance.",
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "authors": [
                {
                    "authorId": "2627244",
                    "name": "Shubhranshu Shekhar"
                },
                {
                    "authorId": "145474474",
                    "name": "Neil Shah"
                },
                {
                    "authorId": "3255268",
                    "name": "L. Akoglu"
                }
            ]
        },
        {
            "paperId": "792eb1b58d9690e4ae889aad18b17f18e9f9228f",
            "title": "How popular are your tweets?",
            "abstract": "Evaluation is a key factor to reflect the quality of a recommender system algorithm. Traditional recommenders pose the problem as an optimization task where they seek to minimize the error in predicted rating for an item or predicted top-n items of interest with respect a user. However, these predictions do not often translate to a well-perceived recommendation. In this work, instead of the typical rating prediction task, we predict the amount of interaction an item would receive through a social network. In particular, we propose a simple and efficient model to generate a ranked list of tweets of a user in the order of expected user interaction that they would receive on Twitter, which is expressed in terms of retweets and favorites. We evaluate our proposed model on an extended version of the MovieTweetings dataset, which contains tweets that are generated when users rate movies on IMDb (using the IMDb iOS app), and show that the proposed model performs better compared to the baselines.",
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "authors": [
                {
                    "authorId": "35797560",
                    "name": "A. Saha"
                },
                {
                    "authorId": "10197529",
                    "name": "Janarthanan Rajendran"
                },
                {
                    "authorId": "2627244",
                    "name": "Shubhranshu Shekhar"
                },
                {
                    "authorId": "1723632",
                    "name": "Balaraman Ravindran"
                }
            ]
        }
    ]
}