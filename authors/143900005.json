{
    "authorId": "143900005",
    "papers": [
        {
            "paperId": "00e6500616920a25ecd95d0d3ad6f7764266b31b",
            "title": "Pride and Prejudice: LLM Amplifies Self-Bias in Self-Refinement",
            "abstract": "Recent studies show that large language models (LLMs) improve their performance through self-feedback on certain tasks while degrade on others. We discovered that such a contrary is due to LLM's bias in evaluating their own output. In this paper, we formally define LLM's self-bias - the tendency to favor its own generation - using two statistics. We analyze six LLMs (GPT-4, GPT-3.5, Gemini, LLaMA2, Mixtral and DeepSeek) on translation, constrained text generation, and mathematical reasoning tasks. We find that self-bias is prevalent in all examined LLMs across multiple languages and tasks. Our analysis reveals that while the self-refine pipeline improves the fluency and understandability of model outputs, it further amplifies self-bias. To mitigate such biases, we discover that larger model size and external feedback with accurate assessment can significantly reduce bias in the self-refine pipeline, leading to actual performance improvement in downstream tasks. The code and data are released at https://github.com/xu1998hz/llm_self_bias.",
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "authors": [
                {
                    "authorId": "145738382",
                    "name": "Wenda Xu"
                },
                {
                    "authorId": "2284743081",
                    "name": "Guanglei Zhu"
                },
                {
                    "authorId": "150345512",
                    "name": "Xuandong Zhao"
                },
                {
                    "authorId": "2256983134",
                    "name": "Liangming Pan"
                },
                {
                    "authorId": "143900005",
                    "name": "Lei Li"
                },
                {
                    "authorId": "2257130314",
                    "name": "W. Wang"
                }
            ]
        },
        {
            "paperId": "333f4070be5b712cf394d2ef411c837b05a4557b",
            "title": "Generative Enzyme Design Guided by Functionally Important Sites and Small-Molecule Substrates",
            "abstract": "Enzymes are genetically encoded biocatalysts capable of accelerating chemical reactions. How can we automatically design functional enzymes? In this paper, we propose EnzyGen, an approach to learn a unified model to design enzymes across all functional families. Our key idea is to generate an enzyme's amino acid sequence and their three-dimensional (3D) coordinates based on functionally important sites and substrates corresponding to a desired catalytic function. These sites are automatically mined from enzyme databases. EnzyGen consists of a novel interleaving network of attention and neighborhood equivariant layers, which captures both long-range correlation in an entire protein sequence and local influence from nearest amino acids in 3D space. To learn the generative model, we devise a joint training objective, including a sequence generation loss, a position prediction loss and an enzyme-substrate interaction loss. We further construct EnzyBench, a dataset with 3157 enzyme families, covering all available enzymes within the protein data bank (PDB). Experimental results show that our EnzyGen consistently achieves the best performance across all 323 testing families, surpassing the best baseline by 10.79% in terms of substrate binding affinity. These findings demonstrate EnzyGen's superior capability in designing well-folded and effective enzymes binding to specific substrates with high affinities.",
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "authors": [
                {
                    "authorId": "6872825",
                    "name": "Zhenqiao Song"
                },
                {
                    "authorId": "2254057315",
                    "name": "Yunlong Zhao"
                },
                {
                    "authorId": "92229033",
                    "name": "Wenxian Shi"
                },
                {
                    "authorId": "2301193304",
                    "name": "Wengong Jin"
                },
                {
                    "authorId": "2254897017",
                    "name": "Yang Yang"
                },
                {
                    "authorId": "143900005",
                    "name": "Lei Li"
                }
            ]
        },
        {
            "paperId": "a932b662645ab4a348c44c73bb81876cb415ae95",
            "title": "DE-COP: Detecting Copyrighted Content in Language Models Training Data",
            "abstract": "How can we detect if copyrighted content was used in the training process of a language model, considering that the training data is typically undisclosed? We are motivated by the premise that a language model is likely to identify verbatim excerpts from its training text. We propose DE-COP, a method to determine whether a piece of copyrighted content was included in training. DE-COP's core approach is to probe an LLM with multiple-choice questions, whose options include both verbatim text and their paraphrases. We construct BookTection, a benchmark with excerpts from 165 books published prior and subsequent to a model's training cutoff, along with their paraphrases. Our experiments show that DE-COP surpasses the prior best method by 9.6% in detection performance (AUC) on models with logits available. Moreover, DE-COP also achieves an average accuracy of 72% for detecting suspect books on fully black-box models where prior methods give approximately 4% accuracy. The code and datasets are available at https://github.com/LeiLiLab/DE-COP.",
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "authors": [
                {
                    "authorId": "2221141068",
                    "name": "Andr\u00e9 V. Duarte"
                },
                {
                    "authorId": "150345512",
                    "name": "Xuandong Zhao"
                },
                {
                    "authorId": "2284263865",
                    "name": "Arlindo L. Oliveira"
                },
                {
                    "authorId": "143900005",
                    "name": "Lei Li"
                }
            ]
        },
        {
            "paperId": "b6513f37d51ef3dcdb77aa47a22e9836139bce34",
            "title": "Where It Really Matters: Few-Shot Environmental Conservation Media Monitoring for Low-Resource Languages",
            "abstract": "Environmental conservation organizations routinely monitor news content on conservation in protected areas to maintain situational awareness of developments that can have an environmental impact. Existing automated media monitoring systems require large amounts of data labeled by domain experts, which is only feasible at scale for high-resource languages like English. However, such tools are most needed in the global south where the news of interest is mainly in local low-resource languages, and far fewer experts are available to annotate datasets on a sustainable basis. In this paper, we propose NewsSerow, a method to automatically recognize environmental conservation content in low-resource languages. NewsSerow is a pipeline of summarization, in-context few-shot classification, and self-reflection using large language models (LLMs). Using at most 10 demonstration example news articles in Nepali, NewsSerow significantly outperforms other few-shot methods and can achieve comparable performance with models fully fine-tuned using thousands of examples. With NewsSerow, Organization X has been able to deploy the media monitoring tool in Nepal, significantly reducing their operational burden, and ensuring that AI tools for conservation actually reach the communities that need them the most. NewsSerow has also been deployed for countries with other languages like Colombia.",
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "authors": [
                {
                    "authorId": "2284716094",
                    "name": "Sameer Jain"
                },
                {
                    "authorId": "150299584",
                    "name": "Sedrick Scott Keh"
                },
                {
                    "authorId": "2284691647",
                    "name": "Shova Chettri"
                },
                {
                    "authorId": "2060195807",
                    "name": "Karun Dewan"
                },
                {
                    "authorId": "2284693083",
                    "name": "Pablo Izquierdo"
                },
                {
                    "authorId": "2284690369",
                    "name": "Johanna Prussman"
                },
                {
                    "authorId": "2284692615",
                    "name": "Pooja Shreshtha"
                },
                {
                    "authorId": "2284691111",
                    "name": "Cesar Suarez"
                },
                {
                    "authorId": "145665132",
                    "name": "Zheyuan Ryan Shi"
                },
                {
                    "authorId": "143900005",
                    "name": "Lei Li"
                },
                {
                    "authorId": "2284696739",
                    "name": "Fei Fang"
                }
            ]
        },
        {
            "paperId": "cb73832f442484075c4b908a9c67ad7293b6b25d",
            "title": "SurfPro: Functional Protein Design Based on Continuous Surface",
            "abstract": "How can we design proteins with desired functions? We are motivated by a chemical intuition that both geometric structure and biochemical properties are critical to a protein's function. In this paper, we propose SurfPro, a new method to generate functional proteins given a desired surface and its associated biochemical properties. SurfPro comprises a hierarchical encoder that progressively models the geometric shape and biochemical features of a protein surface, and an autoregressive decoder to produce an amino acid sequence. We evaluate SurfPro on a standard inverse folding benchmark CATH 4.2 and two functional protein design tasks: protein binder design and enzyme design. Our SurfPro consistently surpasses previous state-of-the-art inverse folding methods, achieving a recovery rate of 57.78% on CATH 4.2 and higher success rates in terms of protein-protein binding and enzyme-substrate interaction scores.",
            "fieldsOfStudy": [
                "Computer Science",
                "Biology"
            ],
            "authors": [
                {
                    "authorId": "6872825",
                    "name": "Zhenqiao Song"
                },
                {
                    "authorId": "2301174407",
                    "name": "Tinglin Huang"
                },
                {
                    "authorId": "143900005",
                    "name": "Lei Li"
                },
                {
                    "authorId": "2301193304",
                    "name": "Wengong Jin"
                }
            ]
        },
        {
            "paperId": "fbf7c1386a188157cdee15e92a5b193ab17d68a7",
            "title": "Hire a Linguist!: Learning Endangered Languages with In-Context Linguistic Descriptions",
            "abstract": "How can large language models (LLMs) process and translate endangered languages? Many languages lack a large corpus to train a decent LLM; therefore existing LLMs rarely perform well in unseen, endangered languages. On the contrary, we observe that 2000 endangered languages, though without a large corpus, have a grammar book or a dictionary. We propose LINGOLLM, a training-free approach to enable an LLM to process unseen languages that hardly occur in its pre-training. Our key insight is to demonstrate linguistic knowledge of an unseen language in an LLM's prompt, including a dictionary, a grammar book, and morphologically analyzed input text. We implement LINGOLLM on top of two models, GPT-4 and Mixtral, and evaluate their performance on 5 tasks across 8 endangered or low-resource languages. Our results show that LINGOLLM elevates translation capability from GPT-4's 0 to 10.5 BLEU for 10 language directions. Our findings demonstrate the tremendous value of linguistic knowledge in the age of LLMs for endangered languages. Our data, code, and model generations can be found at https://github.com/LLiLab/llm4endangeredlang.",
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "authors": [
                {
                    "authorId": "2119058805",
                    "name": "Kexun Zhang"
                },
                {
                    "authorId": "2288054771",
                    "name": "Yee Man Choi"
                },
                {
                    "authorId": "6872825",
                    "name": "Zhenqiao Song"
                },
                {
                    "authorId": "2107034039",
                    "name": "Taiqi He"
                },
                {
                    "authorId": "2257130318",
                    "name": "W. Wang"
                },
                {
                    "authorId": "143900005",
                    "name": "Lei Li"
                }
            ]
        },
        {
            "paperId": "159b9c65260beea062cebdc023d9e802869768f3",
            "title": "Learning from Mistakes via Cooperative Study Assistant for Large Language Models",
            "abstract": "Large language models (LLMs) have demonstrated their potential to refine their generation based on their own feedback. However, the feedback from LLM itself is often inaccurate, thereby limiting its benefits. In this paper, we propose Study Assistant for Large LAnguage Model (SALAM), a novel framework with an auxiliary agent to assist the main LLM in learning from mistakes through interactive cooperation. In the gathering phase, the student assistant agent probes the main LLM, analyzes its errors, and collects the interaction in a mistake memory. During the examination phase, the study assistant provides guidelines by retrieving relevant cases to help the main LLM anticipate and avoid similar errors. We first investigate the effectiveness of a general study assistant and then customize it to provide LLM-specific guidance through imitation learning from successful guidance experiences. Our experiments on three LLMs using two challenging frameworks demonstrate that SALAM can significantly boost LLMs by an accuracy margin of up to 6.6 on BBH and 12.6 on BBQ.",
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "authors": [
                {
                    "authorId": "49371126",
                    "name": "Danqing Wang"
                },
                {
                    "authorId": "143900005",
                    "name": "Lei Li"
                }
            ]
        },
        {
            "paperId": "2bb4fe9bc10dbf1ea70135e52452f9f63bb10671",
            "title": "ALGO: Synthesizing Algorithmic Programs with Generated Oracle Verifiers",
            "abstract": "Large language models (LLMs) excel at implementing code from functionality descriptions but struggle with algorithmic problems that require not only implementation but also identification of the suitable algorithm. Moreover, LLM-generated programs lack guaranteed correctness and require human verification. To address these challenges, we propose ALGO, a framework that synthesizes Algorithmic programs with LLM-Generated Oracles to guide the generation and verify their correctness. ALGO first generates a reference oracle by prompting an LLM to exhaustively enumerate all the combinations of relevant variables. This oracle is then utilized to guide an arbitrary search strategy in exploring the algorithm space and to verify the synthesized algorithms. Our study shows that the LLM-generated oracles are correct for 88% of the cases. With the oracles as verifiers, ALGO can be integrated with any existing code generation model in a model-agnostic manner to enhance its performance. Experiments show that when equipped with ALGO, we achieve an 8x better one-submission pass rate over the Codex model and a 2.6x better one-submission pass rate over CodeT, the current state-of-the-art model on CodeContests. We can also get 1.3x better pass rate over the ChatGPT Code Interpreter on unseen problems. The problem set we used for testing, the prompts we used, the verifier and solution programs, and the test cases generated by ALGO are available at https://github.com/zkx06111/ALGO.",
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "authors": [
                {
                    "authorId": "2119058805",
                    "name": "Kexun Zhang"
                },
                {
                    "authorId": "49371126",
                    "name": "Danqing Wang"
                },
                {
                    "authorId": "2106416170",
                    "name": "Jingtao Xia"
                },
                {
                    "authorId": "1682479",
                    "name": "William Yang Wang"
                },
                {
                    "authorId": "143900005",
                    "name": "Lei Li"
                }
            ]
        },
        {
            "paperId": "460609e217fd59eaa34f5e11a820661f8ec8d7b6",
            "title": "INSTRUCTSCORE: Towards Explainable Text Generation Evaluation with Automatic Feedback",
            "abstract": "The field of automatic evaluation of text generation made tremendous progress in the last few years. In particular, since the advent of neural metrics, like COMET, BLEURT and SEScore2, the newest generation of metrics show a high correlation with human judgment. Unfortunately, quality scores generated with neural metrics are not interpretable and it is unclear which part of the generation output is criticized by the metrics. To address this limitation, we present I NSTRUCT S CORE , an open-source, explainable evaluation metric for text generation. By harnessing both explicit human instruction and the implicit knowledge of GPT4, we fine-tune a LLAMA model to create an evaluative metric that can produce a diagnostic report aligned with human judgment. We evaluate I NSTRUCT S CORE on the WMT22 Zh-En translation task, where our 7B model surpasses other LLM-based baselines, including those based on 175B GPT3. Impressively, our I NSTRUCT S CORE , even without direct super-vision from human-rated data, achieves performance levels on par with state-of-the-art metrics like COMET22, which was fine-tuned on human ratings. 1",
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "authors": [
                {
                    "authorId": "145738382",
                    "name": "Wenda Xu"
                },
                {
                    "authorId": "49371126",
                    "name": "Danqing Wang"
                },
                {
                    "authorId": "3470231",
                    "name": "Liangming Pan"
                },
                {
                    "authorId": "6872825",
                    "name": "Zhenqiao Song"
                },
                {
                    "authorId": "35307070",
                    "name": "Markus Freitag"
                },
                {
                    "authorId": "1682479",
                    "name": "William Yang Wang"
                },
                {
                    "authorId": "143900005",
                    "name": "Lei Li"
                }
            ]
        },
        {
            "paperId": "51afa7e06edbb8107565db93f80c7f1a6784e8f0",
            "title": "Fine-grained LLM Agent: Pinpointing and Refining Large Language Models via Fine-Grained Actionable Feedback",
            "abstract": "Recent large language models (LLM) are leveraging human feedback to improve their generation quality. However, human feedback is costly to obtain, especially during inference. In this work, we propose Fine-grained LLM agent, an inference time optimization method to refine LLM's output. The core idea is to use a learned fine-grained feedback model to pinpoint defects and guide LLM to refine them iteratively. Using original LLM as a proposal of edits, Fine-grained LLM agent searches for defect-less text via simulated annealing, trading off the exploration and exploitation. We conduct experiments on three text generation tasks, including machine translation, long-form question answering (QA), and topical summarization. Fine-grained LLM agent consistently outperforms all baseline approaches, achieving improvements up to 1.7 MetricX points on translation tasks, 8.1 ROUGE-L on ASQA, 2.2 ROUGE-L on topical summarization.",
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "authors": [
                {
                    "authorId": "145738382",
                    "name": "Wenda Xu"
                },
                {
                    "authorId": "2258954267",
                    "name": "Daniel Deutsch"
                },
                {
                    "authorId": "2257001597",
                    "name": "Mara Finkelstein"
                },
                {
                    "authorId": "47080255",
                    "name": "Juraj Juraska"
                },
                {
                    "authorId": "2275942342",
                    "name": "Biao Zhang"
                },
                {
                    "authorId": "2267287179",
                    "name": "Zhongtao Liu"
                },
                {
                    "authorId": "2257130314",
                    "name": "W. Wang"
                },
                {
                    "authorId": "143900005",
                    "name": "Lei Li"
                },
                {
                    "authorId": "2247094600",
                    "name": "Markus Freitag"
                }
            ]
        }
    ]
}