{
    "authorId": "2151684774",
    "papers": [
        {
            "paperId": "0b237a633e92175098a1e221397da770f51fd344",
            "title": "A Large Scale Study and Classification of VirusTotal Reports on Phishing and Malware URLs",
            "abstract": "VirusTotal (VT) is a widely used scanning service for researchers and practitioners to label malicious entities and predict new security threats. Unfortunately, it is little known to the end-users how VT URL scanners decide on the maliciousness of entities and the attack types they are involved in (e.g., phishing or malware-hosting websites). In this paper, we conduct a systematic comparative study on VT URL scanners' behavior for different attack types of malicious URLs, in terms of 1) detection specialties, 2) stability, 3) correlations between scanners, and 4) lead/lag behaviors. Our findings highlight that the VT scanners commonly disagree with each other on their detection and attack type classification, leading to challenges in ascertaining the maliciousness of a URL and taking prompt mitigation actions according to different attack types. This motivates us to present a new highly accurate classifier that helps correctly identify the attack types of malicious URLs at the early stage. This in turn assists practitioners in performing better threat aggregation and choosing proper mitigation actions for different attack types",
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "authors": [
                {
                    "authorId": "40492371",
                    "name": "Euijin Choo"
                },
                {
                    "authorId": "143811518",
                    "name": "Mohamed Nabeel"
                },
                {
                    "authorId": "2261251177",
                    "name": "Doowon Kim"
                },
                {
                    "authorId": "2304350733",
                    "name": "Ravindu De Silva"
                },
                {
                    "authorId": "2151684774",
                    "name": "Tingyue Yu"
                },
                {
                    "authorId": "1783739",
                    "name": "Issa M. Khalil"
                }
            ]
        },
        {
            "paperId": "6f11bdcf4668a5f3c06208ada3d372611839ff68",
            "title": "Exploration of Enterprise Server Data to Assess Ease of Modeling System Behavior",
            "abstract": "Enterprise networks are one of the major targets for cyber attacks due to the vast amount of sensitive and valuable data they contain. A common approach to detecting attacks in the enterprise environment relies on modeling the behavior of users and systems to identify unexpected deviations. The feasibility of this approach crucially depends on how well attack-related events can be isolated from benign and mundane system activities. Despite the signi\ufb01cant focus on end-user systems, the background behavior of servers running critical services for the enterprise is less studied. To guide the design of detection methods tailored for servers, in this work, we examine system event records from 46 servers in a large enterprise obtained over a duration of ten weeks. We analyze the rareness characteristics and the similarity of the provenance relations in the event log data. Our \ufb01ndings show that server activity, in general, is highly variant over time and dissimilar across di\ufb00erent types of servers. However, careful consideration of pro\ufb01ling window of historical events and service level grouping of servers improve rareness measurements by 24.5%. Further, utilizing better contextual representations, the similarity in provenance relationships could be improved. An important implication of our \ufb01ndings is that detection techniques developed considering experimental setups with non-representative characteristics may perform poorly in practice.",
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "authors": [
                {
                    "authorId": "52211685",
                    "name": "Enes Altinisik"
                },
                {
                    "authorId": "1772206",
                    "name": "H. Sencar"
                },
                {
                    "authorId": "143811518",
                    "name": "Mohamed Nabeel"
                },
                {
                    "authorId": "1783739",
                    "name": "Issa M. Khalil"
                },
                {
                    "authorId": "2151684774",
                    "name": "Tingyue Yu"
                }
            ]
        },
        {
            "paperId": "7687dcf2495c3d70ff0309592a3697d358f209d4",
            "title": "Ten Years after ImageNet: A 360{\\deg} Perspective on AI",
            "abstract": "It is ten years since neural networks made their spectacular comeback. Prompted by this anniversary, we take a holistic perspective on Artificial Intelligence (AI). Supervised Learning for cognitive tasks is effectively solved - provided we have enough high-quality labeled data. However, deep neural network models are not easily interpretable, and thus the debate between blackbox and whitebox modeling has come to the fore. The rise of attention networks, self-supervised learning, generative modeling, and graph neural networks has widened the application space of AI. Deep Learning has also propelled the return of reinforcement learning as a core building block of autonomous decision making systems. The possible harms made possible by new AI technologies have raised socio-technical issues such as transparency, fairness, and accountability. The dominance of AI by Big-Tech who control talent, computing resources, and most importantly, data may lead to an extreme AI divide. Failure to meet high expectations in high profile, and much heralded flagship projects like self-driving vehicles could trigger another AI winter.",
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "authors": [
                {
                    "authorId": "50793091",
                    "name": "S. Chawla"
                },
                {
                    "authorId": "1683562",
                    "name": "Preslav Nakov"
                },
                {
                    "authorId": "2141768778",
                    "name": "Ahmed Ali"
                },
                {
                    "authorId": "152252333",
                    "name": "Wendy Hall"
                },
                {
                    "authorId": "2186981636",
                    "name": "Issa M. Khalil"
                },
                {
                    "authorId": "2187086383",
                    "name": "Xiaosong Ma"
                },
                {
                    "authorId": "1772206",
                    "name": "H. Sencar"
                },
                {
                    "authorId": "1684687",
                    "name": "Ingmar Weber"
                },
                {
                    "authorId": "2059979016",
                    "name": "Michael Wooldridge"
                },
                {
                    "authorId": "2151684774",
                    "name": "Tingyue Yu"
                }
            ]
        },
        {
            "paperId": "d8145f177e499fe494f6c83b39b082231e3602d8",
            "title": "Finding MNEMON: Reviving Memories of Node Embeddings",
            "abstract": "Previous security research efforts orbiting around graphs have been exclusively focusing on either (de-)anonymizing the graphs or understanding the security and privacy issues of graph neural networks. Little attention has been paid to understand the privacy risks of integrating the output from graph embedding models (e.g., node embeddings) with complex downstream machine learning pipelines. In this paper, we fill this gap and propose a novel model-agnostic graph recovery attack that exploits the implicit graph structural information preserved in the embeddings of graph nodes. We show that an adversary can recover edges with decent accuracy by only gaining access to the node embedding matrix of the original graph without interactions with the node embedding models. We demonstrate the effectiveness and applicability of our graph recovery attack through extensive experiments.",
            "fieldsOfStudy": [
                "Computer Science",
                "Mathematics"
            ],
            "authors": [
                {
                    "authorId": "2117688523",
                    "name": "Yun Shen"
                },
                {
                    "authorId": "51481296",
                    "name": "Yufei Han"
                },
                {
                    "authorId": "48806102",
                    "name": "Zhikun Zhang"
                },
                {
                    "authorId": "2145944749",
                    "name": "Min Chen"
                },
                {
                    "authorId": "2151684774",
                    "name": "Tingyue Yu"
                },
                {
                    "authorId": "145598514",
                    "name": "Michael Backes"
                },
                {
                    "authorId": "1698138",
                    "name": "Yang Zhang"
                },
                {
                    "authorId": "2350947",
                    "name": "G. Stringhini"
                }
            ]
        }
    ]
}