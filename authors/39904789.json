{
    "authorId": "39904789",
    "papers": [
        {
            "paperId": "b451d72b5f3e71afafc6e09167914e99868b6db4",
            "title": "A dual benchmarking study of facial forgery and facial forensics",
            "abstract": "In recent years, visual facial forgery has reached a level of sophistication that humans cannot identify fraud, which poses a significant threat to information security. A wide range of malicious applications have emerged, such as deepfake, fake news, defamation or blackmailing of celebrities, impersonation of politicians in political warfare, and the spreading of rumours to attract views. As a result, a rich body of visual forensic techniques has been proposed in an attempt to stop this dangerous trend. However, there is no comprehensive, fair, and unified performance evaluation to enlighten the community on best performing methods. The authors present a systematic benchmark beyond traditional surveys that provides in\u2010depth insights into facial forgery and facial forensics, grounding on robustness tests such as contrast, brightness, noise, resolution, missing information, and compression. The authors also provide a practical guideline of the benchmarking results, to determine the characteristics of the methods that serve as a comparative reference in this never\u2010ending war between measures and countermeasures. The authors\u2019 source code is open to the public.",
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "authors": [
                {
                    "authorId": "39904789",
                    "name": "Minh Tam Pham"
                },
                {
                    "authorId": "152399820",
                    "name": "T. T. Huynh"
                },
                {
                    "authorId": "153107187",
                    "name": "Vinh Tong"
                },
                {
                    "authorId": "2117824517",
                    "name": "T. Nguyen"
                },
                {
                    "authorId": "2117824154",
                    "name": "T. Nguyen"
                },
                {
                    "authorId": "2416851",
                    "name": "Hongzhi Yin"
                },
                {
                    "authorId": "144133815",
                    "name": "Q. Nguyen"
                }
            ]
        },
        {
            "paperId": "84de046f8c5e97fcde81a86c39f4dc5d6a1e04ee",
            "title": "A Reverse Supply Chain Model to Reduce Waste of Solar Panel in Ho Chi Minh City, Vietnam",
            "abstract": "The reverse supply chain (RSC) recently attracted many Vietnamese authorities, enterprises and academia owing to the rise of concern on the environment and regulations of waste process. Along with rapid development, Vietnamese manufacturing network has become tightly strained when the end-of-life (EOL) items are not taken back by their manufacturers but end up being processed disorderly in different local businesses. A distressing example is the waste of imported solar panels in Vietnam. Since the number of solar panels has grown steadily in Vietnam recently, we speculate that the network flows of EOL solar panel of Vietnam will be very large and complex in a few years. In order to help Vietnamese government establish efficiently RSC, our paper will apply the mixed-integer linear programming (MILP) and demonstrate an optimized solution for the RSC of EOL solar panel in Ho Chi Minh City. Indeed, via our collected data from current financial market of Ho Chi Minh city, our MILP shows that the optimal cost-reduction is 11219 USD, even with limited constraints of only two landfills and very few collection\u00a0facilities in Ho Chi Minh city at the moment. This result of our proposed RSC demonstrates that a significant profit is definitely possible when the number of collection facilities in Ho\u00a0Chi Minh city increase in the future. Also, our MILP approach is flexible for decision-makers to achieve a satisfactory solution.This is an Open Access article distributed under the terms of the Creative Commons Attribution License (http://creativecommons.org/licenses/by/4.0/), which permits unrestricted use, distribution, and reproduction in any medium\u00a0provided the original work is properly cited.\u00a0",
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "authors": [
                {
                    "authorId": "3364315",
                    "name": "T. Q. Thieu"
                },
                {
                    "authorId": "2146171626",
                    "name": "Anh Phuc Hoang Le"
                },
                {
                    "authorId": "39904789",
                    "name": "Minh Tam Pham"
                },
                {
                    "authorId": "2232108",
                    "name": "Phan Nguyen Ky Phuc"
                },
                {
                    "authorId": "2057663455",
                    "name": "Viet Hung Tran"
                }
            ]
        },
        {
            "paperId": "226dd4b27d5cdd734656d41e5983a7d8e515e0ef",
            "title": "ODAR: A Lightweight Object Detection Framework for Autonomous Driving Robots",
            "abstract": "Object detection is an emerging and essential problem in recent years, which has been widely applied in many aspects of daily life such as video surveillance, self-driving robots, and automatic payment. The rapid development of deep learning models allows object detectors to work in real-time with high accuracy. However, such a sophisticated model often requires robust computing infrastructure such as powerful graphics processing units (GPUs). This requirement might cause a severe issue for embedded systems with small, power-efficient artificial intelligence (AI) systems like Jetson Nano, which are often restricted in both memory storage and computing sheer power. In this work, we aim to address this challenge by proposing a lightweight object detection framework that is specialized for the Internet of Things (IoT) devices with low-power processors such as Jetson Nano. In order to detect the object with different size, our framework employs a backbone residual CNN-based network as the feature extractor. We then design a multi-layer model to combine the feature at different levels of granularity, before using the processed feature to locate and classify the object. We also apply augmentation techniques to enhance the robustness of the framework to adversarial factors. Extensive experiments on real devices in many scenarios, such as autonomous cars or wireless robot recharging systems, showed that our technique can achieve nearly on par results with the state-of-the-art YOLOv5 while requires only one-fourth of computation power.",
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "authors": [
                {
                    "authorId": "2045776591",
                    "name": "Le Hoang Duong"
                },
                {
                    "authorId": "152399820",
                    "name": "T. T. Huynh"
                },
                {
                    "authorId": "39904789",
                    "name": "Minh Tam Pham"
                },
                {
                    "authorId": "3063248",
                    "name": "Gwangzeen Ko"
                },
                {
                    "authorId": "2151193213",
                    "name": "Jung Ick Moon"
                },
                {
                    "authorId": "2053004490",
                    "name": "Jun Jo"
                },
                {
                    "authorId": "2136146454",
                    "name": "N. Q. Hung"
                }
            ]
        },
        {
            "paperId": "3dbf7c825bbda47d8c33d12f39cc22d9de8b1ad0",
            "title": "A War Beyond Deepfake: Benchmarking Facial Counterfeits and Countermeasures",
            "abstract": "In recent years, visual forgery has reached a level of sophistication that humans cannot identify fraud, which poses a signi\ufb01cant threat to information security. A wide range of malicious applications have emerged, such as fake news, defamation or blackmailing of celebrities, impersonation of politicians in political warfare, and the spreading of rumours to attract views. As a result, a rich body of visual forensic techniques has been proposed in an attempt to stop this dangerous trend. In this paper, we present a benchmark that provides in-depth insights into visual forgery and visual forensics, using a comprehensive and empirical approach. More speci\ufb01cally, we develop an independent framework that integrates state-of-the-arts counterfeit generators and detectors, and measure the performance of these techniques using various criteria. We also perform an exhaustive analysis of the benchmarking results, to determine the characteristics of the methods that serve as a comparative reference in this never-ending war between measures and countermeasures.",
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "authors": [
                {
                    "authorId": "39904789",
                    "name": "Minh Tam Pham"
                },
                {
                    "authorId": "152399820",
                    "name": "T. T. Huynh"
                },
                {
                    "authorId": "153107187",
                    "name": "Vinh Tong"
                },
                {
                    "authorId": "2117824517",
                    "name": "T. Nguyen"
                },
                {
                    "authorId": "2117824154",
                    "name": "T. Nguyen"
                },
                {
                    "authorId": "2416851",
                    "name": "Hongzhi Yin"
                },
                {
                    "authorId": "144133815",
                    "name": "Q. Nguyen"
                }
            ]
        },
        {
            "paperId": "6090ba8d3ce0fb13c85fbda078443f0e79414af2",
            "title": "Efficient-Frequency: a hybrid visual forensic framework for facial forgery detection",
            "abstract": "The recent years have witnessed the significant development of visual forgery techniques and their malicious applications such as spreading of fake news and rumours, defamation or blackmailing of politicians and celebrities, manipulation of election result in political warfare. The manipulated contents have reached to such sophisticated level that human cannot tell apart whether a given content is real or fake. To deal with this serious threat, a rich body of visual forensic techniques has been proposed for detecting forged video and images. However, existing techniques either rely solely on engineered features or require a complex deep learning model to extract the underlying patterns. In this paper, we propose a novel end-to-end visual forensic framework that can incorporate different modalities to efficiently classify real and forged contents. The model employs both the original content and its frequency domain analysis to fully exploit the richness of the image latent patterns. They are forwarded into two separated EfficientNet, a light yet efficient neural network architecture specialized for image classification, for pattern extraction. Then, we design a late-fusion mechanism to fuse the learnt features in original and frequency domain based on the importance of the underlying information. Our experimental results show that our proposed technique outperforms other state-of-the-art forensic approaches in many datasets and being robust to various visual forgery techniques.",
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "authors": [
                {
                    "authorId": "2045384711",
                    "name": "Chau Xuan Truong Du"
                },
                {
                    "authorId": "2045776591",
                    "name": "Le Hoang Duong"
                },
                {
                    "authorId": "152399820",
                    "name": "T. T. Huynh"
                },
                {
                    "authorId": "39904789",
                    "name": "Minh Tam Pham"
                },
                {
                    "authorId": "1925773",
                    "name": "Nguyen Quoc Viet Hung"
                },
                {
                    "authorId": "2093140094",
                    "name": "Jun Jo"
                }
            ]
        }
    ]
}