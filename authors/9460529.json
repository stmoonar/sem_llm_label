{
    "authorId": "9460529",
    "papers": [
        {
            "paperId": "032cbe48a88325c50ad9bc73e8d5f000fb84ffe7",
            "title": "Visual Hallucination: Definition, Quantification, and Prescriptive Remediations",
            "abstract": "The troubling rise of hallucination presents perhaps the most significant impediment to the advancement of responsible AI. In recent times, considerable research has focused on detecting and mitigating hallucination in Large Language Models (LLMs). However, it's worth noting that hallucination is also quite prevalent in Vision-Language models (VLMs). In this paper, we offer a fine-grained discourse on profiling VLM hallucination based on two tasks: i) image captioning, and ii) Visual Question Answering (VQA). We delineate eight fine-grained orientations of visual hallucination: i) Contextual Guessing, ii) Identity Incongruity, iii) Geographical Erratum, iv) Visual Illusion, v) Gender Anomaly, vi) VLM as Classifier, vii) Wrong Reading, and viii) Numeric Discrepancy. We curate Visual HallucInation eLiciTation (VHILT), a publicly available dataset comprising 2,000 samples generated using eight VLMs across two tasks of captioning and VQA along with human annotations for the categories as mentioned earlier.",
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "authors": [
                {
                    "authorId": "2106627712",
                    "name": "Anku Rani"
                },
                {
                    "authorId": "9460529",
                    "name": "Vipula Rawte"
                },
                {
                    "authorId": "2293396310",
                    "name": "Harshad Sharma"
                },
                {
                    "authorId": "2293408576",
                    "name": "Neeraj Anand"
                },
                {
                    "authorId": "2293394084",
                    "name": "Krishnav Rajbangshi"
                },
                {
                    "authorId": "2064342742",
                    "name": "Amit P. Sheth"
                },
                {
                    "authorId": "2258322706",
                    "name": "Amitava Das"
                }
            ]
        },
        {
            "paperId": "2839d79911e484e0a5740e8047aa4c7736a9f3e5",
            "title": "FETILDA: Evaluation Framework for Effective Representations of Long Financial Documents",
            "abstract": "In the financial sphere, there is a wealth of accumulated unstructured financial data, such as the textual disclosure documents that companies submit on a regular basis to regulatory agencies, such as the Securities and Exchange Commission. These documents are typically very long and tend to contain valuable soft information about a company\u2019s performance that is not present in quantitative predictors. It is therefore of great interest to learn predictive models from these long textual documents, especially for forecasting numerical key performance indicators. In recent years, there has been great progress in natural language processing via pre-trained language models (LMs) learned from large corpora of textual data. This prompts the important question of whether they can be used effectively to produce representations for long documents, as well as how we can evaluate the effectiveness of representations produced by various LMs. Our work focuses on answering this critical question, namely, the evaluation of the efficacy of various LMs in extracting useful soft information from long textual documents for prediction tasks. In this article, we propose and implement a deep learning evaluation framework that utilizes a sequential chunking approach combined with an attention mechanism. We perform an extensive set of experiments on a collection of 10-K reports submitted annually by U.S. banks, and another dataset of reports submitted by U.S. companies, to investigate thoroughly the performance of different types of language models. Overall, our framework using LMs outperforms strong baseline methods for textual modeling as well as for numerical regression. Our work provides better insights into how utilizing pre-trained domain-specific and fine-tuned long-input LMs for representing long documents can improve the quality of representation of textual data and, therefore, help in improving predictive analyses.",
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "authors": [
                {
                    "authorId": "2296125030",
                    "name": "B. Xia"
                },
                {
                    "authorId": "9460529",
                    "name": "Vipula Rawte"
                },
                {
                    "authorId": "2109972396",
                    "name": "Aparna Gupta"
                },
                {
                    "authorId": "2307114589",
                    "name": "Mohammed J. Zaki"
                }
            ]
        },
        {
            "paperId": "5272acad9e4201e93dabe3fd99bd7ead9b1a544d",
            "title": "A Comprehensive Survey of Hallucination Mitigation Techniques in Large Language Models",
            "abstract": "As Large Language Models (LLMs) continue to advance in their ability to write human-like text, a key challenge remains around their tendency to hallucinate generating content that appears factual but is ungrounded. This issue of hallucination is arguably the biggest hindrance to safely deploying these powerful LLMs into real-world production systems that impact people's lives. The journey toward widespread adoption of LLMs in practical settings heavily relies on addressing and mitigating hallucinations. Unlike traditional AI systems focused on limited tasks, LLMs have been exposed to vast amounts of online text data during training. While this allows them to display impressive language fluency, it also means they are capable of extrapolating information from the biases in training data, misinterpreting ambiguous prompts, or modifying the information to align superficially with the input. This becomes hugely alarming when we rely on language generation capabilities for sensitive applications, such as summarizing medical records, financial analysis reports, etc. This paper presents a comprehensive survey of over 32 techniques developed to mitigate hallucination in LLMs. Notable among these are Retrieval Augmented Generation (Lewis et al, 2021), Knowledge Retrieval (Varshney et al,2023), CoNLI (Lei et al, 2023), and CoVe (Dhuliawala et al, 2023). Furthermore, we introduce a detailed taxonomy categorizing these methods based on various parameters, such as dataset utilization, common tasks, feedback mechanisms, and retriever types. This classification helps distinguish the diverse approaches specifically designed to tackle hallucination issues in LLMs. Additionally, we analyze the challenges and limitations inherent in these techniques, providing a solid foundation for future research in addressing hallucinations and related phenomena within the realm of LLMs.",
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "authors": [
                {
                    "authorId": "2146190509",
                    "name": "S. Tonmoy"
                },
                {
                    "authorId": "2277446934",
                    "name": "S. M. M. Zaman"
                },
                {
                    "authorId": "2212131028",
                    "name": "Vinija Jain"
                },
                {
                    "authorId": "2106627712",
                    "name": "Anku Rani"
                },
                {
                    "authorId": "9460529",
                    "name": "Vipula Rawte"
                },
                {
                    "authorId": "40016108",
                    "name": "Aman Chadha"
                },
                {
                    "authorId": "2258322706",
                    "name": "Amitava Das"
                }
            ]
        },
        {
            "paperId": "b1e3eaa8d51d53037d01ebb7805d882e5e7860b1",
            "title": "FACTOID: FACtual enTailment fOr hallucInation Detection",
            "abstract": "The widespread adoption of Large Language Models (LLMs) has facilitated numerous benefits. However, hallucination is a significant concern. In response, Retrieval Augmented Generation (RAG) has emerged as a highly promising paradigm to improve LLM outputs by grounding them in factual information. RAG relies on textual entailment (TE) or similar methods to check if the text produced by LLMs is supported or contradicted, compared to retrieved documents. This paper argues that conventional TE methods are inadequate for spotting hallucinations in content generated by LLMs. For instance, consider a prompt about the 'USA's stance on the Ukraine war''. The AI-generated text states, ...U.S. President Barack Obama says the U.S. will not put troops in Ukraine...'' However, during the war the U.S. president is Joe Biden which contradicts factual reality. Moreover, current TE systems are unable to accurately annotate the given text and identify the exact portion that is contradicted. To address this, we introduces a new type of TE called ``Factual Entailment (FE).'', aims to detect factual inaccuracies in content generated by LLMs while also highlighting the specific text segment that contradicts reality. We present FACTOID (FACTual enTAILment for hallucInation Detection), a benchmark dataset for FE. We propose a multi-task learning (MTL) framework for FE, incorporating state-of-the-art (SoTA) long text embeddings such as e5-mistral-7b-instruct, along with GPT-3, SpanBERT, and RoFormer. The proposed MTL architecture for FE achieves an avg. 40\\% improvement in accuracy on the FACTOID benchmark compared to SoTA TE methods. As FE automatically detects hallucinations, we assessed 15 modern LLMs and ranked them using our proposed Auto Hallucination Vulnerability Index (HVI_auto). This index quantifies and offers a comparative scale to evaluate and rank LLMs according to their hallucinations.",
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "authors": [
                {
                    "authorId": "9460529",
                    "name": "Vipula Rawte"
                },
                {
                    "authorId": "2293725791",
                    "name": "S. M. Towhidul"
                },
                {
                    "authorId": "2229651428",
                    "name": "Islam Tonmoy"
                },
                {
                    "authorId": "2293394084",
                    "name": "Krishnav Rajbangshi"
                },
                {
                    "authorId": "2293723465",
                    "name": "Shravani Nag"
                },
                {
                    "authorId": "40016108",
                    "name": "Aman Chadha"
                },
                {
                    "authorId": "2064342742",
                    "name": "Amit P. Sheth"
                },
                {
                    "authorId": "2258322706",
                    "name": "Amitava Das"
                },
                {
                    "authorId": "2293724716",
                    "name": "Joe Biden"
                }
            ]
        },
        {
            "paperId": "e3c316369d0f366267958afe5b9f4a263b9e8a68",
            "title": "\"Sorry, Come Again?\" Prompting - Enhancing Comprehension and Diminishing Hallucination with [PAUSE]-injected Optimal Paraphrasing",
            "abstract": "Hallucination has emerged as the most vulnerable aspect of contemporary Large Language Models (LLMs). In this paper, we introduce the Sorry, Come Again (SCA) prompting, aimed to avoid LLM hallucinations by enhancing comprehension through: (i) optimal paraphrasing and (ii) injecting [PAUSE] tokens to delay LLM generation. First, we provide an in-depth analysis of linguistic nuances: formality, readability, and concreteness of prompts for 21 LLMs, and elucidate how these nuances contribute to hallucinated generation. Prompts with lower readability, formality, or concreteness pose comprehension challenges for LLMs, similar to those faced by humans. In such scenarios, an LLM tends to speculate and generate content based on its imagination (associative memory) to fill these information gaps. Although these speculations may occasionally align with factual information, their accuracy is not assured, often resulting in hallucination. Recent studies reveal that an LLM often neglects the middle sections of extended prompts, a phenomenon termed as lost in the middle. While a specific paraphrase may suit one LLM, the same paraphrased version may elicit a different response from another LLM. Therefore, we propose an optimal paraphrasing technique to identify the most comprehensible paraphrase of a given prompt, evaluated using Integrated Gradient (and its variations) to guarantee that the LLM accurately processes all words. While reading lengthy sentences, humans often pause at various points to better comprehend the meaning read thus far. We have fine-tuned an LLM with injected [PAUSE] tokens, allowing the LLM to pause while reading lengthier prompts. This has brought several key contributions: (i) determining the optimal position to inject [PAUSE], (ii) determining the number of [PAUSE] tokens to be inserted, and (iii) introducing reverse proxy tuning to fine-tune the LLM for [PAUSE] insertion.",
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "authors": [
                {
                    "authorId": "9460529",
                    "name": "Vipula Rawte"
                },
                {
                    "authorId": "2243200258",
                    "name": "Prachi Priya"
                },
                {
                    "authorId": "2293725791",
                    "name": "S. M. Towhidul"
                },
                {
                    "authorId": "2229651428",
                    "name": "Islam Tonmoy"
                },
                {
                    "authorId": "2242955156",
                    "name": "M. M. Zaman"
                },
                {
                    "authorId": "40016108",
                    "name": "Aman Chadha"
                },
                {
                    "authorId": "2064342742",
                    "name": "Amit P. Sheth"
                },
                {
                    "authorId": "2258322706",
                    "name": "Amitava Das"
                },
                {
                    "authorId": "2293777416",
                    "name": "Nelson F Liu"
                },
                {
                    "authorId": "2288827368",
                    "name": "Kevin Lin"
                },
                {
                    "authorId": "2285131936",
                    "name": "John Hewitt"
                },
                {
                    "authorId": "40404493",
                    "name": "Ashwin Paranjape"
                },
                {
                    "authorId": "2253475117",
                    "name": "Michele Bevilacqua"
                },
                {
                    "authorId": "2254812433",
                    "name": "F. Petroni"
                },
                {
                    "authorId": "11323179",
                    "name": "Yinhan Liu"
                },
                {
                    "authorId": "40511414",
                    "name": "Myle Ott"
                },
                {
                    "authorId": "39589154",
                    "name": "Naman Goyal"
                },
                {
                    "authorId": "3048577",
                    "name": "Jingfei Du"
                },
                {
                    "authorId": "2285032310",
                    "name": "Mandar Joshi"
                },
                {
                    "authorId": "2255489905",
                    "name": "Danqi Chen"
                },
                {
                    "authorId": "2253752918",
                    "name": "Omer Levy"
                },
                {
                    "authorId": "38909097",
                    "name": "Alec Radford"
                },
                {
                    "authorId": "2242326456",
                    "name": "Jeffrey Wu"
                },
                {
                    "authorId": "48422824",
                    "name": "R. Child"
                },
                {
                    "authorId": "150970919",
                    "name": "D. Luan"
                },
                {
                    "authorId": "2698777",
                    "name": "Dario Amodei"
                },
                {
                    "authorId": "2269733851",
                    "name": "Colin Raffel"
                },
                {
                    "authorId": "1846258",
                    "name": "Noam M. Shazeer"
                },
                {
                    "authorId": "2275223445",
                    "name": "A. Roberts"
                },
                {
                    "authorId": "2275576898",
                    "name": "K. Lee"
                },
                {
                    "authorId": "46617804",
                    "name": "Sharan Narang"
                },
                {
                    "authorId": "1380243217",
                    "name": "Michael Matena"
                },
                {
                    "authorId": "2260365292",
                    "name": "Yanqi Zhou"
                },
                {
                    "authorId": "2293767405",
                    "name": "Wei Li"
                },
                {
                    "authorId": "2260118930",
                    "name": "P. J. L. 2020"
                },
                {
                    "authorId": "46199305",
                    "name": "Rohan Taori"
                },
                {
                    "authorId": "2708454",
                    "name": "Ishaan Gulrajani"
                },
                {
                    "authorId": "2256233130",
                    "name": "Tianyi Zhang"
                },
                {
                    "authorId": "2257007362",
                    "name": "Yann Dubois"
                },
                {
                    "authorId": "2250724754",
                    "name": "Xuechen Li"
                },
                {
                    "authorId": "1412355294",
                    "name": "Carlos Guestrin"
                },
                {
                    "authorId": "2260019213",
                    "name": "Percy Liang"
                },
                {
                    "authorId": "2253575091",
                    "name": "Tatsunori Hashimoto"
                },
                {
                    "authorId": "2260107536",
                    "name": "Stanford"
                },
                {
                    "authorId": "2113243762",
                    "name": "Hugo Touvron"
                },
                {
                    "authorId": "2249724552",
                    "name": "Louis Martin"
                },
                {
                    "authorId": "2282542714",
                    "name": "Kevin Stone"
                },
                {
                    "authorId": "2214809450",
                    "name": "Peter Albert"
                },
                {
                    "authorId": "2634674",
                    "name": "Amjad Almahairi"
                },
                {
                    "authorId": "2223764353",
                    "name": "Yasmine Babaei"
                },
                {
                    "authorId": "2223756247",
                    "name": "Nikolay Bashlykov"
                },
                {
                    "authorId": "47505161",
                    "name": "Soumya Batra"
                },
                {
                    "authorId": "51229603",
                    "name": "Prajjwal Bhargava"
                },
                {
                    "authorId": "2116473",
                    "name": "Shruti Bhosale"
                },
                {
                    "authorId": "2265492068",
                    "name": "Daniel M. Bikel"
                },
                {
                    "authorId": "2040305955",
                    "name": "Lukas Blecher"
                },
                {
                    "authorId": "66286536",
                    "name": "Cristian Cant\u00f3n Ferrer"
                },
                {
                    "authorId": "2108267192",
                    "name": "Moya Chen"
                },
                {
                    "authorId": "7153363",
                    "name": "Guillem Cucurull"
                },
                {
                    "authorId": "71039937",
                    "name": "David Esiobu"
                },
                {
                    "authorId": "2166312768",
                    "name": "Jude Fernandes"
                },
                {
                    "authorId": "2223974989",
                    "name": "Jeremy Fu"
                },
                {
                    "authorId": "2223742000",
                    "name": "Wenyin Fu"
                },
                {
                    "authorId": "2223748737",
                    "name": "Brian Fuller"
                },
                {
                    "authorId": "2294721061",
                    "name": "Cynthia Gao"
                },
                {
                    "authorId": "28554843",
                    "name": "Vedanuj Goswami"
                },
                {
                    "authorId": "2129047988",
                    "name": "Anthony Hartshorn"
                },
                {
                    "authorId": "2268759462",
                    "name": "Saghar Hosseini"
                },
                {
                    "authorId": "2266467782",
                    "name": "Rui Hou"
                },
                {
                    "authorId": "2065277797",
                    "name": "Hakan Inan"
                },
                {
                    "authorId": "2059886128",
                    "name": "Marcin Kardas"
                },
                {
                    "authorId": "2190957318",
                    "name": "Viktor Kerkez"
                },
                {
                    "authorId": "2072010",
                    "name": "Madian Khabsa"
                },
                {
                    "authorId": "2207049",
                    "name": "Isabel M. Kloumann"
                },
                {
                    "authorId": "2293724456",
                    "name": "Punit A. V. Ko-renev"
                },
                {
                    "authorId": "2257006866",
                    "name": "Singh Koura"
                },
                {
                    "authorId": "114952298",
                    "name": "Marie-Anne Lachaux"
                },
                {
                    "authorId": "46183616",
                    "name": "Thibaut Lavril"
                },
                {
                    "authorId": "2223749565",
                    "name": "Jenya Lee"
                },
                {
                    "authorId": "2145259939",
                    "name": "Diana Liskovich"
                },
                {
                    "authorId": "2282552151",
                    "name": "Yinghai Lu"
                },
                {
                    "authorId": "2283511285",
                    "name": "Yu-shan Mao"
                },
                {
                    "authorId": "1490887583",
                    "name": "Xavier Martinet"
                },
                {
                    "authorId": "39980906",
                    "name": "Todor Mihaylov"
                },
                {
                    "authorId": "2282543499",
                    "name": "Pushkar Mishra"
                },
                {
                    "authorId": "66839644",
                    "name": "Igor Molybog"
                },
                {
                    "authorId": "2282534534",
                    "name": "Yixin Nie"
                },
                {
                    "authorId": "2282542314",
                    "name": "Andrew Poulton"
                },
                {
                    "authorId": "39906022",
                    "name": "Jeremy Reizenstein"
                },
                {
                    "authorId": "150282885",
                    "name": "Rashi Rungta"
                },
                {
                    "authorId": "1859294",
                    "name": "Kalyan Saladi"
                },
                {
                    "authorId": "14279694",
                    "name": "Alan Schelten"
                },
                {
                    "authorId": "2214818043",
                    "name": "Ruan Silva"
                },
                {
                    "authorId": "2268821751",
                    "name": "Eric Michael Smith"
                },
                {
                    "authorId": "2293725986",
                    "name": "R. Subramanian"
                },
                {
                    "authorId": "2277112719",
                    "name": "Xianyu Tan"
                },
                {
                    "authorId": "2237987675",
                    "name": "Binh Tang"
                },
                {
                    "authorId": "2110697298",
                    "name": "Ross Taylor"
                },
                {
                    "authorId": "2287206016",
                    "name": "Adina Williams"
                },
                {
                    "authorId": "2223770369",
                    "name": "Jian Xiang Kuan"
                },
                {
                    "authorId": "2214843767",
                    "name": "Puxin Xu"
                },
                {
                    "authorId": "2293992938",
                    "name": "Zhengxu Yan"
                },
                {
                    "authorId": "121929334",
                    "name": "Iliyan Zarov"
                },
                {
                    "authorId": "2108473229",
                    "name": "Yuchen Zhang"
                },
                {
                    "authorId": "2247818297",
                    "name": "Angela Fan"
                },
                {
                    "authorId": "2165660870",
                    "name": "M. Kambadur"
                },
                {
                    "authorId": "2166043087",
                    "name": "Aurelien Rodriguez"
                }
            ]
        },
        {
            "paperId": "71bc0c97c20fffce796a355b16bd202987260029",
            "title": "A Survey of Hallucination in Large Foundation Models",
            "abstract": "Hallucination in a foundation model (FM) refers to the generation of content that strays from factual reality or includes fabricated information. This survey paper provides an extensive overview of recent efforts that aim to identify, elucidate, and tackle the problem of hallucination, with a particular focus on ``Large'' Foundation Models (LFMs). The paper classifies various types of hallucination phenomena that are specific to LFMs and establishes evaluation criteria for assessing the extent of hallucination. It also examines existing strategies for mitigating hallucination in LFMs and discusses potential directions for future research in this area. Essentially, the paper offers a comprehensive examination of the challenges and solutions related to hallucination in LFMs.",
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "authors": [
                {
                    "authorId": "9460529",
                    "name": "Vipula Rawte"
                },
                {
                    "authorId": "144463965",
                    "name": "A. Sheth"
                },
                {
                    "authorId": "48806891",
                    "name": "Amitava Das"
                }
            ]
        },
        {
            "paperId": "99bfe503743c5ec8e16e50ab8438159cdb533a89",
            "title": "The Troubling Emergence of Hallucination in Large Language Models - An Extensive Definition, Quantification, and Prescriptive Remediations",
            "abstract": "The recent advancements in Large Language Models (LLMs) have garnered widespread acclaim for their remarkable emerging capabilities. However, the issue of hallucination has parallelly emerged as a by-product, posing significant concerns. While some recent endeavors have been made to identify and mitigate different types of hallucination, there has been a limited emphasis on the nuanced categorization of hallucination and associated mitigation methods. To address this gap, we offer a fine-grained discourse on profiling hallucination based on its degree, orientation, and category, along with offering strategies for alleviation. As such, we define two overarching orientations of hallucination: (i) factual mirage (FM) and (ii) silver lining (SL). To provide a more comprehensive understanding, both orientations are further sub-categorized into intrinsic and extrinsic, with three degrees of severity - (i) mild, (ii) moderate, and (iii) alarming. We also meticulously categorize hallucination into six types: (i) acronym ambiguity, (ii) numeric nuisance, (iii) generated golem, (iv) virtual voice, (v) geographic erratum, and (vi) time wrap. Furthermore, we curate HallucInation eLiciTation (HILT), a publicly available dataset comprising of 75,000 samples generated using 15 contemporary LLMs along with human annotations for the aforementioned categories. Finally, to establish a method for quantifying and to offer a comparative spectrum that allows us to evaluate and rank LLMs based on their vulnerability to producing hallucinations, we propose Hallucination Vulnerability Index (HVI). We firmly believe that HVI holds significant value as a tool for the wider NLP community, with the potential to serve as a rubric in AI-related policy-making. In conclusion, we propose two solution strategies for mitigating hallucinations.",
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "authors": [
                {
                    "authorId": "9460529",
                    "name": "Vipula Rawte"
                },
                {
                    "authorId": "2257001500",
                    "name": "Swagata Chakraborty"
                },
                {
                    "authorId": "2257001966",
                    "name": "Agnibh Pathak"
                },
                {
                    "authorId": "2189479826",
                    "name": "Anubhav Sarkar"
                },
                {
                    "authorId": "2103483687",
                    "name": "S.M. Towhidul Islam Tonmoy"
                },
                {
                    "authorId": "2229651428",
                    "name": "Islam Tonmoy"
                },
                {
                    "authorId": "40016108",
                    "name": "Aman Chadha"
                },
                {
                    "authorId": "2064342742",
                    "name": "Amit P. Sheth"
                },
                {
                    "authorId": "2258322706",
                    "name": "Amitava Das"
                },
                {
                    "authorId": "2076602721",
                    "name": "Paris"
                },
                {
                    "authorId": "2064327462",
                    "name": "A. Sridhar"
                },
                {
                    "authorId": "2238206449",
                    "name": "Erik Visser"
                },
                {
                    "authorId": "2257006156",
                    "name": "Improved"
                },
                {
                    "authorId": "2279935214",
                    "name": "Jianlin Su"
                },
                {
                    "authorId": "2257339854",
                    "name": "Yu Lu"
                },
                {
                    "authorId": "1382633722",
                    "name": "Shengfeng Pan"
                },
                {
                    "authorId": "2159557286",
                    "name": "Ahmed Murtadha"
                },
                {
                    "authorId": "2079396269",
                    "name": "Bo Wen"
                },
                {
                    "authorId": "2257345549",
                    "name": "Yunfeng Liu"
                },
                {
                    "authorId": "2257006862",
                    "name": "Roformer"
                },
                {
                    "authorId": "46199305",
                    "name": "Rohan Taori"
                },
                {
                    "authorId": "2708454",
                    "name": "Ishaan Gulrajani"
                },
                {
                    "authorId": "2256233130",
                    "name": "Tianyi Zhang"
                },
                {
                    "authorId": "2257007362",
                    "name": "Yann Dubois"
                },
                {
                    "authorId": "2250724754",
                    "name": "Xuechen Li"
                },
                {
                    "authorId": "1412355294",
                    "name": "Carlos Guestrin"
                },
                {
                    "authorId": "2256995425",
                    "name": "Percy Liang"
                },
                {
                    "authorId": "2117567142",
                    "name": "Tatsunori Hashimoto"
                },
                {
                    "authorId": "2250092519",
                    "name": "Stanford"
                },
                {
                    "authorId": "2113243762",
                    "name": "Hugo Touvron"
                },
                {
                    "authorId": "46183616",
                    "name": "Thibaut Lavril"
                },
                {
                    "authorId": "1410231361",
                    "name": "Gautier Izacard"
                },
                {
                    "authorId": "1490887583",
                    "name": "Xavier Martinet"
                },
                {
                    "authorId": "114952298",
                    "name": "Marie-Anne Lachaux"
                },
                {
                    "authorId": "47733973",
                    "name": "Timoth\u00e9e Lacroix"
                },
                {
                    "authorId": "3361236",
                    "name": "Baptiste Rozi\u00e8re"
                },
                {
                    "authorId": "39589154",
                    "name": "Naman Goyal"
                },
                {
                    "authorId": "2072738644",
                    "name": "Eric Hambro"
                },
                {
                    "authorId": "2209986197",
                    "name": "Faisal Azhar"
                },
                {
                    "authorId": "2166043087",
                    "name": "Aurelien Rodriguez"
                },
                {
                    "authorId": "2319608",
                    "name": "Armand Joulin"
                },
                {
                    "authorId": "2257007291",
                    "name": "Thomas Wolf"
                },
                {
                    "authorId": "1380459402",
                    "name": "Lysandre Debut"
                },
                {
                    "authorId": "51918868",
                    "name": "Victor Sanh"
                },
                {
                    "authorId": "40811585",
                    "name": "Julien Chaumond"
                },
                {
                    "authorId": "40899333",
                    "name": "Clement Delangue"
                },
                {
                    "authorId": "1382164294",
                    "name": "Anthony Moi"
                },
                {
                    "authorId": "1382164165",
                    "name": "Pierric Cistac"
                },
                {
                    "authorId": "1382164170",
                    "name": "Tim Rault"
                },
                {
                    "authorId": "2185329",
                    "name": "R\u00e9mi Louf"
                },
                {
                    "authorId": "2257005341",
                    "name": "Morgan Funtow-icz"
                },
                {
                    "authorId": "48776237",
                    "name": "Joe Davison"
                },
                {
                    "authorId": "88728159",
                    "name": "Sam Shleifer"
                },
                {
                    "authorId": "138609838",
                    "name": "Patrick von Platen"
                },
                {
                    "authorId": "2257128341",
                    "name": "Clara Ma"
                },
                {
                    "authorId": "2262249",
                    "name": "Yacine Jernite"
                },
                {
                    "authorId": "3008389",
                    "name": "J. Plu"
                },
                {
                    "authorId": "2257127518",
                    "name": "Canwen Xu"
                },
                {
                    "authorId": "1379806208",
                    "name": "Teven Le Scao"
                },
                {
                    "authorId": "103682620",
                    "name": "Sylvain Gugger"
                },
                {
                    "authorId": "2125818054",
                    "name": "Mariama Drame"
                },
                {
                    "authorId": "2113836945",
                    "name": "Quentin Lhoest"
                },
                {
                    "authorId": "2238121623",
                    "name": "Susan Zhang"
                },
                {
                    "authorId": "3849208",
                    "name": "Stephen Roller"
                },
                {
                    "authorId": "2347956",
                    "name": "Mikel Artetxe"
                },
                {
                    "authorId": "2108267192",
                    "name": "Moya Chen"
                },
                {
                    "authorId": "2257570528",
                    "name": "Shuohui Chen"
                },
                {
                    "authorId": "2257006163",
                    "name": "Christopher De-wan"
                },
                {
                    "authorId": "2138579860",
                    "name": "Mona T. Diab"
                },
                {
                    "authorId": "2257006892",
                    "name": "Xi Xian Li"
                },
                {
                    "authorId": "2257007395",
                    "name": "Todor Victoria Lin"
                },
                {
                    "authorId": "40511414",
                    "name": "Myle Ott"
                },
                {
                    "authorId": "35752280",
                    "name": "Kurt Shuster"
                },
                {
                    "authorId": "2257006894",
                    "name": "Punit Daniel Simig"
                },
                {
                    "authorId": "2257006866",
                    "name": "Singh Koura"
                },
                {
                    "authorId": "2257007723",
                    "name": "Anjali Sridhar"
                },
                {
                    "authorId": "2238056517",
                    "name": "Tianlu Wang"
                },
                {
                    "authorId": "2257007614",
                    "name": "Luke Zettlemoyer. 2022"
                },
                {
                    "authorId": "2052152920",
                    "name": "Daniel M. Ziegler"
                },
                {
                    "authorId": "1387983862",
                    "name": "Nisan Stiennon"
                },
                {
                    "authorId": "2257137166",
                    "name": "Jeffrey Wu"
                },
                {
                    "authorId": "2257135738",
                    "name": "Tom B. Brown"
                },
                {
                    "authorId": "38909097",
                    "name": "Alec Radford"
                },
                {
                    "authorId": "2698777",
                    "name": "Dario Amodei"
                },
                {
                    "authorId": "2257006890",
                    "name": "Paul F. Chris-tiano"
                }
            ]
        },
        {
            "paperId": "9ceed28b20acfcc7e8e3ddee519eb11d7f2aef86",
            "title": "ProKnow: Process knowledge for safety constrained and explainable question generation for mental health diagnostic assistance",
            "abstract": "Virtual Mental Health Assistants (VMHAs) are utilized in health care to provide patient services such as counseling and suggestive care. They are not used for patient diagnostic assistance because they cannot adhere to safety constraints and specialized clinical process knowledge (ProKnow) used to obtain clinical diagnoses. In this work, we define ProKnow as an ordered set of information that maps to evidence-based guidelines or categories of conceptual understanding to experts in a domain. We also introduce a new dataset of diagnostic conversations guided by safety constraints and ProKnow that healthcare professionals use (ProKnow-data). We develop a method for natural language question generation (NLG) that collects diagnostic information from the patient interactively (ProKnow-algo). We demonstrate the limitations of using state-of-the-art large-scale language models (LMs) on this dataset. ProKnow-algo incorporates the process knowledge through explicitly modeling safety, knowledge capture, and explainability. As computational metrics for evaluation do not directly translate to clinical settings, we involve expert clinicians in designing evaluation metrics that test four properties: safety, logical coherence, and knowledge capture for explainability while minimizing the standard cross entropy loss to preserve distribution semantics-based similarity to the ground truth. LMs with ProKnow-algo generated 89% safer questions in the depression and anxiety domain (tested property: safety). Further, without ProKnow-algo generations question did not adhere to clinical process knowledge in ProKnow-data (tested property: knowledge capture). In comparison, ProKnow-algo-based generations yield a 96% reduction in our metrics to measure knowledge capture. The explainability of the generated question is assessed by computing similarity with concepts in depression and anxiety knowledge bases. Overall, irrespective of the type of LMs, ProKnow-algo achieved an averaged 82% improvement over simple pre-trained LMs on safety, explainability, and process-guided question generation. For reproducibility, we will make ProKnow-data and the code repository of ProKnow-algo publicly available upon acceptance.",
            "fieldsOfStudy": [
                "Medicine",
                "Computer Science"
            ],
            "authors": [
                {
                    "authorId": "2091913080",
                    "name": "Kaushik Roy"
                },
                {
                    "authorId": "1491238594",
                    "name": "Manas Gaur"
                },
                {
                    "authorId": "2199859429",
                    "name": "Misagh Soltani"
                },
                {
                    "authorId": "9460529",
                    "name": "Vipula Rawte"
                },
                {
                    "authorId": "51043791",
                    "name": "A. Kalyan"
                },
                {
                    "authorId": "2064342729",
                    "name": "Amit P. Sheth"
                }
            ]
        },
        {
            "paperId": "e9f0b498dd964fae320a7fc145d385298a78ed36",
            "title": "Exploring the Relationship between LLM Hallucinations and Prompt Linguistic Nuances: Readability, Formality, and Concreteness",
            "abstract": "As Large Language Models (LLMs) have advanced, they have brought forth new challenges, with one of the prominent issues being LLM hallucination. While various mitigation techniques are emerging to address hallucination, it is equally crucial to delve into its underlying causes. Consequently, in this preliminary exploratory investigation, we examine how linguistic factors in prompts, specifically readability, formality, and concreteness, influence the occurrence of hallucinations. Our experimental results suggest that prompts characterized by greater formality and concreteness tend to result in reduced hallucination. However, the outcomes pertaining to readability are somewhat inconclusive, showing a mixed pattern.",
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "authors": [
                {
                    "authorId": "9460529",
                    "name": "Vipula Rawte"
                },
                {
                    "authorId": "2243200258",
                    "name": "Prachi Priya"
                },
                {
                    "authorId": "2103483687",
                    "name": "S.M. Towhidul Islam Tonmoy"
                },
                {
                    "authorId": "2229651428",
                    "name": "Islam Tonmoy"
                },
                {
                    "authorId": "2242955156",
                    "name": "M. M. Zaman"
                },
                {
                    "authorId": "144463965",
                    "name": "A. Sheth"
                },
                {
                    "authorId": "48806891",
                    "name": "Amitava Das"
                }
            ]
        },
        {
            "paperId": "2c4f1fe9743e9097f398cf74726da0dc69996fa3",
            "title": "FETILDA: An Effective Framework For Fin-tuned Embeddings For Long Financial Text Documents",
            "abstract": "Unstructured data, especially text, continues to grow rapidly in various domains. In particular, in the financial sphere, there is a wealth of accumulated unstructured financial data, such as the textual disclosure documents that companies submit on a regular basis to regulatory agencies, such as the Securities and Exchange Commission (SEC). These documents are typically very long and tend to contain valuable soft information about a company's performance. It is therefore of great interest to learn predictive models from these long textual documents, especially for forecasting numerical key performance indicators (KPIs). Whereas there has been a great progress in pre-trained language models (LMs) that learn from tremendously large corpora of textual data, they still struggle in terms of effective representations for long documents. Our work fills this critical need, namely how to develop better models to extract useful information from long textual documents and learn effective features that can leverage the soft financial and risk information for text regression (prediction) tasks. In this paper, we propose and implement a deep learning framework that splits long documents into chunks and utilizes pre-trained LMs to process and aggregate the chunks into vector representations, followed by self-attention to extract valuable document-level features. We evaluate our model on a collection of 10-K public disclosure reports from US banks, and another dataset of reports submitted by US companies. Overall, our framework outperforms strong baseline methods for textual modeling as well as a baseline regression model using only numerical data. Our work provides better insights into how utilizing pre-trained domain-specific and fine-tuned long-input LMs in representing long documents can improve the quality of representation of textual data, and therefore, help in improving predictive analyses.",
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "authors": [
                {
                    "authorId": "2170166845",
                    "name": "BolunNamirXia"
                },
                {
                    "authorId": "9460529",
                    "name": "Vipula Rawte"
                },
                {
                    "authorId": "1693515",
                    "name": "Mohammed J. Zaki"
                },
                {
                    "authorId": "2109972396",
                    "name": "Aparna Gupta"
                }
            ]
        }
    ]
}