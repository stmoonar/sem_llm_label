{
    "authorId": "2108915895",
    "papers": [
        {
            "paperId": "425ca30d4afac4fc950b9e4a65dbfb2283b087f2",
            "title": "A Framework for Automated Text Generation Benchmarking",
            "abstract": "Researchersinareassuchastranslationandsummarizationneedtocomparetheirresultstoawiderangeofpublishedbaselinesthatcommonlyusedifferentevaluationmethods.WeaimtoenableaneasycomparisonbypresentingTextGen-Benchmarch,anopen-sourcedtool 1 for streamlining the generation and evaluation of text. Text generation methods and evaluation metrics can easily be added to TextGen-Benchmarch, and its pipeline results in a more efficient comparison between methods as users can supply corpora, systems, and evaluation techniques and receive comparison reports in easy to analyze tabular and graphic formats.",
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "authors": [
                {
                    "authorId": "69529094",
                    "name": "Steven Layne"
                },
                {
                    "authorId": "3159346",
                    "name": "Sebastian Gehrmann"
                },
                {
                    "authorId": "2462276",
                    "name": "Franck Dernoncourt"
                },
                {
                    "authorId": "2108915895",
                    "name": "Lidan Wang"
                },
                {
                    "authorId": "145262461",
                    "name": "Trung Bui"
                },
                {
                    "authorId": "2116858693",
                    "name": "Walter Chang"
                }
            ]
        },
        {
            "paperId": "131d30cdaa978e113e2a5f5113fe7590dc1e8c5e",
            "title": "Open-Domain Question Answering with Pre-Constructed Question Spaces",
            "abstract": "Open-domain question answering aims at locating the answers to user-generated questions in massive collections of documents. Retriever-readers and knowledge graph approaches are two big families of solutions to this task. A retriever-reader first applies information retrieval techniques to locate a few passages that are likely to be relevant, and then feeds the retrieved text to a neural network reader to extract the answer. Alternatively, knowledge graphs can be constructed and queried to answer users\u2019 questions. We propose an algorithm with a novel reader-retriever design that differs from both families. Our reader-retriever first uses an offline reader to read the corpus and generate collections of all answerable questions associated with their answers, and then uses an online retriever to respond to user queries by searching the pre-constructed question spaces for answers that are most likely to be asked in the given way. We further combine one retriever-reader and two reader-retrievers into a hybrid model called R6 for the best performance. Experiments with two large-scale public datasets show that R6 achieves state-of-the-art accuracy.",
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "authors": [
                {
                    "authorId": "46851930",
                    "name": "Jinfeng Xiao"
                },
                {
                    "authorId": "2108915895",
                    "name": "Lidan Wang"
                },
                {
                    "authorId": "2462276",
                    "name": "Franck Dernoncourt"
                },
                {
                    "authorId": "145262461",
                    "name": "Trung Bui"
                },
                {
                    "authorId": "1500530510",
                    "name": "Tong Sun"
                },
                {
                    "authorId": "153034701",
                    "name": "Jiawei Han"
                }
            ]
        },
        {
            "paperId": "36fd05f8e18e7a80426b0780d94b7f89c8d41616",
            "title": "Understanding Points of Correspondence between Sentences for Abstractive Summarization",
            "abstract": "Fusing sentences containing disparate content is a remarkable human ability that helps create informative and succinct summaries. Such a simple task for humans has remained challenging for modern abstractive summarizers, substantially restricting their applicability in real-world scenarios. In this paper, we present an investigation into fusing sentences drawn from a document by introducing the notion of points of correspondence, which are cohesive devices that tie any two sentences together into a coherent text. The types of points of correspondence are delineated by text cohesion theory, covering pronominal and nominal referencing, repetition and beyond. We create a dataset containing the documents, source and fusion sentences, and human annotations of points of correspondence between sentences. Our dataset bridges the gap between coreference resolution and summarization. It is publicly shared to serve as a basis for future work to measure the success of sentence fusion systems.",
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "authors": [
                {
                    "authorId": "50827114",
                    "name": "Logan Lebanoff"
                },
                {
                    "authorId": "1388023893",
                    "name": "John Muchovej"
                },
                {
                    "authorId": "2462276",
                    "name": "Franck Dernoncourt"
                },
                {
                    "authorId": "153586399",
                    "name": "Doo Soon Kim"
                },
                {
                    "authorId": "2108915895",
                    "name": "Lidan Wang"
                },
                {
                    "authorId": "2116858693",
                    "name": "Walter Chang"
                },
                {
                    "authorId": "2118167689",
                    "name": "Fei Liu"
                }
            ]
        },
        {
            "paperId": "499d2a310b2aff5d8d8971221be1bf05c4b43cc6",
            "title": "Bayesian Optimization for Selecting Efficient Machine Learning Models",
            "abstract": "The performance of many machine learning models depends on their hyper-parameter settings. Bayesian Optimization has become a successful tool for hyper-parameter optimization of machine learning algorithms, which aims to identify optimal hyper-parameters during an iterative sequential process. However, most of the Bayesian Optimization algorithms are designed to select models for effectiveness only and ignore the important issue of model training efficiency. Given that both model effectiveness and training time are important for real-world applications, models selected for effectiveness may not meet the strict training time requirements necessary to deploy in a production environment. In this work, we present a unified Bayesian Optimization framework for jointly optimizing models for both prediction effectiveness and training efficiency. We propose an objective that captures the tradeoff between these two metrics and demonstrate how we can jointly optimize them in a principled Bayesian Optimization framework. Experiments on model selection for recommendation tasks indicate models selected this way significantly improves model training efficiency while maintaining strong effectiveness as compared to state-of-the-art Bayesian Optimization algorithms.",
            "fieldsOfStudy": [
                "Computer Science",
                "Mathematics"
            ],
            "authors": [
                {
                    "authorId": "2108915895",
                    "name": "Lidan Wang"
                },
                {
                    "authorId": "2462276",
                    "name": "Franck Dernoncourt"
                },
                {
                    "authorId": "145262461",
                    "name": "Trung Bui"
                }
            ]
        },
        {
            "paperId": "563aad800d7db6689c4340ced4457f8f4a5f8c7c",
            "title": "Learning to Fuse Sentences with Transformers for Summarization",
            "abstract": "The ability to fuse sentences is highly attractive for summarization systems because it is an essential step to produce succinct abstracts. However, to date, summarizers can fail on fusing sentences. They tend to produce few summary sentences by fusion or generate incorrect fusions that lead the summary to fail to retain the original meaning. In this paper, we explore the ability of Transformers to fuse sentences and propose novel algorithms to enhance their ability to perform sentence fusion by leveraging the knowledge of points of correspondence between sentences. Through extensive experiments, we investigate the effects of different design choices on Transformer's performance. Our findings highlight the importance of modeling points of correspondence between sentences for effective sentence fusion.",
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "authors": [
                {
                    "authorId": "50827114",
                    "name": "Logan Lebanoff"
                },
                {
                    "authorId": "2462276",
                    "name": "Franck Dernoncourt"
                },
                {
                    "authorId": "153586399",
                    "name": "Doo Soon Kim"
                },
                {
                    "authorId": "2108915895",
                    "name": "Lidan Wang"
                },
                {
                    "authorId": "145907577",
                    "name": "W. Chang"
                },
                {
                    "authorId": "144544919",
                    "name": "Fei Liu"
                }
            ]
        },
        {
            "paperId": "28025cd7eddbb33b13ca87fda78590c1e9fe92fd",
            "title": "A Community-Enhanced Retrieval Model for Text-Rich Heterogeneous Information Networks",
            "abstract": "In recent years, we have witnessed a large increase in the number of available text-rich heterogeneous networks, in which text documents, users and other objects are interconnected in various ways. Examples include social networks, bibliographic information networks, and collaboration networks. Text-rich heterogeneous networks contain text nodes (e.g., user comments in social networks; scientific publications in bibliographic networks), non-text nodes (e.g., users and companies in social networks), as well as rich relationships between different types of nodes. An important task, which is very useful on its own right, as well as often serves as a preprocessing to mining and analytical tasks, is identifying relevant text information from the heterogeneous information networks given user queries. Unlike Web search and many related problems, the effects of the underlying semantically meaningful patterns in heterogeneous networks play an important role in determining relevant answers for user search queries. For example, there are several structural patterns we can explore to more effectively identify relevant text nodes for a given query. The relevant nodes are likely to come from the same user-topic communities as the query. In addition, the relevant nodes on the same query topic tend to form tight local relationships with each other in the same user-topic community. In this paper, we present a unified and principled framework that effectively integrates network community and local relationship detection with retrieval model construction in a mutually enhancing manner, which leads to a community-enhanced retrieval model for text-rich heterogeneous information networks. Experimental results show that this new model significantly outperforms state-of-the-art baselines.",
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "authors": [
                {
                    "authorId": "2108915895",
                    "name": "Lidan Wang"
                },
                {
                    "authorId": "15644550",
                    "name": "Xiao Yu"
                },
                {
                    "authorId": "3180064",
                    "name": "Fangbo Tao"
                }
            ]
        },
        {
            "paperId": "4c68dda88a5294620ed57eb5f366f1f64a7a19cc",
            "title": "A Markov Network Model for Natural Language Semantic Matching",
            "abstract": "We address the problem of designing practical methods for natural language semantic matching. While current deep neural networks can achieve high accuracy on benchmark datasets, their model structures are typically rigidly defined and as a result often encounter generalization issues and cannot easily adapt to various training data limitations. In this paper, we propose a Markov Network Model that leverages linguistic independence assumptions to decompose the problem into subproblems that can be solved independently for both generalization and the ability to adapt to various amounts of training data. The proposed framework is orthogonal to deep neural networks, since they can be integrated to the framework in the form of potential functions on the cliques corresponding to smaller sub-problems. Experiments on diverse real-world datasets show our method outperforms current state-of-the-art both in terms of accuracy, generalization and the ability to perform under various training data limitations.",
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "authors": [
                {
                    "authorId": "2108915895",
                    "name": "Lidan Wang"
                },
                {
                    "authorId": "145966986",
                    "name": "Trung H. Bui"
                },
                {
                    "authorId": "2462276",
                    "name": "Franck Dernoncourt"
                },
                {
                    "authorId": "2281711",
                    "name": "Natwar Modani"
                }
            ]
        },
        {
            "paperId": "f7c76dd951432217fb935dc1b8a5849731d24dad",
            "title": "Margin Call: an Accessible Web-based Text Viewer with Generated Paragraph Summaries in the Margin",
            "abstract": "We present Margin Call, a web-based text viewer that automatically generates short summaries for each paragraph of the text and displays the summaries in the margin of the text next to the corresponding paragraph. On the back-end, the summarizer first identifies the most important sentence for each paragraph in the text file uploaded by the user. The selected sentence is then automatically compressed to produce the short summary. The resulting summary is a few words long. The displayed summaries can help the user understand and retrieve information faster from the text, while increasing the retention of information.",
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "authors": [
                {
                    "authorId": "122779327",
                    "name": "Naba Rizvi"
                },
                {
                    "authorId": "3159346",
                    "name": "Sebastian Gehrmann"
                },
                {
                    "authorId": "2108915895",
                    "name": "Lidan Wang"
                },
                {
                    "authorId": "2462276",
                    "name": "Franck Dernoncourt"
                }
            ]
        },
        {
            "paperId": "1e2c97b6e23b8579d1b93261f91891867ecaa2f5",
            "title": "RelSim: Relation Similarity Search in Schema-Rich Heterogeneous Information Networks",
            "abstract": "Recent studies have demonstrated the power of modeling real world data as heterogeneous information networks (HINs) consisting of multiple types of entities and relations. Unfortunately, most of such studies (e.g., similarity search) con\ufb01ne discussions on the networks with only a few entity and relationship types, such as DBLP. In the real world, however, the network schema can be rather complex, such as Freebase. In such HINs with rich schema , it is often too much burden to ask users to provide explicit guidance in selecting relations for similarity search. In this paper, we study the problem of relation similarity search in schema-rich HINs. Under our problem setting, users are only asked to provide some simple relation instance examples (e.g., (cid:104) Barack Obama, John Kerry (cid:105) and (cid:104) George W. Bush, Condoleezza Rice (cid:105) ) as a query, and we automatically detect the latent semantic relation (L-SR) implied by the query (e.g., \u201cpresident vs. secretary-of-state\u201d). Such LSR will help to \ufb01nd other similar relation instances (e.g., (cid:104) Bill Clinton, Madeleine Albright (cid:105) ). In order to solve the problem, we \ufb01rst de\ufb01ne a new meta-path-based relation similarity measure, RelSim , to measure the similarity between relation instances in schema-rich HINs. Then given a query, we propose an optimization model to ef\ufb01-ciently learn LSR implied in the query through linear programming, and perform fast relation similarity search using RelSim based on the learned LSR. The experiments on real world datasets derived from Freebase demonstrate the effectiveness and ef\ufb01ciency of our approach.",
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "authors": [
                {
                    "authorId": "2108755854",
                    "name": "Chenguang Wang"
                },
                {
                    "authorId": "2109461904",
                    "name": "Yizhou Sun"
                },
                {
                    "authorId": "1947447",
                    "name": "Yanglei Song"
                },
                {
                    "authorId": "145325584",
                    "name": "Jiawei Han"
                },
                {
                    "authorId": "1809614",
                    "name": "Yangqiu Song"
                },
                {
                    "authorId": "2108915895",
                    "name": "Lidan Wang"
                },
                {
                    "authorId": "47474380",
                    "name": "Ming Zhang"
                }
            ]
        },
        {
            "paperId": "5708b4965a581408cf7cab46a29d89d4f674f7f9",
            "title": "FastHybrid: A Hybrid Model for Efficient Answer Selection",
            "abstract": "Answer selection is a core component in any question-answering systems. It aims to select correct answer sentences for a given question from a pool of candidate sentences. In recent years, many deep learning methods have been proposed and shown excellent results for this task. However, these methods typically require extensive parameter (and hyper-parameter) tuning, which give rise to efficiency issues for large-scale datasets, and potentially make them less portable across new datasets and domains (as re-tuning is usually required). In this paper, we propose an extremely efficient hybrid model (FastHybrid) that tackles the problem from both an accuracy and scalability point of view. FastHybrid is a light-weight model that requires little tuning and adaptation across different domains. It combines a fast deep model (which will be introduced in the method section) with an initial information retrieval model to effectively and efficiently handle answer selection. We introduce a new efficient attention mechanism in the hybrid model and demonstrate its effectiveness on several QA datasets. Experimental results show that although the hybrid uses no training data, its accuracy is often on-par with supervised deep learning techniques, while significantly reducing training and tuning costs across different domains.",
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "authors": [
                {
                    "authorId": "2108915895",
                    "name": "Lidan Wang"
                },
                {
                    "authorId": "144745483",
                    "name": "Ming Tan"
                },
                {
                    "authorId": "145325584",
                    "name": "Jiawei Han"
                }
            ]
        }
    ]
}