{
    "authorId": "143857311",
    "papers": [
        {
            "paperId": "dc49bbb4e3f9c6c2044f101e5b895c0cd91da58b",
            "title": "LEPCNet: A Lightweight End-to-End PCG Classification Neural Network Model for Wearable Devices",
            "abstract": "Wearable intelligent phonocardiogram (PCG) sensors provide a noninvasive method for long-term monitoring of cardiac status, which is crucial for the early detection of cardiovascular diseases (CVDs). As one of the key technologies for intelligent PCG sensors, PCG classification techniques based on computer audition (CA) have been widely leveraged in recent years, such as convolutional neural networks (CNNs), generative adversarial nets, and long short-term memory (LSTM). However, the limitation of these methods is that the models have a sizeable computational complexity, which is not suitable for wearable devices. To this end, we propose an end-to-end neural network for PCG classification with low-computational complexity [52.67k parameters and 1.59M floating point operations per second (FLOPs)]. We utilize two public datasets to test the model, and experimental results demonstrate that the proposed model achieves an accuracy of 93.1% in the 2016 PhysioNet/CinC Challenge 2016 dataset with considerable complexity reduction compared with the state-of-the-art works. Moreover, we design an energy-efficient wearable PCG sensor and deploy the proposed algorithms on it. The experimental results show that our proposed model consumes only 245.1 mW for PCG classification with an accuracy of 89.8% on test datasets. This means that the proposed model obtains excellent performance compared with previous work while consuming lower power, which is significant in practical application scenarios.",
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "authors": [
                {
                    "authorId": "2238900077",
                    "name": "Lixian Zhu"
                },
                {
                    "authorId": "2184464662",
                    "name": "Wanyong Qiu"
                },
                {
                    "authorId": "2316518657",
                    "name": "Yu Ma"
                },
                {
                    "authorId": "66417000",
                    "name": "Fuze Tian"
                },
                {
                    "authorId": "2211282760",
                    "name": "Mengkai Sun"
                },
                {
                    "authorId": "2162626425",
                    "name": "Zhihua Wang"
                },
                {
                    "authorId": "143857311",
                    "name": "Kun Qian"
                },
                {
                    "authorId": "2155151129",
                    "name": "Bin Hu"
                },
                {
                    "authorId": "2029344282",
                    "name": "Yoshiharu Yamamoto"
                },
                {
                    "authorId": "145411696",
                    "name": "Bj\u00f6rn Schuller"
                }
            ]
        },
        {
            "paperId": "10488612735fb6656fca5403dafa529baa371b44",
            "title": "Depression Recognition From EEG Signals Using an Adaptive Channel Fusion Method via Improved Focal Loss",
            "abstract": "Depression is a serious and common psychiatric disease characterized by emotional and cognitive dysfunction. In addition, the rates of clinical diagnosis and treatment for depression are low. Therefore, the accurate recognition of depression is important for its effective treatment. Electroencephalogram (EEG) signals, which can objectively reflect the inner states of human brains, are regarded as promising physiological tools that can enable effective and efficient clinical depression diagnosis and recognition. However, one of the challenges regarding EEG-based depression recognition involves sufficiently optimizing the spatial information derived from the multichannel space of EEG signals. Consequently, we propose an adaptive channel fusion method via improved focal loss (FL) functions for depression recognition based on EEG signals to effectively address this challenge. In this method, we propose two improved FL functions that can enhance the separability of hard examples by upweighting their losses as optimization objectives and can optimize the channel weights by a proposed adaptive channel fusion framework. The experimental results obtained on two EEG datasets show that the developed channel fusion method can achieve improved classification performance. The learned channel weights include the individual characteristics of each EEG epoch, which can effectively optimize the spatial information of each EEG epoch via the channel fusion method. In addition, the proposed method performs better than the state-of-the-art channel fusion methods.",
            "fieldsOfStudy": [
                "Computer Science",
                "Medicine"
            ],
            "authors": [
                {
                    "authorId": "121418047",
                    "name": "Jian Shen"
                },
                {
                    "authorId": "2108131877",
                    "name": "Yanan Zhang"
                },
                {
                    "authorId": "2190916175",
                    "name": "Huajian Liang"
                },
                {
                    "authorId": "2190958963",
                    "name": "Zeguang Zhao"
                },
                {
                    "authorId": "2188790508",
                    "name": "Kexin Zhu"
                },
                {
                    "authorId": "143857311",
                    "name": "Kun Qian"
                },
                {
                    "authorId": "2510838",
                    "name": "Qunxi Dong"
                },
                {
                    "authorId": "46447665",
                    "name": "Xiaowei Zhang"
                },
                {
                    "authorId": "144010725",
                    "name": "B. Hu"
                }
            ]
        },
        {
            "paperId": "169aa651abf2677544223a421db5a8d74f8691a4",
            "title": "Federated Intelligent Terminals Facilitate Stuttering Monitoring",
            "abstract": "Stuttering is a complicated language disorder. The most common form of stuttering is developmental stuttering, which begins in childhood. Early monitoring and intervention are essential for the treatment of children with stuttering. Automatic speech recognition technology has shown its great potential for non-fluent disorder identification, whereas the previous work has not considered the privacy of users\u2019 data. To this end, we propose federated intelligent terminals for automatic monitoring of stuttering speech in different contexts. Experimental results demonstrate that the proposed federated intelligent terminals model can analyze symptoms of stammering speech by taking personal privacy protection into account. Furthermore, the study has explored that the Shapley value approach in the federated learning setting has comparable performance to data-centralised learning.",
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "authors": [
                {
                    "authorId": "2216396166",
                    "name": "Yongzi Yu"
                },
                {
                    "authorId": "2184464662",
                    "name": "Wanyong Qiu"
                },
                {
                    "authorId": "2216446580",
                    "name": "Chen Quan"
                },
                {
                    "authorId": "143857311",
                    "name": "Kun Qian"
                },
                {
                    "authorId": "2162626425",
                    "name": "Zhihua Wang"
                },
                {
                    "authorId": "2316518657",
                    "name": "Yu Ma"
                },
                {
                    "authorId": "144010725",
                    "name": "B. Hu"
                },
                {
                    "authorId": "2090950337",
                    "name": "B. Schuller"
                },
                {
                    "authorId": "2029344282",
                    "name": "Yoshiharu Yamamoto"
                }
            ]
        },
        {
            "paperId": "3425de0b6053474b84c3596a6e2afdc0d2a68657",
            "title": "Enhancing Performance on Seen and Unseen Dialogue Scenarios using Retrieval-Augmented End-to-End Task-Oriented System",
            "abstract": "End-to-end task-oriented dialogue (TOD) systems have achieved promising performance by leveraging sophisticated natural language understanding and natural language generation capabilities of pre-trained models. This work enables the TOD systems with more flexibility through a simple cache. The cache provides the flexibility to dynamically update the TOD systems and handle both existing and unseen dialogue scenarios. Towards this end, we first fine-tune a retrieval module to effectively retrieve the most relevant information entries from the cache. We then train end-to-end TOD models that can refer to and ground on both dialogue history and retrieved information during TOD generation. The introduced cache is straightforward to construct, and the backbone models of TOD systems are compatible with existing pre-trained generative models. Extensive experiments demonstrate the superior performance of our framework, with a notable improvement in non-empty joint goal accuracy by 6.7% compared to strong baselines.",
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "authors": [
                {
                    "authorId": "2108313930",
                    "name": "Jianguo Zhang"
                },
                {
                    "authorId": "3849208",
                    "name": "Stephen Roller"
                },
                {
                    "authorId": "143857311",
                    "name": "Kun Qian"
                },
                {
                    "authorId": "2223887365",
                    "name": "Zhiwei Liu"
                },
                {
                    "authorId": "2087884364",
                    "name": "Rui Meng"
                },
                {
                    "authorId": "71926704",
                    "name": "Shelby Heinecke"
                },
                {
                    "authorId": "46507194",
                    "name": "Haiquan Wang"
                },
                {
                    "authorId": "1702137",
                    "name": "S. Savarese"
                },
                {
                    "authorId": "2054594326",
                    "name": "Caiming Xiong"
                }
            ]
        },
        {
            "paperId": "41acd067dfa57628ee4f8e9b6d9e8b5cfcb327f2",
            "title": "AD-SiamRPN: Anti-Deformation Object Tracking via an Improved Siamese Region Proposal Network on Hyperspectral Videos",
            "abstract": "Object tracking using Hyperspectral Images (HSIs) obtains satisfactory result in distinguishing objects with similar colors. Yet, the tracking algorithm tends to fail when the target undergoes deformation. In this paper, a SiamRPN based hyperspectral tracker is proposed to deal with this problem. Firstly, a band selection method based on a genetic optimization method is designed for rapidly reducing the redundancy of information in HSIs. Specifically, three bands with highest joint entropy are selected. To solve the problem that the information of the template in the SiamRPN model decays over time, an update network is trained on the dataset from general objective tracking benchmark, which can obtain effective cumulative templates. The use of cumulative templates with spectral information makes it easier to track the deformed target. In addition, transfer learning of the pre-trained SiamRPN is designed to obtain a better model for HSIs. The experimental results show that the proposed tracker can obtain good tracking results over the entire public dataset, and that it is better than the other popular trackers when the target\u2019s deformation is qualitatively and quantitatively compared, achieving an overall success rate of 57.5% and a deformation challenge success rate of 70.8%.",
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "authors": [
                {
                    "authorId": "13802955",
                    "name": "Gengxin Liu"
                },
                {
                    "authorId": "143857311",
                    "name": "Kun Qian"
                },
                {
                    "authorId": "143808691",
                    "name": "Jian Shen"
                },
                {
                    "authorId": "2165758783",
                    "name": "Hongyu Ma"
                },
                {
                    "authorId": "2158503071",
                    "name": "Peng Chen"
                }
            ]
        },
        {
            "paperId": "428d2c491f8dcb942931cc44dab295fd5e1dc9a4",
            "title": "User Adaptive Language Learning Chatbots with a Curriculum",
            "abstract": "Along with the development of systems for natural language understanding and generation, dialog systems have been widely adopted for language learning and practicing. Many current educational dialog systems perform chitchat, where the generated content and vocabulary are not constrained. However, for learners in a school setting, practice through dialog is more effective if it aligns with students' curriculum and focuses on textbook vocabulary. Therefore, we adapt lexically constrained decoding to a dialog system, which urges the dialog system to include curriculum-aligned words and phrases in its generated utterances. We adopt a generative dialog system, BlenderBot3, as our backbone model and evaluate our curriculum-based dialog system with middle school students learning English as their second language. The constrained words and phrases are derived from their textbooks, suggested by their English teachers. The evaluation result demonstrates that the dialog system with curriculum infusion improves students' understanding of target words and increases their interest in practicing English.",
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "authors": [
                {
                    "authorId": "143857311",
                    "name": "Kun Qian"
                },
                {
                    "authorId": "2059941813",
                    "name": "Ryan Shea"
                },
                {
                    "authorId": "40058381",
                    "name": "Yu Li"
                },
                {
                    "authorId": "2420534",
                    "name": "Luke K. Fryer"
                },
                {
                    "authorId": "2167255986",
                    "name": "Zhou Yu"
                }
            ]
        },
        {
            "paperId": "59ef1b67c5f238d5d6d175d84fb6b239b4221a97",
            "title": "Stabilized In-Context Learning with Pre-trained Language Models for Few Shot Dialogue State Tracking",
            "abstract": "Prompt-based methods with large pre-trained language models (PLMs) have shown impressive unaided performance across many NLP tasks. These models improve even further with the addition of a few labeled in-context exemplars to guide output generation. However, for more complex tasks such as dialogue state tracking (DST), designing prompts that reliably convey the desired intent is nontrivial, leading to unstable results. Furthermore, building in-context exemplars for dialogue tasks is difficult because conversational contexts are long while model input lengths are relatively short.To overcome these issues we first adapt a meta-learning scheme to the dialogue domain which stabilizes the ability of the model to perform well under various prompts. We additionally design a novel training method to improve upon vanilla retrieval mechanisms to find ideal in-context examples. Finally, we introduce a saliency model to limit dialogue text length, allowing us to include more exemplars per query. In effect, we are able to achieve highly competitive results for few-shot DST on MultiWOZ.",
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "authors": [
                {
                    "authorId": "51250248",
                    "name": "Derek Chen"
                },
                {
                    "authorId": "143857311",
                    "name": "Kun Qian"
                },
                {
                    "authorId": "144007938",
                    "name": "Zhou Yu"
                }
            ]
        },
        {
            "paperId": "6bb9ecf720c318d2d1c0c338dd12892c4dcc616a",
            "title": "An Investigation on Data Augmentation and Multiple Instance Learning for Diagnosis of COVID-19 from Speech and Cough Sound",
            "abstract": "Computer audition based approaches for diagnosing COVID-19 can provide a low-cost, convenient, and real-time solution for combating the ongoing global pandemic. In this contribution, we present an investigation on data augmentation and multiple instance learning methods for diagnosis of COVID-19 from speech and cough sound data. We firstly introduce a novel deep convolutional neural network pre-trained on large scale audio data set, i. e., AudioSet. Moreover, we use a multiple instance learning paradigm to address the training difficulties caused by the varied length of the audio instances. Experimental results demonstrate the efficiency of the proposed methods, which can reach a best performance at 75.9 % of the unweighted average recall, surpassing the official baseline single best by 3.0 % and baseline fusion best by 2.0 %.",
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "authors": [
                {
                    "authorId": "153181043",
                    "name": "Tomoya Koike"
                },
                {
                    "authorId": "2162626425",
                    "name": "Zhihua Wang"
                },
                {
                    "authorId": "143857311",
                    "name": "Kun Qian"
                },
                {
                    "authorId": "144010725",
                    "name": "B. Hu"
                },
                {
                    "authorId": "2090950337",
                    "name": "B. Schuller"
                },
                {
                    "authorId": "2029344282",
                    "name": "Yoshiharu Yamamoto"
                }
            ]
        },
        {
            "paperId": "74041ffe7c1c8a5cbc5d50d3ba4f75353d6e11e3",
            "title": "Daily Mental Health Monitoring from Speech: A Real-World Japanese Dataset and Multitask Learning Analysis",
            "abstract": "Translating mental health recognition from clinical research into real-world application requires extensive data, yet existing emotion datasets are impoverished in terms of daily mental health monitoring, especially when aiming for self-reported anxiety and depression recognition. We introduce the Japanese Daily Speech Dataset (JDSD), a large in-the-wild daily speech emotion dataset consisting of 20,827 speech samples from 342 speakers and 54 hours of total duration. The data is annotated on the Depression and Anxiety Mood Scale (DAMS) \u2013 9 self-reported emotions to evaluate mood state including \"vigorous\", \"gloomy\", \"concerned\", \"happy\", \"unpleasant\", \"anxious\", \"cheerful\", \"depressed\", and \"worried\". Our dataset possesses emotional states, activity, and time diversity, making it useful for training models to track daily emotional states for healthcare purposes. We partition our corpus and provide a multi-task benchmark across nine emotions, demonstrating that mental health states can be predicted reliably from self-reports with a Concordance Correlation Coefficient value of .547 on average. We hope that JDSD will become a valuable resource to further the development of daily emotional healthcare tracking.",
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "authors": [
                {
                    "authorId": "1456106683",
                    "name": "Meishu Song"
                },
                {
                    "authorId": "31316588",
                    "name": "Andreas Triantafyllopoulos"
                },
                {
                    "authorId": "1455840609",
                    "name": "Zijiang Yang"
                },
                {
                    "authorId": "2099190363",
                    "name": "Hiroki Takeuchi"
                },
                {
                    "authorId": "2217252541",
                    "name": "Toru Nakamura"
                },
                {
                    "authorId": "6555763",
                    "name": "A. Kishi"
                },
                {
                    "authorId": "8487861",
                    "name": "Tetsuro Ishizawa"
                },
                {
                    "authorId": "3289193",
                    "name": "K. Yoshiuchi"
                },
                {
                    "authorId": "2149914472",
                    "name": "Xin Jing"
                },
                {
                    "authorId": "1423719032",
                    "name": "Vincent Karas"
                },
                {
                    "authorId": "2210043973",
                    "name": "Zhonghao Zhao"
                },
                {
                    "authorId": "143857311",
                    "name": "Kun Qian"
                },
                {
                    "authorId": "144010725",
                    "name": "B. Hu"
                },
                {
                    "authorId": "2090950337",
                    "name": "B. Schuller"
                },
                {
                    "authorId": "2029344282",
                    "name": "Yoshiharu Yamamoto"
                }
            ]
        },
        {
            "paperId": "7a0d2f3e9ca7a9eb1ac8712691619bdba80b859e",
            "title": "The Three-Lead EEG Sensor: Introducing an EEG-Assisted Depression Diagnosis System Based on Ant Lion Optimization",
            "abstract": "For depression diagnosis, traditional methods such as interviews and clinical scales have been widely leveraged in the past few decades, but they are subjective, time-consuming, and labor-consuming. With the development of affective computing and Artificial Intelligence (AI) technologies, Electroencephalogram (EEG)-based depression detection methods have emerged. However, previous research has virtually neglected practical application scenarios, as most studies have focused on analyzing and modeling EEG data. Furthermore, EEG data is typically obtained from specialized devices that are large, complex to operate, and poorly ubiquitous. To address these challenges, a wearable three-lead EEG sensor with flexible electrodes was developed to obtain prefrontal-lobe EEG data. Experimental measurements show that the EEG sensor achieves promising performance (background noise of no more than 0.91 <inline-formula><tex-math notation=\"LaTeX\">$\\mu$</tex-math></inline-formula>Vpp, Signal-to-Noise Ratio (SNR) of 26--48 dB, and electrode-skin contact impedance of less than 1 K<inline-formula><tex-math notation=\"LaTeX\">$\\Omega$</tex-math></inline-formula>). In addition, EEG data from 70 depressed patients and 108 healthy controls were collected using the EEG sensor, and the linear and nonlinear features were extracted. The features were then weighted and selected using the Ant Lion Optimization (ALO) algorithm to improve classification performance. The experimental results show that the <inline-formula><tex-math notation=\"LaTeX\">$k$</tex-math></inline-formula>-NN classifier achieves a classification accuracy of 90.70%, specificity of 96.53%, and sensitivity of 81.79%, indicating the promising potential of the three-lead EEG sensor combined with the ALO algorithm and the <inline-formula><tex-math notation=\"LaTeX\">$k$</tex-math></inline-formula>-NN classifier for EEG-assisted depression diagnosis.",
            "fieldsOfStudy": [
                "Computer Science",
                "Medicine"
            ],
            "authors": [
                {
                    "authorId": "66417000",
                    "name": "Fuze Tian"
                },
                {
                    "authorId": "2238900077",
                    "name": "Lixian Zhu"
                },
                {
                    "authorId": "2568822",
                    "name": "Qiuxia Shi"
                },
                {
                    "authorId": "40601625",
                    "name": "Rui Wang"
                },
                {
                    "authorId": "2144156653",
                    "name": "Lixin Zhang"
                },
                {
                    "authorId": "2510838",
                    "name": "Qunxi Dong"
                },
                {
                    "authorId": "143857311",
                    "name": "Kun Qian"
                },
                {
                    "authorId": "2118377283",
                    "name": "Qinglin Zhao"
                },
                {
                    "authorId": "144010725",
                    "name": "B. Hu"
                }
            ]
        }
    ]
}