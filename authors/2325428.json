{
    "authorId": "2325428",
    "papers": [
        {
            "paperId": "3302dd45af2f280aaaf1378af91cea3d5745f36e",
            "title": "Counterfactual Situation Testing: Uncovering Discrimination under Fairness given the Difference",
            "abstract": "We present counterfactual situation testing (CST), a causal data mining framework for detecting individual discrimination in a dataset of classifier decisions. CST answers the question \u201cwhat would have been the model outcome had the individual, or complainant, been of a different protected status?\u201d in an actionable and meaningful way. It extends the legally-grounded situation testing of Thanh et al. [62] by operationalizing the notion of fairness given the difference of Kohler-Hausmann [38] using counterfactual reasoning. In standard situation testing we find for each complainant similar protected and non-protected instances in the dataset; construct respectively a control and test group; and compare the groups such that a difference in decision outcomes implies a case of potential individual discrimination. In CST we avoid this idealized comparison by establishing the test group on the complainant\u2019s counterfactual generated via the steps of abduction, action, and prediction. The counterfactual reflects how the protected attribute, when changed, affects the other seemingly neutral attributes of the complainant. Under CST we, thus, test for discrimination by comparing similar individuals within each group but dissimilar individuals across both groups for each complainant. Evaluating it on two classification scenarios, CST uncovers a greater number of cases than ST, even when the classifier is counterfactually fair.",
            "fieldsOfStudy": [
                "Mathematics",
                "Computer Science"
            ],
            "authors": [
                {
                    "authorId": "2112782985",
                    "name": "J. \u00c1lvarez"
                },
                {
                    "authorId": "2325428",
                    "name": "S. Ruggieri"
                }
            ]
        },
        {
            "paperId": "4ddaaf045afc618f3a1c849d6a088b7982e8477a",
            "title": "A Model-Agnostic Heuristics for Selective Classification",
            "abstract": "Selective classification (also known as classification with reject option) conservatively extends a classifier with a selection function to determine whether or not a prediction should be accepted (i.e., trusted, used, deployed). This is a highly relevant issue in socially sensitive tasks, such as credit scoring.\nState-of-the-art approaches rely on Deep Neural Networks (DNNs) that train at the same time both the classifier and the selection function. These approaches are model-specific and computationally expensive. \nWe propose a model-agnostic approach, as it can work with any base probabilistic binary classification algorithm, and it can be scalable to large tabular datasets if the base classifier is so. The proposed algorithm, called SCROSS, exploits a cross-fitting strategy and theoretical results for quantile estimation to build the selection function. Experiments on real-world data show that SCROSS improves over existing methods.",
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "authors": [
                {
                    "authorId": "2150773786",
                    "name": "Andrea Pugnana"
                },
                {
                    "authorId": "2325428",
                    "name": "S. Ruggieri"
                }
            ]
        },
        {
            "paperId": "44070f32949ca85c6bd4e1b2e2764e3409a63156",
            "title": "Fairness Implications of Encoding Protected Categorical Attributes",
            "abstract": "Past research has demonstrated that the explicit use of protected attributes in machine learning can improve both performance and fairness. Many machine learning algorithms, however, cannot directly process categorical attributes, such as country of birth or ethnicity. Because protected attributes frequently are categorical, they must be encoded as features that can be input to a chosen machine learning algorithm, e.g. support vector machines, gradient boosting decision trees or linear models. Thereby, encoding methods influence how and what the machine learning algorithm will learn, affecting model performance and fairness. This work compares the accuracy and fairness implications of the two most well-known encoding methods: one-hot encoding and target encoding. We distinguish between two types of induced bias that may arise from these encoding methods and may lead to unfair models. The first type, irreducible bias, is due to direct group category discrimination and the second type, reducible bias, is due to the large variance in statistically underrepresented groups. We investigate the interaction between categorical encodings and target encoding regularization methods that reduce unfairness. Furthermore, we consider the problem of intersectional unfairness that may arise when machine learning best practices improve performance measures by encoding several categorical attributes into a high-cardinality feature.",
            "fieldsOfStudy": [
                "Computer Science",
                "Mathematics"
            ],
            "authors": [
                {
                    "authorId": "115400334",
                    "name": "Carlos Mougan"
                },
                {
                    "authorId": "2974008",
                    "name": "J. \u00c1lvarez"
                },
                {
                    "authorId": "51964560",
                    "name": "Gourab K. Patro"
                },
                {
                    "authorId": "2325428",
                    "name": "S. Ruggieri"
                },
                {
                    "authorId": "1752093",
                    "name": "Steffen Staab"
                }
            ]
        },
        {
            "paperId": "5b3349e92884a416b9438e0ddd8bf4b9eee8bc6d",
            "title": "AUC-based Selective Classification",
            "abstract": "Selective classification (or classification with a reject option) pairs a classifier with a selection function to determine whether or not a prediction should be accepted. This framework trades off coverage (probability of accepting a prediction) with predictive performance, typically measured by distributive loss functions. In many application scenarios, such as credit scoring, performance is instead measured by ranking metrics, such as the Area Under the ROC Curve (AUC). We propose a model-agnostic approach to associate a selection function to a given probabilistic binary classifier. The approach is specifically targeted at optimizing the AUC. We provide both theoretical justifications and a novel algorithm, called AUCROSS, to achieve such a goal. Experiments show that our method succeeds in trading-off coverage for AUC, improving over existing selective classification methods targeted at optimizing accuracy.",
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "authors": [
                {
                    "authorId": "2150773786",
                    "name": "Andrea Pugnana"
                },
                {
                    "authorId": "2325428",
                    "name": "S. Ruggieri"
                }
            ]
        },
        {
            "paperId": "a0d7cca1783383880f9a331f7764da698d2ae597",
            "title": "Methods and tools for causal discovery and causal inference",
            "abstract": "Causality is a complex concept, which roots its developments across several fields, such as statistics, economics, epidemiology, computer science, and philosophy. In recent years, the study of causal relationships has become a crucial part of the Artificial Intelligence community, as causality can be a key tool for overcoming some limitations of correlation\u2010based Machine Learning systems. Causality research can generally be divided into two main branches, that is, causal discovery and causal inference. The former focuses on obtaining causal knowledge directly from observational data. The latter aims to estimate the impact deriving from a change of a certain variable over an outcome of interest. This article aims at covering several methodologies that have been developed for both tasks. This survey does not only focus on theoretical aspects. But also provides a practical toolkit for interested researchers and practitioners, including software, datasets, and running examples.",
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "authors": [
                {
                    "authorId": "90933721",
                    "name": "Ana Rita Nogueira"
                },
                {
                    "authorId": "2150773786",
                    "name": "Andrea Pugnana"
                },
                {
                    "authorId": "2325428",
                    "name": "S. Ruggieri"
                },
                {
                    "authorId": "1693341",
                    "name": "D. Pedreschi"
                },
                {
                    "authorId": "2065401401",
                    "name": "Jo\u00e3o Gama"
                }
            ]
        },
        {
            "paperId": "d7c0212334f21d3a4af2f4749f3377a7a79967cd",
            "title": "Bias Discovery within Human Raters: A Case Study of the Jigsaw Dataset",
            "abstract": "Understanding and quantifying the bias introduced by human annotation of data is a crucial problem for trustworthy supervised learning. Recently, a perspectivist trend has emerged in the NLP community, focusing on the inadequacy of previous aggregation schemes, which suppose the existence of single ground truth. This assumption is particularly problematic for sensitive tasks involving subjective human judgments, such as toxicity detection. To address these issues, we propose a preliminary approach for bias discovery within human raters by exploring individual ratings for specific sensitive topics annotated in the texts. Our analysis\u2019s object consists of the Jigsaw dataset, a collection of comments aiming at challenging online toxicity identification.",
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "authors": [
                {
                    "authorId": "2165226916",
                    "name": "Marta Marchiori Manerba"
                },
                {
                    "authorId": "1704327",
                    "name": "Riccardo Guidotti"
                },
                {
                    "authorId": "3449062",
                    "name": "Lucia C. Passaro"
                },
                {
                    "authorId": "2325428",
                    "name": "S. Ruggieri"
                }
            ]
        },
        {
            "paperId": "7e66308eaa68edde30e7e25d85f0b70dd314f12c",
            "title": "Estimating the Total Volume of Queries to a Search Engine",
            "abstract": "We study the problem of estimating the total number of searches (volume) of queries in a specific domain, which were submitted to a search engine in a given time period. Our statistical model assumes that the distribution of searches follows a Zipf\u2019s law, and that the observed sample volumes are biased accordingly to three possible scenarios. These assumptions are consistent with empirical data, with keyword research practices, and with approximate algorithms used to take counts of query frequencies. A few estimators of the parameters of the distribution are devised and experimented, based on the nature of the empirical/simulated data. For continuous data, we recommend using nonlinear least square regression (NLS) on the top-volume queries, where the bound on the volume is obtained from the well-known Clauset, Shalizi and Newman (CSN) estimation of power-law parameters. For binned data, we propose using a Chi-square minimization approach restricted to the top-volume queries, where the bound is obtained by the binned version of the CSN method. Estimations are then derived for the total number of queries and for the total volume of the population, including statistical error bounds. We apply the methods on the domain of recipes and cooking queries searched in Italian in 2017. The observed volumes of sample queries are collected from Google Trends (continuous data) and SearchVolume (binned data). The estimated total number of queries and total volume are computed for the two cases, and the results are compared and discussed.",
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "authors": [
                {
                    "authorId": "46933023",
                    "name": "F. Lillo"
                },
                {
                    "authorId": "2325428",
                    "name": "S. Ruggieri"
                }
            ]
        },
        {
            "paperId": "fee596406375592b29b2f051910e8247ea501c01",
            "title": "Introduction to The Special Section on Bias and Fairness in AI",
            "abstract": "Fairness in Artificial Intelligence rightfully receives a lot of attention these days. Many life-impacting decisions are being partially automated, including health-care resource planning decisions, insurance and credit risk predictions, recidivism predictions, etc. Much of work appearing on this topic within the Data Mining, Machine Learning and Artificial Intelligence community is focused on technological aspects. Nevertheless, fairness is much wider than this as it lies at the intersection of philosophy, ethics, legislation, and practical perspectives. Therefore, to fill this gap and bring together scholars of these disciplines working on fairness, the first workshop on Bias and Fairness in AI was held online on September 18, 2020 at the ECML-PKDD 2020 conference. This special section includes six articles presenting different perspectives on bias and fairness from different angles.",
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "authors": [
                {
                    "authorId": "2067055961",
                    "name": "T. Calders"
                },
                {
                    "authorId": "1804618",
                    "name": "Eirini Ntoutsi"
                },
                {
                    "authorId": "1691997",
                    "name": "Mykola Pechenizkiy"
                },
                {
                    "authorId": "1779035",
                    "name": "B. Rosenhahn"
                },
                {
                    "authorId": "2325428",
                    "name": "S. Ruggieri"
                }
            ]
        },
        {
            "paperId": "17f423a5e542a4bd4de0243548e127038dea6ab5",
            "title": "Bias in data\u2010driven artificial intelligence systems\u2014An introductory survey",
            "abstract": "Artificial Intelligence (AI)\u2010based systems are widely employed nowadays to make decisions that have far\u2010reaching impact on individuals and society. Their decisions might affect everyone, everywhere, and anytime, entailing concerns about potential human rights issues. Therefore, it is necessary to move beyond traditional AI algorithms optimized for predictive performance and embed ethical and legal principles in their design, training, and deployment to ensure social good while still benefiting from the huge potential of the AI technology. The goal of this survey is to provide a broad multidisciplinary overview of the area of bias in AI systems, focusing on technical challenges and solutions as well as to suggest new research directions towards approaches well\u2010grounded in a legal frame. In this survey, we focus on data\u2010driven AI, as a large part of AI is powered nowadays by (big) data and powerful machine learning algorithms. If otherwise not specified, we use the general term bias to describe problems related to the gathering or processing of data that might result in prejudiced decisions on the bases of demographic features such as race, sex, and so forth.",
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "authors": [
                {
                    "authorId": "1804618",
                    "name": "Eirini Ntoutsi"
                },
                {
                    "authorId": "2393008",
                    "name": "P. Fafalios"
                },
                {
                    "authorId": "2516584",
                    "name": "U. Gadiraju"
                },
                {
                    "authorId": "3176896",
                    "name": "Vasileios Iosifidis"
                },
                {
                    "authorId": "1744808",
                    "name": "W. Nejdl"
                },
                {
                    "authorId": "143858195",
                    "name": "Maria-Esther Vidal"
                },
                {
                    "authorId": "2325428",
                    "name": "S. Ruggieri"
                },
                {
                    "authorId": "1707206",
                    "name": "F. Turini"
                },
                {
                    "authorId": "144178604",
                    "name": "S. Papadopoulos"
                },
                {
                    "authorId": "28075447",
                    "name": "Emmanouil Krasanakis"
                },
                {
                    "authorId": "119661806",
                    "name": "I. Kompatsiaris"
                },
                {
                    "authorId": "1404596968",
                    "name": "K. Kinder-Kurlanda"
                },
                {
                    "authorId": "144065562",
                    "name": "Claudia Wagner"
                },
                {
                    "authorId": "51118506",
                    "name": "F. Karimi"
                },
                {
                    "authorId": "152179862",
                    "name": "Miriam Fern\u00e1ndez"
                },
                {
                    "authorId": "145842687",
                    "name": "Harith Alani"
                },
                {
                    "authorId": "2990203",
                    "name": "Bettina Berendt"
                },
                {
                    "authorId": "3144221",
                    "name": "Tina Kruegel"
                },
                {
                    "authorId": "49729602",
                    "name": "C. Heinze"
                },
                {
                    "authorId": "2102011",
                    "name": "Klaus Broelemann"
                },
                {
                    "authorId": "1686448",
                    "name": "Gjergji Kasneci"
                },
                {
                    "authorId": "1726746",
                    "name": "T. Tiropanis"
                },
                {
                    "authorId": "1752093",
                    "name": "Steffen Staab"
                }
            ]
        },
        {
            "paperId": "79164aec34709012be2b7f02f49a29ebc0e363e3",
            "title": "Give more data, awareness and control to individual citizens, and they will help COVID-19 containment",
            "abstract": "The rapid dynamics of COVID-19 calls for quick and effective tracking of virus transmission chains and early detection of outbreaks, especially in the phase 2 of the pandemic, when lockdown and other restriction measures are progressively withdrawn, in order to avoid or minimize contagion resurgence. For this purpose, contact-tracing apps are being proposed for large scale adoption by many countries. A centralized approach, where data sensed by the app are all sent to a nation-wide server, raises concerns about citizens' privacy and needlessly strong digital surveillance, thus alerting us to the need to minimize personal data collection and avoiding location tracking. We advocate the conceptual advantage of a decentralized approach, where both contact and location data are collected exclusively in individual citizens' \"personal data stores\", to be shared separately and selectively, voluntarily, only when the citizen has tested positive for COVID-19, and with a privacy preserving level of granularity. This approach better protects the personal sphere of citizens and affords multiple benefits: it allows for detailed information gathering for infected people in a privacy-preserving fashion;and, in turn this enables both contact tracing, and, the early detection of outbreak hotspots on more finely-granulated geographic scale. Our recommendation is two-fold. First to extend existing decentralized architectures with a light touch, in order to manage the collection of location data locally on the device, and allow the user to share spatio-temporal aggregates - if and when they want, for specific aims - with health authorities, for instance. Second, we favour a longer-term pursuit of realizing a Personal Data Store vision, giving users the opportunity to contribute to collective good in the measure they want, enhancing self-awareness, and cultivating collective efforts for rebuilding society.",
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "authors": [
                {
                    "authorId": "1717192",
                    "name": "M. Nanni"
                },
                {
                    "authorId": "50663909",
                    "name": "G. Andrienko"
                },
                {
                    "authorId": "2172195129",
                    "name": "Albert-L'aszl'o Barab'asi"
                },
                {
                    "authorId": "144386157",
                    "name": "C. Boldrini"
                },
                {
                    "authorId": "1705764",
                    "name": "F. Bonchi"
                },
                {
                    "authorId": "144300761",
                    "name": "C. Cattuto"
                },
                {
                    "authorId": "3098280",
                    "name": "Francesca Chiaromonte"
                },
                {
                    "authorId": "2235275955",
                    "name": "Giovanni Comand'e"
                },
                {
                    "authorId": "2060071082",
                    "name": "M. Conti"
                },
                {
                    "authorId": "40638665",
                    "name": "Marc-Alexandre C\u00f4t\u00e9"
                },
                {
                    "authorId": "79774420",
                    "name": "F. Dignum"
                },
                {
                    "authorId": "1716665",
                    "name": "Virginia Dignum"
                },
                {
                    "authorId": "1393591007",
                    "name": "J. Domingo-Ferrer"
                },
                {
                    "authorId": "1681278",
                    "name": "P. Ferragina"
                },
                {
                    "authorId": "1685102",
                    "name": "F. Giannotti"
                },
                {
                    "authorId": "1704327",
                    "name": "Riccardo Guidotti"
                },
                {
                    "authorId": "1768825",
                    "name": "D. Helbing"
                },
                {
                    "authorId": "145670814",
                    "name": "K. Kaski"
                },
                {
                    "authorId": "2207387183",
                    "name": "J\u00e1nos Kert\u00e9sz"
                },
                {
                    "authorId": "31413949",
                    "name": "S. Lehmann"
                },
                {
                    "authorId": "1776476",
                    "name": "B. Lepri"
                },
                {
                    "authorId": "2199139669",
                    "name": "P. Lukowicz"
                },
                {
                    "authorId": "1749003",
                    "name": "S. Matwin"
                },
                {
                    "authorId": "2229020742",
                    "name": "D. Jim'enez"
                },
                {
                    "authorId": "2296962",
                    "name": "A. Monreale"
                },
                {
                    "authorId": "1752599",
                    "name": "K. Morik"
                },
                {
                    "authorId": "145709776",
                    "name": "Nuria Oliver"
                },
                {
                    "authorId": "2174176466",
                    "name": "A. Passarella"
                },
                {
                    "authorId": "1702610",
                    "name": "Andrea Passerini"
                },
                {
                    "authorId": "1693341",
                    "name": "D. Pedreschi"
                },
                {
                    "authorId": "153439805",
                    "name": "A. Pentland"
                },
                {
                    "authorId": "1760810",
                    "name": "F. Pianesi"
                },
                {
                    "authorId": "33769943",
                    "name": "Francesca Pratesi"
                },
                {
                    "authorId": "2120595",
                    "name": "S. Rinzivillo"
                },
                {
                    "authorId": "2325428",
                    "name": "S. Ruggieri"
                },
                {
                    "authorId": "2227342424",
                    "name": "A. Siebes"
                },
                {
                    "authorId": "3005971",
                    "name": "R. Trasarti"
                },
                {
                    "authorId": "7485612",
                    "name": "J. Hoven"
                },
                {
                    "authorId": "80273596",
                    "name": "A. Vespignani"
                }
            ]
        }
    ]
}