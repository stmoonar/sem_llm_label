{
    "authorId": "1751591",
    "papers": [
        {
            "paperId": "0dc5e71beb0b51ff8f7ea122ccc2b2642410698d",
            "title": "TIQ: A Benchmark for Temporal Question Answering with Implicit Time Constraints",
            "abstract": "Temporal question answering (QA) involves explicit (e.g., \"...before 2024\") or implicit (e.g., \"...during the Cold War period\") time constraints. Implicit constraints are more challenging; yet benchmarks for temporal QA largely disregard such questions. This shortcoming spans three aspects. First, implicit questions are scarce in existing benchmarks. Second, questions are created based on hand-crafted rules, thus lacking diversity in formulations. Third, the source for answering is either a KB or a text corpus, disregarding cues from multiple sources. We propose a benchmark, called TIQ (Temporal Implicit Questions), based on novel techniques for constructing questions with implicit time constraints. First, questions are created automatically, with systematic control of topical diversity, timeframe, head vs. tail entities, etc. Second, questions are formulated using diverse snippets and further paraphrasing by a large language model. Third, snippets for answering come from a variety of sources including KB, text, and infoboxes. The TIQ benchmark contains 10,000 questions with ground-truth answers and underlying snippets as supporting evidence.",
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "authors": [
                {
                    "authorId": "2301751529",
                    "name": "Zhen Jia"
                },
                {
                    "authorId": "1389567580",
                    "name": "Philipp Christmann"
                },
                {
                    "authorId": "1751591",
                    "name": "G. Weikum"
                }
            ]
        },
        {
            "paperId": "45e6120063b1af5a97bac0a326c55b35ac4ba865",
            "title": "Faithful Temporal Question Answering over Heterogeneous Sources",
            "abstract": "Temporal question answering (QA) involves time constraints, with phrases such as \"... in 2019\" or \"... before COVID\". In the former, time is an explicit condition, in the latter it is implicit. State-of-the-art methods have limitations along three dimensions. First, with neural inference, time constraints are merely soft-matched, giving room to invalid or inexplicable answers. Second, questions with implicit time are poorly supported. Third, answers come from a single source: either a knowledge base (KB) or a text corpus. We propose a temporal QA system that addresses these shortcomings. First, it enforces temporal constraints for faithful answering with tangible evidence. Second, it properly handles implicit questions. Third, it operates over heterogeneous sources, covering KB, text and web tables in a unified manner. The method has three stages: (i) understanding the question and its temporal conditions, (ii) retrieving evidence from all sources, and (iii) faithfully answering the question. As implicit questions are sparse in prior benchmarks, we introduce a principled method for generating diverse questions. Experiments show superior performance over a suite of baselines.",
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "authors": [
                {
                    "authorId": "2170780773",
                    "name": "Zhen Jia"
                },
                {
                    "authorId": "1389567580",
                    "name": "Philipp Christmann"
                },
                {
                    "authorId": "1751591",
                    "name": "G. Weikum"
                }
            ]
        },
        {
            "paperId": "5fa3b8a364d4845ffed5f4cfcdc5b61dd6282ec7",
            "title": "CardiO: Predicting Cardinality from Online Sources",
            "abstract": "Count questions are an important type of information need, though often present in noisy, contradictory, or semantically not fully aligned form on the Web. In this work, we propose CardiO, a lightweight and modular framework for searching entity counts on the Web. CardiO extracts all counts from a set of relevant Web snippets, and infers the most central count based on semantic and numeric distances from other candidates. In the absence of supporting evidence, the system relies on peer sets of similar size, to provide an estimate. Experiments show that CardiO can produce accurate and traceable counts better than small LLM-only methods. Although larger models have higher precision, when used to enhance CardiO components, they do not contribute to the final precision or recall.",
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "authors": [
                {
                    "authorId": "2135976772",
                    "name": "Shrestha Ghosh"
                },
                {
                    "authorId": "2066327465",
                    "name": "S. Razniewski"
                },
                {
                    "authorId": "2301210406",
                    "name": "Damien Graux"
                },
                {
                    "authorId": "1751591",
                    "name": "G. Weikum"
                }
            ]
        },
        {
            "paperId": "7c88a2a2626f2821968b8ff5ad126b66d7e2c3ff",
            "title": "SIRUP: Search-based Book Recommendation Playground",
            "abstract": "This work presents a playground platform to demonstrate and interactively explore a suite of methods for utilizing user review texts to generate book recommendations. The focus is on search-based settings where the user provides situative context by focusing on a genre, a given item, her full user profile, or a newly formulated query. The platform allows exploration over two large datasets with various methods for creating concise user profiles.",
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "authors": [
                {
                    "authorId": "2215626665",
                    "name": "Ghazaleh Haratinezhad Torbati"
                },
                {
                    "authorId": "2583806",
                    "name": "Anna Tigunova"
                },
                {
                    "authorId": "1751591",
                    "name": "G. Weikum"
                }
            ]
        },
        {
            "paperId": "81e1ec6b6155523655772826dd39f32a44d59cbd",
            "title": "Cultural Commonsense Knowledge for Intercultural Dialogues",
            "abstract": "Despite recent progress, large language models (LLMs) still face the challenge of appropriately reacting to the intricacies of social and cultural conventions. This paper presents MANGO, a methodology for distilling high-accuracy, high-recall assertions of cultural knowledge. We judiciously and iteratively prompt LLMs for this purpose from two entry points, concepts and cultures. Outputs are consolidated via clustering and generative summarization. Running the MANGO method with GPT-3.5 as underlying LLM yields 167K high-accuracy assertions for 30K concepts and 11K cultures, surpassing prior resources by a large margin in quality and size. In an extrinsic evaluation for intercultural dialogues, we explore augmenting dialogue systems with cultural knowledge assertions. Notably, despite LLMs inherently possessing cultural knowledge, we find that adding knowledge from MANGO improves the overall quality, specificity, and cultural sensitivity of dialogue responses, as judged by human annotators. Data and code are available for download.",
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "authors": [
                {
                    "authorId": "8615485",
                    "name": "Tuan-Phong Nguyen"
                },
                {
                    "authorId": "2066327465",
                    "name": "S. Razniewski"
                },
                {
                    "authorId": "1751591",
                    "name": "G. Weikum"
                }
            ]
        },
        {
            "paperId": "9b4b67f9c26ed5aa316f439dab7b3709ba06fad6",
            "title": "Recall Them All: Retrieval-Augmented Language Models for Long Object List Extraction from Long Documents",
            "abstract": "Methods for relation extraction from text mostly focus on high precision, at the cost of limited recall. High recall is crucial, though, to populate long lists of object entities that stand in a specific relation with a given subject. Cues for relevant objects can be spread across many passages in long texts. This poses the challenge of extracting long lists from long texts. We present the L3X method which tackles the problem in two stages: (1) recall-oriented generation using a large language model (LLM) with judicious techniques for retrieval augmentation, and (2) precision-oriented scrutinization to validate or prune candidates. Our L3X method outperforms LLM-only generations by a substantial margin.",
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "authors": [
                {
                    "authorId": "29001552",
                    "name": "Sneha Singhania"
                },
                {
                    "authorId": "2066327465",
                    "name": "S. Razniewski"
                },
                {
                    "authorId": "1751591",
                    "name": "G. Weikum"
                }
            ]
        },
        {
            "paperId": "ee0fe15afaedbe6752379fe15fb0d715369386cd",
            "title": "FASETS: Discovering Faceted Sets of Entities",
            "abstract": "Computing related entities for a given seed entity is an important task in exploratory search and comparative data analysis.Prior works, using the seed-based set expansion paradigm, have focused on the single aspect of identifying homogeneous sets with high pairwise relatedness. A few recent works discuss cluster-based approaches to tackle multi-faceted set expansion, however, they fail in harnessing the specificity of the clusters and generating an explanation for them. This paper poses the multi-faceted set expansion as an optimization problem, where the goal is to compute multiple groups of entities that convey different aspects in an explainable manner, with high similarity within each group and diversity across groups. To extend a seed entity, we collect a large pool of candidate entities and facets (e.g., categories)from Wikipedia and knowledge bases, and construct a candidate graph. We propose FASETS, an efficient algorithm for computing faceted groups of bounded size, based on random walks over the candidate graph. Our extensive evaluation shows the superiority of FASETS against prior baselines, with regard to ground-truth collected from crowdsourcing.",
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "authors": [
                {
                    "authorId": "2514979",
                    "name": "K. Pal"
                },
                {
                    "authorId": "40434178",
                    "name": "Hiba Arnaout"
                },
                {
                    "authorId": "2066327465",
                    "name": "S. Razniewski"
                },
                {
                    "authorId": "1751591",
                    "name": "G. Weikum"
                }
            ]
        },
        {
            "paperId": "02dd9ca2145393ac1865dd7c026970a460fafb49",
            "title": "Personal Data for Personal Use: Vision or Reality?",
            "abstract": "The vision of collecting all of one's personal information into one searchable database has been around at least since Vannevar Bush's 1945 paper on the Memex System [2]. In the late 1990's, Gordon Bell and his colleagues at Microsoft Research built MyLifeBits [1, 6], which was the first serious attempt to build such a database. Since then, there has been continued interest in our community to build personal information management systems [3-5, 7, 8, 10]. Recently, the Solid Project proposes a more radical approach to personal information, arguing that all of one's data should reside in their own data pod, and applications should be redesigned to fetch data from the pod [9].",
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "authors": [
                {
                    "authorId": "145867172",
                    "name": "X. Dong"
                },
                {
                    "authorId": "2155883057",
                    "name": "Bo Li"
                },
                {
                    "authorId": "1682824",
                    "name": "Julia Stoyanovich"
                },
                {
                    "authorId": "1699730",
                    "name": "A. Tung"
                },
                {
                    "authorId": "1751591",
                    "name": "G. Weikum"
                },
                {
                    "authorId": "1770962",
                    "name": "A. Halevy"
                },
                {
                    "authorId": "2131764025",
                    "name": "Wang-Chiew Tan"
                }
            ]
        },
        {
            "paperId": "1c86c5793c150a62d5f6581af2f79454f26faa20",
            "title": "UnCommonSense in Action! Informative Negations for Commonsense Knowledge Bases",
            "abstract": "Knowledge bases about commonsense knowledge i.e., CSKBs, are crucial in applications such as search and question answering. Prominent CSKBs mostly focus on positive statements. In this paper we show that materializing important negations increases the usability of CSKBs. We present Uncommonsense, a web portal to explore informative negations about everyday concepts: (i) in a research-focused interface, users get a glimpse into results-per-steps of the methodology; (ii) in a trivia interface, users can browse fun negative trivia about concepts of their choice; and (iii) in a query interface, users can submit triple-pattern queries with explicit negated relations and compare results with significantly less relevant answers from the positive-only baseline. It can be accessed at:https://uncommonsense.mpi-inf.mpg.de/.",
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "authors": [
                {
                    "authorId": "40434178",
                    "name": "Hiba Arnaout"
                },
                {
                    "authorId": "8615485",
                    "name": "Tuan-Phong Nguyen"
                },
                {
                    "authorId": "2066327465",
                    "name": "S. Razniewski"
                },
                {
                    "authorId": "1751591",
                    "name": "G. Weikum"
                }
            ]
        },
        {
            "paperId": "3cff5f004426d02fac2edf68837829240497a7c3",
            "title": "Recommendations by Concise User Profiles from Review Text",
            "abstract": "Recommender systems are most successful for popular items and users with ample interactions (likes, ratings etc.). This work addresses the difficult and underexplored case of supporting users who have very sparse interactions but post informative review texts. Our experimental studies address two book communities with these characteristics. We design a framework with Transformer-based representation learning, covering user-item interactions, item content, and user-provided reviews. To overcome interaction sparseness, we devise techniques for selecting the most informative cues to construct concise user profiles. Comprehensive experiments, with datasets from Amazon and Goodreads, show that judicious selection of text snippets achieves the best performance, even in comparison to LLM-generated rankings and to using LLMs to generate user profiles.",
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "authors": [
                {
                    "authorId": "104424084",
                    "name": "G. H. Torbati"
                },
                {
                    "authorId": "2583806",
                    "name": "Anna Tigunova"
                },
                {
                    "authorId": "2264609990",
                    "name": "Andrew Yates"
                },
                {
                    "authorId": "1751591",
                    "name": "G. Weikum"
                }
            ]
        }
    ]
}