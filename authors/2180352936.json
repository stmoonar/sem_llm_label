{
    "authorId": "2180352936",
    "papers": [
        {
            "paperId": "1cfb5e097c584151e4f2422bbdb5bf9d6d6fb67d",
            "title": "A Novel Ball-Racket Rebound Model for Table Tennis Robot Based on Continuous Contact Force",
            "abstract": "In table tennis, developing a precise ball-racket rebound model is crucial for predicting the trajectory and spin of a ball after it hits the racket, which is instrumental in racket design and enhancing the capabilities of table tennis robots. To this end, accuracy and computational efficiency are two challenges to overcome, which has not been perfectly handled using existing methods such as finite element (FE) and simplified rigid-body models. This article introduces a new model that calculates ball-racket rebounds in two orthogonal directions. Vertically, the collision dynamics are analyzed with the Kelvin\u2013Voigt model, revealing that the contact duration is independent of the incoming ball\u2019s velocity. Horizontally, we establish that the restitution coefficient varies as a function of the incident velocity, based on a continuous contact force model and momentum conservation principles. High-speed camera data corroborate these findings and confirm the model\u2019s efficacy across diverse conditions. Compared to an established representative model, our method not only maintains high computational efficiency but also improves the accuracy of predicting the ball\u2019s linear and angular velocities by an average of 42.72% and 33.77%, respectively, as evidenced by our experimental data.",
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "authors": [
                {
                    "authorId": "2293901331",
                    "name": "Yu Sun"
                },
                {
                    "authorId": "2180352936",
                    "name": "Yuxin Wang"
                },
                {
                    "authorId": "3234292",
                    "name": "Chengeng Qu"
                },
                {
                    "authorId": "2256806848",
                    "name": "Yu Liu"
                },
                {
                    "authorId": "2293842210",
                    "name": "Yuman Nie"
                },
                {
                    "authorId": "2243031884",
                    "name": "Zhiyong Sun"
                },
                {
                    "authorId": "2105722685",
                    "name": "Bo Song"
                }
            ]
        },
        {
            "paperId": "d2224fcd25dcccf6a8c9284d055213a904e36853",
            "title": "A Novel Trajectory-Based Ball Spin Estimation Method for Table Tennis Robot",
            "abstract": "Sport and game industry has grown rapidly in recent years due to the application of novel sensors and algorithms for quantitative analysis. For example, flying speed and spin estimation is essential to help players to improve their skills in table tennis. However, the spin estimation for a table tennis ball is challenging, as it is difficult to observe using cameras and model the aerodynamics of ball flight with spin. This article proposes a generalized aerodynamic model with variable aerodynamic coefficients to accurately represent the flying state of a table tennis ball. Analytical solutions for the aerodynamic coefficients and the acceleration due to the Magnus force are also developed for accurate ball spin estimation using pre- and postrebounding flight trajectories. The experimental results showed that compared to current state-of-the-art methods, the proposed method has achieved the best performance in angular velocity magnitude estimation for topspinning and backspinning balls. It also achieved an error of below 10\u00b0 in angular velocity amplitude estimation. Using the proposed spin estimation method, our table tennis robot could strike balls with either topspin or backspin with a high success rate of up to 84.6%. Besides, the experimental results also demonstrated the potential of the proposed method in the area of table tennis training and sports-broadcasting.",
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "authors": [
                {
                    "authorId": "2180352936",
                    "name": "Yuxin Wang"
                },
                {
                    "authorId": "2243031884",
                    "name": "Zhiyong Sun"
                },
                {
                    "authorId": "97685390",
                    "name": "Yongle Luo"
                },
                {
                    "authorId": "2258409301",
                    "name": "Haibo Zhang"
                },
                {
                    "authorId": "2258519340",
                    "name": "Wen Zhang"
                },
                {
                    "authorId": "2057564824",
                    "name": "Kun Dong"
                },
                {
                    "authorId": "2258431850",
                    "name": "Qiyu He"
                },
                {
                    "authorId": "2258615679",
                    "name": "Qiang Zhang"
                },
                {
                    "authorId": "2065660974",
                    "name": "Erkang Cheng"
                },
                {
                    "authorId": "2105722685",
                    "name": "Bo Song"
                }
            ]
        },
        {
            "paperId": "01e0386fd9bc398990231ad0d0c21844fe49a082",
            "title": "GAR: Generalized Autoregression for Multi-Fidelity Fusion",
            "abstract": "In many scientific research and engineering applications where repeated simulations of complex systems are conducted, a surrogate is commonly adopted to quickly estimate the whole system. To reduce the expensive cost of generating training examples, it has become a promising approach to combine the results of low-fidelity (fast but inaccurate) and high-fidelity (slow but accurate) simulations. Despite the fast developments of multi-fidelity fusion techniques, most existing methods require particular data structures and do not scale well to high-dimensional output. To resolve these issues, we generalize the classic autoregression (AR), which is wildly used due to its simplicity, robustness, accuracy, and tractability, and propose generalized autoregression (GAR) using tensor formulation and latent features. GAR can deal with arbitrary dimensional outputs and arbitrary multifidelity data structure to satisfy the demand of multi-fidelity fusion for complex problems; it admits a fully tractable likelihood and posterior requiring no approximate inference and scales well to high-dimensional problems. Furthermore, we prove the autokrigeability theorem based on GAR in the multi-fidelity case and develop CIGAR, a simplified GAR with the exact predictive mean accuracy with computation reduction by a factor of d 3, where d is the dimensionality of the output. The empirical assessment includes many canonical PDEs and real scientific examples and demonstrates that the proposed method consistently outperforms the SOTA methods with a large margin (up to 6x improvement in RMSE) with only a couple high-fidelity training samples.",
            "fieldsOfStudy": [
                "Mathematics",
                "Computer Science",
                "Physics"
            ],
            "authors": [
                {
                    "authorId": "2180352936",
                    "name": "Yuxin Wang"
                },
                {
                    "authorId": "73362761",
                    "name": "Zhengrong Xing"
                },
                {
                    "authorId": "1409337650",
                    "name": "Wei W. Xing"
                }
            ]
        },
        {
            "paperId": "3e09cec24d15564929a58af93d139c956a4a2128",
            "title": "RenderMe-360: A Large Digital Asset Library and Benchmarks Towards High-fidelity Head Avatars",
            "abstract": "Synthesizing high-fidelity head avatars is a central problem for computer vision and graphics. While head avatar synthesis algorithms have advanced rapidly, the best ones still face great obstacles in real-world scenarios. One of the vital causes is inadequate datasets -- 1) current public datasets can only support researchers to explore high-fidelity head avatars in one or two task directions; 2) these datasets usually contain digital head assets with limited data volume, and narrow distribution over different attributes. In this paper, we present RenderMe-360, a comprehensive 4D human head dataset to drive advance in head avatar research. It contains massive data assets, with 243+ million complete head frames, and over 800k video sequences from 500 different identities captured by synchronized multi-view cameras at 30 FPS. It is a large-scale digital library for head avatars with three key attributes: 1) High Fidelity: all subjects are captured by 60 synchronized, high-resolution 2K cameras in 360 degrees. 2) High Diversity: The collected subjects vary from different ages, eras, ethnicities, and cultures, providing abundant materials with distinctive styles in appearance and geometry. Moreover, each subject is asked to perform various motions, such as expressions and head rotations, which further extend the richness of assets. 3) Rich Annotations: we provide annotations with different granularities: cameras' parameters, matting, scan, 2D/3D facial landmarks, FLAME fitting, and text description. Based on the dataset, we build a comprehensive benchmark for head avatar research, with 16 state-of-the-art methods performed on five main tasks: novel view synthesis, novel expression synthesis, hair rendering, hair editing, and talking head generation. Our experiments uncover the strengths and weaknesses of current methods. RenderMe-360 opens the door for future exploration in head avatars.",
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "authors": [
                {
                    "authorId": "8674964",
                    "name": "Dongwei Pan"
                },
                {
                    "authorId": "82706357",
                    "name": "Long Zhuo"
                },
                {
                    "authorId": "1453752225",
                    "name": "Jingtan Piao"
                },
                {
                    "authorId": "50052383",
                    "name": "Huiwen Luo"
                },
                {
                    "authorId": "2116794168",
                    "name": "W. Cheng"
                },
                {
                    "authorId": "2180352936",
                    "name": "Yuxin Wang"
                },
                {
                    "authorId": "2218877713",
                    "name": "Siming Fan"
                },
                {
                    "authorId": "2218690705",
                    "name": "Shengqi Liu"
                },
                {
                    "authorId": "2165477990",
                    "name": "Lei Yang"
                },
                {
                    "authorId": "144445937",
                    "name": "Bo Dai"
                },
                {
                    "authorId": "2117940996",
                    "name": "Ziwei Liu"
                },
                {
                    "authorId": "1717179",
                    "name": "Chen Change Loy"
                },
                {
                    "authorId": "144461220",
                    "name": "Chen Qian"
                },
                {
                    "authorId": "2110050420",
                    "name": "Wayne Wu"
                },
                {
                    "authorId": "1807606",
                    "name": "Dahua Lin"
                },
                {
                    "authorId": "41016969",
                    "name": "Kwan-Yee Lin"
                }
            ]
        },
        {
            "paperId": "612d15383f5bd258f0521b81b295c7d3c811e4d5",
            "title": "From Hypergraph Energy Functions to Hypergraph Neural Networks",
            "abstract": "Hypergraphs are a powerful abstraction for representing higher-order interactions between entities of interest. To exploit these relationships in making downstream predictions, a variety of hypergraph neural network architectures have recently been proposed, in large part building upon precursors from the more traditional graph neural network (GNN) literature. Somewhat differently, in this paper we begin by presenting an expressive family of parameterized, hypergraph-regularized energy functions. We then demonstrate how minimizers of these energies effectively serve as node embeddings that, when paired with a parameterized classifier, can be trained end-to-end via a supervised bilevel optimization process. Later, we draw parallels between the implicit architecture of the predictive models emerging from the proposed bilevel hypergraph optimization, and existing GNN architectures in common use. Empirically, we demonstrate state-of-the-art results on various hypergraph node classification benchmarks. Code is available at https://github.com/yxzwang/PhenomNN.",
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "authors": [
                {
                    "authorId": "2180352936",
                    "name": "Yuxin Wang"
                },
                {
                    "authorId": "47594426",
                    "name": "Quan Gan"
                },
                {
                    "authorId": "1767521",
                    "name": "Xipeng Qiu"
                },
                {
                    "authorId": "1790227",
                    "name": "Xuanjing Huang"
                },
                {
                    "authorId": "2242717",
                    "name": "D. Wipf"
                }
            ]
        },
        {
            "paperId": "74a2b64af133c30609aae1c64ba31ee2f0f02418",
            "title": "Reinforcement Learning with Goal Relabeling and Dynamic Model for Robotic Tasks",
            "abstract": "Improving sample efficiency is crucial for reinforcement learning, especially for the robot manipulation tasks. The model-based method could improve the sample efficiency by introducing a dynamic model to generate a large number of samples, so that the requirement of interaction with the environment can be reduced. However, as the dynamic model is constructed by the deep network, the model error is inevitable. This error will increase the errors of the data generated by the model, which may damage the policy training process to a certain extent. To overcome the limitations of the above data augmentation methods, this paper proposes a new reinforcement learning method based on goal relabeling and dynamic (GMRL) model. In the GMRL, the quality of the explored data will be improved by the goal relabeling at first, followed by introducing a dynamic model to further increase the data quantity. The proposed method has been tested in a reinforcement learning benchmark environment, and the results show that the performance of the proposed method is significantly better than that both of the goal relabeling and standard model-based methods. At the same time, the proposed method has a higher sample efficiency than other existing combined schema of goal relabeling and dynamic model.",
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "authors": [
                {
                    "authorId": "2057564824",
                    "name": "Kun Dong"
                },
                {
                    "authorId": "97685390",
                    "name": "Yongle Luo"
                },
                {
                    "authorId": "2180352936",
                    "name": "Yuxin Wang"
                },
                {
                    "authorId": "2242949258",
                    "name": "Shan Fang"
                },
                {
                    "authorId": "2256806848",
                    "name": "Yu Liu"
                },
                {
                    "authorId": "2065660974",
                    "name": "Erkang Cheng"
                },
                {
                    "authorId": "2243031884",
                    "name": "Zhiyong Sun"
                },
                {
                    "authorId": "19219781",
                    "name": "Q. Zhang"
                },
                {
                    "authorId": "2105722685",
                    "name": "Bo Song"
                }
            ]
        },
        {
            "paperId": "9152fd51e077aaa54baf2d9406aa6b37942c16be",
            "title": "D2SR: Transferring Dense Reward Function to Sparse by Network Resetting",
            "abstract": "In Reinforcement Learning (RL), most algorithms use a fixed reward function, and few studies discuss transferring the reward function during learning. Actually, different types of reward functions have different characteristics. In general, a shaped dense reward function has the advantage of quickly guiding the agent to a high-value state but has the disadvantage of being difficult to design a well-shaped function and susceptible to noise. The sparse reward has the advantages of being robust and consistent with the task, but less efficient in early exploration. Therefore, this paper proposes an algorithm called Dense2Sparse by Network Resetting (D2SR), which simultaneously satisfies the efficiency of dense reward functions and the robustness of sparse rewards. Specifically, the D2SR method can rescue the agent from being misled by suboptimal dense rewards by network resetting parameters and transferring experience to sparse rewards, thereby achieving significant improvements in the direction of the global optimum. In this study, through a series of ablation experiments on challenging robot manipulation tasks, we find that D2SR can reduce the requirement of dense reward function design, which can also balance efficiency and performance in tasks with noisy rewards.",
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "authors": [
                {
                    "authorId": "97685390",
                    "name": "Yongle Luo"
                },
                {
                    "authorId": "2180352936",
                    "name": "Yuxin Wang"
                },
                {
                    "authorId": "2057564824",
                    "name": "Kun Dong"
                },
                {
                    "authorId": "2256806848",
                    "name": "Yu Liu"
                },
                {
                    "authorId": "2243031884",
                    "name": "Zhiyong Sun"
                },
                {
                    "authorId": "19219781",
                    "name": "Q. Zhang"
                },
                {
                    "authorId": "2105722685",
                    "name": "Bo Song"
                }
            ]
        },
        {
            "paperId": "a9e85253afd50eeaeb5dd0a09b1a690221c23f7b",
            "title": "SIRL: Self-Imitation Reinforcement Learning for Single-step Hitting Tasks",
            "abstract": "Reinforcement learning (RL) has demonstrated significant success in various sequential decision-making tasks. However, standard RL frameworks suffer from low efficiency in single-step robotic hitting tasks, which require accurate control and single-step decision-making under delayed reward. To address this challenge of single-step tasks, a Self-Imitation Reinforcement Learning (SIRL) algorithm is proposed to better utilize each interaction sample. With SIRL, the agent can obtain optimal successful samples during itself interactions without human demonstrations, even if the actual interaction fails. The proposed SIRL uses the self-imitation learning of these optimal samples to accelerate the learning of RL policy. In this paper, we create two challenging hitting tasks in MuJoCo simulation, Slide, and TableTennis, to evaluate our approach. Experimental results demonstrate that the proposed SIRL algorithm outperforms the standard RL methods and supervised learning methods in terms of both sample efficiency and performance. Especially, in sparse reward settings, SIRL stands out as the only RL-based method that can learn these tasks, as self-imitation learning provides the agent with more gradient information for policy optimization.",
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "authors": [
                {
                    "authorId": "97685390",
                    "name": "Yongle Luo"
                },
                {
                    "authorId": "2180352936",
                    "name": "Yuxin Wang"
                },
                {
                    "authorId": "2057564824",
                    "name": "Kun Dong"
                },
                {
                    "authorId": "2256806848",
                    "name": "Yu Liu"
                },
                {
                    "authorId": "48064593",
                    "name": "Zhiyong Sun"
                },
                {
                    "authorId": "19219781",
                    "name": "Q. Zhang"
                },
                {
                    "authorId": "2105722685",
                    "name": "Bo Song"
                }
            ]
        },
        {
            "paperId": "32231cc95cb7fb2be6f70ffce1a111bf5116b3f2",
            "title": "Discovering New Intents Using Latent Variables",
            "abstract": "Discovering new intents is of great significance to establishing Bootstrapped Task-Oriented Dialogue System. Most existing methods either lack the ability to transfer prior knowledge in the known intent data or fall into the dilemma of forgetting prior knowledge in the follow-up. More importantly, these methods do not deeply explore the intrinsic structure of unlabeled data, so they can not seek out the characteristics that make an intent in general. In this paper, starting from the intuition that discovering intents could be beneficial to the identification of the known intents, we propose a probabilistic framework for discovering intents where intent assignments are treated as latent variables. We adopt Expectation Maximization framework for optimization. Specifically, In E-step, we conduct discovering intents and explore the intrinsic structure of unlabeled data by the posterior of intent assignments. In M-step, we alleviate the forgetting of prior knowledge transferred from known intents by optimizing the discrimination of labeled data. Extensive experiments conducted in three challenging real-world datasets demonstrate our method can achieve substantial improvements.",
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "authors": [
                {
                    "authorId": "2118117212",
                    "name": "Yunhua Zhou"
                },
                {
                    "authorId": "2129354313",
                    "name": "Peiju Liu"
                },
                {
                    "authorId": "2180352936",
                    "name": "Yuxin Wang"
                },
                {
                    "authorId": "1767521",
                    "name": "Xipeng Qiu"
                }
            ]
        },
        {
            "paperId": "c21f829b3412e0c859d2528151499352b16f4997",
            "title": "The Open-World Lottery Ticket Hypothesis for OOD Intent Classification",
            "abstract": "Most existing methods of Out-of-Domain (OOD) intent classification rely on extensive auxiliary OOD corpora or specific training paradigms. However, they are underdeveloped in the underlying principle that the models should have differentiated confidence in In- and Out-of-domain intent. In this work, we shed light on the fundamental cause of model overconfidence on OOD and demonstrate that calibrated subnetworks can be uncovered by pruning the overparameterized model. Calibrated confidence provided by the subnetwork can better distinguish In- and Out-of-domain, which can be a benefit for almost all post hoc methods. In addition to bringing fundamental insights, we also extend the Lottery Ticket Hypothesis to open-world scenarios. We conduct extensive experiments on four real-world datasets to demonstrate our approach can establish consistent improvements compared with a suite of competitive baselines.",
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "authors": [
                {
                    "authorId": "2118117212",
                    "name": "Yunhua Zhou"
                },
                {
                    "authorId": "2129354313",
                    "name": "Peiju Liu"
                },
                {
                    "authorId": "2180352936",
                    "name": "Yuxin Wang"
                },
                {
                    "authorId": "1767521",
                    "name": "Xipeng Qiu"
                }
            ]
        }
    ]
}