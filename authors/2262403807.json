{
    "authorId": "2262403807",
    "papers": [
        {
            "paperId": "2bc0e1b782ec7ff56bcd0d117e553f411c7940b0",
            "title": "Prompt Tuning as User Inherent Profile Inference Machine",
            "abstract": "Large Language Models (LLMs) have exhibited significant promise in recommender systems by empowering user profiles with their extensive world knowledge and superior reasoning capabilities. However, LLMs face challenges like unstable instruction compliance, modality gaps, and high inference latency, leading to textual noise and limiting their effectiveness in recommender systems. To address these challenges, we propose UserIP-Tuning, which uses prompt-tuning to infer user profiles. It integrates the causal relationship between user profiles and behavior sequences into LLMs' prompts. And employs expectation maximization to infer the embedded latent profile, minimizing textual noise by fixing the prompt template. Furthermore, A profile quantization codebook bridges the modality gap by categorizing profile embeddings into collaborative IDs, which are pre-stored for online deployment. This improves time efficiency and reduces memory usage. Experiments on four public datasets show that UserIP-Tuning outperforms state-of-the-art recommendation algorithms. Additional tests and case studies confirm its effectiveness, robustness, and transferability.",
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "authors": [
                {
                    "authorId": "2256815726",
                    "name": "Yusheng Lu"
                },
                {
                    "authorId": "2294672261",
                    "name": "Zhaocheng Du"
                },
                {
                    "authorId": "2181637944",
                    "name": "Xiangyang Li"
                },
                {
                    "authorId": "2238104000",
                    "name": "Xiangyu Zhao"
                },
                {
                    "authorId": "2130051800",
                    "name": "Weiwen Liu"
                },
                {
                    "authorId": "2262403807",
                    "name": "Yichao Wang"
                },
                {
                    "authorId": "3339005",
                    "name": "Huifeng Guo"
                },
                {
                    "authorId": "2262216857",
                    "name": "Ruiming Tang"
                },
                {
                    "authorId": "2274021958",
                    "name": "Zhenhua Dong"
                },
                {
                    "authorId": "2309213607",
                    "name": "Yongrui Duan"
                }
            ]
        },
        {
            "paperId": "33546ba889b58a5ae4fd842e44af8b1a265c28cd",
            "title": "LLM4MSR: An LLM-Enhanced Paradigm for Multi-Scenario Recommendation",
            "abstract": "As the demand for more personalized recommendation grows and a dramatic boom in commercial scenarios arises, the study on multi-scenario recommendation (MSR) has attracted much attention, which uses the data from all scenarios to simultaneously improve their recommendation performance. However, existing methods tend to integrate insufficient scenario knowledge and neglect learning personalized cross-scenario preferences, thus leading to suboptimal performance and inadequate interpretability. Meanwhile, though large language model (LLM) has shown great capability of reasoning and capturing semantic information, the high inference latency and high computation cost of tuning hinder its implementation in industrial recommender systems. To fill these gaps, we propose an effective efficient interpretable LLM-enhanced paradigm LLM4MSR in this work. Specifically, we first leverage LLM to uncover multi-level knowledge including scenario correlations and users' cross-scenario interests from the designed scenario- and user-level prompt without fine-tuning the LLM, then adopt hierarchical meta networks to generate multi-level meta layers to explicitly improves the scenario-aware and personalized recommendation capability. Our experiments on KuaiSAR-small, KuaiSAR, and Amazon datasets validate two significant advantages of LLM4MSR: (i) the effectiveness and compatibility with different multi-scenario backbone models (achieving 1.5%, 1%, and 40% AUC improvement on three datasets), (ii) high efficiency and deployability on industrial recommender systems, and (iii) improved interpretability. The implemented code and data is available to ease reproduction.",
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "authors": [
                {
                    "authorId": "2223878432",
                    "name": "Yuhao Wang"
                },
                {
                    "authorId": "2262403807",
                    "name": "Yichao Wang"
                },
                {
                    "authorId": "2275537250",
                    "name": "Zichuan Fu"
                },
                {
                    "authorId": "2181637944",
                    "name": "Xiangyang Li"
                },
                {
                    "authorId": "2238104000",
                    "name": "Xiangyu Zhao"
                },
                {
                    "authorId": "3339005",
                    "name": "Huifeng Guo"
                },
                {
                    "authorId": "2257180930",
                    "name": "Ruiming Tang"
                }
            ]
        },
        {
            "paperId": "47fd9714c6bb7ebf481638fa1b0a8b7d5d3c3ec0",
            "title": "M-scan: A Multi-Scenario Causal-driven Adaptive Network for Recommendation",
            "abstract": "We primarily focus on the field of multi-scenario recommendation, which poses a significant challenge in effectively leveraging data from different scenarios to enhance predictions in scenarios with limited data. Current mainstream efforts mainly center around innovative model network architectures, with the aim of enabling the network to implicitly acquire knowledge from diverse scenarios. However, the uncertainty of implicit learning in networks arises from the absence of explicit modeling, leading to not only difficulty in training but also incomplete user representation and suboptimal performance. Furthermore, through causal graph analysis, we have discovered that the scenario itself directly influences click behavior, yet existing approaches directly incorporate data from other scenarios during the training of the current scenario, leading to prediction biases when they directly utilize click behaviors from other scenarios to train models. To address these problems, we propose the Multi-Scenario Causal-driven Adaptive Network M-scan). This model incorporates a Scenario-Aware Co-Attention mechanism that explicitly extracts user interests from other scenarios that align with the current scenario. Additionally, it employs a Scenario Bias Eliminator module utilizing causal counterfactual inference to mitigate biases introduced by data from other scenarios. Extensive experiments on two public datasets demonstrate the efficacy of our M-scan compared to the existing baseline models.",
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "authors": [
                {
                    "authorId": "2296232413",
                    "name": "Jiachen Zhu"
                },
                {
                    "authorId": "2262403807",
                    "name": "Yichao Wang"
                },
                {
                    "authorId": "2144908858",
                    "name": "Jianghao Lin"
                },
                {
                    "authorId": "79494403",
                    "name": "Jiarui Qin"
                },
                {
                    "authorId": "2257180930",
                    "name": "Ruiming Tang"
                },
                {
                    "authorId": "2240768092",
                    "name": "Weinan Zhang"
                },
                {
                    "authorId": "2237958078",
                    "name": "Yong Yu"
                }
            ]
        },
        {
            "paperId": "56503e479a8514dafaad423410286d3526bd67c8",
            "title": "D3: A Methodological Exploration of Domain Division, Modeling, and Balance in Multi-Domain Recommendations",
            "abstract": "To enhance the efficacy of multi-scenario services in industrial recommendation systems, the emergence of multi-domain recommendation has become prominent, which entails simultaneous modeling of all domains through a unified model, effectively capturing commonalities and differences among them. However, current methods rely on manual domain partitioning, which overlook the intricate domain relationships and the heterogeneity of different domains during joint optimization, hindering the integration of domain commonalities and differences. To address these challenges, this paper proposes a universal and flexible framework D3 aimed at optimizing the multi-domain recommendation pipeline from three key aspects. Firstly, an attention-based domain adaptation module is introduced to automatically identify and incorporate domain-sensitive features during training. Secondly, we propose a fusion gate module that enables the seamless integration of commonalities and diversities among domains, allowing for implicit characterization of intricate domain relationships. Lastly, we tackle the issue of joint optimization by deriving loss weights from two complementary viewpoints: domain complexity and domain specificity, alleviating inconsistencies among different domains during the training phase. Experiments on three public datasets demonstrate the effectiveness and superiority of our proposed framework. In addition, D3 has been implemented on a real-life, high-traffic internet platform catering to millions of users daily.",
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "authors": [
                {
                    "authorId": "2264224432",
                    "name": "Pengyue Jia"
                },
                {
                    "authorId": "2262403807",
                    "name": "Yichao Wang"
                },
                {
                    "authorId": "2293567811",
                    "name": "Shanru Lin"
                },
                {
                    "authorId": "2238125533",
                    "name": "Xiaopeng Li"
                },
                {
                    "authorId": "2238104000",
                    "name": "Xiangyu Zhao"
                },
                {
                    "authorId": "3339005",
                    "name": "Huifeng Guo"
                },
                {
                    "authorId": "2257180930",
                    "name": "Ruiming Tang"
                }
            ]
        },
        {
            "paperId": "8349c04b60be2ac2114e11a3f39cc334ea21fc47",
            "title": "ERASE: Benchmarking Feature Selection Methods for Deep Recommender Systems",
            "abstract": "Deep Recommender Systems (DRS) are increasingly dependent on a large number of feature fields for more precise recommendations. Effective feature selection methods are consequently becoming critical for further enhancing the accuracy and optimizing storage efficiencies to align with the deployment demands. This research area, particularly in the context of DRS, is nascent and faces three core challenges. Firstly, variant experimental setups across research papers often yield unfair comparisons, obscuring practical insights. Secondly, the existing literature's lack of detailed analysis on selection attributes, based on large-scale datasets and a thorough comparison among selection techniques and DRS backbones, restricts the generalizability of findings and impedes deployment on DRS. Lastly, research often focuses on comparing the peak performance achievable by feature selection methods, an approach that is typically computationally infeasible for identifying the optimal hyperparameters and overlooks evaluating the robustness and stability of these methods. To bridge these gaps, this paper presents ERASE, a comprehensive bEnchmaRk for feAture SElection for DRS. ERASE comprises a thorough evaluation of eleven feature selection methods, covering both traditional and deep learning approaches, across four public datasets, private industrial datasets, and a real-world commercial platform, achieving significant enhancement. Our code is available online for ease of reproduction.",
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "authors": [
                {
                    "authorId": "2264224432",
                    "name": "Pengyue Jia"
                },
                {
                    "authorId": "2162455919",
                    "name": "Yejing Wang"
                },
                {
                    "authorId": "2174600044",
                    "name": "Zhaochen Du"
                },
                {
                    "authorId": "2238104000",
                    "name": "Xiangyu Zhao"
                },
                {
                    "authorId": "2262403807",
                    "name": "Yichao Wang"
                },
                {
                    "authorId": "92633145",
                    "name": "Bo Chen"
                },
                {
                    "authorId": "2211473272",
                    "name": "Wanyu Wang"
                },
                {
                    "authorId": "3339005",
                    "name": "Huifeng Guo"
                },
                {
                    "authorId": "2257180930",
                    "name": "Ruiming Tang"
                }
            ]
        },
        {
            "paperId": "9ffab7e041dc10f4ae3f8acb20aed55bd8fc90f7",
            "title": "LLM-enhanced Reranking in Recommender Systems",
            "abstract": "Reranking is a critical component in recommender systems, playing an essential role in refining the output of recommendation algorithms. Traditional reranking models have focused predominantly on accuracy, but modern applications demand consideration of additional criteria such as diversity and fairness. Existing reranking approaches often fail to harmonize these diverse criteria effectively at the model level. Moreover, these models frequently encounter challenges with scalability and personalization due to their complexity and the varying significance of different reranking criteria in diverse scenarios. In response, we introduce a comprehensive reranking framework enhanced by LLM, designed to seamlessly integrate various reranking criteria while maintaining scalability and facilitating personalized recommendations. This framework employs a fully connected graph structure, allowing the LLM to simultaneously consider multiple aspects such as accuracy, diversity, and fairness through a coherent Chain-of-Thought (CoT) process. A customizable input mechanism is also integrated, enabling the tuning of the language model's focus to meet specific reranking needs. We validate our approach using three popular public datasets, where our framework demonstrates superior performance over existing state-of-the-art reranking models in balancing multiple criteria. The code for this implementation is publicly available.",
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "authors": [
                {
                    "authorId": "2161309826",
                    "name": "Jingtong Gao"
                },
                {
                    "authorId": "2258709565",
                    "name": "Bo Chen"
                },
                {
                    "authorId": "2238104000",
                    "name": "Xiangyu Zhao"
                },
                {
                    "authorId": "2130051800",
                    "name": "Weiwen Liu"
                },
                {
                    "authorId": "2181637944",
                    "name": "Xiangyang Li"
                },
                {
                    "authorId": "2262403807",
                    "name": "Yichao Wang"
                },
                {
                    "authorId": "2187882131",
                    "name": "Zijian Zhang"
                },
                {
                    "authorId": "2211473272",
                    "name": "Wanyu Wang"
                },
                {
                    "authorId": "2307408755",
                    "name": "Yuyang Ye"
                },
                {
                    "authorId": "2293567811",
                    "name": "Shanru Lin"
                },
                {
                    "authorId": "3339005",
                    "name": "Huifeng Guo"
                },
                {
                    "authorId": "2257180930",
                    "name": "Ruiming Tang"
                }
            ]
        },
        {
            "paperId": "ac457964969cdf99650acacb65cd84985eb84863",
            "title": "Tired of Plugins? Large Language Models Can Be End-To-End Recommenders",
            "abstract": "Recommender systems aim to predict user interest based on historical behavioral data. They are mainly designed in sequential pipelines, requiring lots of data to train different sub-systems, and are hard to scale to new domains. Recently, Large Language Models (LLMs) have demonstrated remarkable generalized capabilities, enabling a singular model to tackle diverse recommendation tasks across various scenarios. Nonetheless, existing LLM-based recommendation systems utilize LLM purely for a single task of the recommendation pipeline. Besides, these systems face challenges in presenting large-scale item sets to LLMs in natural language format, due to the constraint of input length. To address these challenges, we introduce an LLM-based end-to-end recommendation framework: UniLLMRec. Specifically, UniLLMRec integrates multi-stage tasks (e.g. recall, ranking, re-ranking) via chain-of-recommendations. To deal with large-scale items, we propose a novel strategy to structure all items into an item tree, which can be dynamically updated and effectively retrieved. UniLLMRec shows promising zero-shot results in comparison with conventional supervised models. Additionally, it boasts high efficiency, reducing the input token need by 86% compared to existing LLM-based models. Such efficiency not only accelerates task completion but also optimizes resource utilization. To facilitate model understanding and to ensure reproducibility, we have made our code publicly available.",
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "authors": [
                {
                    "authorId": "2294381452",
                    "name": "Wenlin Zhang"
                },
                {
                    "authorId": "2276003321",
                    "name": "Chuhan Wu"
                },
                {
                    "authorId": "2181637944",
                    "name": "Xiangyang Li"
                },
                {
                    "authorId": "2223878432",
                    "name": "Yuhao Wang"
                },
                {
                    "authorId": "2275185317",
                    "name": "Kuicai Dong"
                },
                {
                    "authorId": "2262403807",
                    "name": "Yichao Wang"
                },
                {
                    "authorId": "2105646417",
                    "name": "Xinyi Dai"
                },
                {
                    "authorId": "2238104000",
                    "name": "Xiangyu Zhao"
                },
                {
                    "authorId": "3339005",
                    "name": "Huifeng Guo"
                },
                {
                    "authorId": "2257180930",
                    "name": "Ruiming Tang"
                }
            ]
        },
        {
            "paperId": "ae1cd3e1db5268dd77d10924717b87c7eb8b7c7a",
            "title": "All Roads Lead to Rome: Unveiling the Trajectory of Recommender Systems Across the LLM Era",
            "abstract": "Recommender systems (RS) are vital for managing information overload and delivering personalized content, responding to users' diverse information needs. The emergence of large language models (LLMs) offers a new horizon for redefining recommender systems with vast general knowledge and reasoning capabilities. Standing across this LLM era, we aim to integrate recommender systems into a broader picture, and pave the way for more comprehensive solutions for future research. Therefore, we first offer a comprehensive overview of the technical progression of recommender systems, particularly focusing on language foundation models and their applications in recommendation. We identify two evolution paths of modern recommender systems -- via list-wise recommendation and conversational recommendation. These two paths finally converge at LLM agents with superior capabilities of long-term memory, reflection, and tool intelligence. Along these two paths, we point out that the information effectiveness of the recommendation is increased, while the user's acquisition cost is decreased. Technical features, research methodologies, and inherent challenges for each milestone along the path are carefully investigated -- from traditional list-wise recommendation to LLM-enhanced recommendation to recommendation with LLM agents. Finally, we highlight several unresolved challenges crucial for the development of future personalization technologies and interfaces and discuss the future prospects.",
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "authors": [
                {
                    "authorId": "2258709565",
                    "name": "Bo Chen"
                },
                {
                    "authorId": "2105646417",
                    "name": "Xinyi Dai"
                },
                {
                    "authorId": "2290027703",
                    "name": "Huifeng Guo"
                },
                {
                    "authorId": "2260810851",
                    "name": "Wei Guo"
                },
                {
                    "authorId": "2130051800",
                    "name": "Weiwen Liu"
                },
                {
                    "authorId": "2297898895",
                    "name": "Yong Liu"
                },
                {
                    "authorId": "79494403",
                    "name": "Jiarui Qin"
                },
                {
                    "authorId": "2284295184",
                    "name": "Ruiming Tang"
                },
                {
                    "authorId": "2262403807",
                    "name": "Yichao Wang"
                },
                {
                    "authorId": "2276003321",
                    "name": "Chuhan Wu"
                },
                {
                    "authorId": "2311410517",
                    "name": "Yaxiong Wu"
                },
                {
                    "authorId": "2298987734",
                    "name": "Hao Zhang"
                }
            ]
        },
        {
            "paperId": "dc2f4aeb6a5ff87f01a4ed1aa4e8a2ae4f68c310",
            "title": "Diff-MSR: A Diffusion Model Enhanced Paradigm for Cold-Start Multi-Scenario Recommendation",
            "abstract": "With the explosive growth of various commercial scenarios, there is an increasing number of studies on multi-scenario recommendation (MSR) which trains the recommender system with the data from multiple scenarios, aiming to improve the recommendation performance on all these scenarios synchronously. However, due to the large discrepancy in the number of interactions among domains, multi-scenario recommendation models usually suffer from insufficient learning and negative transfer especially on the cold-start scenarios, thus exacerbating the data sparsity issue. To fill this gap, in this work we propose a novel diffusion model enhanced paradigm tailored for the cold-start problem in multi-scenario recommendation in a data-driven generative manner. Specifically, based on all-domain data, we leverage the diffusion model with our newly designed variance schedule and the proposed classifier, which explicitly boosts the recommendation performance on the cold-start scenarios by exploiting the generated high-quality and informative embedding, leveraging the abundance of rich scenarios. Our experiments on Douban and Amazon datasets demonstrate two strengths of the proposed paradigm: (i) its effectiveness with a significant increase of 8.5% and 1% in accuracy on the two datasets, and (ii) its compatibility with various multi-scenario backbone models. The implementation code is available for easy reproduction.",
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "authors": [
                {
                    "authorId": "2223878432",
                    "name": "Yuhao Wang"
                },
                {
                    "authorId": "2204700561",
                    "name": "Ziru Liu"
                },
                {
                    "authorId": "2262403807",
                    "name": "Yichao Wang"
                },
                {
                    "authorId": "2116711669",
                    "name": "Xiangyu Zhao"
                },
                {
                    "authorId": "2258709565",
                    "name": "Bo Chen"
                },
                {
                    "authorId": "3339005",
                    "name": "Huifeng Guo"
                },
                {
                    "authorId": "2240536007",
                    "name": "Ruiming Tang"
                }
            ]
        },
        {
            "paperId": "e78407851276377b9005f103d90782784c6b0252",
            "title": "IncMSR: An Incremental Learning Approach for Multi-Scenario Recommendation",
            "abstract": "For better performance and less resource consumption, multi-scenario recommendation (MSR) is proposed to train a unified model to serve all scenarios by leveraging data from multiple scenarios. Current works in MSR focus on designing effective networks for better information transfer among different scenarios. However, they omit two important issues when applying MSR models in industrial situations. The first is the efficiency problem brought by mixed data, which delays the update of models and further leads to performance degradation. The second is that MSR models are insensitive to the changes of distribution over time, resulting in suboptimal effectiveness in the incoming data. In this paper, we propose an incremental learning approach for MSR (IncMSR), which can not only improve the training efficiency but also perceive changes in distribution over time. Specifically, we first quantify the pair-wise distance between representations from scenario, time and time-scenario dimensions respectively. Then, we decompose the MSR model into scenario-shared and scenario-specific parts and apply fine-grained constraints on the distances quantified with respect to the two different parts. Finally, all constraints are fused in an elegant way using a metric learning framework as a supplementary penalty term to the original MSR loss function. Offline experiments on two real-world datasets are conducted to demonstrate the superiority and compatibility of our proposed approach.",
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "authors": [
                {
                    "authorId": "2260834761",
                    "name": "Kexin Zhang"
                },
                {
                    "authorId": "2262403807",
                    "name": "Yichao Wang"
                },
                {
                    "authorId": "2206198477",
                    "name": "Xiu Li"
                },
                {
                    "authorId": "2240536007",
                    "name": "Ruiming Tang"
                },
                {
                    "authorId": "2274191373",
                    "name": "Rui Zhang"
                }
            ]
        }
    ]
}