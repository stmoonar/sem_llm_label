{
    "authorId": "2204700561",
    "papers": [
        {
            "paperId": "31b568751206e847669ad0d10d145aac70ce6236",
            "title": "Modeling User Retention through Generative Flow Networks",
            "abstract": "Recommender systems aim to fulfill the user's daily demands. While most existing research focuses on maximizing the user's engagement with the system, it has recently been pointed out that how frequently the users come back for the service also reflects the quality and stability of recommendations. However, optimizing this user retention behavior is non-trivial and poses several challenges including the intractable leave-and-return user activities, the sparse and delayed signal, and the uncertain relations between users' retention and their immediate feedback towards each item in the recommendation list. In this work, we regard the retention signal as an overall estimation of the user's end-of-session satisfaction and propose to estimate this signal through a probabilistic flow. This flow-based modeling technique can back-propagate the retention reward towards each recommended item in the user session, and we show that the flow combined with traditional learning-to-rank objectives eventually optimizes a non-discounted cumulative reward for both immediate user feedback and user retention. We verify the effectiveness of our method through both offline empirical studies on two public datasets and online A/B tests in an industrial platform.",
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "authors": [
                {
                    "authorId": "2204700561",
                    "name": "Ziru Liu"
                },
                {
                    "authorId": "2244772979",
                    "name": "Shuchang Liu"
                },
                {
                    "authorId": "2257116892",
                    "name": "Bin Yang"
                },
                {
                    "authorId": "2093481204",
                    "name": "Zhenghai Xue"
                },
                {
                    "authorId": "2244625023",
                    "name": "Qingpeng Cai"
                },
                {
                    "authorId": "2244774353",
                    "name": "Xiangyu Zhao"
                },
                {
                    "authorId": "2298640483",
                    "name": "Zijian Zhang"
                },
                {
                    "authorId": "2258334183",
                    "name": "Lantao Hu"
                },
                {
                    "authorId": "2281741404",
                    "name": "Han Li"
                },
                {
                    "authorId": "2244625137",
                    "name": "Peng Jiang"
                }
            ]
        },
        {
            "paperId": "a8d187fcd203caa2509e6c679015fb62bce428a7",
            "title": "Sequential Recommendation for Optimizing Both Immediate Feedback and Long-term Retention",
            "abstract": "In the landscape of Recommender System (RS) applications, reinforcement learning (RL) has recently emerged as a powerful tool, primarily due to its proficiency in optimizing long-term rewards. Nevertheless, it suffers from instability in the learning process, stemming from the intricate interactions among bootstrapping, off-policy training, and function approximation. Moreover, in multi-reward recommendation scenarios, designing a proper reward setting that reconciles the inner dynamics of various tasks is quite intricate. In response to these challenges, we introduce DT4IER, an advanced decision transformer-based recommendation model that is engineered to not only elevate the effectiveness of recommendations but also to achieve a harmonious balance between immediate user engagement and long-term retention. The DT4IER applies an innovative multi-reward design that adeptly balances short and long-term rewards with user-specific attributes, which serve to enhance the contextual richness of the reward sequence ensuring a more informed and personalized recommendation process. To enhance its predictive capabilities, DT4IER incorporates a high-dimensional encoder, skillfully designed to identify and leverage the intricate interrelations across diverse tasks. Furthermore, we integrate a contrastive learning approach within the action embedding predictions, a strategy that significantly boosts the model's overall performance. Experiments on three real-world datasets demonstrate the effectiveness of DT4IER against state-of-the-art Sequential Recommender Systems (SRSs) and Multi-Task Learning (MTL) models in terms of both prediction accuracy and effectiveness in specific tasks. The source code is accessible online to facilitate replication",
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "authors": [
                {
                    "authorId": "2204700561",
                    "name": "Ziru Liu"
                },
                {
                    "authorId": "2244772979",
                    "name": "Shuchang Liu"
                },
                {
                    "authorId": "2187882131",
                    "name": "Zijian Zhang"
                },
                {
                    "authorId": "2244625023",
                    "name": "Qingpeng Cai"
                },
                {
                    "authorId": "2244774353",
                    "name": "Xiangyu Zhao"
                },
                {
                    "authorId": "2187856386",
                    "name": "Kesen Zhao"
                },
                {
                    "authorId": "2258334183",
                    "name": "Lantao Hu"
                },
                {
                    "authorId": "2244625137",
                    "name": "Peng Jiang"
                },
                {
                    "authorId": "2244624390",
                    "name": "Kun Gai"
                }
            ]
        },
        {
            "paperId": "c497b1de58f9a53338ea3b7507cdc4d0056f48a1",
            "title": "M3oE: Multi-Domain Multi-Task Mixture-of Experts Recommendation Framework",
            "abstract": "Multi-domain recommendation and multi-task recommendation have demonstrated their effectiveness in leveraging common information from different domains and objectives for comprehensive user modeling. Nonetheless, the practical recommendation usually faces multiple domains and tasks simultaneously, which cannot be well-addressed by current methods. To this end, we introduce M3oE, an adaptive Multi-domain Multi-task Mixture-of-Experts recommendation framework. M3oE integrates multi-domain information, maps knowledge across domains and tasks, and optimizes multiple objectives. We leverage three mixture-of-experts modules to learn common, domain-aspect, and task-aspect user preferences respectively to address the complex dependencies among multiple domains and tasks in a disentangled manner. Additionally, we design a two-level fusion mechanism for precise control over feature extraction and fusion across diverse domains and tasks. The framework's adaptability is further enhanced by applying AutoML technique, which allows dynamic structure optimization. To the best of the authors' knowledge, our M3oE is the first effort to solve multi-domain multi-task recommendation self-adaptively. Extensive experiments on two benchmark datasets against diverse baselines demonstrate M3oE's superior performance. The implementation code is available to ensure reproducibility.",
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "authors": [
                {
                    "authorId": "2298640483",
                    "name": "Zijian Zhang"
                },
                {
                    "authorId": "2244772979",
                    "name": "Shuchang Liu"
                },
                {
                    "authorId": "2298904141",
                    "name": "Jiaao Yu"
                },
                {
                    "authorId": "2244625023",
                    "name": "Qingpeng Cai"
                },
                {
                    "authorId": "2244774353",
                    "name": "Xiangyu Zhao"
                },
                {
                    "authorId": "7923634",
                    "name": "Chunxu Zhang"
                },
                {
                    "authorId": "2204700561",
                    "name": "Ziru Liu"
                },
                {
                    "authorId": "2240559309",
                    "name": "Qidong Liu"
                },
                {
                    "authorId": "2244169478",
                    "name": "Hongwei Zhao"
                },
                {
                    "authorId": "2258334183",
                    "name": "Lantao Hu"
                },
                {
                    "authorId": "2244625137",
                    "name": "Peng Jiang"
                },
                {
                    "authorId": "2244624390",
                    "name": "Kun Gai"
                }
            ]
        },
        {
            "paperId": "dc2f4aeb6a5ff87f01a4ed1aa4e8a2ae4f68c310",
            "title": "Diff-MSR: A Diffusion Model Enhanced Paradigm for Cold-Start Multi-Scenario Recommendation",
            "abstract": "With the explosive growth of various commercial scenarios, there is an increasing number of studies on multi-scenario recommendation (MSR) which trains the recommender system with the data from multiple scenarios, aiming to improve the recommendation performance on all these scenarios synchronously. However, due to the large discrepancy in the number of interactions among domains, multi-scenario recommendation models usually suffer from insufficient learning and negative transfer especially on the cold-start scenarios, thus exacerbating the data sparsity issue. To fill this gap, in this work we propose a novel diffusion model enhanced paradigm tailored for the cold-start problem in multi-scenario recommendation in a data-driven generative manner. Specifically, based on all-domain data, we leverage the diffusion model with our newly designed variance schedule and the proposed classifier, which explicitly boosts the recommendation performance on the cold-start scenarios by exploiting the generated high-quality and informative embedding, leveraging the abundance of rich scenarios. Our experiments on Douban and Amazon datasets demonstrate two strengths of the proposed paradigm: (i) its effectiveness with a significant increase of 8.5% and 1% in accuracy on the two datasets, and (ii) its compatibility with various multi-scenario backbone models. The implementation code is available for easy reproduction.",
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "authors": [
                {
                    "authorId": "2223878432",
                    "name": "Yuhao Wang"
                },
                {
                    "authorId": "2204700561",
                    "name": "Ziru Liu"
                },
                {
                    "authorId": "2262403807",
                    "name": "Yichao Wang"
                },
                {
                    "authorId": "2116711669",
                    "name": "Xiangyu Zhao"
                },
                {
                    "authorId": "2258709565",
                    "name": "Bo Chen"
                },
                {
                    "authorId": "3339005",
                    "name": "Huifeng Guo"
                },
                {
                    "authorId": "2240536007",
                    "name": "Ruiming Tang"
                }
            ]
        },
        {
            "paperId": "13cc7cb462d3146cbc35ccb128f66609c788a96a",
            "title": "Multi-Task Recommendations with Reinforcement Learning",
            "abstract": "In recent years, Multi-task Learning (MTL) has yielded immense success in Recommender System (RS) applications [40]. However, current MTL-based recommendation models tend to disregard the session-wise patterns of user-item interactions because they are predominantly constructed based on item-wise datasets. Moreover, balancing multiple objectives has always been a challenge in this field, which is typically avoided via linear estimations in existing works. To address these issues, in this paper, we propose a Reinforcement Learning (RL) enhanced MTL framework, namely RMTL, to combine the losses of different recommendation tasks using dynamic weights. To be specific, the RMTL structure can address the two aforementioned issues by (i) constructing an MTL environment from session-wise interactions and (ii) training multi-task actor-critic network structure, which is compatible with most existing MTL-based recommendation models, and (iii) optimizing and fine-tuning the MTL loss function using the weights generated by critic networks. Experiments on two real-world public datasets demonstrate the effectiveness of RMTL with a higher AUC against state-of-the-art MTL-based recommendation models. Additionally, we evaluate and validate RMTL\u2019s compatibility and transferability across various MTL models.",
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "authors": [
                {
                    "authorId": "2204700561",
                    "name": "Ziru Liu"
                },
                {
                    "authorId": "2204719513",
                    "name": "Jiejie Tian"
                },
                {
                    "authorId": "144994208",
                    "name": "Qingpeng Cai"
                },
                {
                    "authorId": "2116711669",
                    "name": "Xiangyu Zhao"
                },
                {
                    "authorId": "2161309826",
                    "name": "Jingtong Gao"
                },
                {
                    "authorId": "50152132",
                    "name": "Shuchang Liu"
                },
                {
                    "authorId": "2113596993",
                    "name": "Da Chen"
                },
                {
                    "authorId": "2204642544",
                    "name": "Tonghao He"
                },
                {
                    "authorId": "2153430224",
                    "name": "Dong Zheng"
                },
                {
                    "authorId": "2061280682",
                    "name": "Peng Jiang"
                },
                {
                    "authorId": "20029557",
                    "name": "Kun Gai"
                }
            ]
        },
        {
            "paperId": "2807de52310ca3750ccc8dd2636d5ddc6d14a187",
            "title": "KuaiSim: A Comprehensive Simulator for Recommender Systems",
            "abstract": "Reinforcement Learning (RL)-based recommender systems (RSs) have garnered considerable attention due to their ability to learn optimal recommendation policies and maximize long-term user rewards. However, deploying RL models directly in online environments and generating authentic data through A/B tests can pose challenges and require substantial resources. Simulators offer an alternative approach by providing training and evaluation environments for RS models, reducing reliance on real-world data. Existing simulators have shown promising results but also have limitations such as simplified user feedback, lacking consistency with real-world data, the challenge of simulator evaluation, and difficulties in migration and expansion across RSs. To address these challenges, we propose KuaiSim, a comprehensive user environment that provides user feedback with multi-behavior and cross-session responses. The resulting simulator can support three levels of recommendation problems: the request level list-wise recommendation task, the whole-session level sequential recommendation task, and the cross-session level retention optimization task. For each task, KuaiSim also provides evaluation protocols and baseline recommendation algorithms that further serve as benchmarks for future research. We also restructure existing competitive simulators on the KuaiRand Dataset and compare them against KuaiSim to future assess their performance and behavioral differences. Furthermore, to showcase KuaiSim's flexibility in accommodating different datasets, we demonstrate its versatility and robustness when deploying it on the ML-1m dataset.",
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "authors": [
                {
                    "authorId": "2187856386",
                    "name": "Kesen Zhao"
                },
                {
                    "authorId": "2244772979",
                    "name": "Shuchang Liu"
                },
                {
                    "authorId": "2244625023",
                    "name": "Qingpeng Cai"
                },
                {
                    "authorId": "2244774353",
                    "name": "Xiangyu Zhao"
                },
                {
                    "authorId": "2204700561",
                    "name": "Ziru Liu"
                },
                {
                    "authorId": "2153430224",
                    "name": "Dong Zheng"
                },
                {
                    "authorId": "2244625137",
                    "name": "Peng Jiang"
                },
                {
                    "authorId": "2244624390",
                    "name": "Kun Gai"
                }
            ]
        },
        {
            "paperId": "7d948a1f2ab7bffc60fc959b1bb853b5a4d5c819",
            "title": "Learning Empirical Bregman Divergence for Uncertain Distance Representation",
            "abstract": "Deep metric learning techniques have been used for visual representation in various supervised and unsupervised learning tasks through learning embeddings of samples with deep networks. However, classic approaches, which employ a fixed distance metric as a similarity function between two embeddings, may lead to suboptimal performance for capturing the complex data distribution. The Bregman divergence generalizes measures of various distance metrics and arises throughout many fields of deep metric learning. In this paper, we first show how deep metric learning loss can arise from the Bregman divergence. We then introduce a novel method for learning empirical Bregman divergence directly from data based on parameterizing the convex function underlying the Bregman divergence with a deep learning setting. We further experimentally show that our approach performs effectively on five popular public datasets compared to other SOTA deep metric learning methods, particularly for pattern recognition problems.",
            "fieldsOfStudy": [
                "Computer Science",
                "Mathematics"
            ],
            "authors": [
                {
                    "authorId": "2118949132",
                    "name": "Zhiyuan Li"
                },
                {
                    "authorId": "2204700561",
                    "name": "Ziru Liu"
                },
                {
                    "authorId": "2152680230",
                    "name": "An\u2013Min Zou"
                },
                {
                    "authorId": "1952385",
                    "name": "A. Ralescu"
                }
            ]
        },
        {
            "paperId": "941dd711ef05ca159213bb32ea57c268961252e9",
            "title": "Multi-Task Deep Recommender Systems: A Survey",
            "abstract": "Multi-task learning (MTL) aims at learning related tasks in a unified model to achieve mutual improvement among tasks considering their shared knowledge. It is an important topic in recommendation due to the demand for multi-task prediction considering performance and efficiency. Although MTL has been well studied and developed, there is still a lack of systematic review in the recommendation community. To fill the gap, we provide a comprehensive review of existing multi-task deep recommender systems (MTDRS) in this survey. To be specific, the problem definition of MTDRS is first given, and it is compared with other related areas. Next, the development of MTDRS is depicted and the taxonomy is introduced from the task relation and methodology aspects. Specifically, the task relation is categorized into parallel, cascaded, and auxiliary with main, while the methodology is grouped into parameter sharing, optimization, and training mechanism. The survey concludes by summarizing the application and public datasets of MTDRS and highlighting the challenges and future directions of the field.",
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "authors": [
                {
                    "authorId": "2185248657",
                    "name": "Yuhao Wang"
                },
                {
                    "authorId": "3222510",
                    "name": "Ha T. Lam"
                },
                {
                    "authorId": "2150070704",
                    "name": "Y. Wong"
                },
                {
                    "authorId": "2204700561",
                    "name": "Ziru Liu"
                },
                {
                    "authorId": "2116711312",
                    "name": "Xiang Zhao"
                },
                {
                    "authorId": "2116640929",
                    "name": "Yichao Wang"
                },
                {
                    "authorId": "92633145",
                    "name": "Bo Chen"
                },
                {
                    "authorId": "3339005",
                    "name": "Huifeng Guo"
                },
                {
                    "authorId": "2824766",
                    "name": "Ruiming Tang"
                }
            ]
        }
    ]
}