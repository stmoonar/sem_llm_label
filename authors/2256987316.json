{
    "authorId": "2256987316",
    "papers": [
        {
            "paperId": "2c6638f6c817b7dc94365e217138d5b60cc699fa",
            "title": "A Chinese Dataset for Evaluating the Safeguards in Large Language Models",
            "abstract": "Many studies have demonstrated that large language models (LLMs) can produce harmful responses, exposing users to unexpected risks when LLMs are deployed. Previous studies have proposed comprehensive taxonomies of the risks posed by LLMs, as well as corresponding prompts that can be used to examine the safety mechanisms of LLMs. However, the focus has been almost exclusively on English, and little has been explored for other languages. Here we aim to bridge this gap. We first introduce a dataset for the safety evaluation of Chinese LLMs, and then extend it to two other scenarios that can be used to better identify false negative and false positive examples in terms of risky prompt rejections. We further present a set of fine-grained safety assessment criteria for each risk type, facilitating both manual annotation and automatic evaluation in terms of LLM response harmfulness. Our experiments on five LLMs show that region-specific risks are the prevalent type of risk, presenting the major issue with all Chinese LLMs we experimented with. Our data is available at https://github.com/Libr-AI/do-not-answer. Warning: this paper contains example data that may be offensive, harmful, or biased.",
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "authors": [
                {
                    "authorId": "2275119551",
                    "name": "Yuxia Wang"
                },
                {
                    "authorId": "51230252",
                    "name": "Zenan Zhai"
                },
                {
                    "authorId": "49404498",
                    "name": "Haonan Li"
                },
                {
                    "authorId": "2110982198",
                    "name": "Xudong Han"
                },
                {
                    "authorId": "2284823063",
                    "name": "Lizhi Lin"
                },
                {
                    "authorId": "2284691442",
                    "name": "Zhenxuan Zhang"
                },
                {
                    "authorId": "2284725378",
                    "name": "Jingru Zhao"
                },
                {
                    "authorId": "2026545715",
                    "name": "Preslav Nakov"
                },
                {
                    "authorId": "2256987316",
                    "name": "Timothy Baldwin"
                }
            ]
        },
        {
            "paperId": "953b304d0dd3745861f5fa56fd342a2edbd30710",
            "title": "IndoCulture: Exploring Geographically-Influenced Cultural Commonsense Reasoning Across Eleven Indonesian Provinces",
            "abstract": "Although commonsense reasoning is greatly shaped by cultural and geographical factors, previous studies have predominantly centered on cultures grounded in the English language, potentially resulting in an Anglocentric bias. In this paper, we introduce IndoCulture, aimed at understanding the influence of geographical factors on language model reasoning ability, with a specific emphasis on the diverse cultures found within eleven Indonesian provinces. In contrast to prior work that has relied on templates (Yin et al., 2022) and online scrapping (Fung et al., 2024), we create IndoCulture by asking local people to manually develop a cultural context and plausible options, across a set of predefined topics. Evaluation of 27 language models reveals several insights: (1) the open-weight Llama-3 is competitive with GPT-4, while other open-weight models struggle, with accuracies below 50%; (2) there is a general pattern of models generally performing better for some provinces, such as Bali and West Java, and less well for others; and (3) the inclusion of location context enhances performance, especially for larger models like GPT-4, emphasizing the significance of geographical context in commonsense reasoning.",
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "authors": [
                {
                    "authorId": "2789148",
                    "name": "Fajri Koto"
                },
                {
                    "authorId": "1935324",
                    "name": "Rahmad Mahendra"
                },
                {
                    "authorId": "2256987672",
                    "name": "Nurul Aisyah"
                },
                {
                    "authorId": "2256987316",
                    "name": "Timothy Baldwin"
                }
            ]
        },
        {
            "paperId": "9686f718fc9955bfdb6f8ce3e37fe46f57bc123b",
            "title": "Web2Code: A Large-scale Webpage-to-Code Dataset and Evaluation Framework for Multimodal LLMs",
            "abstract": "Multimodal large language models (MLLMs) have shown impressive success across modalities such as image, video, and audio in a variety of understanding and generation tasks. However, current MLLMs are surprisingly poor at understanding webpage screenshots and generating their corresponding HTML code. To address this problem, we propose Web2Code, a benchmark consisting of a new large-scale webpage-to-code dataset for instruction tuning and an evaluation framework for the webpage understanding and HTML code translation abilities of MLLMs. For dataset construction, we leverage pretrained LLMs to enhance existing webpage-to-code datasets as well as generate a diverse pool of new webpages rendered into images. Specifically, the inputs are webpage images and instructions, while the responses are the webpage's HTML code. We further include diverse natural language QA pairs about the webpage content in the responses to enable a more comprehensive understanding of the web content. To evaluate model performance in these tasks, we develop an evaluation framework for testing MLLMs' abilities in webpage understanding and web-to-code generation. Extensive experiments show that our proposed dataset is beneficial not only to our proposed tasks but also in the general visual domain, while previous datasets result in worse performance. We hope our work will contribute to the development of general MLLMs suitable for web-based content generation and task automation. Our data and code will be available at https://github.com/MBZUAI-LLM/web2code.",
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "authors": [
                {
                    "authorId": "2309244234",
                    "name": "Sukmin Yun"
                },
                {
                    "authorId": "2309308754",
                    "name": "Haokun Lin"
                },
                {
                    "authorId": "2267722797",
                    "name": "Rusiru Thushara"
                },
                {
                    "authorId": "2309007033",
                    "name": "Mohammad Qazim Bhat"
                },
                {
                    "authorId": "2309064828",
                    "name": "Yongxin Wang"
                },
                {
                    "authorId": "2293320123",
                    "name": "Zutao Jiang"
                },
                {
                    "authorId": "2146867236",
                    "name": "Mingkai Deng"
                },
                {
                    "authorId": "2309017495",
                    "name": "Jinhong Wang"
                },
                {
                    "authorId": "2242959702",
                    "name": "Tianhua Tao"
                },
                {
                    "authorId": "2254290083",
                    "name": "Junbo Li"
                },
                {
                    "authorId": "2274084215",
                    "name": "Haonan Li"
                },
                {
                    "authorId": "2026545715",
                    "name": "Preslav Nakov"
                },
                {
                    "authorId": "2256987316",
                    "name": "Timothy Baldwin"
                },
                {
                    "authorId": "100468503",
                    "name": "Zhengzhong Liu"
                },
                {
                    "authorId": "2266839099",
                    "name": "Eric P. Xing"
                },
                {
                    "authorId": "2309503120",
                    "name": "Xiaodan Liang"
                },
                {
                    "authorId": "2273778277",
                    "name": "Zhiqiang Shen"
                }
            ]
        },
        {
            "paperId": "9ff25b04f81d21f700deb5b386857840b81a1f23",
            "title": "ArabicMMLU: Assessing Massive Multitask Language Understanding in Arabic",
            "abstract": "The focus of language model evaluation has transitioned towards reasoning and knowledge-intensive tasks, driven by advancements in pretraining large models. While state-of-the-art models are partially trained on large Arabic texts, evaluating their performance in Arabic remains challenging due to the limited availability of relevant datasets. To bridge this gap, we present \\datasetname{}, the first multi-task language understanding benchmark for the Arabic language, sourced from school exams across diverse educational levels in different countries spanning North Africa, the Levant, and the Gulf regions. Our data comprises 40 tasks and 14,575 multiple-choice questions in Modern Standard Arabic (MSA) and is carefully constructed by collaborating with native speakers in the region. Our comprehensive evaluations of 35 models reveal substantial room for improvement, particularly among the best open-source models. Notably, BLOOMZ, mT0, LLaMA2, and Falcon struggle to achieve a score of 50%, while even the top-performing Arabic-centric model only achieves a score of 62.3%.",
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "authors": [
                {
                    "authorId": "2789148",
                    "name": "Fajri Koto"
                },
                {
                    "authorId": "2274084215",
                    "name": "Haonan Li"
                },
                {
                    "authorId": "2210193043",
                    "name": "Sara Shatnawi"
                },
                {
                    "authorId": "1724523030",
                    "name": "Jad Doughman"
                },
                {
                    "authorId": "2233498337",
                    "name": "Abdelrahman Boda Sadallah"
                },
                {
                    "authorId": "2284767001",
                    "name": "Aisha Alraeesi"
                },
                {
                    "authorId": "2284765679",
                    "name": "Khalid Almubarak"
                },
                {
                    "authorId": "25098419",
                    "name": "Zaid Alyafeai"
                },
                {
                    "authorId": "2284771123",
                    "name": "Neha Sengupta"
                },
                {
                    "authorId": "38510157",
                    "name": "Shady Shehata"
                },
                {
                    "authorId": "2257292541",
                    "name": "Nizar Habash"
                },
                {
                    "authorId": "2026545715",
                    "name": "Preslav Nakov"
                },
                {
                    "authorId": "2256987316",
                    "name": "Timothy Baldwin"
                }
            ]
        },
        {
            "paperId": "b156cdef9e685be5e8aa4a5ab45eb8a5b25ee167",
            "title": "Learning From Failure: Integrating Negative Examples when Fine-tuning Large Language Models as Agents",
            "abstract": "Large language models (LLMs) have achieved success in acting as agents, which interact with environments through tools such as search engines. However, LLMs are optimized for language generation instead of tool use during training or alignment, limiting their effectiveness as agents. To resolve this problem, previous work has first collected interaction trajectories between LLMs and environments, using only trajectories that successfully finished the task to fine-tune smaller models, making fine-tuning data scarce and acquiring it both difficult and costly. Discarding failed trajectories also leads to significant wastage of data and resources and limits the possible optimization paths during fine-tuning. In this paper, we argue that unsuccessful trajectories offer valuable insights, and LLMs can learn from these trajectories through appropriate quality control and fine-tuning strategies. By simply adding a prefix or suffix that tells the model whether to generate a successful trajectory during training, we improve model performance by a large margin on mathematical reasoning, multi-hop question answering, and strategic question answering tasks. We further analyze the inference results and find that our method provides a better trade-off between valuable information and errors in unsuccessful trajectories. To our knowledge, we are the first to demonstrate the value of negative trajectories and their application in agent-tunning scenarios. Our findings offer guidance for developing better agent-tuning methods and low-resource data usage techniques.",
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "authors": [
                {
                    "authorId": "2215688800",
                    "name": "Renxi Wang"
                },
                {
                    "authorId": "49404498",
                    "name": "Haonan Li"
                },
                {
                    "authorId": "2110982198",
                    "name": "Xudong Han"
                },
                {
                    "authorId": "2266000475",
                    "name": "Yixuan Zhang"
                },
                {
                    "authorId": "2256987316",
                    "name": "Timothy Baldwin"
                }
            ]
        },
        {
            "paperId": "b6aca622200ad7f722c667058d1dd664946d241b",
            "title": "ToolGen: Unified Tool Retrieval and Calling via Generation",
            "abstract": "As large language models (LLMs) advance, their inability to autonomously execute tasks by directly interacting with external tools remains a critical limitation. Traditional methods rely on inputting tool descriptions as context, which is constrained by context length and requires separate, often inefficient, retrieval mechanisms. We introduce ToolGen, a paradigm shift that integrates tool knowledge directly into the LLM's parameters by representing each tool as a unique token. This enables the LLM to generate tool calls and arguments as part of its next token prediction capabilities, seamlessly blending tool invocation with language generation. Our framework allows the LLM to access and utilize a vast amount of tools with no additional retrieval step, significantly enhancing both performance and scalability. Experimental results with over 47,000 tools show that ToolGen not only achieves superior results in both tool retrieval and autonomous task completion but also sets the stage for a new era of AI agents that can adapt to tools across diverse domains. By fundamentally transforming tool retrieval into a generative process, ToolGen paves the way for more versatile, efficient, and autonomous AI systems. ToolGen enables end-to-end tool learning and opens opportunities for integration with other advanced techniques such as chain-of-thought and reinforcement learning, thereby expanding the practical capabilities of LLMs.",
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "authors": [
                {
                    "authorId": "2215688800",
                    "name": "Renxi Wang"
                },
                {
                    "authorId": "2110982198",
                    "name": "Xudong Han"
                },
                {
                    "authorId": "2324845118",
                    "name": "Lei Ji"
                },
                {
                    "authorId": "2324674179",
                    "name": "Shu Wang"
                },
                {
                    "authorId": "2256987316",
                    "name": "Timothy Baldwin"
                },
                {
                    "authorId": null,
                    "name": "Haonan Li"
                }
            ]
        },
        {
            "paperId": "bf53b1f16b364704bcfc633b3f531450551aa45d",
            "title": "Location Aware Modular Biencoder for Tourism Question Answering",
            "abstract": "Answering real-world tourism questions that seek Point-of-Interest (POI) recommendations is challenging, as it requires both spatial and non-spatial reasoning, over a large candidate pool. The traditional method of encoding each pair of question and POI becomes inefficient when the number of candidates increases, making it infeasible for real-world applications. To overcome this, we propose treating the QA task as a dense vector retrieval problem, where we encode questions and POIs separately and retrieve the most relevant POIs for a question by utilizing embedding space similarity. We use pretrained language models (PLMs) to encode textual information, and train a location encoder to capture spatial information of POIs. Experiments on a real-world tourism QA dataset demonstrate that our approach is effective, efficient, and outperforms previous methods across all metrics. Enabled by the dense retrieval architecture, we further build a global evaluation baseline, expanding the search space by 20 times compared to previous work. We also explore several factors that impact on the model's performance through follow-up experiments. Our code and model are publicly available at https://github.com/haonan-li/LAMB.",
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "authors": [
                {
                    "authorId": "49404498",
                    "name": "Haonan Li"
                },
                {
                    "authorId": "2277740513",
                    "name": "Martin Tomko"
                },
                {
                    "authorId": "2256987316",
                    "name": "Timothy Baldwin"
                }
            ]
        },
        {
            "paperId": "d22e336171c7ac92167f9b03b0e660af922069b4",
            "title": "Zero-shot Sentiment Analysis in Low-Resource Languages Using a Multilingual Sentiment Lexicon",
            "abstract": "Improving multilingual language models capabilities in low-resource languages is generally difficult due to the scarcity of large-scale data in those languages. In this paper, we relax the reliance on texts in low-resource languages by using multilingual lexicons in pretraining to enhance multilingual capabilities. Specifically, we focus on zero-shot sentiment analysis tasks across 34 languages, including 6 high/medium-resource languages, 25 low-resource languages, and 3 code-switching datasets. We demonstrate that pretraining using multilingual lexicons, without using any sentence-level sentiment data, achieves superior zero-shot performance compared to models fine-tuned on English sentiment datasets, and large language models like GPT\u20133.5, BLOOMZ, and XGLM. These findings are observable for unseen low-resource languages to code-mixed scenarios involving high-resource languages.",
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "authors": [
                {
                    "authorId": "2789148",
                    "name": "Fajri Koto"
                },
                {
                    "authorId": "2282538967",
                    "name": "Tilman Beck"
                },
                {
                    "authorId": "2138053020",
                    "name": "Zeerak Talat"
                },
                {
                    "authorId": "69033154",
                    "name": "Iryna Gurevych"
                },
                {
                    "authorId": "2256987316",
                    "name": "Timothy Baldwin"
                }
            ]
        },
        {
            "paperId": "ed24b6814946c1975b0d86736055fa528b6419c0",
            "title": "Against The Achilles' Heel: A Survey on Red Teaming for Generative Models",
            "abstract": "Generative models are rapidly gaining popularity and being integrated into everyday applications, raising concerns over their safety issues as various vulnerabilities are exposed. Faced with the problem, the field of red teaming is experiencing fast-paced growth, which highlights the need for a comprehensive organization covering the entire pipeline and addressing emerging topics for the community. Our extensive survey, which examines over 120 papers, introduces a taxonomy of fine-grained attack strategies grounded in the inherent capabilities of language models. Additionally, we have developed the searcher framework that unifies various automatic red teaming approaches. Moreover, our survey covers novel areas including multimodal attacks and defenses, risks around multilingual models, overkill of harmless queries, and safety of downstream applications. We hope this survey can provide a systematic perspective on the field and unlock new areas of research.",
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "authors": [
                {
                    "authorId": "2284823063",
                    "name": "Lizhi Lin"
                },
                {
                    "authorId": "2292039878",
                    "name": "Honglin Mu"
                },
                {
                    "authorId": "51230252",
                    "name": "Zenan Zhai"
                },
                {
                    "authorId": "2242189619",
                    "name": "Minghan Wang"
                },
                {
                    "authorId": "2275119551",
                    "name": "Yuxia Wang"
                },
                {
                    "authorId": "2215688800",
                    "name": "Renxi Wang"
                },
                {
                    "authorId": "2294509423",
                    "name": "Junjie Gao"
                },
                {
                    "authorId": "2266000475",
                    "name": "Yixuan Zhang"
                },
                {
                    "authorId": "2292032004",
                    "name": "Wanxiang Che"
                },
                {
                    "authorId": "2256987316",
                    "name": "Timothy Baldwin"
                },
                {
                    "authorId": "2110982198",
                    "name": "Xudong Han"
                },
                {
                    "authorId": "2266086775",
                    "name": "Haonan Li"
                }
            ]
        },
        {
            "paperId": "f68a7f40d755e87aa076df8ab74669e1c7cfdce3",
            "title": "Loki: An Open-Source Tool for Fact Verification",
            "abstract": "We introduce Loki, an open-source tool designed to address the growing problem of misinformation. Loki adopts a human-centered approach, striking a balance between the quality of fact-checking and the cost of human involvement. It decomposes the fact-checking task into a five-step pipeline: breaking down long texts into individual claims, assessing their check-worthiness, generating queries, retrieving evidence, and verifying the claims. Instead of fully automating the claim verification process, Loki provides essential information at each step to assist human judgment, especially for general users such as journalists and content moderators. Moreover, it has been optimized for latency, robustness, and cost efficiency at a commercially usable level. Loki is released under an MIT license and is available on GitHub. We also provide a video presenting the system and its capabilities.",
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "authors": [
                {
                    "authorId": "2274084215",
                    "name": "Haonan Li"
                },
                {
                    "authorId": "2289460054",
                    "name": "Xudong Han"
                },
                {
                    "authorId": "2324499769",
                    "name": "Hao Wang"
                },
                {
                    "authorId": "2275119551",
                    "name": "Yuxia Wang"
                },
                {
                    "authorId": "2242189619",
                    "name": "Minghan Wang"
                },
                {
                    "authorId": "2323789608",
                    "name": "Rui Xing"
                },
                {
                    "authorId": "2323788235",
                    "name": "Yilin Geng"
                },
                {
                    "authorId": "51230252",
                    "name": "Zenan Zhai"
                },
                {
                    "authorId": "2026545715",
                    "name": "Preslav Nakov"
                },
                {
                    "authorId": "2256987316",
                    "name": "Timothy Baldwin"
                }
            ]
        }
    ]
}