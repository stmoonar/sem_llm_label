{
    "authorId": "1664776313",
    "papers": [
        {
            "paperId": "28f27fa8df45052bd5a5e99fb1cce162c2fe857e",
            "title": "Matching Game for Multi-Task Federated Learning in Internet of Vehicles",
            "abstract": "To overcome the inherent defects of massive data uploading and processing in traditional machine learning, federated learning is emerged as a promising tool given that it enables to implement privacy-preserved distributed machine learning in Internet of Vehicles (IoV). However, the performance of federated learning suffers from several challenges, especially ineffective execution of delay-sensitive tasks triggered simultaneously by moving vehicles. To minimize the total execution delay of multiple tasks, we propose a multi-task federated learning framework which improves task completion rate and enables each task to be completed in time. Moreover, we also aim to improve the network utility of the IoV. The algorithm of joint optimization algorithm is proposed to achieve a stable partition of vehicle coalitions based on the block coordinate descent (BCD) method, the matching game-based coalition method, and gradient projection method. The performance of the proposed multi-task federated learning is evaluated through numerical simulations in terms of total latency, network utility, and accuracy of federated learning tasks. The results show that our proposed multi-task federated learning framework and algorithm guarantees the completion of multiple delay-sensitive tasks effectively while improving vehicular network utility.",
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "authors": [
                {
                    "authorId": "2109964925",
                    "name": "Zejun Li"
                },
                {
                    "authorId": "1664776313",
                    "name": "Hao Wu"
                },
                {
                    "authorId": "50028927",
                    "name": "Yunlong Lu"
                },
                {
                    "authorId": "2238040948",
                    "name": "Bo Ai"
                },
                {
                    "authorId": "143697813",
                    "name": "Z. Zhong"
                },
                {
                    "authorId": "2152819646",
                    "name": "Yan Zhang"
                }
            ]
        },
        {
            "paperId": "7f14bacd61a92c03f28d15259fd3720fdc3616a9",
            "title": "Dynamic Inference via Localizing Semantic Intervals in Sensor Data for Budget-Tunable Activity Recognition",
            "abstract": "During recent years, deep convolutional neural networks have demonstrated dominant performance in human activity recognition (HAR) using wearable sensors. However, they often come at high computational cost when fueled with fixed-length sliding window. This article primarily aims to accelerate activity inference from a novel perspective of reducing temporal redundancy in sensor data. Inspired by the fact that not all time intervals within a window are activity-relevant, we formulate the activity prediction problem as a dynamic inference process by continuously attending to a sequence of small activity-discriminative intervals, which are selected from an original window by progressively predicting the discriminative importance of each interval with an interpretable interval proposal network. The dynamic process can adaptively decide when to halt for each individual sample, which considerably avoids excessive computation by letting \u201ceasy\u201d activity exit as early as possible while progressively focusing on small salient intervals for \u201chard\u201d activity. Given a limited budget, the accuracy-cost tradeoff can be flexibly and precisely controlled via tuning confidence thresholds online without requiring to be retrained from scratch\u2014a practical requirement in real-world HAR applications. Extensive experiments on several standard benchmarks including University of California-Irvine-Human Activity Recognition (UCI-HAR), wireless sensor data mining (WISDM), University of Southern California-Human Activity Dataset (USC-HAD), and Weakly Labeled dataset demonstrate that our dynamic inference process significantly outperforms previous static methods according to theoretical and practical computational efficiency.",
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "authors": [
                {
                    "authorId": "2215760535",
                    "name": "Can Bu"
                },
                {
                    "authorId": "2152830323",
                    "name": "Lei Zhang"
                },
                {
                    "authorId": "2248217888",
                    "name": "Hengtao Cui"
                },
                {
                    "authorId": "2249112000",
                    "name": "Guangyu Yang"
                },
                {
                    "authorId": "1664776313",
                    "name": "Hao Wu"
                }
            ]
        },
        {
            "paperId": "ecc4c7c8a22b70ce9e7f8c60023e1617f5a2b7e5",
            "title": "A Collaborative Compression Scheme for Fast Activity Recognition on Mobile Devices via Global Compression Ratio Decision",
            "abstract": "Despite strong representation ability, deep convolutional neural networks (CNNs) are largely hindered in practical human activity recognition (HAR) deployment due to high computational cost, which is often unaffordable on resource-limited wearable devices. In this article, to bridge the gap between on-device HAR and deep learning, we present a collaborative compression scheme to reduce the runtime of HAR with an acceptable performance degradation, which combines channel pruning and tensor decomposition to simultaneously handle sparsity and low-rankness when fully considering mutual interference in one network consisting of efficient 1-dimensional convolutional kernels. Our method includes two main stages. Concretely, given a target compression ratio, a global compression ratio decision optimization is first performed to automatically decide per-layer compression ratio by measuring compression sensitivity, without requiring labor-exhaustive human intervention. Then a multi-step collaborative compression is iteratively implemented to remove the least important compression unit based on an improved importance metric until the per-layer target compression ratio is attained. Extensive experiments on multiple HAR benchmarks show that our approach considerably outperforms previous compression strategies. For example, it can achieve around 50% FLOPs reduction with only an accuracy drop of 0.25% and 0.15% on UCI-HAR and PAMAP2, respectively. Actual implementation is evaluated on an embedded platform.",
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "authors": [
                {
                    "authorId": "2046928315",
                    "name": "Junjie Liang"
                },
                {
                    "authorId": "2152830323",
                    "name": "Lei Zhang"
                },
                {
                    "authorId": "2154406938",
                    "name": "Chaolei Han"
                },
                {
                    "authorId": "2215760535",
                    "name": "Can Bu"
                },
                {
                    "authorId": "1664776313",
                    "name": "Hao Wu"
                },
                {
                    "authorId": "2119319577",
                    "name": "Aiguo Song"
                }
            ]
        },
        {
            "paperId": "f5a41bfe44e68997798aae6870b304896eaf3f33",
            "title": "An Ordered Submodularity-Based Budget-Feasible Mechanism for Opportunistic Mobile Crowdsensing Task Allocation and Pricing",
            "abstract": "Mobile crowdsensing services are divided into two categories: opportunistic and participatory. In opportunistic mobile crowdsensing services, users do not need to specify the crowdsensing tasks to be completed. Compared with participatory crowdsensing services, the application scope is wider and more user-friendly. In participatory crowdsensing, the service provider assumes that the user can successfully complete the data collection task. However, such an approach cannot work in an opportunistic crowdsensing service because in opportunistic crowdsensing, the user\u2019s execution of the task is uncertain, which brings great challenges to the quality of the crowdsensing service. This article is based on the assumption of the user coverage probability model and transforms the opportunistic mobile crowdsensing value maximization problem into an ordered submodularity value function model with budget constraints. This model is also good at representing participatory crowdsourcing problems. To the best of our knowledge, this is the first study to apply the ordered submodularity feature to a mobile crowdsensing service. Furthermore, we combine the properties of ordered submodular and auction models and propose an ordered submodularity-proportional share mechanism (O-PSM) to solve the allocation and payment problems in opportunistic mobile crowdsensing services. Specifically, in the allocation stage, the winning users are selected based on the proportional share threshold, and in the payment stage, the payment price for the winning users is designed based on critical value theory. We prove that the mechanism satisfies the economic characteristics of individual rationality, truthfulness, and budget feasibility. In the experimental section, the mechanism design based on ordered submodularity is shown to enable the service provider to obtain a higher value and a lower payment.",
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "authors": [
                {
                    "authorId": "2108115697",
                    "name": "Jixian Zhang"
                },
                {
                    "authorId": "39509574",
                    "name": "Yan Zhang"
                },
                {
                    "authorId": "1664776313",
                    "name": "Hao Wu"
                },
                {
                    "authorId": "2154983699",
                    "name": "Weidong Li"
                }
            ]
        },
        {
            "paperId": "0244dd4ce41b7a1ad441185e0a2f48433e976cfc",
            "title": "ChatGPT or Grammarly? Evaluating ChatGPT on Grammatical Error Correction Benchmark",
            "abstract": "ChatGPT is a cutting-edge artificial intelligence language model developed by OpenAI, which has attracted a lot of attention due to its surprisingly strong ability in answering follow-up questions. In this report, we aim to evaluate ChatGPT on the Grammatical Error Correction(GEC) task, and compare it with commercial GEC product (e.g., Grammarly) and state-of-the-art models (e.g., GECToR). By testing on the CoNLL2014 benchmark dataset, we find that ChatGPT performs not as well as those baselines in terms of the automatic evaluation metrics (e.g., $F_{0.5}$ score), particularly on long sentences. We inspect the outputs and find that ChatGPT goes beyond one-by-one corrections. Specifically, it prefers to change the surface expression of certain phrases or sentence structure while maintaining grammatical correctness. Human evaluation quantitatively confirms this and suggests that ChatGPT produces less under-correction or mis-correction issues but more over-corrections. These results demonstrate that ChatGPT is severely under-estimated by the automatic evaluation metrics and could be a promising tool for GEC.",
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "authors": [
                {
                    "authorId": "1664776313",
                    "name": "Hao Wu"
                },
                {
                    "authorId": "2144328160",
                    "name": "Wenxuan Wang"
                },
                {
                    "authorId": "2167583580",
                    "name": "Yuxuan Wan"
                },
                {
                    "authorId": "12386833",
                    "name": "Wenxiang Jiao"
                },
                {
                    "authorId": "2146840128",
                    "name": "Michael R. Lyu"
                }
            ]
        },
        {
            "paperId": "0a769757e3df414f6c4843d704812faaf3f1ed97",
            "title": "Channel-Equalization-HAR: A Light-weight Convolutional Neural Network for Wearable Sensor Based Human Activity Recognition",
            "abstract": "Recently, human activity recognition (HAR) that uses wearable sensors has become a research hotspot due to its wide applications in a large variety of real-world scenarios including fitness, health-care, and sports tracking. In essence, HAR can be treated as multi-channel time series classification problem, where different channels may come from heterogeneous sensor modalities. Deep learning, especially convolutional neural networks (CNNs) have made major breakthroughs in ubiquitous HAR computing scenario. Various normalization methods have played an indispensable role in prior HAR works, which enable every layer of the network to do learning more independently by normalizing hybrid sensor features. However, normalization tends to produce a \u2018channel collapse\u2019 phenomenon, where a large fraction of channels only generates very small values. Most channels are inhibited and contribute very little to activity recognition. As a result, the network has to rely on only a few valid channels, which inevitably impair the generality ability of a network. In this paper, we provide an alternative called Channel Equalization to reactivate these inhibited channels by performing whitening or decorrelation operation, which compels all channels to contribute more or less to feature representation. Experiments conducted on several benchmarks including UCI-HAR, OPPORTUNITY, UniMiB-SHAR, WISDM, PAMAP2, and USC-HAD show that the proposed Channel Equalization module is an impressive alternative of convolution layers, and achieve higher recognition performance to baseline models with simliar computational cost, which significantly surpasses recent state-of-the-arts for activity recongition. To the best of our knowledge, the Channel Equalization is for the first time to be applied in multi-modal HAR scenario. Finally, the actual operation is evaluated on an embedded Raspberry Pi Model 3 B plus platform.",
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "authors": [
                {
                    "authorId": "2158104269",
                    "name": "Wenbo Huang"
                },
                {
                    "authorId": "2152836514",
                    "name": "Lei Zhang"
                },
                {
                    "authorId": "1664776313",
                    "name": "Hao Wu"
                },
                {
                    "authorId": "2059245581",
                    "name": "Fuhong Min"
                },
                {
                    "authorId": "2119319577",
                    "name": "Aiguo Song"
                }
            ]
        },
        {
            "paperId": "0dacf3ed73121450f18c410f311b33b6cf66e758",
            "title": "Fairness-aware Guaranteed Display Advertising Allocation under Traffic Cost Constraint",
            "abstract": "Real-time Bidding (RTB) and Guaranteed Display (GD) advertising are two primary ways to sell impressions for publishers in online display advertising. Although GD contract serves less efficiently compared to RTB ads, it helps advertisers reach numerous target audiences at a lower cost and allows publishers to increase overall advertising revenue. However, with billion-scale requests online per day, it\u2019s a challenging problem for publishers to decide whether and which GD ad to display for each impression. In this paper, we propose an optimal allocation model for GD contracts considering optimizing three objectives: maximizing guaranteed delivery and impressions\u2019 quality and minimizing the extra traffic cost of GD contracts to increase overall revenue. The traffic cost of GD contracts is defined as the potential expected revenue if the impression is allocated to RTB ads. Our model dynamically adjusts the weights for each GD contract between impressions\u2019 quality and traffic cost based on real-time performance, which produces fairness-aware allocation results. A parallel training framework based on Parameter-Server (PS) architecture is utilized to efficiently and periodically update the model. Deriving from the allocation model, we also propose a simple and adaptive online bidding strategy for GD contracts, which can be updated quickly by feedback-based algorithms to achieve optimal impression allocation even in complex and dynamic environments. We demonstrate the effectiveness of our proposed method by using both offline evaluation and online A/B testing.",
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "authors": [
                {
                    "authorId": "15997479",
                    "name": "Liang Dai"
                },
                {
                    "authorId": "2133191248",
                    "name": "Zhonglin Zu"
                },
                {
                    "authorId": "1664776313",
                    "name": "Hao Wu"
                },
                {
                    "authorId": "2144691567",
                    "name": "Liang Wang"
                },
                {
                    "authorId": "145646411",
                    "name": "Bo Zheng"
                }
            ]
        },
        {
            "paperId": "15e61063ddefcbe46d1ad5a1f4ce2e4a55e1a2ec",
            "title": "A Simple Framework for Text-Supervised Semantic Segmentation",
            "abstract": "Text-supervised semantic segmentation is a novel research topic that allows semantic segments to emerge with image-text contrasting. However, pioneering methods could be subject to specifically designed network architectures. This paper shows that a vanilla contrastive language-image pretraining (CLIP) model is an effective text-supervised semantic segmentor by itself. First, we reveal that a vanilla CLIP is inferior to localization and segmentation due to its optimization being driven by densely aligning visual and language representations. Second, we propose the locality-driven alignment (LoDA) to address the problem, where CLIP optimization is driven by sparsely aligning local representations. Third, we propose a simple segmentation (SimSeg) framework. LoDA and SimSeg jointly amelio-rate a vanilla CLIP to produce impressive semantic segmentation results. Our method outperforms previous state-of-the-art methods on PASCAL VOC 2012, PASCAL Context and COCO datasets by large margins. Code and models are available at github.com/muyangyi/SimSeg.",
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "authors": [
                {
                    "authorId": "1897822614",
                    "name": "Muyang Yi"
                },
                {
                    "authorId": "144802953",
                    "name": "Quan Cui"
                },
                {
                    "authorId": "1664776313",
                    "name": "Hao Wu"
                },
                {
                    "authorId": "2154172861",
                    "name": "Cheng Yang"
                },
                {
                    "authorId": "1409223773",
                    "name": "O. Yoshie"
                },
                {
                    "authorId": "2115864460",
                    "name": "Hongtao Lu"
                }
            ]
        },
        {
            "paperId": "27be451186b3a1b0367591e5aa328eb9065e4e1f",
            "title": "A Closer Look at Few-shot Classification Again",
            "abstract": "Few-shot classification consists of a training phase where a model is learned on a relatively large dataset and an adaptation phase where the learned model is adapted to previously-unseen tasks with limited labeled samples. In this paper, we empirically prove that the training algorithm and the adaptation algorithm can be completely disentangled, which allows algorithm analysis and design to be done individually for each phase. Our meta-analysis for each phase reveals several interesting insights that may help better understand key aspects of few-shot classification and connections with other fields such as visual representation learning and transfer learning. We hope the insights and research challenges revealed in this paper can inspire future work in related directions. Code and pre-trained models (in PyTorch) are available at https://github.com/Frankluox/CloserLookAgainFewShot.",
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "authors": [
                {
                    "authorId": "2115611493",
                    "name": "Xu Luo"
                },
                {
                    "authorId": "1664776313",
                    "name": "Hao Wu"
                },
                {
                    "authorId": "2116921931",
                    "name": "Ji Zhang"
                },
                {
                    "authorId": "2671321",
                    "name": "Lianli Gao"
                },
                {
                    "authorId": "2212230799",
                    "name": "Jing Xu"
                },
                {
                    "authorId": "2346105",
                    "name": "Jingkuan Song"
                }
            ]
        },
        {
            "paperId": "2ddd19d350f218b7fc08e98185030cdec1c945fa",
            "title": "DiST-GAN: Distillation-based Semantic Transfer for Text-Guided Face Generation",
            "abstract": "Recently, large-scale pre-training has achieved great success in multi-modal tasks and shown powerful generalization ability due to superior semantic comprehension. In the field of text-to-image synthesis, recent works induce large-scale pre-training with VQ-VAE as a discrete visual tokenizer, which can synthesize realistic images from arbitrary text inputs. However, the quality of images generated by these methods is still inferior to that of images generated by GAN-based methods, especially in some specific domains. To leverage both the superior semantic comprehension of large-scale pre-training models and the powerful ability of GAN-based models in photorealistic image generation, we propose a novel knowledge distillation framework termed DiST-GAN to transfer the semantic knowledge of large-scale visual-language pre-training models (e.g., CLIP) to GAN-based generator for text-guided face image generation. Our DiST-GAN consists of two key components: (1) A new CLIP-based adaptive contrastive loss is devised to ensure the generated images are consistent with the input texts. (2) A language-to-vision (L2V) transformation module is learned to transform token embeddings of each text into an intermediate embedding that is aligned with the image embedding extracted by CLIP. With these two novel components, the semantic knowledge contained in CLIP can thus be transferred to GAN-based generator which preserves the superior ability of photorealistic image generation in the mean time. Extensive results on the Multi-Modal CelebA-HQ dataset show that our DiST-GAN achieves significant improvements over the state-of-the-arts.",
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "authors": [
                {
                    "authorId": "2109946595",
                    "name": "Guoxing Yang"
                },
                {
                    "authorId": "2053417915",
                    "name": "Feifei Fu"
                },
                {
                    "authorId": "21313225",
                    "name": "Nanyi Fei"
                },
                {
                    "authorId": "1664776313",
                    "name": "Hao Wu"
                },
                {
                    "authorId": "2234008783",
                    "name": "Ruitao Ma"
                },
                {
                    "authorId": "1776220",
                    "name": "Zhiwu Lu"
                }
            ]
        }
    ]
}