{
    "authorId": "2953855",
    "papers": [
        {
            "paperId": "16eab6b9ce5a6ab10520563500985e15c596052d",
            "title": "The Generalized Eigenvalue Problem as a Nash Equilibrium",
            "abstract": "The generalized eigenvalue problem (GEP) is a fundamental concept in numerical linear algebra. It captures the solution of many classical machine learning problems such as canonical correlation analysis, independent components analysis, partial least squares, linear discriminant analysis, principal components, successor features and others. Despite this, most general solvers are prohibitively expensive when dealing with massive data sets and research has instead concentrated on \ufb01nding e\ufb03cient solutions to speci\ufb01c problem instances. In this work, we develop a game-theoretic formulation of the top-k GEP whose Nash equilibrium is the set of generalized eigenvectors. We also present a parallelizable algorithm with guaranteed asymptotic convergence to the Nash. Current state-of-the-art methods require O ( d 2 k ) complexity per iteration which is prohibitively expensive when the number of dimensions ( d ) is large. We show how to achieve O ( dk ) complexity, scaling to datasets 100 \u00d7 larger than those evaluated by prior methods. Empirically we demonstrate that our algorithm is able to solve a variety of GEP problem instances including a large-scale analysis of neural network activations.",
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "authors": [
                {
                    "authorId": "8616871",
                    "name": "I. Gemp"
                },
                {
                    "authorId": "50994378",
                    "name": "Chen Chen"
                },
                {
                    "authorId": "2953855",
                    "name": "B. McWilliams"
                }
            ]
        },
        {
            "paperId": "6044fade70d6d8dc53a6f2c8bb0d9b157b4cfe25",
            "title": "Pushing the limits of self-supervised ResNets: Can we outperform supervised learning without labels on ImageNet?",
            "abstract": "Despite recent progress made by self-supervised methods in representation learning with residual networks, they still underperform supervised learning on the ImageNet classification benchmark, limiting their applicability in performance-critical settings. Building on prior theoretical insights from ReLIC [Mitrovic et al., 2021], we include additional inductive biases into self-supervised learning. We propose a new self-supervised representation learning method, ReLICv2, which combines an explicit invariance loss with a contrastive objective over a varied set of appropriately constructed data views to avoid learning spurious correlations and obtain more informative representations. ReLICv2 achieves $77.1\\%$ top-$1$ accuracy on ImageNet under linear evaluation on a ResNet50, thus improving the previous state-of-the-art by absolute $+1.5\\%$; on larger ResNet models, ReLICv2 achieves up to $80.6\\%$ outperforming previous self-supervised approaches with margins up to $+2.3\\%$. Most notably, ReLICv2 is the first unsupervised representation learning method to consistently outperform the supervised baseline in a like-for-like comparison over a range of ResNet architectures. Using ReLICv2, we also learn more robust and transferable representations that generalize better out-of-distribution than previous work, both on image classification and semantic segmentation. Finally, we show that despite using ResNet encoders, ReLICv2 is comparable to state-of-the-art self-supervised vision transformers.",
            "fieldsOfStudy": [
                "Computer Science",
                "Mathematics"
            ],
            "authors": [
                {
                    "authorId": "2213266",
                    "name": "Nenad Toma\u0161ev"
                },
                {
                    "authorId": "39965049",
                    "name": "Ioana Bica"
                },
                {
                    "authorId": "2953855",
                    "name": "B. McWilliams"
                },
                {
                    "authorId": "1981334",
                    "name": "Lars Buesing"
                },
                {
                    "authorId": "1996134",
                    "name": "Razvan Pascanu"
                },
                {
                    "authorId": "1723876",
                    "name": "C. Blundell"
                },
                {
                    "authorId": "37955812",
                    "name": "Jovana Mitrovic"
                }
            ]
        },
        {
            "paperId": "63f11a67a80a6795f7c3ce18d2761a3f42faac1e",
            "title": "The Symmetric Generalized Eigenvalue Problem as a Nash Equilibrium",
            "abstract": "The symmetric generalized eigenvalue problem (SGEP) is a fundamental concept in numerical linear algebra. It captures the solution of many classical machine learning problems such as canonical correlation analysis, independent components analysis, partial least squares, linear discriminant analysis, principal components and others. Despite this, most general solvers are prohibitively expensive when dealing with streaming data sets (i.e., minibatches) and research has instead concentrated on finding efficient solutions to specific problem instances. In this work, we develop a game-theoretic formulation of the top-$k$ SGEP whose Nash equilibrium is the set of generalized eigenvectors. We also present a parallelizable algorithm with guaranteed asymptotic convergence to the Nash. Current state-of-the-art methods require $O(d^2k)$ runtime complexity per iteration which is prohibitively expensive when the number of dimensions ($d$) is large. We show how to modify this parallel approach to achieve $O(dk)$ runtime complexity. Empirically we demonstrate that this resulting algorithm is able to solve a variety of SGEP problem instances including a large-scale analysis of neural network activations.",
            "fieldsOfStudy": [
                "Computer Science",
                "Mathematics"
            ],
            "authors": [
                {
                    "authorId": "8616871",
                    "name": "I. Gemp"
                },
                {
                    "authorId": "50994378",
                    "name": "Chen Chen"
                },
                {
                    "authorId": "2953855",
                    "name": "B. McWilliams"
                }
            ]
        },
        {
            "paperId": "f5888d776f122f53292973bd3693628ebd265bc6",
            "title": "TwHIN-BERT: A Socially-Enriched Pre-trained Language Model for Multilingual Tweet Representations at Twitter",
            "abstract": "Pre-trained language models (PLMs) are fundamental for natural language processing applications. Most existing PLMs are not tailored to the noisy user-generated text on social media, and the pre-training does not factor in the valuable social engagement logs available in a social network. We present TwHIN-BERT, a multilingual language model productionized at Twitter, trained on in-domain data from the popular social network. TwHIN-BERT differs from prior pre-trained language models as it is trained with not only text-based self-supervision but also with a social objective based on the rich social engagements within a Twitter heterogeneous information network (TwHIN). Our model is trained on 7 billion tweets covering over 100 distinct languages, providing a valuable representation to model short, noisy, user-generated text. We evaluate our model on various multilingual social recommendation and semantic understanding tasks and demonstrate significant metric improvement over established pre-trained language models. We open-source TwHIN-BERT and our curated hashtag prediction and social engagement benchmark datasets to the research community.",
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "authors": [
                {
                    "authorId": "2108262811",
                    "name": "Xinyang Zhang"
                },
                {
                    "authorId": "2104662",
                    "name": "Yury Malkov"
                },
                {
                    "authorId": "1752662",
                    "name": "Omar U. Florez"
                },
                {
                    "authorId": "152662346",
                    "name": "Serim Park"
                },
                {
                    "authorId": "2953855",
                    "name": "B. McWilliams"
                },
                {
                    "authorId": "2111759643",
                    "name": "Jiawei Han"
                },
                {
                    "authorId": "1398503968",
                    "name": "Ahmed El-Kishky"
                }
            ]
        },
        {
            "paperId": "f9464bda6ca2e1ae20a335163b0172a3fcf599f8",
            "title": "EigenGame Unloaded: When playing games is better than optimizing",
            "abstract": "We build on the recently proposed EigenGame that views eigendecomposition as a competitive game. EigenGame's updates are biased if computed using minibatches of data, which hinders convergence and more sophisticated parallelism in the stochastic setting. In this work, we propose an unbiased stochastic update that is asymptotically equivalent to EigenGame, enjoys greater parallelism allowing computation on datasets of larger sample sizes, and outperforms EigenGame in experiments. We present applications to finding the principal components of massive datasets and performing spectral clustering of graphs. We analyze and discuss our proposed update in the context of EigenGame and the shift in perspective from optimization to games.",
            "fieldsOfStudy": [
                "Computer Science",
                "Mathematics"
            ],
            "authors": [
                {
                    "authorId": "8616871",
                    "name": "I. Gemp"
                },
                {
                    "authorId": "2953855",
                    "name": "B. McWilliams"
                },
                {
                    "authorId": "2297833",
                    "name": "Claire Vernade"
                },
                {
                    "authorId": "1686971",
                    "name": "T. Graepel"
                }
            ]
        },
        {
            "paperId": "17281d4de91cdd5c480f6f35a5e1a33b7abb18d2",
            "title": "EigenGame: PCA as a Nash Equilibrium",
            "abstract": "We present a novel view on principal component analysis (PCA) as a competitive game in which each approximate eigenvector is controlled by a player whose goal is to maximize their own utility function. We analyze the properties of this PCA game and the behavior of its gradient based updates. The resulting algorithm which combines elements from Oja's rule with a generalized Gram-Schmidt orthogonalization is naturally decentralized and hence parallelizable through message passing. We demonstrate the scalability of the algorithm with experiments on large image datasets and neural network activations. We discuss how this new view of PCA as a differentiable game can lead to further algorithmic developments and insights.",
            "fieldsOfStudy": [
                "Computer Science",
                "Mathematics"
            ],
            "authors": [
                {
                    "authorId": "8616871",
                    "name": "I. Gemp"
                },
                {
                    "authorId": "2953855",
                    "name": "B. McWilliams"
                },
                {
                    "authorId": "2297833",
                    "name": "Claire Vernade"
                },
                {
                    "authorId": "1686971",
                    "name": "T. Graepel"
                }
            ]
        },
        {
            "paperId": "40cef14a5d423df4620003b707ea5028d23eaae6",
            "title": "Less can be more in contrastive learning",
            "abstract": "Unsupervised representation learning provides an attractive alternative to its supervised counterpart because of the abundance of unlabelled data. Contrastive learning has recently emerged as one of the most successful approaches to unsupervised representation learning. Given a datapoint, contrastive learning involves discriminating between a matching, or positive, datapoint and a number of non-matching, or negative, ones. Usually the other datapoints in the batch serve as the negatives for the given datapoint. It has been shown empirically that large batch sizes are needed to achieve good performance, which led the the belief that a large number of negatives is preferable. In order to understand this phenomenon better, in this work investigate the role of negatives in contrastive learning by decoupling the number of negatives from the batch size. Surprisingly, we discover that for a \ufb01xed batch size performance actually degrades as the number of negatives is increased. We also show that using fewer negatives can lead to a better signal-to-noise ratio for the model gradients, which could explain the improved performance.",
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "authors": [
                {
                    "authorId": "37955812",
                    "name": "Jovana Mitrovic"
                },
                {
                    "authorId": "2953855",
                    "name": "B. McWilliams"
                },
                {
                    "authorId": "34353503",
                    "name": "M\u00e9lanie Rey"
                }
            ]
        },
        {
            "paperId": "57835c5ad5424f94ee75901c3113730f3900e656",
            "title": "Representation Learning via Invariant Causal Mechanisms",
            "abstract": "Self-supervised learning has emerged as a strategy to reduce the reliance on costly supervised signal by pretraining representations only using unlabeled data. These methods combine heuristic proxy classification tasks with data augmentations and have achieved significant success, but our theoretical understanding of this success remains limited. In this paper we analyze self-supervised representation learning using a causal framework. We show how data augmentations can be more effectively utilized through explicit invariance constraints on the proxy classifiers employed during pretraining. Based on this, we propose a novel self-supervised objective, Representation Learning via Invariant Causal Mechanisms (ReLIC), that enforces invariant prediction of proxy targets across augmentations through an invariance regularizer which yields improved generalization guarantees. Further, using causality we generalize contrastive learning, a particular kind of self-supervised method, and provide an alternative theoretical explanation for the success of these methods. Empirically, ReLIC significantly outperforms competing methods in terms of robustness and out-of-distribution generalization on ImageNet, while also significantly outperforming these methods on Atari achieving above human-level performance on $51$ out of $57$ games.",
            "fieldsOfStudy": [
                "Computer Science",
                "Mathematics"
            ],
            "authors": [
                {
                    "authorId": "37955812",
                    "name": "Jovana Mitrovic"
                },
                {
                    "authorId": "2953855",
                    "name": "B. McWilliams"
                },
                {
                    "authorId": "1944655894",
                    "name": "Jacob Walker"
                },
                {
                    "authorId": "1981334",
                    "name": "Lars Buesing"
                },
                {
                    "authorId": "1723876",
                    "name": "C. Blundell"
                }
            ]
        },
        {
            "paperId": "f7de8f36a91a147403f0696609c4f6ec789b835f",
            "title": "Social Diversity and Social Preferences in Mixed-Motive Reinforcement Learning",
            "abstract": "Recent research on reinforcement learning in pure-conflict and pure-common interest games has emphasized the importance of population heterogeneity. In contrast, studies of reinforcement learning in mixed-motive games have primarily leveraged homogeneous approaches. Given the defining characteristic of mixed-motive games--the imperfect correlation of incentives between group members--we study the effect of population heterogeneity on mixed-motive reinforcement learning. We draw on interdependence theory from social psychology and imbue reinforcement learning agents with Social Value Orientation (SVO), a flexible formalization of preferences over group outcome distributions. We subsequently explore the effects of diversity in SVO on populations of reinforcement learning agents in two mixed-motive Markov games. We demonstrate that heterogeneity in SVO generates meaningful and complex behavioral variation among agents similar to that suggested by interdependence theory. Empirical results in these mixed-motive dilemmas suggest agents trained in heterogeneous populations develop particularly generalized, high-performing policies relative to those trained in homogeneous populations.",
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "authors": [
                {
                    "authorId": "47610458",
                    "name": "Kevin R. McKee"
                },
                {
                    "authorId": "8616871",
                    "name": "I. Gemp"
                },
                {
                    "authorId": "2953855",
                    "name": "B. McWilliams"
                },
                {
                    "authorId": "1400818648",
                    "name": "Edgar A. Du\u00e9\u00f1ez-Guzm\u00e1n"
                },
                {
                    "authorId": "37591038",
                    "name": "Edward Hughes"
                },
                {
                    "authorId": "1700356",
                    "name": "Joel Z. Leibo"
                }
            ]
        },
        {
            "paperId": "0f225656e73fb8d47d5cbe1c6131273568a16e6c",
            "title": "Spectrogram Feature Losses for Music Source Separation",
            "abstract": "In this paper we study deep learning-based music source separation, and explore using an alternative loss to the standard spectrogram pixel-level L2 loss for model training. Our main contribution is in demonstrating that adding a high-level feature loss term, extracted from the spectrograms using a VGG net, can improve separation quality vis-a-vis a pure pixel-level loss. We show this improvement in the context of the MMDenseNet, a State-of-the-Art deep learning model for this task, for the extraction of drums and vocal sounds from songs in the musdb18 database, covering a broad range of western music genres. We believe that this finding can be generalized and applied to broader machine learning-based systems in the audio domain.",
            "fieldsOfStudy": [
                "Computer Science",
                "Engineering",
                "Mathematics"
            ],
            "authors": [
                {
                    "authorId": "49201339",
                    "name": "Abhimanyu Sahai"
                },
                {
                    "authorId": "145848224",
                    "name": "Romann M. Weber"
                },
                {
                    "authorId": "2953855",
                    "name": "B. McWilliams"
                }
            ]
        }
    ]
}