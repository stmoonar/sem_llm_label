{
    "authorId": "2111356",
    "papers": [
        {
            "paperId": "098be01c95b4c18e2c7e8b4164d29dbb0903e71f",
            "title": "Can a Multichoice Dataset be Repurposed for Extractive Question Answering?",
            "abstract": "The rapid evolution of Natural Language Processing (NLP) has favored major languages such as English, leaving a significant gap for many others due to limited resources. This is especially evident in the context of data annotation, a task whose importance cannot be underestimated, but which is time-consuming and costly. Thus, any dataset for resource-poor languages is precious, in particular when it is task-specific. Here, we explore the feasibility of repurposing existing datasets for a new NLP task: we repurposed the Belebele dataset (Bandarkar et al., 2023), which was designed for multiple-choice question answering (MCQA), to enable extractive QA (EQA) in the style of machine reading comprehension. We present annotation guidelines and a parallel EQA dataset for English and Modern Standard Arabic (MSA). We also present QA evaluation results for several monolingual and cross-lingual QA pairs including English, MSA, and five Arabic dialects. Our aim is to enable others to adapt our approach for the 120+ other language variants in Belebele, many of which are deemed under-resourced. We also conduct a thorough analysis and share our insights from the process, which we hope will contribute to a deeper understanding of the challenges and the opportunities associated with task reformulation in NLP research.",
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "authors": [
                {
                    "authorId": "2298756162",
                    "name": "Teresa Lynn"
                },
                {
                    "authorId": "51935928",
                    "name": "Malik H. Altakrori"
                },
                {
                    "authorId": "148087360",
                    "name": "S. Magdy"
                },
                {
                    "authorId": "2211732585",
                    "name": "Rocktim Jyoti Das"
                },
                {
                    "authorId": "2266387313",
                    "name": "Chenyang Lyu"
                },
                {
                    "authorId": "2056258384",
                    "name": "Mohamed Nasr"
                },
                {
                    "authorId": "2282523149",
                    "name": "Younes Samih"
                },
                {
                    "authorId": "8129718",
                    "name": "Alham Fikri Aji"
                },
                {
                    "authorId": "2026545715",
                    "name": "Preslav Nakov"
                },
                {
                    "authorId": "2111356",
                    "name": "S. Godbole"
                },
                {
                    "authorId": "1781292",
                    "name": "S. Roukos"
                },
                {
                    "authorId": "2261287685",
                    "name": "Radu Florian"
                },
                {
                    "authorId": "2257292541",
                    "name": "Nizar Habash"
                }
            ]
        },
        {
            "paperId": "860305f8fe7e93bec9d53074b1f4cfcbaca8ed9b",
            "title": "A Framework for Emission Reduction in Scope 3 Climate Actions using Domain-adapted Foundation Model",
            "abstract": "Large enterprises face a crucial imperative to achieve the Sustainable Development Goals (SDGs), especially goal 13, which focuses on combating climate change and its impacts. To mitigate the effects of climate change, reducing enterprise Scope 3 (supply chain emissions) is vital, as it accounts for more than 90% of total emission inventories. However, tracking Scope 3 emissions proves challenging, as data must be collected from thousands of upstream and downstream suppliers. We propose a novel framework that uses domain-adapted NLP foundation model to estimate Scope 3 emissions by leveraging financial transactions as a proxy of embodied emission of purchased goods and services and recommends appropriate climate actions to reduce scope3 emission through counterfactual queries. Our results show that the domain-adapted foundation model outperforms state-of-the-art text mining techniques and performs as well as a subject matter expert (SME). We also show how the proposed framework can identify Scope 3 hotspots and explain the factors that create them. Finally, we carry out what-if analysis to take climate actions that help achieve SDG 13. We present a case study demonstrating how this framework can be used by a real estate enterprise to take Scope 3 climate actions.",
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "authors": [
                {
                    "authorId": "2256950912",
                    "name": "Ayush Jain"
                },
                {
                    "authorId": "3014226",
                    "name": "Manikandan Padmanaban"
                },
                {
                    "authorId": "2209473610",
                    "name": "Jagabondhu Hazra"
                },
                {
                    "authorId": "2111356",
                    "name": "S. Godbole"
                },
                {
                    "authorId": "3217172",
                    "name": "Komminist Weldemariam"
                }
            ]
        },
        {
            "paperId": "effd5f47269c4f336474f2d66cb1719ff7620abf",
            "title": "AI for Environmental Intelligence in the Digital Economy",
            "abstract": "In today's digital economy, companies face climate-related damage to their assets, disruptions to supply chains and operations, and increasing pressure from consumers and regulators to their sustainability goals. Researchers need better tools to support climate research; businesses need better technologies to accelerate their sustainable digital transformation journeys. These include reimagining operations, supply chains, emissions management, or ESG and climate risk reporting with the help of emerging technologies for organizations to meet their sustainability goals. In this paper, we focus on some of the proposed approaches for helping enterprises to decarbonize their emission as they embrace their digital economy transformation.",
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "authors": [
                {
                    "authorId": "2209473610",
                    "name": "Jagabondhu Hazra"
                },
                {
                    "authorId": "2111356",
                    "name": "S. Godbole"
                },
                {
                    "authorId": "2181934308",
                    "name": "Kommy Weldemariam"
                },
                {
                    "authorId": "2243282524",
                    "name": "Maja Vukovi\u0107"
                }
            ]
        },
        {
            "paperId": "fef2dc696c8355f86b40bd6c3548d83439d62eb3",
            "title": "Supply chain emission estimation using large language models",
            "abstract": "Large enterprises face a crucial imperative to achieve the Sustainable Development Goals (SDGs), especially goal 13, which focuses on combating climate change and its impacts. To mitigate the effects of climate change, reducing enterprise Scope 3 (supply chain emissions) is vital, as it accounts for more than 90\\% of total emission inventories. However, tracking Scope 3 emissions proves challenging, as data must be collected from thousands of upstream and downstream suppliers.To address the above mentioned challenges, we propose a first-of-a-kind framework that uses domain-adapted NLP foundation models to estimate Scope 3 emissions, by utilizing financial transactions as a proxy for purchased goods and services. We compared the performance of the proposed framework with the state-of-art text classification models such as TF-IDF, word2Vec, and Zero shot learning. Our results show that the domain-adapted foundation model outperforms state-of-the-art text mining techniques and performs as well as a subject matter expert (SME). The proposed framework could accelerate the Scope 3 estimation at Enterprise scale and will help to take appropriate climate actions to achieve SDG 13.",
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "authors": [
                {
                    "authorId": "2110542258",
                    "name": "A. Jain"
                },
                {
                    "authorId": "3014226",
                    "name": "Manikandan Padmanaban"
                },
                {
                    "authorId": "1771491",
                    "name": "J. Hazra"
                },
                {
                    "authorId": "2111356",
                    "name": "S. Godbole"
                },
                {
                    "authorId": "2181934308",
                    "name": "Kommy Weldemariam"
                }
            ]
        },
        {
            "paperId": "782ee41493f426e807fa92fc569f3fcb88cd970a",
            "title": "Towards Context-based Model Selection for Improved Crop Price Forecasting",
            "abstract": "Accuracy of crop price forecasting techniques plays an important role in enabling the supply chain planners and government bodies to take necessary actions by estimating market factors such as demand and supply. In emerging economies such as India, the crop prices at marketplaces are manually entered, which can be prone to human-induced errors like entry of incorrect data or entry of no data for many days. In addition to such human prone errors, the fluctuations in the prices itself make the creation of stable and robust forecasting solution a challenging task. Considering such complexities in crop price forecasting, in this paper, we present techniques to build robust crop price prediction models considering various features such as (i) historical price and market arrival quantity of crops, (ii) historical weather data that influence crop production and transportation, (iii) data quality-related features obtained by performing statistical analysis. Furthermore, we propose a crop-specific context-based model selection strategy using trend analysis to deal with high fluctuations in crop prices. To show the efficacy of the proposed approach, we show experimental results using two different time-series feature representations on two crops - Tomato and Maize for 14 marketplaces in India and demonstrate that the proposed approach provides improved accuracy metrics when compared to standard forecasting techniques.",
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "authors": [
                {
                    "authorId": "2110542258",
                    "name": "A. Jain"
                },
                {
                    "authorId": "1846370",
                    "name": "S. Marvaniya"
                },
                {
                    "authorId": "2111356",
                    "name": "S. Godbole"
                },
                {
                    "authorId": "1821191",
                    "name": "Vitobha Munigala"
                }
            ]
        },
        {
            "paperId": "d3d66bb822e4adb2512a08b875b8d36de61721e8",
            "title": "A Framework for Crop Price Forecasting in Emerging Economies by Analyzing the Quality of Time-series Data",
            "abstract": "Accuracy of crop price forecasting techniques is important because it enables the supply chain planners and government bodies to take appropriate actions by estimating market factors such as demand and supply. In emerging economies such as India, the crop prices at marketplaces are manually entered every day, which can be prone to human-induced errors like the entry of incorrect data or entry of no data for many days. In addition to such human prone errors, the fluctuations in the prices itself make the creation of stable and robust forecasting solution a challenging task. Considering such complexities in crop price forecasting, in this paper, we present techniques to build robust crop price prediction models considering various features such as (i) historical price and market arrival quantity of crops, (ii) historical weather data that influence crop production and transportation, (iii) data quality-related features obtained by performing statistical analysis. We additionally propose a framework for context-based model selection and retraining considering factors such as model stability, data quality metrics, and trend analysis of crop prices. To show the efficacy of the proposed approach, we show experimental results on two crops - Tomato and Maize for 14 marketplaces in India and demonstrate that the proposed approach not only improves accuracy metrics significantly when compared against the standard forecasting techniques but also provides robust models.",
            "fieldsOfStudy": [
                "Mathematics",
                "Economics",
                "Computer Science"
            ],
            "authors": [
                {
                    "authorId": "2110542258",
                    "name": "A. Jain"
                },
                {
                    "authorId": "1846370",
                    "name": "S. Marvaniya"
                },
                {
                    "authorId": "2111356",
                    "name": "S. Godbole"
                },
                {
                    "authorId": "1821191",
                    "name": "Vitobha Munigala"
                }
            ]
        },
        {
            "paperId": "21db98d3d1e29819090ec865eb009701c83d3aa2",
            "title": "Learning Outcomes and Their Relatedness in a Medical Curriculum",
            "abstract": "A typical medical curriculum is organized in a hierarchy of instructional objectives called Learning Outcomes (LOs); a few thousand LOs span five years of study. Gaining a thorough understanding of the curriculum requires learners to recognize and apply related LOs across years, and across different parts of the curriculum. However, given the large scope of the curriculum, manually labeling related LOs is tedious, and almost impossible to scale. In this paper, we build a system that learns relationships between LOs, and we achieve up to human-level performance in the LO relationship extraction task. We then present an application where the proposed system is employed to build a map of related LOs and Learning Resources (LRs) pertaining to a virtual patient case. We believe that our system can help medical students grasp the curriculum better, within classroom as well as in Intelligent Tutoring Systems (ITS) settings.",
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "authors": [
                {
                    "authorId": "1796279288",
                    "name": "Sneha Mondal"
                },
                {
                    "authorId": "2952437",
                    "name": "Tejas I. Dhamecha"
                },
                {
                    "authorId": "2111356",
                    "name": "S. Godbole"
                },
                {
                    "authorId": "2072060686",
                    "name": "Smriti Pathak"
                },
                {
                    "authorId": "2099798465",
                    "name": "Red Mendoza"
                },
                {
                    "authorId": "151423305",
                    "name": "K. G. Wijayarathna"
                },
                {
                    "authorId": "2485426",
                    "name": "N. Zary"
                },
                {
                    "authorId": "35106509",
                    "name": "Swarnadeep Saha"
                },
                {
                    "authorId": "3095731",
                    "name": "Malolan Chetlur"
                }
            ]
        },
        {
            "paperId": "b4cf1b331fe45263a660a8f94d1cf4a4ff1d1036",
            "title": "Aligning Learning Outcomes to Learning Resources: A Lexico-Semantic Spatial Approach",
            "abstract": "Aligning Learning Outcomes (LO) to relevant portions of Learning Resources (LR) is necessary to help students quickly navigate within the recommended learning material. In general, the problem can be viewed as finding the relevant sections of a document (LR) that is pertinent to a broad question (LO). In this paper, we introduce the novel problem of aligning LOs (LO is usually a sentence long text) to relevant pages of LRs (LRs are in the form of slide decks). We observe that the set of relevant pages can be composed of multiple chunks (a chunk is a contiguous set of pages) and the same page of an LR might be relevant to multiple LOs. To this end, we develop a novel Lexico-Semantic Spatial approach that captures the lexical, semantic, and spatial aspects of the task, and also alleviates the limited availability of training data. Our approach first identifies the relevancy of a page to an LO by using lexical and semantic features from each page independently. The spatial model at a later stage exploits the dependencies between the sequence of pages in the LR to further improve the alignment task. We empirically establish the importance of the lexical, semantic, and spatial models within the proposed approach. We show that, on average, a student can navigate to a relevant page from the first predicted page by about four clicks within a 38 page slide deck, as compared to two clicks by human experts.",
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "authors": [
                {
                    "authorId": "35106509",
                    "name": "Swarnadeep Saha"
                },
                {
                    "authorId": "3095731",
                    "name": "Malolan Chetlur"
                },
                {
                    "authorId": "2952437",
                    "name": "Tejas I. Dhamecha"
                },
                {
                    "authorId": "151423305",
                    "name": "K. G. Wijayarathna"
                },
                {
                    "authorId": "2099798465",
                    "name": "Red Mendoza"
                },
                {
                    "authorId": "144390880",
                    "name": "P. Gagnon"
                },
                {
                    "authorId": "2485426",
                    "name": "N. Zary"
                },
                {
                    "authorId": "2111356",
                    "name": "S. Godbole"
                }
            ]
        },
        {
            "paperId": "2027eafd0fda1d21e4c307b06f03806dfe563e58",
            "title": "Taxonomy grounded aggregation of classifiers with different label sets",
            "abstract": "We describe the problem of aggregating the label predictions of diverse classifiers using a class taxonomy. Such a taxonomy may not have been available or referenced when the individual classifiers were designed and trained, yet mapping the output labels into the taxonomy is desirable to integrate the effort spent in training the constituent classifiers. A hierarchical taxonomy representing some domain knowledge may be different from, but partially mappable to, the label sets of the individual classifiers. We present a heuristic approach and a principled graphical model to aggregate the label predictions by grounding them into the available taxonomy. Our model aggregates the labels using the taxonomy structure as constraints to find the most likely hierarchically consistent class. We experimentally validate our proposed method on image and text classification tasks.",
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "authors": [
                {
                    "authorId": "2909575",
                    "name": "Amrita Saha"
                },
                {
                    "authorId": "3167032",
                    "name": "Sathish Indurthi"
                },
                {
                    "authorId": "2111356",
                    "name": "S. Godbole"
                },
                {
                    "authorId": "3329096",
                    "name": "Subendhu Rongali"
                },
                {
                    "authorId": "145769639",
                    "name": "V. Raykar"
                }
            ]
        },
        {
            "paperId": "f19675260eafc9beb1e4c1d7557a997246a80fe9",
            "title": "Real-time customer probing and decision support in a call center",
            "abstract": "In customer-care contact centers, agents are sometimes tasked with selling products to customers. The state-of-the-art guided selling solutions augment available historical data about customers with real-time information collected during the call that is fed into the real-time product recommendation models to generate offers tailored to the customer's needs and preferences. However, the technology does not address the question of how to scientifically structure and design this real-time information gathering activity. We propose a scientific approach to question (probe) customers via a sequence of questions optimally selected for individual customers. We describe the design of a complete product recommendation tool that makes use of our customer probing approach and is deployed in the call center of a global bank to assist agents with cross-selling and upselling. Carefully controlled experiments show our solution helping agents achieve close to a 20% improvement in sales revenues and reducing the performance gap between novice and experienced agents.",
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "authors": [
                {
                    "authorId": "2601402",
                    "name": "R. Lotlikar"
                },
                {
                    "authorId": "1405786817",
                    "name": "P. Pachigolla"
                },
                {
                    "authorId": "1405786819",
                    "name": "D. Miller-Davie"
                },
                {
                    "authorId": "2111356",
                    "name": "S. Godbole"
                }
            ]
        }
    ]
}