{
    "authorId": "2185347291",
    "papers": [
        {
            "paperId": "3aeef78315d74568f2f29d6bb733e6ceec889ef1",
            "title": "Structures Aware Fine-Grained Contrastive Adversarial Hashing for Cross-Media Retrieval",
            "abstract": "Deep cross-media hashing provides an efficient semantic representation learning solution for large-scale cross-media retrieval. The existing methods only consider the inter-media or intra-media semantic association learning, ignore the guiding of semantic structure information, and have weak reasoning ability for implicit fine-grained semantic associations. To tackle this problem, we propose a novel structures aware fine-grained contrastive adversarial hashing method for cross-media retrieval. A novel cross-media contrastive adversarial hash network is constructed for the first time, which integrates the cross-media and intra-media contrastive learning and multi-modal adversarial learning, aiming at maximizing the semantic association between different modalities, and improving the semantic discrimination and consistency of cross-media unified hash representation, thereby the inter-media and intra-media semantic preserving ability can be well enhanced; A fine-grained cross-media semantic feature learning method based on fine-grained semantic reasoning with transformers is proposed, which captures fine-grained salient features of different modalities for semantic association learning, and enhances the reasoning ability of fine-grained implicit semantic association; A semantic label graph convolutional network guided cross-media semantic association learning strategy is proposed, which makes full use of semantic structure information to enhance the learning ability of implicit cross-media semantic associations. Extensive experiments on several large-scale cross-media benchmark datasets demonstrate that the proposed method outperforms the state-of-the-art methods.",
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "authors": [
                {
                    "authorId": "2281749687",
                    "name": "Meiyu Liang"
                },
                {
                    "authorId": "2185347291",
                    "name": "Yawen Li"
                },
                {
                    "authorId": "2281950242",
                    "name": "Yang Yu"
                },
                {
                    "authorId": "2034186530",
                    "name": "Xiaowen Cao"
                },
                {
                    "authorId": "2183921349",
                    "name": "Zhe Xue"
                },
                {
                    "authorId": "2264494136",
                    "name": "Ang Li"
                },
                {
                    "authorId": "2281746766",
                    "name": "Kangkang Lu"
                }
            ]
        },
        {
            "paperId": "71f208be9aae041db4b96b87bd0b783fb4510ab1",
            "title": "Traceable Federated Continual Learning",
            "abstract": "Federated continual learning (FCL) is a typical mecha-nism to achieve collaborative model training among clients that own dynamic data. While traditional FCL methods have been proved effective, they do not consider the task repeatability and fail to achieve good performance under this practical scenario. In this paper, we propose a new paradigm, namely Traceable Federated Continual Learning (TFCL), aiming to cope with repetitive tasks by tracing and augmenting them. Following the new paradigm, we de-velop TagFed, a framework that enables accurate and ef-fective Tracing, augmentation, and Federation for TFCL. The key idea is to decompose the whole model into a se-ries of marked sub-models for optimizing each client task, before conducting group-wise knowledge aggregation, such that the repetitive tasks can be located precisely and fed-erated selectively for improved performance. Extensive ex-periments on our constructed benchmark demonstrate the effectiveness and efficiency of the proposed framework. We will release our code at: https://github.com/POwerWeirdo/TagFCL.",
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "authors": [
                {
                    "authorId": "2321719244",
                    "name": "Qiang Wang"
                },
                {
                    "authorId": "2308487108",
                    "name": "Bingyan Liu"
                },
                {
                    "authorId": "2185347291",
                    "name": "Yawen Li"
                }
            ]
        },
        {
            "paperId": "78f1c2356bde4db5cebef5060c4a7cc436bb8ae4",
            "title": "Calibrating Graph Neural Networks from a Data-centric Perspective",
            "abstract": "Graph neural networks (GNNs) have gained popularity in modeling various complex networks, e.g., social network and webpage network. Despite the promising accuracy, the confidences of GNNs are shown to be miscalibrated, indicating limited awareness of prediction uncertainty and harming the reliability of model decisions. Existing calibration methods primarily focus on improving GNN models, e.g., adding regularization during training or introducing temperature scaling after training. In this paper, we argue that the miscalibration of GNNs may stem from the graph data and can be alleviated through topology modification. To support this motivation, we conduct data observations by examining the impacts ofdecisive andhomophilic edges on calibration performance, where decisive edges play a critical role in GNN predictions and homophilic edges connect nodes of the same class. By assigning larger weights to these edges in the adjacency matrix, we observe an improvement in calibration performance without sacrificing classification accuracy. This suggests the potential of a data-centric approach for calibrating GNNs. Motivated by our observations, we propose Data-centric Graph Calibration (DCGC), which uses two edge weighting modules to adjust the input graph for GNN calibration. The first module learns the weights of decisive edges by parameterizing the adjacency matrix and enabling backpropagation of the prediction loss to edge weights. This emphasizes critical edges that fit the prediction needs. The second module computes weights for homophilic edges based on predicted label distributions, assigning larger weights to edges with stronger homophily. These modifications operate at the data level and can be easily integrated with temperature scaling-based methods for better calibration. Experimental results on 8 benchmark datasets demonstrate that DCGC achieves state-of-the-art calibration performance, with an average relative improvement of 36.4% in ECE, while maintaining or even slightly improving classification accuracy. Ablation studies and hyper-parameter analysis further validate the effectiveness and robustness of our proposed method DCGC. Code and data are available at https://github.com/BUPT-GAMMA/DCGC.",
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "authors": [
                {
                    "authorId": "2257052319",
                    "name": "Cheng Yang"
                },
                {
                    "authorId": "2257052319",
                    "name": "Cheng Yang"
                },
                {
                    "authorId": "2260331653",
                    "name": "Chuan Shi"
                },
                {
                    "authorId": "2185347291",
                    "name": "Yawen Li"
                },
                {
                    "authorId": "2019870682",
                    "name": "Zhiqiang Zhang"
                },
                {
                    "authorId": "2151550753",
                    "name": "Jun Zhou"
                }
            ]
        },
        {
            "paperId": "8028de9ab1f83f9939b4c2dc76aeeedfab812d71",
            "title": "Text-Rich Graph Neural Networks With Subjective-Objective Semantic Modeling",
            "abstract": "Graph Neural Networks (GNNs), which obtain node embeddings by attribute propagates along graph topology, exhibit significant power in graph-structured data mining. However, graphs in the real world are usually text-rich, where the text can not only be represented as node attributes, but also contains valuable objective semantic structures. Moreover, the graph topology also exhibits complex subjective semantic structures, especially the heterophily where nodes from different classes are prone to build connections, making existing GNNs that work under the assumption of homophily incapable to realize generalization. To tackle aforementioned limitations, we design a new text-rich graph neural network from a unified perspective, namely SO-GNN. It can effectively enhance the expressive power of GNNs by modeling the implicit but informative subjective-objective semantics underlying the text-rich graphs. Specifically, we first introduce a new constrained Markov matrix with well-defined probabilistic diffusion dynamics to guide information propagation, where the neighbors are more appropriate and indicative in providing both local and global subjective semantics. We then construct a flexible heterogeneous text graph to gain a deeper insight into objective semantics, providing indispensable information for learning node embedding. Finally, we unite subjective and objective semantics in an end-to-end manner, so that the model can fully utilize the most relevant information for downstream tasks. Extensive experiments across various text-rich graphs with low-to-high homophily demonstrate the effectiveness and flexibility of the proposed SO-GNN over state-of-the-arts.",
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "authors": [
                {
                    "authorId": "2185347291",
                    "name": "Yawen Li"
                },
                {
                    "authorId": "12073135",
                    "name": "Zhizhi Yu"
                },
                {
                    "authorId": "2258959961",
                    "name": "Dongxiao He"
                }
            ]
        },
        {
            "paperId": "da971dc75d5b4d289cb3116a1eac4ae42156df6d",
            "title": "RFDG: Reinforcement Federated Domain Generalization",
            "abstract": "During the training process of federated learning models, the domain information of the target test data on the server can differ greatly from the training data of each client, leading to a decrease in the performance of the federated model. Additionally, due to privacy protection during federated training, clients cannot see the target domain test data, and the distribution information of the target data cannot be used. This poses a new challenge for federated learning. Domain generalization techniques are often used in centralized frameworks to resolve such problems. In recent years, the domain generalization method based on feature decorrelation has enabled models to learn knowledge with a stronger generalization ability in unseen target domain data. However, existing methods require data centralization in the feature decorrelation process, which conflicts with data privacy protection in federated learning. To address these issues, we propose Reinforcement Federated Domain Generalization (RFDG), which incorporates domain generalization in federated learning via reinforcement learning. RFDG can improve the generalization ability of the federated model of unseen target domain test data. We design a reinforcement federated feature decorrelation policy that uses reinforcement learning technology to transform the sample reweight work into a parameterized sample reweight policy that can be shared among federated learning clients. We develop reinforcement federated experience replay techniques to supplement the feature information loss of local data due to the mini-batch mechanism during the policy learning process. When the policy is shared by each client, those features can be decorrelated from a global perspective, allowing the model to focus on capturing the fundamental association between features and labels to learn domain-invariant knowledge. We verified the effectiveness of our method through extensive experiments using four publicly available datasets.",
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "authors": [
                {
                    "authorId": "107956870",
                    "name": "Zeli Guan"
                },
                {
                    "authorId": "2185347291",
                    "name": "Yawen Li"
                },
                {
                    "authorId": "2227936624",
                    "name": "Zhenhui Pan"
                },
                {
                    "authorId": "2214931527",
                    "name": "Yuxin Liu"
                },
                {
                    "authorId": "2052285030",
                    "name": "Zhe Xue"
                }
            ]
        },
        {
            "paperId": "9d10eac7b7a9010c27c8e55d33694a94c678b2a4",
            "title": "Recent Advances on Federated Learning: A Systematic Survey",
            "abstract": "Federated learning has emerged as an effective paradigm to achieve privacy-preserving collaborative learning among different parties. Compared to traditional centralized learning that requires collecting data from each party, in federated learning, only the locally trained models or computed gradients are exchanged, without exposing any data information. As a result, it is able to protect privacy to some extent. In recent years, federated learning has become more and more prevalent and there have been many surveys for summarizing related methods in this hot research topic. However, most of them focus on a specific perspective or lack the latest research progress. In this paper, we provide a systematic survey on federated learning, aiming to review the recent advanced federated methods and applications from different aspects. Specifically, this paper includes four major contributions. First, we present a new taxonomy of federated learning in terms of the pipeline and challenges in federated scenarios. Second, we summarize federated learning methods into several categories and briefly introduce the state-of-the-art methods under these categories. Third, we overview some prevalent federated learning frameworks and introduce their features. Finally, some potential deficiencies of current methods and several future directions are discussed.",
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "authors": [
                {
                    "authorId": "70633617",
                    "name": "Bingyan Liu"
                },
                {
                    "authorId": "2199246944",
                    "name": "Nuoyan Lv"
                },
                {
                    "authorId": "2199307789",
                    "name": "Yuanchun Guo"
                },
                {
                    "authorId": "2185347291",
                    "name": "Yawen Li"
                }
            ]
        },
        {
            "paperId": "c0683cd86fe5946202eb9a9cbdedfa41367f6248",
            "title": "Heterogeneous Collaborative Learning for Personalized Healthcare Analytics via Messenger Distillation",
            "abstract": "The Healthcare Internet-of-Things (IoT) framework aims to provide personalized medical services with edge devices. Due to the inevitable data sparsity on an individual device, cross-device collaboration is introduced to enhance the power of distributed artificial intelligence. Conventional collaborative learning protocols (e.g., sharing model parameters or gradients) strictly require the homogeneity of all participant models. However, real-life end devices have various hardware configurations (e.g., compute resources), leading to heterogeneous on-device models with different architectures. Moreover, clients (i.e., end devices) may participate in the collaborative learning process at different times. In this paper, we propose a Similarity-Quality-based Messenger Distillation (SQMD) framework for heterogeneous asynchronous on-device healthcare analytics. By introducing a preloaded reference dataset, SQMD enables all participant devices to distill knowledge from peers via messengers (i.e., the soft labels of the reference dataset generated by clients) without assuming the same model architecture. Furthermore, the messengers also carry important auxiliary information to calculate the similarity between clients and evaluate the quality of each client model, based on which the central server creates and maintains a dynamic collaboration graph (communication graph) to improve the personalization and reliability of SQMD under asynchronous conditions. Extensive experiments on three real-life datasets show that SQMD achieves superior performance.",
            "fieldsOfStudy": [
                "Computer Science",
                "Medicine"
            ],
            "authors": [
                {
                    "authorId": "1849611",
                    "name": "Guanhua Ye"
                },
                {
                    "authorId": "1490931831",
                    "name": "Tong Chen"
                },
                {
                    "authorId": "2185347291",
                    "name": "Yawen Li"
                },
                {
                    "authorId": "101457473",
                    "name": "Li-zhen Cui"
                },
                {
                    "authorId": "144133815",
                    "name": "Q. Nguyen"
                },
                {
                    "authorId": "2416851",
                    "name": "Hongzhi Yin"
                }
            ]
        }
    ]
}