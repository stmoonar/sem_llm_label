{
    "authorId": "2120846500",
    "papers": [
        {
            "paperId": "03dd209a79b302cd7bc976c0bbe6761c152c05b3",
            "title": "Bridging Multicalibration and Out-of-distribution Generalization Beyond Covariate Shift",
            "abstract": "We establish a new model-agnostic optimization framework for out-of-distribution generalization via multicalibration, a criterion that ensures a predictor is calibrated across a family of overlapping groups. Multicalibration is shown to be associated with robustness of statistical inference under covariate shift. We further establish a link between multicalibration and robustness for prediction tasks both under and beyond covariate shift. We accomplish this by extending multicalibration to incorporate grouping functions that consider covariates and labels jointly. This leads to an equivalence of the extended multicalibration and invariance, an objective for robust learning in existence of concept shift. We show a linear structure of the grouping function class spanned by density ratios, resulting in a unifying framework for robust learning by designing specific grouping functions. We propose MC-Pseudolabel, a post-processing algorithm to achieve both extended multicalibration and out-of-distribution generalization. The algorithm, with lightweight hyperparameters and optimization through a series of supervised regression steps, achieves superior performance on real-world datasets with distribution shift.",
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "authors": [
                {
                    "authorId": "2265797598",
                    "name": "Jiayun Wu"
                },
                {
                    "authorId": "2120846500",
                    "name": "Jiashuo Liu"
                },
                {
                    "authorId": "2300089202",
                    "name": "Peng Cui"
                },
                {
                    "authorId": "2238047775",
                    "name": "Zhiwei Steven Wu"
                }
            ]
        },
        {
            "paperId": "9fbe2f0de9789949353bbc0dd4ad6994c21f1617",
            "title": "Stability Evaluation via Distributional Perturbation Analysis",
            "abstract": "The performance of learning models often deteriorates when deployed in out-of-sample environments. To ensure reliable deployment, we propose a stability evaluation criterion based on distributional perturbations. Conceptually, our stability evaluation criterion is defined as the minimal perturbation required on our observed dataset to induce a prescribed deterioration in risk evaluation. In this paper, we utilize the optimal transport (OT) discrepancy with moment constraints on the \\textit{(sample, density)} space to quantify this perturbation. Therefore, our stability evaluation criterion can address both \\emph{data corruptions} and \\emph{sub-population shifts} -- the two most common types of distribution shifts in real-world scenarios. To further realize practical benefits, we present a series of tractable convex formulations and computational methods tailored to different classes of loss functions. The key technical tool to achieve this is the strong duality theorem provided in this paper. Empirically, we validate the practical utility of our stability evaluation criterion across a host of real-world applications. These empirical studies showcase the criterion's ability not only to compare the stability of different learning models and features but also to provide valuable guidelines and strategies to further improve models.",
            "fieldsOfStudy": [
                "Computer Science",
                "Mathematics"
            ],
            "authors": [
                {
                    "authorId": "2274692483",
                    "name": "Jos\u00e9 H. Blanchet"
                },
                {
                    "authorId": "2300089202",
                    "name": "Peng Cui"
                },
                {
                    "authorId": "2281712035",
                    "name": "Jiajin Li"
                },
                {
                    "authorId": "2120846500",
                    "name": "Jiashuo Liu"
                }
            ]
        },
        {
            "paperId": "aed62071aa0dd51a03e8f12484c9a5597931d3fd",
            "title": "Topology-Aware Dynamic Reweighting for Distribution Shifts on Graph",
            "abstract": "Graph Neural Networks (GNNs) are widely used for node classification tasks but often fail to generalize when training and test nodes come from different distributions, limiting their practicality. To overcome this, recent approaches adopt invariant learning techniques from the out-of-distribution (OOD) generalization field, which seek to establish stable prediction methods across environments. However, the applicability of these invariant assumptions to graph data remains unverified, and such methods often lack solid theoretical support. In this work, we introduce the Topology-Aware Dynamic Reweighting (TAR) framework, which dynamically adjusts sample weights through gradient flow in the geometric Wasserstein space during training. Instead of relying on strict invariance assumptions, we prove that our method is able to provide distributional robustness, thereby enhancing the out-of-distribution generalization performance on graph data. By leveraging the inherent graph structure, TAR effectively addresses distribution shifts. Our framework's superiority is demonstrated through standard testing on four graph OOD datasets and three class-imbalanced node classification datasets, exhibiting marked improvements over existing methods.",
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "authors": [
                {
                    "authorId": "2305113473",
                    "name": "Weihuang Zheng"
                },
                {
                    "authorId": "2120846500",
                    "name": "Jiashuo Liu"
                },
                {
                    "authorId": "2216402502",
                    "name": "Jiaxing Li"
                },
                {
                    "authorId": "2265797598",
                    "name": "Jiayun Wu"
                },
                {
                    "authorId": "2300089202",
                    "name": "Peng Cui"
                },
                {
                    "authorId": "2304458958",
                    "name": "Youyong Kong"
                }
            ]
        },
        {
            "paperId": "c5211f32b79661cbd9ea6a904772d7d1ca5c935b",
            "title": "A Survey on Evaluation of Out-of-Distribution Generalization",
            "abstract": "Machine learning models, while progressively advanced, rely heavily on the IID assumption, which is often unfulfilled in practice due to inevitable distribution shifts. This renders them susceptible and untrustworthy for deployment in risk-sensitive applications. Such a significant problem has consequently spawned various branches of works dedicated to developing algorithms capable of Out-of-Distribution (OOD) generalization. Despite these efforts, much less attention has been paid to the evaluation of OOD generalization, which is also a complex and fundamental problem. Its goal is not only to assess whether a model's OOD generalization capability is strong or not, but also to evaluate where a model generalizes well or poorly. This entails characterizing the types of distribution shifts that a model can effectively address, and identifying the safe and risky input regions given a model. This paper serves as the first effort to conduct a comprehensive review of OOD evaluation. We categorize existing research into three paradigms: OOD performance testing, OOD performance prediction, and OOD intrinsic property characterization, according to the availability of test data. Additionally, we briefly discuss OOD evaluation in the context of pretrained models. In closing, we propose several promising directions for future research in OOD evaluation.",
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "authors": [
                {
                    "authorId": "2187083103",
                    "name": "Han Yu"
                },
                {
                    "authorId": "2120846500",
                    "name": "Jiashuo Liu"
                },
                {
                    "authorId": "51258901",
                    "name": "Xingxuan Zhang"
                },
                {
                    "authorId": "2265797598",
                    "name": "Jiayun Wu"
                },
                {
                    "authorId": "2283771726",
                    "name": "Peng Cui"
                }
            ]
        },
        {
            "paperId": "4253c94be50505ef94a6bdc635cdd3ff376f4ac9",
            "title": "Meta Adaptive Task Sampling for Few-Domain Generalization",
            "abstract": "To ensure the out-of-distribution (OOD) generalization performance, traditional domain generalization (DG) methods resort to training on data from multiple sources with different underlying distributions. And the success of those DG methods largely depends on the fact that there are diverse training distributions. However, it usually needs great efforts to obtain enough heterogeneous data due to the high expenses, privacy issues or the scarcity of data. Thus an interesting yet seldom investigated problem arises: how to improve the OOD generalization performance when the perceived heterogeneity is limited. In this paper, we instantiate a new framework called few-domain generalization (FDG), which aims to learn a generalizable model from very few domains of novel tasks with the knowledge acquired from previous learning experiences on base tasks. Moreover, we propose a Meta Adaptive Task Sampling (MATS) procedure to differentiate base tasks according to their semantic and domain-shift similarity to the novel task. Empirically, we show that the newly introduced FDG framework can substantially improve the OOD generalization performance on the novel task and further combining MATS with episodic training could outperform several state-of-the-art DG baselines on widely used benchmarks like PACS and DomainNet.",
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "authors": [
                {
                    "authorId": "24069072",
                    "name": "Zheyan Shen"
                },
                {
                    "authorId": "2187083103",
                    "name": "Han Yu"
                },
                {
                    "authorId": "2153522384",
                    "name": "Peng Cui"
                },
                {
                    "authorId": "2120846500",
                    "name": "Jiashuo Liu"
                },
                {
                    "authorId": "51258901",
                    "name": "Xingxuan Zhang"
                },
                {
                    "authorId": "48207021",
                    "name": "Linjun Zhou"
                },
                {
                    "authorId": "39853706",
                    "name": "Furui Liu"
                }
            ]
        },
        {
            "paperId": "8cb7d16c3741a64bd8b95b965c5600fb4e6de32f",
            "title": "Offline Policy Evaluation in Large Action Spaces via Outcome-Oriented Action Grouping",
            "abstract": "Offline policy evaluation (OPE) aims to accurately estimate the performance of a hypothetical policy using only historical data, which has drawn increasing attention in a wide range of applications including recommender systems and personalized medicine. With the presence of rising granularity of consumer data, many industries started exploring larger action candidate spaces to support more precise personalized action. While inverse propensity score (IPS) is a standard OPE estimator, it suffers from more severe variance issues with increasing action spaces. To address this issue, we theoretically prove that the estimation variance can be reduced by merging actions into groups while the distinction among these action effects on the outcome can induce extra bias. Motivated by these, we propose a novel IPS estimator with outcome-oriented action Grouping (GroupIPS), which leverages a Lipschitz regularized network to measure the distance of action effects in the embedding space and merges nearest action neighbors. This strategy enables more robust estimation by achieving smaller variances while inducing minor additional bias. Empirically, extensive experiments on both synthetic and real world datasets demonstrate the effectiveness of our proposed method.",
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "authors": [
                {
                    "authorId": "2215557755",
                    "name": "Jie Peng"
                },
                {
                    "authorId": "145742335",
                    "name": "Hao Zou"
                },
                {
                    "authorId": "2120846500",
                    "name": "Jiashuo Liu"
                },
                {
                    "authorId": "2118845842",
                    "name": "Shaoming Li"
                },
                {
                    "authorId": "50262723",
                    "name": "Yibao Jiang"
                },
                {
                    "authorId": "2188744953",
                    "name": "Jian Pei"
                },
                {
                    "authorId": "2052469774",
                    "name": "P. Cui"
                }
            ]
        },
        {
            "paperId": "9010c30ee5f7c6e2a273f76da358341ba866e137",
            "title": "Geometry-Calibrated DRO: Combating Over-Pessimism with Free Energy Implications",
            "abstract": "Machine learning algorithms minimizing average risk are susceptible to distributional shifts. Distributionally Robust Optimization (DRO) addresses this issue by optimizing the worst-case risk within an uncertainty set. However, DRO suffers from over-pessimism, leading to low-confidence predictions, poor parameter estimations as well as poor generalization. In this work, we conduct a theoretical analysis of a probable root cause of over-pessimism: excessive focus on noisy samples. To alleviate the impact of noise, we incorporate data geometry into calibration terms in DRO, resulting in our novel Geometry-Calibrated DRO (GCDRO) for regression. We establish the connection between our risk objective and the Helmholtz free energy in statistical physics, and this free-energy-based risk can extend to standard DRO methods. Leveraging gradient flow in Wasserstein space, we develop an approximate minimax optimization algorithm with a bounded error ratio and elucidate how our approach mitigates noisy sample effects. Comprehensive experiments confirm GCDRO's superiority over conventional DRO methods.",
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "authors": [
                {
                    "authorId": "2120846500",
                    "name": "Jiashuo Liu"
                },
                {
                    "authorId": "2265797598",
                    "name": "Jiayun Wu"
                },
                {
                    "authorId": "2265756663",
                    "name": "Tianyu Wang"
                },
                {
                    "authorId": "2265753601",
                    "name": "Hao Zou"
                },
                {
                    "authorId": "2293527219",
                    "name": "Bo Li"
                },
                {
                    "authorId": "2276610161",
                    "name": "Peng Cui"
                }
            ]
        },
        {
            "paperId": "91632ba973be074d2ef72c5be16a9c72b292a914",
            "title": "On the Need of a Modeling Language for Distribution Shifts: Illustrations on Tabular Datasets",
            "abstract": "Different distribution shifts require different interventions, and algorithms must be grounded in the specific shifts they address. However, methodological development for robust algorithms typically relies on structural assumptions that lack empirical validation. Advocating for an empirically grounded data-driven approach to research, we build an empirical testbed comprising natural shifts across 5 tabular datasets and 60,000 method configurations encompassing imbalanced learning and distributionally robust optimization (DRO) methods. We find $Y|X$-shifts are most prevalent on our testbed, in stark contrast to the heavy focus on $X$ (covariate)-shifts in the ML literature. The performance of robust algorithms varies significantly over shift types, and is no better than that of vanilla methods. To understand why, we conduct an in-depth empirical analysis of DRO methods and find that although often neglected by researchers, implementation details -- such as the choice of underlying model class (e.g., XGBoost) and hyperparameter selection -- have a bigger impact on performance than the ambiguity set or its radius. To further bridge that gap between methodological research and practice, we design case studies that illustrate how such a data-driven, inductive understanding of distribution shifts can enhance both data-centric and algorithmic interventions.",
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "authors": [
                {
                    "authorId": "2120846500",
                    "name": "Jiashuo Liu"
                },
                {
                    "authorId": "2021471490",
                    "name": "Tianyu Wang"
                },
                {
                    "authorId": "2153522384",
                    "name": "Peng Cui"
                },
                {
                    "authorId": "40281109",
                    "name": "Hongseok Namkoong"
                }
            ]
        },
        {
            "paperId": "9899ca21399eb30d1800eb5c4b083c3c89533eb4",
            "title": "Predictive Heterogeneity: Measures and Applications",
            "abstract": "As an intrinsic and fundamental property of big data, data heterogeneity exists in a variety of real-world applications, such as precision medicine, autonomous driving, financial applications, etc. For machine learning algorithms, the ignorance of data heterogeneity will greatly hurt the generalization performance and the algorithmic fairness, since the prediction mechanisms among different sub-populations are likely to differ from each other. In this work, we focus on the data heterogeneity that affects the prediction of machine learning models, and firstly propose the \\emph{usable predictive heterogeneity}, which takes into account the model capacity and computational constraints. We prove that it can be reliably estimated from finite data with probably approximately correct (PAC) bounds. Additionally, we design a bi-level optimization algorithm to explore the usable predictive heterogeneity from data. Empirically, the explored heterogeneity provides insights for sub-population divisions in income prediction, crop yield prediction and image classification tasks, and leveraging such heterogeneity benefits the out-of-distribution generalization performance.",
            "fieldsOfStudy": [
                "Computer Science",
                "Mathematics"
            ],
            "authors": [
                {
                    "authorId": "2120846500",
                    "name": "Jiashuo Liu"
                },
                {
                    "authorId": "39903185",
                    "name": "Jiayun Wu"
                },
                {
                    "authorId": "48218911",
                    "name": "B. Li"
                },
                {
                    "authorId": "2135616913",
                    "name": "Peng Cui"
                }
            ]
        },
        {
            "paperId": "b61b1c2e5827548134b64c4095b8c3c3b1b9ed84",
            "title": "Exploring and Exploiting Data Heterogeneity in Recommendation",
            "abstract": "Massive amounts of data are the foundation of data-driven recommendation models. As an inherent nature of big data, data heterogeneity widely exists in real-world recommendation systems. It reflects the differences in the properties among sub-populations. Ignoring the heterogeneity in recommendation data could limit the performance of recommendation models, hurt the sub-populational robustness, and make the models misled by biases. However, data heterogeneity has not attracted substantial attention in the recommendation community. Therefore, it inspires us to adequately explore and exploit heterogeneity for solving the above problems and assisting data analysis. In this work, we focus on exploring two representative categories of heterogeneity in recommendation data that is the heterogeneity of prediction mechanism and covariate distribution and propose an algorithm that explores the heterogeneity through a bilevel clustering method. Furthermore, the uncovered heterogeneity is exploited for two purposes in recommendation scenarios which are prediction with multiple sub-models and supporting debias. Extensive experiments on real-world data validate the existence of heterogeneity in recommendation data and the effectiveness of exploring and exploiting data heterogeneity in recommendation.",
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "authors": [
                {
                    "authorId": "2117418792",
                    "name": "Zimu Wang"
                },
                {
                    "authorId": "2120846500",
                    "name": "Jiashuo Liu"
                },
                {
                    "authorId": "145742335",
                    "name": "Hao Zou"
                },
                {
                    "authorId": "51258901",
                    "name": "Xingxuan Zhang"
                },
                {
                    "authorId": "2145031333",
                    "name": "Yue He"
                },
                {
                    "authorId": "2218202008",
                    "name": "Dongxu Liang"
                },
                {
                    "authorId": "2153522384",
                    "name": "Peng Cui"
                }
            ]
        }
    ]
}