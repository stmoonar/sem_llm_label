{
    "authorId": "2193279092",
    "papers": [
        {
            "paperId": "9573e2025440219a1d3393664b3c80bda51ac8f4",
            "title": "Prompt-Based Monte-Carlo Tree Search for Goal-Oriented Dialogue Policy Planning",
            "abstract": "Planning for goal-oriented dialogue often requires simulating future dialogue interactions and estimating task progress. Many approaches thus consider training neural networks to perform look-ahead search algorithms such as A* search and Monte Carlo Tree Search (MCTS). However, this training often requires abundant annotated data, which creates challenges when faced with noisy annotations or low-resource settings. We introduce GDP-Zero, an approach using Open-Loop MCTS to perform goal-oriented dialogue policy planning without any model training. GDP-Zero prompts a large language model to act as a policy prior, value function, user simulator, and system model during the tree search. We evaluate GDP-Zero on the goal-oriented task PersuasionForGood, and find that its responses are preferred over ChatGPT up to 59.32% of the time, and are rated more persuasive than ChatGPT during interactive evaluations.",
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "authors": [
                {
                    "authorId": "2193279092",
                    "name": "Xiao Yu"
                },
                {
                    "authorId": "66615738",
                    "name": "Maximillian Chen"
                },
                {
                    "authorId": "144007938",
                    "name": "Zhou Yu"
                }
            ]
        },
        {
            "paperId": "ed2221b2260169acf5fe962cf757e46082f85bbf",
            "title": "Controllable Mixed-Initiative Dialogue Generation through Prompting",
            "abstract": "Mixed-initiative dialogue tasks involve repeated exchanges of information and conversational control. Conversational agents gain control by generating responses that follow particular dialogue intents or strategies, prescribed by a policy planner. The standard approach has been fine-tuning pre-trained language models to perform generation conditioned on these intents. However, these supervised generation models are limited by the cost and quality of data annotation.We instead prompt large language models as a drop-in replacement to fine-tuning on conditional generation. We formalize prompt construction for controllable mixed-initiative dialogue. Our findings show improvements over fine-tuning and ground truth responses according to human evaluation and automatic metrics for two tasks: PersuasionForGood and Emotional Support Conversations.",
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "authors": [
                {
                    "authorId": "66615738",
                    "name": "Maximillian Chen"
                },
                {
                    "authorId": "2193279092",
                    "name": "Xiao Yu"
                },
                {
                    "authorId": "8299781",
                    "name": "Weiyan Shi"
                },
                {
                    "authorId": "2216556621",
                    "name": "Urvi Awasthi"
                },
                {
                    "authorId": "2167255986",
                    "name": "Zhou Yu"
                }
            ]
        },
        {
            "paperId": "1660de28d9f1121e7f0116b92ed9e21e17eb30aa",
            "title": "KRLS: Improving End-to-End Response Generation in Task Oriented Dialog with Reinforced Keywords Learning",
            "abstract": "In task-oriented dialogs (TOD), reinforcement learning (RL) algorithms train a model to directly optimize response for task-related metrics. However, RL needs to perform exploration, which can be time-consuming due to the slow auto-regressive sequence generation process. We investigate an approach to create a more efficient RL-based algorithm to improve TOD performance in an offline setting. First, we use a faster generation procedure that samples from independent next-word distributions after training the language model (LM) with supervised learning. We then introduce a fine-grained reward function to help the model focus on learning key information in a dialog, by measuring the importance and semantic closeness of each generated token. Experiments on the MultiWoZ dataset show our new training algorithm, Keywords Reinforcement Learning with Next-word Sampling (KRLS), achieves state-of-the-art performance on the end-to-end response generation task, with a 15% training time reduction compared to a standard RL algorithm using auto-regressive generation.",
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "authors": [
                {
                    "authorId": "2193279092",
                    "name": "Xiao Yu"
                },
                {
                    "authorId": "2152862795",
                    "name": "Qingyang Wu"
                },
                {
                    "authorId": "143857311",
                    "name": "Kun Qian"
                },
                {
                    "authorId": "144007938",
                    "name": "Zhou Yu"
                }
            ]
        },
        {
            "paperId": "40b023c55ee5aaefa4e972e0b619c7888a63622f",
            "title": "Distributed MQTT Brokers at Network Edges: A Study on Message Dissemination",
            "abstract": "Edge computing attempts to deliver low-latency services by offloading data storage and processing from remote data centers to distributed edge servers near end users, whereas network protocols, designed for centralized management, do not internally scale to distributed edge scenarios. In this paper, we establish the message dissemination support of MQTT, a de facto protocol for Internet of Things, for fully distributed edge networks. We summarize and formulate existing mechanisms, namely publication flooding and subscription flooding, and propose a topic-centric solution called selective subscription forwarding, which forwards subscriptions only when necessary by leveraging the topic containment of MQTT messages and therefore reduces inter-broker traffics. Evaluation results demonstrate that compared with existing solutions, more than 40% subscription traffic can be reduced with the proposed mechanism.",
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "authors": [
                {
                    "authorId": "35490134",
                    "name": "Luoyao Hao"
                },
                {
                    "authorId": "2193279092",
                    "name": "Xiao Yu"
                },
                {
                    "authorId": "2186382099",
                    "name": "Tingrui Zhang"
                },
                {
                    "authorId": "1700719",
                    "name": "H. Schulzrinne"
                }
            ]
        },
        {
            "paperId": "b274acf5b045f762ff6269b4eef25cff90fc9e4e",
            "title": "FastKASSIM: A Fast Tree Kernel-Based Syntactic Similarity Metric",
            "abstract": "Syntax is a fundamental component of language, yet few metrics have been employed to capture syntactic similarity or coherence at the utterance- and document-level. The existing standard document-level syntactic similarity metric is computationally expensive and performs inconsistently when faced with syntactically dissimilar documents. To address these challenges, we present FastKASSIM, a metric for utterance- and document-level syntactic similarity which pairs and averages the most similar constituency parse trees between a pair of documents based on tree kernels. FastKASSIM is more robust to syntactic dissimilarities and runs up to to 5.32 times faster than its predecessor over documents in the r/ChangeMyView corpus. FastKASSIM\u2019s improvements allow us to examine hypotheses in two settings with large documents. We find that syntactically similar arguments on r/ChangeMyView tend to be more persuasive, and that syntax is predictive of authorship attribution in the Australian High Court Judgment corpus.",
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "authors": [
                {
                    "authorId": "66615738",
                    "name": "Maximillian Chen"
                },
                {
                    "authorId": "2109063802",
                    "name": "Caitlyn Chen"
                },
                {
                    "authorId": "2193279092",
                    "name": "Xiao Yu"
                },
                {
                    "authorId": "144007938",
                    "name": "Zhou Yu"
                }
            ]
        },
        {
            "paperId": "bf2755f9014befbc3c02262f6770ab7605aac86d",
            "title": "Improving Model Training via Self-learned Label Representations",
            "abstract": "Modern neural network architectures have shown remarkable success in several large-scale classification and prediction tasks. Part of the success of these architectures is their flexibility to transform the data from the raw input representations (e.g. pixels for vision tasks, or text for natural language processing tasks) to one-hot output encoding. While much of the work has focused on studying how the input gets transformed to the one-hot encoding, very little work has examined the effectiveness of these one-hot labels. In this work, we demonstrate that more sophisticated label representations are better for classification than the usual one-hot encoding. We propose Learning with Adaptive Labels (LwAL) algorithm, which simultaneously learns the label representation while training for the classification task. These learned labels can significantly cut down on the training time (usually by more than 50%) while often achieving better test accuracies. Our algorithm introduces negligible additional parameters and has a minimal computational overhead. Along with improved training times, our learned labels are semantically meaningful and can reveal hierarchical relationships that may be present in the data.",
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "authors": [
                {
                    "authorId": "2193279092",
                    "name": "Xiao Yu"
                },
                {
                    "authorId": "39706047",
                    "name": "Nakul Verma"
                }
            ]
        }
    ]
}