{
    "authorId": "2265723835",
    "papers": [
        {
            "paperId": "76830c84fbb48fe22e044effa6f567daf13665ef",
            "title": "Dynamically Configurable FIR Filters Based on Serial MACs and Systolic Arrays",
            "abstract": "FIR (Finite Impulse Response) filters are widely used in digital communication systems, digital image processing, and many other fields. A great deal of research has been done on the flexible configuration of FIR filters, particularly on the dynamic adjustment of coefficients and orders. Existing FIR filter structures can be configured to a higher-order filter for a lower-order use, leading to low hardware utilization. This paper presents a dynamically configurable architecture for FIR filters based on a novel architecture with systolic arrays and serial multiply accumulators (MACs). This design can be configured to a higher-order filter or to several independent lower-order filters, thus increasing utilization. We demonstrate a 2048-order FIR filter that can be configured to a minimum of 16 orders and a maximum of 128 channels using only 256 multipliers and adders.",
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "authors": [
                {
                    "authorId": "2309522156",
                    "name": "Bo Ruan"
                },
                {
                    "authorId": "2115196093",
                    "name": "Limin Jiang"
                },
                {
                    "authorId": "2265723835",
                    "name": "Shan Cao"
                },
                {
                    "authorId": "2261778994",
                    "name": "Zhiyuan Jiang"
                }
            ]
        },
        {
            "paperId": "7b1aacb640da5adbd7a69c0d5265a31b984c49bd",
            "title": "Hybrid-Grained Pruning and Hardware Acceleration for Convolutional Neural Networks",
            "abstract": "Throughout various convolutional neural network (CNN) models, the sparsity increases as the network deepens, which poses significant potential to model compression and hardware acceleration. In this paper, a dual-factor hybrid-grained pruning method is introduced to make a good balance between model compression and accuracy preservation. The pro-posed pruning method combines hardware-friendly unstructured vector-level pruning with structured filter-level pruning to explore multiple grains of sparsity in CNNs. The architecture of the corresponding hardware accelerator is then proposed based on the row-based convolution dataflow, which could fully utilize the hybrid sparsity to accelerate CNN processing. Experimental results demonstrate that the proposed method increases the compression rate by 1.08\u00d7 while causing 0.21% accuracy loss compared to the state-of-the-art filter pruning method in VGG16, and 2.39% hardware resource increase compared to the accelerator without sparsity optimization.",
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "authors": [
                {
                    "authorId": "2281280539",
                    "name": "Yu Li"
                },
                {
                    "authorId": "2265723835",
                    "name": "Shan Cao"
                },
                {
                    "authorId": "2311820607",
                    "name": "Beining Zhao"
                },
                {
                    "authorId": "2259237565",
                    "name": "Wei Zhang"
                },
                {
                    "authorId": "2261778994",
                    "name": "Zhiyuan Jiang"
                }
            ]
        },
        {
            "paperId": "8bc1d22d03432b83d57272138079ca4a7eed2095",
            "title": "A Hierarchical Dataflow-Driven Heterogeneous Architecture for Wireless Baseband Processing",
            "abstract": "Wireless baseband processing (WBP) is a key element of wireless communications, with a series of signal processing modules to improve data throughput and counter channel fading. Conventional hardware solutions, such as digital signal processors (DSPs) and more recently, graphic processing units (GPUs), provide various degrees of parallelism, yet they both fail to take into account the cyclical and consecutive character of WBP. Furthermore, the large amount of data in WBPs cannot be processed quickly in symmetric multiprocessors (SMPs) due to the unpredictability of memory latency. To address this issue, we propose a hierarchical dataflow-driven architecture to accelerate WBP. A pack-and-ship approach is presented under a non-uniform memory access (NUMA) architecture to allow the subordinate tiles to operate in a bundled access and execute manner. We also propose a multi-level dataflow model and the related scheduling scheme to manage and allocate the heterogeneous hardware resources. Experiment results demonstrate that our prototype achieves $2\\times$ and $2.3\\times$ speedup in terms of normalized throughput and single-tile clock cycles compared with GPU and DSP counterparts in several critical WBP benchmarks. Additionally, a link-level throughput of $288$ Mbps can be achieved with a $45$-core configuration.",
            "fieldsOfStudy": [
                "Computer Science",
                "Engineering"
            ],
            "authors": [
                {
                    "authorId": "2115196093",
                    "name": "Limin Jiang"
                },
                {
                    "authorId": "2288114035",
                    "name": "Yi Shi"
                },
                {
                    "authorId": "2288143796",
                    "name": "Haiqin Hu"
                },
                {
                    "authorId": "2287930558",
                    "name": "Qingyu Deng"
                },
                {
                    "authorId": "2287981828",
                    "name": "Siyi Xu"
                },
                {
                    "authorId": "2288037503",
                    "name": "Yintao Liu"
                },
                {
                    "authorId": "2287929663",
                    "name": "Feng Yuan"
                },
                {
                    "authorId": "2288124898",
                    "name": "Si Wang"
                },
                {
                    "authorId": "2288065599",
                    "name": "Yihao Shen"
                },
                {
                    "authorId": "2287932415",
                    "name": "Fangfang Ye"
                },
                {
                    "authorId": "2265723835",
                    "name": "Shan Cao"
                },
                {
                    "authorId": "2261778994",
                    "name": "Zhiyuan Jiang"
                }
            ]
        },
        {
            "paperId": "548557c9cbf8752b211bc45230c76df33cbfd295",
            "title": "Parallel Computing for Energy-Efficient Baseband Processing in O-RAN: Synchronization and OFDM Implementation Based on SPMD",
            "abstract": "Open radio access network (O-RAN) is considered as a viable method for reducing the cost and enhancing the energy efficiency of cellular networks, due to its native incorporation of intelligence and open interfaces. However, the processing delay of software-based wireless protocol stacks has hindered its development. This paper presents the implementation of parallel computing acceleration for an LTE baseband system based on single program multiple data (SPMD) methodology, and proposes detailed optimization strategies for the time-consuming synchronization and OFDM modulation modules in the system. Experiment results based on the implicit SPMD program compiler (ISPC) show that continuous memory access has a significant impact on the final acceleration effect. Moreover, the processing speed of software-based physical layer can be increased up to 10\u201330 times through SPMD.",
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "authors": [
                {
                    "authorId": "2288065599",
                    "name": "Yihao Shen"
                },
                {
                    "authorId": "2287929663",
                    "name": "Feng Yuan"
                },
                {
                    "authorId": "2265723835",
                    "name": "Shan Cao"
                },
                {
                    "authorId": "2261778994",
                    "name": "Zhiyuan Jiang"
                },
                {
                    "authorId": "2221285178",
                    "name": "Sheng Zhou"
                }
            ]
        },
        {
            "paperId": "82a12414a27969b9b644c08e4608db4c33b16631",
            "title": "An FPGA-based Low Latency Sensing and Communication Platform for Collaborative Autonomous Driving",
            "abstract": "Vehicle-Infrastructure cooperation is an advanced development stage of autonomous driving, which helps to upgrade the capability of vehicles by fully implementing real-time information interaction among vehicles, roads and pedestrians. However, perception, computing and communication are usually decoupled in today\u2019s vehicle-road coordination applications, which significantly adds delay and cost to the system. In this paper, we propose and implement a platform that integrates perception, computing and communication to provide timely roadside feature maps to vehicles for vision fusion. A neural processing unit (NPU) for computing and a cellular vehicle-to-everything (C-V2X) wireless baseband IP for communication are both implemented on FPGA. We evaluate the effectiveness of the proposed platform using CoBEVT algorithm on the camera track of the OPV2V perception dataset. The experimental result show that our platform can expand the view of vehicles as well as improve information freshness in terms of end-to-end delay.",
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "authors": [
                {
                    "authorId": "2155469922",
                    "name": "Wei Zhang"
                },
                {
                    "authorId": "2222887849",
                    "name": "Yuhang Gu"
                },
                {
                    "authorId": "153212289",
                    "name": "Yi-xing Shi"
                },
                {
                    "authorId": "2115196093",
                    "name": "Limin Jiang"
                },
                {
                    "authorId": "2265661770",
                    "name": "Shan Li"
                },
                {
                    "authorId": "2265719092",
                    "name": "Yijie Huang"
                },
                {
                    "authorId": "2265723835",
                    "name": "Shan Cao"
                },
                {
                    "authorId": "2261778994",
                    "name": "Zhiyuan Jiang"
                },
                {
                    "authorId": "2143666481",
                    "name": "Ruiqing Mao"
                },
                {
                    "authorId": "2221285178",
                    "name": "Sheng Zhou"
                }
            ]
        },
        {
            "paperId": "8bc56c5b3507b56f1048f29fcf28eefefa563e6e",
            "title": "Loop-Tiling Based Compiling Optimization for CNN Accelerators",
            "abstract": "With the rapid development of convolutional neural networks (CNNs), CNN accelerators have been a research focus and are continuously being developed. Loop tiling is a commonly deployed optimization method to guide hardware architecture design based on hardware resource constraints. However, the potential performance gain of loop tiling at the compiler phase is rarely considered. In this paper, a loop-tiling based compiling scheme is proposed, which could assist a large range of hardware architecture to improve the versatility and performance of inference. A network reorganization scheme is introduced which is customized to the target hardware architecture and reconstructed the network model in a more hardware-friendly manner. At the same time, the weight re-ordering is performed correspondingly to the newly generated network model to guarantee correct data access. Experimental results demonstrate that the proposed method could effectively enlarge the range of supported CNN models for CNN accelerators with various hardware configurations.",
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "authors": [
                {
                    "authorId": "2218352697",
                    "name": "Meiling Yang"
                },
                {
                    "authorId": "2265723835",
                    "name": "Shan Cao"
                },
                {
                    "authorId": "2259237565",
                    "name": "Wei Zhang"
                },
                {
                    "authorId": "2281280539",
                    "name": "Yu Li"
                },
                {
                    "authorId": "2261778994",
                    "name": "Zhiyuan Jiang"
                }
            ]
        }
    ]
}