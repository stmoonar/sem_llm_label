{
    "authorId": "5790290",
    "papers": [
        {
            "paperId": "b04aae9a1dac75f7e83f717d41bd5116e2c537ca",
            "title": "Functional Dependencies to Mitigate Data Bias",
            "abstract": "Technologies based on data are frequently adopted in many sensitive environments to build models that support important and life-changing decisions. As a result, for an application to be ethically reliable, it should be associated with tools to discover and mitigate bias in data, in order to avoid (possibly unintentional) unethical behaviors and the associated consequences. In this paper we propose a novel solution that, exploiting the notion of Functional Dependency and its variants - well-known data constraints - aims at enforcing fairness by discovering and solving discrimination in datasets. Our system first identifies the attributes of a dataset that encompass discrimination (e.g. gender, ethnicity or religion), generating a list of dependencies, then, based on this information, determines the smallest set of tuples that must be added or removed to mitigate such bias in the dataset. Experimental results on two real-world datasets demonstrated that our approach can greatly improve the ethical quality of data sources.",
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "authors": [
                {
                    "authorId": "25919018",
                    "name": "Fabio Azzalini"
                },
                {
                    "authorId": "5790290",
                    "name": "Chiara Criscuolo"
                },
                {
                    "authorId": "1779997",
                    "name": "L. Tanca"
                }
            ]
        },
        {
            "paperId": "b1119c6a7775c9c65bec45791e2668592039c565",
            "title": "SoCRATe: a Framework for Compensating Users Over Time with Limited Availability Recommendations",
            "abstract": "We present our preliminary ideas for developing SoCRATe, a framework and an online system dedicated to providing recommendations to users when items\u2019 availability is limited. SoCRATe is relevant to several real-world applications, among which movie and task recommendations. SoCRATe has several appealing features: it watches users as they consume recommendations and accounts for user feedback in refining recommendations in the next round, it implements loss compensation strategies to make up for sub-optimal recommendations, in terms of accuracy, when items have limited availability, and it decides when to re-generate recommendations on a need-based fashion. SoCRATe accommodates real users as well as simulated users to enable testing multiple recommendation choice models. To frame evaluation, SoCRATe introduces a new set of measures that capture recommendation accuracy over time as well as throughput and user satisfaction. All these features make SoCRATe unique and able to adapt recommendations to user preferences in a resource-limited setting.",
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "authors": [
                {
                    "authorId": "25867417",
                    "name": "Davide Azzalini"
                },
                {
                    "authorId": "25919018",
                    "name": "Fabio Azzalini"
                },
                {
                    "authorId": "5790290",
                    "name": "Chiara Criscuolo"
                },
                {
                    "authorId": "2182555493",
                    "name": "Tommaso Dolci"
                },
                {
                    "authorId": "3152861",
                    "name": "D. Martinenghi"
                },
                {
                    "authorId": "1779997",
                    "name": "L. Tanca"
                },
                {
                    "authorId": "1403657578",
                    "name": "S. Amer-Yahia"
                }
            ]
        },
        {
            "paperId": "c0922becac3bfe298ff632f1999bf060775bd9ea",
            "title": "FAIR-DB: A system to discover unfairness in datasets",
            "abstract": "In our everyday lives, technologies based on data play an increasingly important role. With the widespread adoption of decision making systems also in very sensitive environments, fairness has become a very important topic of discussion within the data science community. In this context, it is crucial to ensure that the data on which we base these decisions, are fair, and do not reflect historical biases. In this demo, we propose FAIR-DB (FunctionAl dependencIes to discoveR Data Bias), a system that exploiting the notion of Functional Dependency, a particular type of constraint on the data, can discover unethical behaviours in a dataset. The proposed solution is implemented as a web-based application, that, given an input dataset, generates such dependencies, walks the user trough their analysis, and finally provides many insights about bias present in the data. Our tool uses a novel metric to evaluate the unfairness present in datasets, identifies the attributes that encompass discrimination (e.g. ethnicity, sex or religion), and provides very precise information about the groups treated unequally. We also provide a detailed description of the system architecture and present a demonstration scenario, based on a real-world dataset frequently used in the field of computer ethics.",
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "authors": [
                {
                    "authorId": "25919018",
                    "name": "Fabio Azzalini"
                },
                {
                    "authorId": "5790290",
                    "name": "Chiara Criscuolo"
                },
                {
                    "authorId": "1779997",
                    "name": "L. Tanca"
                }
            ]
        },
        {
            "paperId": "c9c84ab6b1bb88cd3368092ea0feadf263c47d8a",
            "title": "E-FAIR-DB: Functional Dependencies to Discover Data Bias and Enhance Data Equity",
            "abstract": "Decisions based on algorithms and systems generated from data have become essential tools that pervade all aspects of our daily lives; for these advances to be reliable, the results should be accurate but should also respect all the facets of data equity [11]. In this context, the concepts of Fairness and Diversity have become relevant topics of discussion within the field of Data Science Ethics and, in general, in Data Science. Although data equity is desirable, reconciling this property with accurate decision-making is a critical tradeoff, because applying a repair procedure to restore equity might modify the original data in such a way that the final decision is inaccurate w.r.t. the ultimate objective of the analysis. In this work, we propose E-FAIR-DB, a novel solution that, exploiting the notion of Functional Dependency\u2014a type of data constraint\u2014aims at restoring data equity by discovering and solving discrimination in datasets. The proposed solution is implemented as a pipeline that, first, mines functional dependencies to detect and evaluate fairness and diversity in the input dataset, and then, based on these understandings and on the objective of the data analysis, mitigates data bias, minimizing the number of modifications. Our tool can identify, through the mined dependencies, the attributes of the database that encompass discrimination (e.g., gender, ethnicity, or religion); then, based on these dependencies, it determines the smallest amount of data that must be added and/or removed to mitigate such bias. We evaluate our proposal both through theoretical considerations and experiments on two real-world datasets.",
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "authors": [
                {
                    "authorId": "25919018",
                    "name": "Fabio Azzalini"
                },
                {
                    "authorId": "5790290",
                    "name": "Chiara Criscuolo"
                },
                {
                    "authorId": "1779997",
                    "name": "L. Tanca"
                }
            ]
        },
        {
            "paperId": "daff53367af4565f5c32e308155df57601f6eb26",
            "title": "SoCRATe: A Recommendation System with Limited-Availability Items",
            "abstract": "We demonstrate SoCRATe, an online system dedicated to providing adaptive recommendations to users when items have limited availability. SoCRATe is relevant to several real-world applications, among which movie and task recommendations. SoCRATe has several appealing features: (i) watching users as they consume recommendations and accounting for user feedback in refining recommendations in the next round; (ii) implementing loss compensation strategies to make up for sub-optimal recommendations, in terms of accuracy, when items have limited availability; (iii) deciding when to re-generate recommendations on a need-based fashion. SoCRATe accommodates real users as well as simulated users to enable testing multiple recommendation choice models. To frame evaluation, SoCRATe introduces a new set of measures that capture recommendation accuracy, user satisfaction and item consumption over time. All these features make SoCRATe unique and able to adapt recommendations to user preferences in a resource-limited setting. A video of SoCRATe is available at https://youtu.be/4wlaScc_rUo.",
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "authors": [
                {
                    "authorId": "25867417",
                    "name": "Davide Azzalini"
                },
                {
                    "authorId": "25919018",
                    "name": "Fabio Azzalini"
                },
                {
                    "authorId": "5790290",
                    "name": "Chiara Criscuolo"
                },
                {
                    "authorId": "2182555493",
                    "name": "Tommaso Dolci"
                },
                {
                    "authorId": "3152861",
                    "name": "D. Martinenghi"
                },
                {
                    "authorId": "1403657578",
                    "name": "S. Amer-Yahia"
                }
            ]
        },
        {
            "paperId": "08a7fa4cf4beeea652e5d5b6ed855a0dea9c9599",
            "title": "FAIR-DB: FunctionAl DependencIes to discoveR Data Bias",
            "abstract": "Computers and algorithms have become essential tools that per-vade all aspects of our daily lives; this technology is based on data and, for it to be reliable, we have to make sure that the data on which it is based on is fair and without bias. In this context, Fairness has become a relevant topic of discussion within the field of Data Science Ethics, and in general in Data Science. Today\u2019s applications should therefore be associated with tools to discover bias in data, in order to avoid (possibly unintentional) unethical behavior and consequences; as a result, technologies that accurately discover discrimination and bias in databases are of paramount importance. In this work we propose FAIR-DB (FunctionAl dependencIes to discoveR Data Bias), a novel solution to detect biases and discover discrimination in datasets, that exploits the notion of Functional Dependency, a particular type of constraint on the data. The proposed solution is implemented as a framework that focuses on the mining of such dependencies, also proposing some new metrics for evaluating the bias found in the input dataset. Our tool can identify the attributes of the database that encompass discrimination (e.g. gender, ethnicity or religion) and the ones that instead verify various fairness measures; moreover, based on special aspects of these metrics and the intrinsic nature of dependencies, the framework provides very precise information about the groups treated unequally, obtaining more insights regarding the bias present in dataset compared to other existing tools. Finally, our system also suggests possible future steps, by indicating the most appropriate (already existing) algorithms to correct the dataset on the basis of the computed results.",
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "authors": [
                {
                    "authorId": "25919018",
                    "name": "Fabio Azzalini"
                },
                {
                    "authorId": "5790290",
                    "name": "Chiara Criscuolo"
                },
                {
                    "authorId": "1779997",
                    "name": "L. Tanca"
                }
            ]
        }
    ]
}