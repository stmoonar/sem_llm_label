{
    "authorId": "2113235078",
    "papers": [
        {
            "paperId": "765ad480e2c6f08decce773c288709fcc7471594",
            "title": "Generalized Deep Mixed Models",
            "abstract": "We introduce generalized deep mixed model (GDMix), a class of machine learning models for large-scale recommender systems that combines the power of deep neural networks and the efficiency of logistic regression. GDMix leverages state-of-the-art deep neural networks (DNNs) as the global models (fixed effects), and further improves the performance by adding entity-specific personalized models (random effects). For instance, the click response from a particular user m to a job posting j may consist of contributions from a DNN model common to all users and job postings, a model specific to the user m and a model specific to the job j. GDMix models not only possess powerful modeling capabilities but also enjoy high training efficiency especially for web-scale recommender systems. We demonstrate the capabilities by detailing their use in Feed and Ads recommendation at LinkedIn. The source code for the GDMix training framework is available at https://github.com/linkedin/gdmix https://github.com/linkedin/gdmix under the BSD-2-Clause License.",
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "authors": [
                {
                    "authorId": "2113235078",
                    "name": "Jun Shi"
                },
                {
                    "authorId": "2156197059",
                    "name": "Chengming Jiang"
                },
                {
                    "authorId": "1633418058",
                    "name": "Aman Gupta"
                },
                {
                    "authorId": "1893250486",
                    "name": "Mingzhou Zhou"
                },
                {
                    "authorId": "1828232",
                    "name": "Yunbo Ouyang"
                },
                {
                    "authorId": "2181260857",
                    "name": "Q. Xiao"
                },
                {
                    "authorId": "25274194",
                    "name": "Qingquan Song"
                },
                {
                    "authorId": "2181446519",
                    "name": "Yi (Alice) Wu"
                },
                {
                    "authorId": "2175570239",
                    "name": "Haichao Wei"
                },
                {
                    "authorId": "1722362",
                    "name": "Huiji Gao"
                }
            ]
        },
        {
            "paperId": "0b8c232cf1feadca218fa9ef74c7e6b3db951564",
            "title": "Causal Incremental Graph Convolution for Recommender System Retraining",
            "abstract": "The real-world recommender system needs to be regularly retrained to keep with the new data. In this work, we consider how to efficiently retrain graph convolution network (GCN)-based recommender models that are state-of-the-art techniques for the collaborative recommendation. To pursue high efficiency, we set the target as using only new data for model updating, meanwhile not sacrificing the recommendation accuracy compared with full model retraining. This is nontrivial to achieve since the interaction data participates in both the graph structure for model construction and the loss function for model learning, whereas the old graph structure is not allowed to use in model updating. Toward the goal, we propose a causal incremental graph convolution (IGC) approach, which consists of two new operators named IGC and colliding effect distillation (CED) to estimate the output of full graph convolution. In particular, we devise simple and effective modules for IGC to ingeniously combine the old representations and the incremental graph and effectively fuse the long- and short-term preference signals. CED aims to avoid the out-of-date issue of inactive nodes that are not in the incremental graph, which connects the new data with inactive nodes through causal inference. In particular, CED estimates the causal effect of new data on the representation of inactive nodes through the control of their collider. Extensive experiments on three real-world datasets demonstrate both accuracy gains and significant speed-ups over the existing retraining mechanism.",
            "fieldsOfStudy": [
                "Computer Science",
                "Medicine"
            ],
            "authors": [
                {
                    "authorId": "2046758017",
                    "name": "Sihao Ding"
                },
                {
                    "authorId": "2163400298",
                    "name": "Fuli Feng"
                },
                {
                    "authorId": "7792071",
                    "name": "Xiangnan He"
                },
                {
                    "authorId": "2114122035",
                    "name": "Yong Liao"
                },
                {
                    "authorId": "2113235078",
                    "name": "Jun Shi"
                },
                {
                    "authorId": "1699819",
                    "name": "Yongdong Zhang"
                }
            ]
        },
        {
            "paperId": "16b0573b8a99746bd56c725bbbacab985be58557",
            "title": "AutoDim: Field-aware Embedding Dimension Searchin Recommender Systems",
            "abstract": "Practical large-scale recommender systems usually contain thousands of feature fields from users, items, contextual information, and their interactions. Most of them empirically allocate a unified dimension to all feature fields, which is memory inefficient. Thus it is highly desired to assign various embedding dimensions to different feature fields according to their importance and predictability. Due to the large amounts of feature fields and the nuanced relationship between embedding dimensions with feature distributions and neural network architectures, manually allocating embedding dimensions in practical recommender systems can be challenging. To this end, we propose an AutoML-based framework (AutoDim) in this paper, which can automatically select dimensions for different feature fields in a data-driven fashion. Specifically, we first proposed an end-to-end differentiable framework that can calculate the weights over various dimensions in a soft and continuous manner for feature fields, and an AutoML-based optimization algorithm; then, we derive a hard and discrete embedding component architecture according to the maximal weights and retrain the whole recommender framework. We conduct extensive experiments on benchmark datasets to validate the effectiveness of AutoDim.",
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "authors": [
                {
                    "authorId": "2733057",
                    "name": "Xiangyu Zhao"
                },
                {
                    "authorId": "66442354",
                    "name": "Haochen Liu"
                },
                {
                    "authorId": "2146672392",
                    "name": "Hui Liu"
                },
                {
                    "authorId": "1736632",
                    "name": "Jiliang Tang"
                },
                {
                    "authorId": "2109155757",
                    "name": "Weiwei Guo"
                },
                {
                    "authorId": "2113235078",
                    "name": "Jun Shi"
                },
                {
                    "authorId": "16230274",
                    "name": "Sida Wang"
                },
                {
                    "authorId": "1722362",
                    "name": "Huiji Gao"
                },
                {
                    "authorId": "143947042",
                    "name": "Bo Long"
                }
            ]
        },
        {
            "paperId": "73b1ca258d3440e7690ddf0db756e4ea08061705",
            "title": "Incremental Learning for Personalized Recommender Systems",
            "abstract": "Ubiquitous personalized recommender systems are built to achieve two seemingly conflicting goals, to serve high quality content tailored to individual user's taste and to adapt quickly to the ever changing environment. The former requires a complex machine learning model that is trained on a large amount of data; the latter requires frequent update to the model. We present an incremental learning solution to provide both the training efficiency and the model quality. Our solution is based on sequential Bayesian update and quadratic approximation. Our focus is on large-scale personalized logistic regression models, with extensions to deep learning models. This paper fills in the gap between the theory and the practice by addressing a few implementation challenges that arise when applying incremental learning to large personalized recommender systems. Detailed offline and online experiments demonstrated our approach can significantly shorten the training time while maintaining the model accuracy. The solution is deployed in LinkedIn and directly applicable to industrial scale recommender systems.",
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "authors": [
                {
                    "authorId": "1828232",
                    "name": "Yunbo Ouyang"
                },
                {
                    "authorId": "2113235078",
                    "name": "Jun Shi"
                },
                {
                    "authorId": "2799847",
                    "name": "Haichao Wei"
                },
                {
                    "authorId": "1722362",
                    "name": "Huiji Gao"
                }
            ]
        },
        {
            "paperId": "dbc40e7fa1f9fdfd8e5a13db7cf71d020fa7990a",
            "title": "Logit Attenuating Weight Normalization",
            "abstract": "Over-parameterized deep networks trained using gradient-based optimizers are a popular choice for solving classification and ranking problems. Without appropriately tuned $\\ell_2$ regularization or weight decay, such networks have the tendency to make output scores (logits) and network weights large, causing training loss to become too small and the network to lose its adaptivity (ability to move around) in the parameter space. Although regularization is typically understood from an overfitting perspective, we highlight its role in making the network more adaptive and enabling it to escape more easily from weights that generalize poorly. To provide such a capability, we propose a method called Logit Attenuating Weight Normalization (LAWN), that can be stacked onto any gradient-based optimizer. LAWN controls the logits by constraining the weight norms of layers in the final homogeneous sub-network. Empirically, we show that the resulting LAWN variant of the optimizer makes a deep network more adaptive to finding minimas with superior generalization performance on large-scale image classification and recommender systems. While LAWN is particularly impressive in improving Adam, it greatly improves all optimizers when used with large batch sizes",
            "fieldsOfStudy": [
                "Computer Science",
                "Mathematics"
            ],
            "authors": [
                {
                    "authorId": "1633418058",
                    "name": "Aman Gupta"
                },
                {
                    "authorId": "2051517",
                    "name": "R. Ramanath"
                },
                {
                    "authorId": "2113235078",
                    "name": "Jun Shi"
                },
                {
                    "authorId": "2123334249",
                    "name": "Anika Ramachandran"
                },
                {
                    "authorId": "2148335442",
                    "name": "Sirou Zhou"
                },
                {
                    "authorId": "1893250486",
                    "name": "Mingzhou Zhou"
                },
                {
                    "authorId": "144106136",
                    "name": "S. Keerthi"
                }
            ]
        },
        {
            "paperId": "ea98c1074a20a6e6d2235f7844f70dfb370d1446",
            "title": "Memory-efficient Embedding for Recommendations",
            "abstract": "Practical large-scale recommender systems usually contain thousands of feature fields from users, items, contextual information, and their interactions. Most of them empirically allocate a unified dimension to all feature fields, which is memory inefficient. Thus it is highly desired to assign different embedding dimensions to different feature fields according to their importance and predictability. Due to the large amounts of feature fields and the nuanced relationship between embedding dimensions with feature distributions and neural network architectures, manually allocating embedding dimensions in practical recommender systems can be very difficult. To this end, we propose an AutoML based framework (AutoDim) in this paper, which can automatically select dimensions for different feature fields in a data-driven fashion. Specifically, we first proposed an end-to-end differentiable framework that can calculate the weights over various dimensions for feature fields in a soft and continuous manner with an AutoML based optimization algorithm; then we derive a hard and discrete embedding component architecture according to the maximal weights and retrain the whole recommender framework. We conduct extensive experiments on benchmark datasets to validate the effectiveness of the AutoDim framework.",
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "authors": [
                {
                    "authorId": "2733057",
                    "name": "Xiangyu Zhao"
                },
                {
                    "authorId": "66442354",
                    "name": "Haochen Liu"
                },
                {
                    "authorId": "2146672392",
                    "name": "Hui Liu"
                },
                {
                    "authorId": "1736632",
                    "name": "Jiliang Tang"
                },
                {
                    "authorId": "48544634",
                    "name": "Weiwei Guo"
                },
                {
                    "authorId": "2113235078",
                    "name": "Jun Shi"
                },
                {
                    "authorId": "16230274",
                    "name": "Sida Wang"
                },
                {
                    "authorId": "1722362",
                    "name": "Huiji Gao"
                },
                {
                    "authorId": "143947042",
                    "name": "Bo Long"
                }
            ]
        },
        {
            "paperId": "fb1e7c75979d748568a6795ea6e2710d458eee58",
            "title": "Deep Learning for Search and Recommender Systems in Practice",
            "abstract": "In this talk, we will go over the components of personalized search and recommender systems and demonstrate the applications of various deep learning techniques along the way. Search and recommender systems are probably the most prevalent ML powered application across the industry. They share most of the components composition and provide a user a ranked list of items, while there is subtle difference that a search system typically acts passively with a clear user intention in terms of queries and a recommender system acts more proactively. Deep learning has been wildly successful in solving complex tasks such as image recognition, speech recognition, natural language processing and understanding, machine translation, etc. In the area of personalized recommender systems, deep learning has been showing tremendous impact in recent years. Search and recommender systems can be staged roughly in three phases: 1. User and query understanding, where a query or a user profile are processed so that the systems can use the processed information to 2. retrieve all the related items (high recall) and 3. rank the items by the order of the most relevance to the user's intent (high precision). Each phase has its unique challenges but deep learning has been ubiquitously pushing beyond the limit. After walking through the talk, we hope the audience would gain some first-hand experience building a personalized search/recommender system using deep learning techniques.",
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "authors": [
                {
                    "authorId": "1887610660",
                    "name": "Zhoutong Fu"
                },
                {
                    "authorId": "1722362",
                    "name": "Huiji Gao"
                },
                {
                    "authorId": "48544634",
                    "name": "Weiwei Guo"
                },
                {
                    "authorId": "8117157",
                    "name": "S. Jha"
                },
                {
                    "authorId": "2117241913",
                    "name": "Jun Jia"
                },
                {
                    "authorId": "2109116511",
                    "name": "Xiaowei Liu"
                },
                {
                    "authorId": "143947042",
                    "name": "Bo Long"
                },
                {
                    "authorId": "2113235078",
                    "name": "Jun Shi"
                },
                {
                    "authorId": "16230274",
                    "name": "Sida Wang"
                },
                {
                    "authorId": "1893250486",
                    "name": "Mingzhou Zhou"
                }
            ]
        },
        {
            "paperId": "1bee5a41d301ae47fcc07470c937671784bf2681",
            "title": "Deep Natural Language Processing for Search and Recommender Systems",
            "abstract": "Search and recommender systems share many fundamental components including language understanding, retrieval and ranking, and language generation. Building powerful search and recommender systems requires processing natural language effectively and efficiently. Recent rapid growth of deep learning technologies has presented both opportunities and challenges in this area. This tutorial offers an overview of deep learning based natural language processing (NLP) for search and recommender systems from an industry perspective. It first introduces deep learning based NLP technologies, including language understanding and language generation. Then it details how those technologies can be applied to common tasks in search and recommender systems, including query and document understanding, retrieval and ranking, and language generation. Applications in LinkedIn production systems are presented. The tutorial concludes with discussion of future trend.",
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "authors": [
                {
                    "authorId": "2579583",
                    "name": "Weiwei Guo"
                },
                {
                    "authorId": "1722362",
                    "name": "Huiji Gao"
                },
                {
                    "authorId": "2113235078",
                    "name": "Jun Shi"
                },
                {
                    "authorId": "143947042",
                    "name": "Bo Long"
                },
                {
                    "authorId": "2146644146",
                    "name": "Liang Zhang"
                },
                {
                    "authorId": "34252531",
                    "name": "Bee-Chung Chen"
                },
                {
                    "authorId": "2596058",
                    "name": "D. Agarwal"
                }
            ]
        },
        {
            "paperId": "d63136d43757cbf74c7b163818243c830b5b8c70",
            "title": "Deep Natural Language Processing for Search Systems",
            "abstract": "Deep learning models have been very successful in many natural language processing tasks. Search engine works with rich natural language data, e.g., queries and documents, which implies great potential of applying deep natural language processing on such data to improve search performance. Furthermore, it opens an unprecedented opportunity to explore more advanced search experience, such as conversational search and chatbot. This tutorial offers an overview on deep learning based natural language processing for search systems from an industry perspective. We focus on how deep natural language processing powers search systems in practice. The tutorial introduces basic concepts, elaborates associated challenges, reviews the state-of-the-art approaches, covers end-to-end tasks in search systems with examples, and discusses the future trend.",
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "authors": [
                {
                    "authorId": "2579583",
                    "name": "Weiwei Guo"
                },
                {
                    "authorId": "1722362",
                    "name": "Huiji Gao"
                },
                {
                    "authorId": "2113235078",
                    "name": "Jun Shi"
                },
                {
                    "authorId": "143947042",
                    "name": "Bo Long"
                }
            ]
        }
    ]
}