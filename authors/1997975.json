{
    "authorId": "1997975",
    "papers": [
        {
            "paperId": "1bdcd5f05a5f8439f6e8601582f7e9adbb28cbce",
            "title": "BIP! NDR (NoDoiRefs): A Dataset of Citations From Papers Without DOIs in Computer Science Conferences and Workshops",
            "abstract": "In the field of Computer Science, conference and workshop papers serve as important contributions, carrying substantial weight in research assessment processes, compared to other disciplines. However, a considerable number of these papers are not assigned a Digital Object Identifier (DOI), hence their citations are not reported in widely used citation datasets like OpenCitations and Crossref, raising limitations to citation analysis. While the Microsoft Academic Graph (MAG) previously addressed this issue by providing substantial coverage, its discontinuation has created a void in available data. BIP! NDR aims to alleviate this issue and enhance the research assessment processes within the field of Computer Science. To accomplish this, it leverages a workflow that identifies and retrieves Open Science papers lacking DOIs from the DBLP Corpus, and by performing text analysis, it extracts citation information directly from their full text. The current version of the dataset contains more than 510K citations made by approximately 60K open access Computer Science conference or workshop papers that, according to DBLP, do not have a DOI.",
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "authors": [
                {
                    "authorId": "1396233390",
                    "name": "Paris Koloveas"
                },
                {
                    "authorId": "40056258",
                    "name": "Serafeim Chatzopoulos"
                },
                {
                    "authorId": "1997975",
                    "name": "Christos Tryfonopoulos"
                },
                {
                    "authorId": "1768540",
                    "name": "Thanasis Vergoulis"
                }
            ]
        },
        {
            "paperId": "842aeff2f2dd20e61bd5deb828c2bb0b02977d82",
            "title": "RoG\u00a7: A Pipeline for Automated Sensitive Data Identification and Anonymisation",
            "abstract": "Nowadays, the amount of data available online is constantly increasing. This data may contain sensitive or private information that can expose the person behind the data or be misused by malicious actors for identity theft, stalking, and other nefarious purposes. There is thus, a growing need to protect individuals' privacy and prevent data breaches in several application domains. Protecting data privacy though, is a complex and multifaceted issue that involves a range of legal, ethical, and technical considerations. In this paper, we discuss the challenges associated with data protection, the role of automated tools, and the effectiveness of identifying and anonymising sensitive data. We then, propose a fully-automated process for sensitive data identification and anonymisation, based on Natural Language Processing (NLP) techniques, that can be applied both in big diverse datasets and to a wide range of domains.",
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "authors": [
                {
                    "authorId": "2181833020",
                    "name": "Sotirios Nikoletos"
                },
                {
                    "authorId": "2070177783",
                    "name": "S. Vlachos"
                },
                {
                    "authorId": "2226316888",
                    "name": "Efstathios Zaragkas"
                },
                {
                    "authorId": "2252034",
                    "name": "C. Vassilakis"
                },
                {
                    "authorId": "1997975",
                    "name": "Christos Tryfonopoulos"
                },
                {
                    "authorId": "1963357",
                    "name": "Paraskevi Raftopoulou"
                }
            ]
        },
        {
            "paperId": "86bdbfd59ca9d0722833e583326ebeb895fa3fe6",
            "title": "Comparing Data Store Performance for Full-Text Search: To SQL or to NoSQL?",
            "abstract": ": The amount of textual data produced nowadays is constantly increasing as the number and variety of both new and reproduced textual information created by humans and (lately) also by bots is unprecedented. Storing, handling and querying such high volumes of textual data have become more challenging than ever and both research and industry have been using various alternatives, ranging from typical Relational Database Management Systems to specialised text engines and NoSQL databases, in an effort to cope with the volume. However, all these decisions are, largely, based on experience or personal preference for one system over another, since there is no performance comparison study that compares the available solutions regarding full-text search and retrieval. In this work, we fill this gap in the literature by systematically comparing four popular databases in full-text search scenarios and reporting their performance across different datasets, full-text search operators and parameters. To the best of our knowledge, our study is the first to go beyond the comparison of characteristics, like expressiveness of the query language or popularity, and actually compare popular relational, NoSQL, and textual data stores in terms of retrieval efficiency for full-text search. Moreover, our findings quantify the differences in full-text search performance between the examined solutions and reveal both anticipated and less anticipated results.",
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "authors": [
                {
                    "authorId": "39719523",
                    "name": "G. Fotopoulos"
                },
                {
                    "authorId": "1396233390",
                    "name": "Paris Koloveas"
                },
                {
                    "authorId": "1963357",
                    "name": "Paraskevi Raftopoulou"
                },
                {
                    "authorId": "1997975",
                    "name": "Christos Tryfonopoulos"
                }
            ]
        },
        {
            "paperId": "3ad88b425fd26a6475250bbafd525b12f17f960d",
            "title": "Atrapos: Real-time Evaluation of Metapath Query Workloads",
            "abstract": "Heterogeneous information networks (HINs) represent different types of entities and relationships between them. Exploring and mining HINs relies on metapath queries that identify pairs of entities connected by relationships of diverse semantics. While the real-time evaluation of metapath query workloads on large, web-scale HINs is highly demanding in computational cost, current approaches do not exploit interrelationships among the queries. In this paper, we present Atrapos, a new approach for the real-time evaluation of metapath query workloads that leverages a combination of efficient sparse matrix multiplication and intermediate result caching. Atrapos selects intermediate results to cache and reuse by detecting frequent sub-metapaths among workload queries in real time, using a tailor-made data structure, the Overlap Tree, and an associated caching policy. Our experimental study on real data shows that Atrapos accelerates exploratory data analysis and mining on HINs, outperforming off-the-shelf caching approaches and state-of-the-art research prototypes in all examined scenarios.",
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "authors": [
                {
                    "authorId": "40056258",
                    "name": "Serafeim Chatzopoulos"
                },
                {
                    "authorId": "1768540",
                    "name": "Thanasis Vergoulis"
                },
                {
                    "authorId": "1807115",
                    "name": "Dimitrios Skoutas"
                },
                {
                    "authorId": "7974521",
                    "name": "Theodore Dalamagas"
                },
                {
                    "authorId": "1997975",
                    "name": "Christos Tryfonopoulos"
                },
                {
                    "authorId": "1731655",
                    "name": "Panagiotis Karras"
                }
            ]
        },
        {
            "paperId": "1551d4c248f9081a83050c2af20e703c9af44940",
            "title": "VeTo-web: A Recommendation Tool for the Expansion of Sets of Scholars",
            "abstract": "Expanding a set of known experts with new ones that share similar expertise is a problem that emerges in various real-life applications. We demonstrate VeTo-web, an open source, publicly available tool that deals with this problem in the context of searching for academic experts. VeTo-web exploits analysis techniques for scholarly knowledge graphs to identify scholars that share similar research activities with a given expert group and offers a Web-based user interface to assist its users in expanding a set of academic experts with additional scholars with similar expertise.",
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "authors": [
                {
                    "authorId": "40056258",
                    "name": "Serafeim Chatzopoulos"
                },
                {
                    "authorId": "1768540",
                    "name": "Thanasis Vergoulis"
                },
                {
                    "authorId": "7974521",
                    "name": "Theodore Dalamagas"
                },
                {
                    "authorId": "1997975",
                    "name": "Christos Tryfonopoulos"
                }
            ]
        },
        {
            "paperId": "186318dd628d9e918e8d999289450c557ac7da83",
            "title": "Social Media Monitoring for IoT Cyber-Threats",
            "abstract": "The rapid development of IoT applications and their use in various fields of everyday life has resulted in an escalated number of different possible cyber-threats, and has consequently raised the need of securing IoT devices. Collecting Cyber-Threat Intelligence (e.g., zero-day vulnerabilities or trending exploits) from various online sources and utilizing it to proactively secure IoT systems or prepare mitigation scenarios has proven to be a promising direction. In this work, we focus on social media monitoring and investigate real-time Cyber-Threat Intelligence detection from the Twitter stream. Initially, we compare and extensively evaluate six different machine-learning based classification alternatives trained with vulnerability descriptions and tested with real-world data from the Twitter stream to identify the best-fitting solution. Subsequently, based on our findings, we propose a novel social media monitoring system tailored to the IoT domain; the system allows users to identify recent/trending vulnerabilities and exploits on IoT devices. Finally, to aid research on the field and support the reproducibility of our results we publicly release all annotated datasets created during this process.",
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "authors": [
                {
                    "authorId": "2087452260",
                    "name": "Sofia Alevizopoulou"
                },
                {
                    "authorId": "1396233390",
                    "name": "Paris Koloveas"
                },
                {
                    "authorId": "1997975",
                    "name": "Christos Tryfonopoulos"
                },
                {
                    "authorId": "1963357",
                    "name": "Paraskevi Raftopoulou"
                }
            ]
        },
        {
            "paperId": "2fac7757bda12659a7bce47682641aa7541d6a7f",
            "title": "Visualising Scientific Topic Evolution",
            "abstract": "The automatic extraction of topics is a standard technique for summarizing text corpora from various domains (e.g., news articles, transport or logistic reports, scientific publications) that has several applications. Since, in many cases, topics are subject to continuous change there is the need to monitor the evolution of a set of topics of interest, as the corresponding corpora are updated. The evolution of scientific topics, in particular, is of great interest for researchers, policy makers, fund managers, and other professionals/engineers in the research and academic community. In this work, we demonstrate a prototype that provides intuitive visualisations for the evolution of scientific topics providing insights about topic transformation, merging, and splitting during the recent years. Although the prototype works on top of a scientific text corpus, its implementation is generic and can be easily applied on texts from other domains, as well.",
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "authors": [
                {
                    "authorId": "13815532",
                    "name": "P. Deligiannis"
                },
                {
                    "authorId": "1768540",
                    "name": "Thanasis Vergoulis"
                },
                {
                    "authorId": "40056258",
                    "name": "Serafeim Chatzopoulos"
                },
                {
                    "authorId": "1997975",
                    "name": "Christos Tryfonopoulos"
                }
            ]
        },
        {
            "paperId": "336b5e6820e1fbee15af2945c9ee63453cac45c0",
            "title": "Efficient deep learning models for land cover image classification",
            "abstract": "\u2014The availability of the sheer volume of Copernicus Sentinel imagery has created new opportunities for land use land cover (LULC) mapping at large scales using deep learning. Training on such large datasets though is a non-trivial task. In this work we experiment with the BigEarthNet dataset for LULC image classi\ufb01cation and benchmark different state-of-the-art models, including Convolution Neural Networks, Multi-Layer Perceptron, Visual Transformer, Ef\ufb01cientNets and Wide Residual Networks (WRN) architectures. Our aim is to leverage classi\ufb01cation accuracy, training time and inference rate. We propose a framework based on Ef\ufb01cientNets for compound scaling of WRNs in terms of network depth, width and input data resolution, for ef\ufb01ciently training and testing different model setups. We design a novel scaled WRN architecture enhanced with an Ef\ufb01cient Channel Attention mechanism. Our proposed lightweight model has an order of magnitude less trainable parameters, achieves 4.5% higher averaged f-score classi\ufb01cation accuracy for all 19 LULC classes and is trained two times faster with respect to a ResNet50 state-of-the-art model that we use as a baseline. We provide access to more than 50 trained models, along with our code for distributed training on multiple GPU nodes.",
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "authors": [
                {
                    "authorId": "49032213",
                    "name": "I. Papoutsis"
                },
                {
                    "authorId": "2007384465",
                    "name": "N. Bountos"
                },
                {
                    "authorId": "2141215023",
                    "name": "Angelos Zavras"
                },
                {
                    "authorId": "145741802",
                    "name": "D. Michail"
                },
                {
                    "authorId": "1997975",
                    "name": "Christos Tryfonopoulos"
                }
            ]
        },
        {
            "paperId": "5052c1283d201a7ccab0135330c6d50d52f127f1",
            "title": "A System for Collecting, Managing, Analyzing and Sharing Diverse, Multi-Faceted Cultural Heritage and Tourism Data",
            "abstract": "Today, social media platforms and other online sources, like forums and review sites, offer an abundance of cultural and touristic information that is voluntarily offered by travelers; this information, although helpful for other travelers, is typically fragmented and thus cannot be easily leveraged to exploitable knowledge by scientists and other tourism stakeholders. In this work, we present a novel, integrated system for collecting, managing, analyzing and sharing diverse, multi-faceted cultural heritage/tourism-related data that aims to assist scientists in the cultural heritage domain and tourism stakeholders to gather and synthesize scattered information to exploitable knowledge. The proposed system is tailored to the tourism domain needs, and allows users with minimum effort and zero IT expertise to (i) gather data from both structured and unstructured/semi-structured online sources, (ii) leverage the data to knowledge via appropriate analysis and visualization tools, and (iii) share the collected data and gathered knowledge with other stakeholders via appropriate publish-subscribe mechanisms. The proposed system is entirely open-source, designed upon big data tools and principles for the data store, the analytics production, and the knowledge sharing, and targets both performance and usability.",
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "authors": [
                {
                    "authorId": "1726227610",
                    "name": "Kimon Deligiannis"
                },
                {
                    "authorId": "1963357",
                    "name": "Paraskevi Raftopoulou"
                },
                {
                    "authorId": "1997975",
                    "name": "Christos Tryfonopoulos"
                },
                {
                    "authorId": "2252034",
                    "name": "C. Vassilakis"
                }
            ]
        },
        {
            "paperId": "5b9629b6cb2e33917a6e4811dbb7ec0cf93d4e35",
            "title": "inTIME: A Machine Learning-Based Framework for Gathering and Leveraging Web Data to Cyber-Threat Intelligence",
            "abstract": "In today\u2019s world, technology has become deep-rooted and more accessible than ever over a plethora of different devices and platforms, ranging from company servers and commodity PCs to mobile phones and wearables, interconnecting a wide range of stakeholders such as households, organizations and critical infrastructures. The sheer volume and variety of the different operating systems, the device particularities, the various usage domains and the accessibility-ready nature of the platforms creates a vast and complex threat landscape that is difficult to contain. Staying on top of these evolving cyber-threats has become an increasingly difficult task that presently relies heavily on collecting and utilising cyber-threat intelligence before an attack (or at least shortly after, to minimize the damage) and entails the collection, analysis, leveraging and sharing of huge volumes of data. In this work, we put forward inTIME, a machine learning-based integrated framework that provides an holistic view in the cyber-threat intelligence process and allows security analysts to easily identify, collect, analyse, extract, integrate, and share cyber-threat intelligence from a wide variety of online sources including clear/deep/dark web sites, forums and marketplaces, popular social networks, trusted structured sources (e.g., known security databases), or other datastore types (e.g., pastebins). inTIME is a zero-administration, open-source, integrated framework that enables security analysts and security stakeholders to (i) easily deploy a wide variety of data acquisition services (such as focused web crawlers, site scrapers, domain downloaders, social media monitors), (ii) automatically rank the collected content according to its potential to contain useful intelligence, (iii) identify and extract cyber-threat intelligence and security artifacts via automated natural language understanding processes, (iv) leverage the identified intelligence to actionable items by semi-automatic entity disambiguation, linkage and correlation, and (v) manage, share or collaborate on the stored intelligence via open standards and intuitive tools. To the best of our knowledge, this is the first solution in the literature to provide an end-to-end cyber-threat intelligence management platform that is able to support the complete threat lifecycle via an integrated, simple-to-use, yet extensible framework.",
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "authors": [
                {
                    "authorId": "1396233390",
                    "name": "Paris Koloveas"
                },
                {
                    "authorId": "148186522",
                    "name": "Thanasis Chantzios"
                },
                {
                    "authorId": "2087452260",
                    "name": "Sofia Alevizopoulou"
                },
                {
                    "authorId": "1688897",
                    "name": "Spiros Skiadopoulos"
                },
                {
                    "authorId": "1997975",
                    "name": "Christos Tryfonopoulos"
                }
            ]
        }
    ]
}