{
    "authorId": "1750800",
    "papers": [
        {
            "paperId": "6eceea09df2c283c9378906283fb4cf3e9912fdd",
            "title": "Optimizing the Cray Graph Engine for performant analytics on cluster, SuperDome Flex, Shasta systems and cloud deployment",
            "abstract": "We present updates to the Cray Graph Engine, a high performance in\u2010memory semantic graph database, which enable performant execution across multiple architectures as well as deployment in a container to support cloud and as\u2010a\u2010service graph analytics. This paper discusses the changes required to port and optimize CGE to target multiple architectures, including Cray Shasta systems, large shared\u2010memory machines such as SuperDome Flex (SDF), and cluster environments such as Apollo systems. The porting effort focused primarily on removing dependences on XPMEM and Cray PGAS and replacing these with a simplified PGAS library based upon POSIX shared memory and one\u2010sided MPI, while preserving the existing Coarray\u2010C++ CGE code base. We also discuss the containerization of CGE using Singularity and the techniques required to enable container performance matching native execution. We present early benchmarking results for running CGE on the SDF, Infiniband clusters and Slingshot interconnect\u2010based Shasta systems.",
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "authors": [
                {
                    "authorId": "2913778",
                    "name": "Christopher D. Rickett"
                },
                {
                    "authorId": "3096072",
                    "name": "K. Maschhoff"
                },
                {
                    "authorId": "1750800",
                    "name": "S. Sukumar"
                }
            ]
        },
        {
            "paperId": "794ba58adbce4d1630bbf3e3001347c2643f9a65",
            "title": "Workflows Community Summit 2022: A Roadmap Revolution",
            "abstract": "Scientific workflows have become integral tools in broad scientific computing use cases. Science discovery is increasingly dependent on workflows to orchestrate large and complex scientific experiments that range from execution of a cloud-based data preprocessing pipeline to multi-facility instrument-to-edge-to-HPC computational workflows. Given the changing landscape of scientific computing and the evolving needs of emerging scientific applications, it is paramount that the development of novel scientific workflows and system functionalities seek to increase the efficiency, resilience, and pervasiveness of existing systems and applications. Specifically, the proliferation of machine learning/artificial intelligence (ML/AI) workflows, need for processing large scale datasets produced by instruments at the edge, intensification of near real-time data processing, support for long-term experiment campaigns, and emergence of quantum computing as an adjunct to HPC, have significantly changed the functional and operational requirements of workflow systems. Workflow systems now need to, for example, support data streams from the edge-to-cloud-to-HPC enable the management of many small-sized files, allow data reduction while ensuring high accuracy, orchestrate distributed services (workflows, instruments, data movement, provenance, publication, etc.) across computing and user facilities, among others. Further, to accelerate science, it is also necessary that these systems implement specifications/standards and APIs for seamless (horizontal and vertical) integration between systems and applications, as well as enabling the publication of workflows and their associated products according to the FAIR principles. This document reports on discussions and findings from the 2022 international edition of the Workflows Community Summit that took place on November 29 and 30, 2022.",
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "authors": [
                {
                    "authorId": "2140039842",
                    "name": "Rafael Ferreira da Silva"
                },
                {
                    "authorId": "1799983",
                    "name": "Rosa M. Badia"
                },
                {
                    "authorId": "2213299279",
                    "name": "Venkat Bala"
                },
                {
                    "authorId": "152409031",
                    "name": "Deborah Bard"
                },
                {
                    "authorId": "145466013",
                    "name": "P. Bremer"
                },
                {
                    "authorId": "2213305232",
                    "name": "Ian Buckley"
                },
                {
                    "authorId": "2304561021",
                    "name": "Silvina Ca\u00edno-Lores"
                },
                {
                    "authorId": "3091414",
                    "name": "K. Chard"
                },
                {
                    "authorId": "46555127",
                    "name": "C. Goble"
                },
                {
                    "authorId": "1693678",
                    "name": "S. Jha"
                },
                {
                    "authorId": "2059296518",
                    "name": "D. Katz"
                },
                {
                    "authorId": "33947553",
                    "name": "D. Laney"
                },
                {
                    "authorId": "145203664",
                    "name": "M. Parashar"
                },
                {
                    "authorId": "35531371",
                    "name": "F. Suter"
                },
                {
                    "authorId": "50329328",
                    "name": "N. Tyler"
                },
                {
                    "authorId": "2066071",
                    "name": "T. Uram"
                },
                {
                    "authorId": "1729053",
                    "name": "I. Altintas"
                },
                {
                    "authorId": "121299213",
                    "name": "S. Andersson"
                },
                {
                    "authorId": "144110414",
                    "name": "W. Arndt"
                },
                {
                    "authorId": "2057561277",
                    "name": "J. Aznar"
                },
                {
                    "authorId": "2062906007",
                    "name": "Jonathan Bader"
                },
                {
                    "authorId": "1960359",
                    "name": "B. Bali\u015b"
                },
                {
                    "authorId": "108377253",
                    "name": "Chris E. Blanton"
                },
                {
                    "authorId": "2199664",
                    "name": "K. Braghetto"
                },
                {
                    "authorId": "2651403",
                    "name": "Aharon Brodutch"
                },
                {
                    "authorId": "2213427261",
                    "name": "Paul Brunk"
                },
                {
                    "authorId": "1707417",
                    "name": "H. Casanova"
                },
                {
                    "authorId": "104449865",
                    "name": "Alba Cervera Lierta"
                },
                {
                    "authorId": "2213298896",
                    "name": "Justin Chigu"
                },
                {
                    "authorId": "1572245697",
                    "name": "T. Coleman"
                },
                {
                    "authorId": "2065988217",
                    "name": "Nick Collier"
                },
                {
                    "authorId": "2120657141",
                    "name": "Iacopo Colonnelli"
                },
                {
                    "authorId": "144108029",
                    "name": "Frederik Coppens"
                },
                {
                    "authorId": "144361904",
                    "name": "M. Crusoe"
                },
                {
                    "authorId": "2058475897",
                    "name": "W. Cunningham"
                },
                {
                    "authorId": "3362335",
                    "name": "B. Kinoshita"
                },
                {
                    "authorId": "3062856",
                    "name": "Paolo Di Tommaso"
                },
                {
                    "authorId": "2802678",
                    "name": "C. Doutriaux"
                },
                {
                    "authorId": "143916458",
                    "name": "M. Downton"
                },
                {
                    "authorId": "1799299",
                    "name": "W. Elwasif"
                },
                {
                    "authorId": "144504471",
                    "name": "B. Enders"
                },
                {
                    "authorId": "17606192",
                    "name": "Chris Erdmann"
                },
                {
                    "authorId": "1719226",
                    "name": "T. Fahringer"
                },
                {
                    "authorId": "84336109",
                    "name": "Ludmilla Figueiredo"
                },
                {
                    "authorId": "1698908",
                    "name": "Rosa Filgueira"
                },
                {
                    "authorId": "1443779643",
                    "name": "M. Foltin"
                },
                {
                    "authorId": "2850787",
                    "name": "A. Fouilloux"
                },
                {
                    "authorId": "2811678",
                    "name": "Luiz M. R. Gadelha"
                },
                {
                    "authorId": "2053600243",
                    "name": "Andrew Gallo"
                },
                {
                    "authorId": "2079451840",
                    "name": "A. G. Saez"
                },
                {
                    "authorId": "1398926410",
                    "name": "D. Garijo"
                },
                {
                    "authorId": "2027553659",
                    "name": "R. Gerlach"
                },
                {
                    "authorId": "2072840094",
                    "name": "Ryan E. Grant"
                },
                {
                    "authorId": "51124744",
                    "name": "Samuel Grayson"
                },
                {
                    "authorId": "2923900",
                    "name": "Patricia A. Grubel"
                },
                {
                    "authorId": "48985473",
                    "name": "Johan O. R. Gustafsson"
                },
                {
                    "authorId": "2308097253",
                    "name": "Val\u00e9rie Hayot-Sasson"
                },
                {
                    "authorId": "2053161325",
                    "name": "Oscar R. Hernandez"
                },
                {
                    "authorId": "1967862",
                    "name": "Marcus Hilbrich"
                },
                {
                    "authorId": "2205970689",
                    "name": "Annmary Justine"
                },
                {
                    "authorId": "152142617",
                    "name": "I. Laflotte"
                },
                {
                    "authorId": "151494370",
                    "name": "Fabian Lehmann"
                },
                {
                    "authorId": "50631038",
                    "name": "Andr\u00e9 Luckow"
                },
                {
                    "authorId": "2086648690",
                    "name": "Jakob Luettgau"
                },
                {
                    "authorId": "145341601",
                    "name": "K. Maheshwari"
                },
                {
                    "authorId": "3299313",
                    "name": "Motohiko Matsuda"
                },
                {
                    "authorId": "3421209",
                    "name": "Doriana Medic"
                },
                {
                    "authorId": "102153641",
                    "name": "P. Mendygral"
                },
                {
                    "authorId": "32733424",
                    "name": "M. Michalewicz"
                },
                {
                    "authorId": "2489735",
                    "name": "J. Nonaka"
                },
                {
                    "authorId": "40258733",
                    "name": "Maciej Pawlik"
                },
                {
                    "authorId": "34635073",
                    "name": "L. Pottier"
                },
                {
                    "authorId": "32809071",
                    "name": "Line C. Pouchard"
                },
                {
                    "authorId": "2213308235",
                    "name": "Mathias Putz"
                },
                {
                    "authorId": "46254996",
                    "name": "Santosh Kumar Radha"
                },
                {
                    "authorId": "1792683",
                    "name": "L. Ramakrishnan"
                },
                {
                    "authorId": "3445802",
                    "name": "S. Ristov"
                },
                {
                    "authorId": "1961788",
                    "name": "P. Romano"
                },
                {
                    "authorId": "21168032",
                    "name": "Daniel Rosendo"
                },
                {
                    "authorId": "3493555",
                    "name": "M. Ruefenacht"
                },
                {
                    "authorId": "2771040",
                    "name": "Katarzyna Rycerz"
                },
                {
                    "authorId": "2653506",
                    "name": "Nishant Saurabh"
                },
                {
                    "authorId": "144276915",
                    "name": "V. Savchenko"
                },
                {
                    "authorId": "2057456497",
                    "name": "Martin Schulz"
                },
                {
                    "authorId": "2037776232",
                    "name": "C. Simpson"
                },
                {
                    "authorId": "66188222",
                    "name": "R. Sirvent"
                },
                {
                    "authorId": "8884013",
                    "name": "Tyler J. Skluzacek"
                },
                {
                    "authorId": "1399487720",
                    "name": "S. Soiland-Reyes"
                },
                {
                    "authorId": "144712722",
                    "name": "Renan Souza"
                },
                {
                    "authorId": "1750800",
                    "name": "S. Sukumar"
                },
                {
                    "authorId": "48064827",
                    "name": "Ziheng Sun"
                },
                {
                    "authorId": "1746329",
                    "name": "A. Sussman"
                },
                {
                    "authorId": "1686699",
                    "name": "D. Thain"
                },
                {
                    "authorId": "2072191295",
                    "name": "Mikhail Titov"
                },
                {
                    "authorId": "50883695",
                    "name": "Benjam\u00edn Tovar"
                },
                {
                    "authorId": "2643562",
                    "name": "Aalap Tripathy"
                },
                {
                    "authorId": "1840916",
                    "name": "M. Turilli"
                },
                {
                    "authorId": "2165288240",
                    "name": "Bartosz Tuznik"
                },
                {
                    "authorId": "1942636",
                    "name": "H. V. Dam"
                },
                {
                    "authorId": "2006915860",
                    "name": "Aurelio Vivas"
                },
                {
                    "authorId": "47766095",
                    "name": "Logan T. Ward"
                },
                {
                    "authorId": "2946172",
                    "name": "Patrick M. Widener"
                },
                {
                    "authorId": "153569593",
                    "name": "Sean R. Wilkinson"
                },
                {
                    "authorId": "2169430585",
                    "name": "Justyna Zawalska"
                },
                {
                    "authorId": "2065914488",
                    "name": "M. Zulfiqar"
                }
            ]
        },
        {
            "paperId": "eb6aa1886412168e5f70adbde1b915587cf4b834",
            "title": "Towards Rapid Autonomous Electron Microscopy with Active Meta-Learning",
            "abstract": "We introduce a novel approach, Active Meta-learning, to improve computational control across various scientific experiments. It's particularly valuable for spectral reconstruction in STEM EELS nanoparticle plasmonic images. Traditionally, separate AI models were trained for each experiment via active learning, but this approach could face scalability issues with high-resolution data and the need for complex AI models due to intricate structure-property relationships. In this work we demonstrate the feasibility of learning AI structural representations across multiple experiments. We train a meta model from 10 prior experiments carried out such that the model can adapt to new unseen conditions in considerably less time than when trained from scratch. We utilize the Reptile algorithm, a first-order, model-agnostic meta-learning approach. To enhance and expand the meta-training dataset, conventional computer vision methods are applied to augment images from previous experiments. We observe up to \u223c30-40% reduction in the number of training epochs for active learning exploration. The approach will be extended to distributed meta-learning workflows; meta-model trained in HPC datacenter using data from different microscopy sites and pushed to individual sites for active learning.",
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "authors": [
                {
                    "authorId": "2266291943",
                    "name": "Gayathri Saranathan"
                },
                {
                    "authorId": "2266296359",
                    "name": "Martin Foltin"
                },
                {
                    "authorId": "2643562",
                    "name": "Aalap Tripathy"
                },
                {
                    "authorId": "144432098",
                    "name": "M. Ziatdinov"
                },
                {
                    "authorId": "2266291876",
                    "name": "Ann Mary Justine Koomthanam"
                },
                {
                    "authorId": "2238221125",
                    "name": "Suparna Bhattacharya"
                },
                {
                    "authorId": "2258418662",
                    "name": "Ayana Ghosh"
                },
                {
                    "authorId": "96565510",
                    "name": "Kevin M. Roccapriore"
                },
                {
                    "authorId": "1750800",
                    "name": "S. Sukumar"
                },
                {
                    "authorId": "2199436255",
                    "name": "Paolo Faraboschi"
                }
            ]
        },
        {
            "paperId": "be939f7a6a1d761299ba82a148706ead10cb2063",
            "title": "Survival of the Fittest Amidst the Cambrian Explosion of Processor Architectures for Artificial Intelligence : Invited Paper",
            "abstract": "The need for high performance computing in data-driven artificial intelligence (AI) workloads has led to the Cambrian explosion of processor architectures. As these novel processor architectures aim to evolve and thrive inside datacenters and cloud-services, we need to understand different figures-of-merit for device-, server- and rack-scale systems. Towards that goal, we share early-access hands-on experience with these processor/accelerator architectures. We describe an evaluation plan that includes carefully chosen neural network models to gauge the maturity of the hardware and software ecosystem. Our hands-on evaluation using benchmarks reveals significant benefits of hardware acceleration while exposing several blind spots in the software ecosystem. Ranking the benefits based on different figures of merit such as cost, energy, and adoption efficiency reveals a \"heterogenous\" future for production systems with multiple processor architectures in the edge-to-datacenter AI workflow.Preparing to survive in this heterogeneous future, we describe a method to profile and predict the performance benefits of a deep learning training workload on novel architectures. Our approach profiles the neural network model for memory, bandwidth and compute requirements by analyzing the model definition. Then, using profiling tools, we estimate the I/O and arithmetic intensity requirements at different batch sizes. By overlaying profiler results onto analytic roofline models of the emerging processor architectures, we identify opportunities for potential acceleration. We discuss how the interpretation of the roofline analysis can guide system architecture to deliver productive performance and conclude with recommendations to survive the Cambrian explosion.",
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "authors": [
                {
                    "authorId": "1750800",
                    "name": "S. Sukumar"
                },
                {
                    "authorId": "66948537",
                    "name": "J. Balma"
                },
                {
                    "authorId": "2110086543",
                    "name": "Cong Xu"
                },
                {
                    "authorId": "2400013",
                    "name": "S. Serebryakov"
                }
            ]
        },
        {
            "paperId": "aa0b401f21ee75696bb7260423fc72a9a8fb716b",
            "title": "Deep Learning Predicts Protein-Ligand Interactions",
            "abstract": "This paper presents results from a rapid-response industry-academia collaboration for virtual screening of chemical, natural and virtual drug ligands towards identifying potential therapeutics for COVID-19. Compared to resource-intensive traditional approaches of either conducting high- throughput screening in a lab or in-silico molecular dynamics simulations on supercomputers, we have developed an open- source framework that leverages artificial intelligence (AI) to accurately and quickly predict the binding potential of a drug ligand with a target protein. We have trained a novel molecular-highway graph neural network architecture using the entirety of the BindingDB database to predict the probability of a drug ligand binding to a protein target. Our approach achieves a prodigious 98.3% accuracy with its predictions. Through this paper, we disseminate our source code and use the AI model to screen both public (ChEMBL, DrugBank) and proprietary databases. Compared to other AI-based methods, our approach outperforms the state-of-the-art on the following metrics - (i) number of molecules currently undergoing active clinical trials, (ii) number of antiviral drugs correctly identified, (iii) accuracy despite not needing active-site priors, and (iv) ability to screen more compounds in unit time.",
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "authors": [
                {
                    "authorId": "66948537",
                    "name": "J. Balma"
                },
                {
                    "authorId": "3348010",
                    "name": "A. Vose"
                },
                {
                    "authorId": "2164085",
                    "name": "Y. Peterson"
                },
                {
                    "authorId": "144589594",
                    "name": "A. Chittiboyina"
                },
                {
                    "authorId": "2036732",
                    "name": "P. Pandey"
                },
                {
                    "authorId": "32814096",
                    "name": "C. R. Yates"
                },
                {
                    "authorId": "3054938",
                    "name": "I. Khan"
                },
                {
                    "authorId": "1750800",
                    "name": "S. Sukumar"
                }
            ]
        },
        {
            "paperId": "fd3240159c976d3bfefeb0c3c5f20b1e513a599b",
            "title": "Massively Parallel Processing Database for Sequence and Graph Data Structures Applied to Rapid-Response Drug Repurposing",
            "abstract": "In this paper, we present the application of a massively parallel-processing graph database for rapid-response drug repurposing. The novelty of our approach is that the scalable graph database is able to host a knowledge graph of medically relevant facts integrated from multiple knowledge sources and also act as a computational engine capable of in-database protein sequence analytics. We demonstrate the performance of the graph database on a real-world use-case to hypothesize cures for COVID-19, leveraging its built-in accelerated protein-sequence matching capabilities at unprecedented scale (to simultaneously handle data size and query latency requirements for interactive research). Based on supporting evidence from medical literature, we show that results generated by computing similarity of COVID-19 virus proteins across 4 million other open-science sequences and intelligently traversing over a 150 billion facts from open-science medical knowledge produces biologically insightful results. By presenting sample queries and extending application to use-cases beyond COVID-19, we demonstrate the use and value of the novel database for hypotheses generation in reducing the time-to-insight and increasing researcher productivity with interactivity.",
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "authors": [
                {
                    "authorId": "2913778",
                    "name": "Christopher D. Rickett"
                },
                {
                    "authorId": "3096072",
                    "name": "K. Maschhoff"
                },
                {
                    "authorId": "1750800",
                    "name": "S. Sukumar"
                }
            ]
        },
        {
            "paperId": "202a4bab48ff0bed498b07dfe24cc9192df68ee2",
            "title": "Evaluating Scientific Workflow Engines for Data and Compute Intensive Discoveries",
            "abstract": "Workflow engines used to script scientific experiments involving numerical simulation, data analysis, instruments, edge sensors, and artificial intelligence have to deal with the complexities of hardware, software, resource availability, and the collaborative nature of science. In this paper, we survey workflow engines used in data-intensive and compute-intensive discovery pipelines from scientific disciplines such as astronomy, high energy physics, earth system science, bio-medicine, and material science and present a qualitative analysis of their respective capabilities. We compare 5 popular workflow engines and their differentiated approach to job orchestration, job launching, data management and provenance, security authentication, ease-ofuse, workflow description, and scripting semantics. The comparisons presented in this paper allow practitioners to choose the appropriate engine for their scientific experiment and lead to recommendations for future work.",
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "authors": [
                {
                    "authorId": "2109455118",
                    "name": "Rina Singh"
                },
                {
                    "authorId": "144492731",
                    "name": "J. Graves"
                },
                {
                    "authorId": "143689243",
                    "name": "V. Anantharaj"
                },
                {
                    "authorId": "1750800",
                    "name": "S. Sukumar"
                }
            ]
        },
        {
            "paperId": "caedd086a4a64fefd7a0c7c5334b4a92d91b72fd",
            "title": "A Flexible-blocking Based Approach for Performance Tuning of Matrix Multiplication Routines for Large Matrices with Edge Cases",
            "abstract": "Efficient and scalable matrix operations are being highly demanding in the recent era of Machine Learning, Deep Learning, and Big Data Analytics. The two commonly used matrix-matrix operations in the Basic Linear Algebra Subprograms (BLAS) specification are General Matrix-Matrix multiplication (GEMM) and Symmetric Rank-k update (SYRK). The SYRK routine is a specialization of the GEMM routine, where half of the multiplications are skipped as the resultant matrix is known to be symmetric. Fortunately, several linear algebra libraries implement these BLAS routines quite efficiently. The libraries usually partition the input matrices into blocks and place them in processor caches, thus improving performance by leveraging the caches. However, the contemporary libraries are highly optimized for squarish matrices, but the performance degrades significantly for the matrices with edge case (strictly thin or strictly fat shapes) in the multicore machine. The primary reason is that the current state-of-the-art libraries make fixed block shapes based on a processor architecture, and do not consider the shape of the input matrices. In this paper, we propose a new blocking approach, we name it Flexible-blocking, to mitigate the scalability issues. In contrast to the contemporary libraries, our approach formulates the blocks of the input matrices based on the shapes of the matrices as well as the number of threads used in the implementation. Our proposed technique shows noticeable performance improvement on multicore shared-memory machines for the edge case matrices.",
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "authors": [
                {
                    "authorId": "47412046",
                    "name": "Md Mosharaf Hossain"
                },
                {
                    "authorId": "66253611",
                    "name": "Thomas M. Hines"
                },
                {
                    "authorId": "145902237",
                    "name": "S. Ghafoor"
                },
                {
                    "authorId": "144584926",
                    "name": "Sheikh Rabiul Islam"
                },
                {
                    "authorId": "34058303",
                    "name": "R. Kannan"
                },
                {
                    "authorId": "1750800",
                    "name": "S. Sukumar"
                }
            ]
        },
        {
            "paperId": "221fdc6739773105d9c0d2e874ce9e81eb60f816",
            "title": "Mini-apps for high performance data analysis",
            "abstract": "Scaling-up scientific data analysis and machine learning algorithms for data-driven discovery is a grand challenge that we face today. Despite the growing need for analysis from science domains that are generating \u2018Big Data\u2019 from instruments and simulations, building high-performance analytical workflows of data-intensive algorithms have been daunting because: (i) the \u2018Big Data\u2019 hardware and software architecture landscape is constantly evolving, (ii) newer architectures impose new programming models, and (iii) data-parallel kernels of analysis algorithms and their performance facets on different architectures are poorly understood. To address these problems, we have: (i) identified scalable data-parallel kernels of popular data analysis algorithms, (ii) implemented \u2018Mini-Apps\u2019 of those kernels using different programming models (e.g. Map Reduce, MPI, etc.), (iii) benchmarked and validated the performance of the kernels in diverse architectures. In this paper, we discuss two of those Mini-Apps and show the execution of principal component analysis built as a workflow of the Mini-Apps. We show that Mini-Apps enable scientists to (i) write domain-specific data analysis code that scales on most HPC hardware and (ii) and offers the ability (most times with over a 10x speed-up) to analyze data sizes 100 times the size of what off-the-shelf desktop/workstations of today can handle.",
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "authors": [
                {
                    "authorId": "1750800",
                    "name": "S. Sukumar"
                },
                {
                    "authorId": "2212466",
                    "name": "Michael A. Matheson"
                },
                {
                    "authorId": "34058303",
                    "name": "R. Kannan"
                },
                {
                    "authorId": "8600116",
                    "name": "Seung-Hwan Lim"
                }
            ]
        },
        {
            "paperId": "23728435ac8d96427ee31173c3b86aa3bbf65c3d",
            "title": "FatMan vs. LittleBoy: Scaling Up Linear Algebraic Operations in Scale-Out Data Platforms",
            "abstract": "Linear algebraic operations such as matrix manipulations form the kernel of many machine learning and other crucial algorithms. Scaling up as well as scaling out such algorithms are highly desirable to enable efficient processing over millions of data points. To this end, we present a matrix manipulation approach to effectively scale-up each node in a scale-out data parallel platform such as Apache Spark. Specifically, we enable hardware acceleration for matrix multiplications in a distributed Spark setup without user intervention. Our approach supports both dense and sparse distributed matrices, and provides flexible control of acceleration by matrix density. We demonstrate the benefit of our approach for generalized matrix multiplication operations over large matrices with up to four billion elements. To connect the effectiveness of our approach with machine learning applications, we performed Gramian matrix computation via generalized matrix multiplications. Our experiments show that our approach achieves more than 2\u00d7 performance speed-up, and up to 96.1% computation improvement, compared to a state of the art Spark MLlib for dense matrices.",
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "authors": [
                {
                    "authorId": "46265704",
                    "name": "Luna Xu"
                },
                {
                    "authorId": "8600116",
                    "name": "Seung-Hwan Lim"
                },
                {
                    "authorId": "3287952",
                    "name": "A. Butt"
                },
                {
                    "authorId": "1750800",
                    "name": "S. Sukumar"
                },
                {
                    "authorId": "34058303",
                    "name": "R. Kannan"
                }
            ]
        }
    ]
}