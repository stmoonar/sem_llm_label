{
    "authorId": "2670023",
    "papers": [
        {
            "paperId": "be7122f7b2db3bce3137519b1f81e79fa57c9eaa",
            "title": "Eureka: Evaluating and Understanding Large Foundation Models",
            "abstract": "Rigorous and reproducible evaluation is critical for assessing the state of the art and for guiding scientific advances in Artificial Intelligence. Evaluation is challenging in practice due to several reasons, including benchmark saturation, lack of transparency in methods used for measurement, development challenges in extracting measurements for generative tasks, and, more generally, the extensive number of capabilities required for a well-rounded comparison across models. We make three contributions to alleviate the above challenges. First, we present Eureka, an open-source framework for standardizing evaluations of large foundation models beyond single-score reporting and rankings. Second, we introduce Eureka-Bench as an extensible collection of benchmarks testing capabilities that (i) are still challenging for state-of-the-art models and (ii) represent fundamental but overlooked language and multimodal capabilities. The inherent space for improvement in non-saturated benchmarks enables us to discover meaningful differences between models at a capability level. Third, using Eureka, we conduct an analysis of 12 state-of-the-art models, providing in-depth insights into failure understanding and model comparison, which can be leveraged to plan targeted improvements. In contrast to recent trends in reports and leaderboards showing absolute rankings and claims for one model or another to be the best, our analysis shows that there is no such best model. Different models have different strengths, but there are models that appear more often than others as best performers for some capabilities. Despite the recent improvements, current models still struggle with several fundamental capabilities including detailed image understanding, benefiting from multimodal input when available rather than fully relying on language, factuality and grounding for information retrieval, and over refusals.",
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "authors": [
                {
                    "authorId": "143820870",
                    "name": "Vidhisha Balachandran"
                },
                {
                    "authorId": "2321484904",
                    "name": "Jingya Chen"
                },
                {
                    "authorId": "2250480908",
                    "name": "Neel Joshi"
                },
                {
                    "authorId": "2571049",
                    "name": "Besmira Nushi"
                },
                {
                    "authorId": "2247662718",
                    "name": "Hamid Palangi"
                },
                {
                    "authorId": "2321455461",
                    "name": "Eduardo Salinas"
                },
                {
                    "authorId": "143729959",
                    "name": "Vibhav Vineet"
                },
                {
                    "authorId": "2321455359",
                    "name": "James Woffinden-Luey"
                },
                {
                    "authorId": "2670023",
                    "name": "Safoora Yousefi"
                }
            ]
        },
        {
            "paperId": "26338627747d22a83dfe37f3d7709fcceaba651e",
            "title": "Decoding In-Context Learning: Neuroscience-inspired Analysis of Representations in Large Language Models",
            "abstract": "Large language models (LLMs) exhibit remarkable performance improvement through in-context learning (ICL) by leveraging task-specific examples in the input. However, the mechanisms behind this improvement remain elusive. In this work, we investigate how LLM embeddings and attention representations change following in-context-learning, and how these changes mediate improvement in behavior. We employ neuroscience-inspired techniques such as representational similarity analysis (RSA) and propose novel methods for parameterized probing and measuring ratio of attention to relevant vs. irrelevant information in Llama-2 70B and Vicuna 13B. We designed two tasks with a priori relationships among their conditions: linear regression and reading comprehension. We formed hypotheses about expected similarities in task representations and measured hypothesis alignment of LLM representations before and after ICL as well as changes in attention. Our analyses revealed a meaningful correlation between improvements in behavior after ICL and changes in both embeddings and attention weights across LLM layers. This empirical framework empowers a nuanced understanding of how latent representations shape LLM behavior, offering valuable tools and insights for future research and practical applications.",
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "authors": [
                {
                    "authorId": "2670023",
                    "name": "Safoora Yousefi"
                },
                {
                    "authorId": "15449757",
                    "name": "Leo Betthauser"
                },
                {
                    "authorId": "2245381886",
                    "name": "Hosein Hasanbeig"
                },
                {
                    "authorId": "2249763478",
                    "name": "Raphael Milliere"
                },
                {
                    "authorId": "2248289111",
                    "name": "Ida Momennejad"
                }
            ]
        },
        {
            "paperId": "8f89d716d3d3db9755bd68cbe7a71f84702f6ab5",
            "title": "Streaming Active Learning with Deep Neural Networks",
            "abstract": "Active learning is perhaps most naturally posed as an online learning problem. However, prior active learning approaches with deep neural networks assume offline access to the entire dataset ahead of time. This paper proposes VeSSAL, a new algorithm for batch active learning with deep neural networks in streaming settings, which samples groups of points to query for labels at the moment they are encountered. Our approach trades off between uncertainty and diversity of queried samples to match a desired query rate without requiring any hand-tuned hyperparameters. Altogether, we expand the applicability of deep neural networks to realistic active learning scenarios, such as applications relevant to HCI and large, fractured datasets.",
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "authors": [
                {
                    "authorId": "2121909819",
                    "name": "Akanksha Saran"
                },
                {
                    "authorId": "2670023",
                    "name": "Safoora Yousefi"
                },
                {
                    "authorId": "37019006",
                    "name": "A. Krishnamurthy"
                },
                {
                    "authorId": "144162125",
                    "name": "J. Langford"
                },
                {
                    "authorId": "40401847",
                    "name": "J. Ash"
                }
            ]
        },
        {
            "paperId": "6d5edf710fb84c99a59acfb40a46c416b5145c03",
            "title": "Detecting Elevated Air Pollution Levels by Monitoring Web Search Queries: Algorithm Development and Validation",
            "abstract": "Background Real-time air pollution monitoring is a valuable tool for public health and environmental surveillance. In recent years, there has been a dramatic increase in air pollution forecasting and monitoring research using artificial neural networks. Most prior work relied on modeling pollutant concentrations collected from ground-based monitors and meteorological data for long-term forecasting of outdoor ozone (O3), oxides of nitrogen, and fine particulate matter (PM2.5). Given that traditional, highly sophisticated air quality monitors are expensive and not universally available, these models cannot adequately serve those not living near pollutant monitoring sites. Furthermore, because prior models were built based on physical measurement data collected from sensors, they may not be suitable for predicting the public health effects of pollution exposure. Objective This study aimed to develop and validate models to nowcast the observed pollution levels using web search data, which are publicly available in near real time from major search engines. Methods We developed novel machine learning\u2013based models using both traditional supervised classification methods and state-of-the-art deep learning methods to detect elevated air pollution levels at the US city level by using generally available meteorological data and aggregate web-based search volume data derived from Google Trends. We validated the performance of these methods by predicting 3 critical air pollutants (O3, nitrogen dioxide, and PM2.5) across 10 major US metropolitan statistical areas in 2017 and 2018. We also explore different variations of the long short-term memory model and propose a novel search term dictionary learner-long short-term memory model to learn sequential patterns across multiple search terms for prediction. Results The top-performing model was a deep neural sequence model long short-term memory, using meteorological and web search data, and reached an accuracy of 0.82 (F1-score 0.51) for O3, 0.74 (F1-score 0.41) for nitrogen dioxide, and 0.85 (F1-score 0.27) for PM2.5, when used for detecting elevated pollution levels. Compared with using only meteorological data, the proposed method achieved superior accuracy by incorporating web search data. Conclusions The results show that incorporating web search data with meteorological data improves the nowcasting performance for all 3 pollutants and suggest promising novel applications for tracking global physical phenomena using web search data.",
            "fieldsOfStudy": [
                "Computer Science",
                "Medicine"
            ],
            "authors": [
                {
                    "authorId": "2146250512",
                    "name": "Chen Lin"
                },
                {
                    "authorId": "2670023",
                    "name": "Safoora Yousefi"
                },
                {
                    "authorId": "102353403",
                    "name": "E. Kahoro"
                },
                {
                    "authorId": "2497878",
                    "name": "Payam Karisani"
                },
                {
                    "authorId": "2300476285",
                    "name": "D. Liang"
                },
                {
                    "authorId": "2094967",
                    "name": "J. Sarnat"
                },
                {
                    "authorId": "1685296",
                    "name": "Eugene Agichtein"
                }
            ]
        },
        {
            "paperId": "55949f3fc182584d41667afa938a66ac6204f6bd",
            "title": "Learning Clinical Outcomes from Heterogeneous Genomic Data Sources",
            "abstract": "Translating the vast data generated by genomic platforms into reliable predictions of clinical outcomes remains a critical challenge in realizing the promise of genomic medicine largely due to small number of independent samples. In this paper, we show that neural networks can be trained to predict clinical outcomes using heterogeneous genomic data sources via multi-task learning and adversarial representation learning, allowing one to combine multiple cohorts and outcomes in training. We compare our proposed method to two baselines and demonstrate that it can be used to help mitigate the data scarcity and clinical outcome censorship in cancer genomics learning problems.",
            "fieldsOfStudy": [
                "Computer Science",
                "Biology"
            ],
            "authors": [
                {
                    "authorId": "2670023",
                    "name": "Safoora Yousefi"
                },
                {
                    "authorId": "2966051",
                    "name": "Amirreza Shaban"
                },
                {
                    "authorId": "50072002",
                    "name": "M. Amgad"
                },
                {
                    "authorId": "95577348",
                    "name": "Ramraj Chandradevan"
                },
                {
                    "authorId": "144584903",
                    "name": "L. Cooper"
                }
            ]
        },
        {
            "paperId": "a17b87e9d9880e9e239e978f3ebe5ccdbe7655ca",
            "title": "Transfer Learning from Nucleus Detection to Classification in Histopathology Images",
            "abstract": "Despite significant recent success, modern computer vision techniques such as Convolutional Neural Networks (CNNs) are expensive to apply to cell-level prediction problems in histopathology images due to difficulties in providing cell-level supervision. This work explores the transferability of features learned by an object detection CNN (Faster R-CNN) to nucleus classification in histopathology images. We detect nuclei in these images using class-agnostic models trained on small annotated patches, and use the CNN representations of detected nuclei to cluster and classify them. We show that with a small training dataset, the proposed pipeline can achieve superior nucleus detection and classification performance, and generalizes well to unseen stain types.",
            "fieldsOfStudy": [
                "Computer Science",
                "Biology"
            ],
            "authors": [
                {
                    "authorId": "2670023",
                    "name": "Safoora Yousefi"
                },
                {
                    "authorId": "2055489829",
                    "name": "Yao Nie"
                }
            ]
        },
        {
            "paperId": "7b05161938f4e5f89ddd7ab7f432de8ecab1566e",
            "title": "Predicting cancer outcomes from histology and genomics using convolutional networks",
            "abstract": "Significance Predicting the expected outcome of patients diagnosed with cancer is a critical step in treatment. Advances in genomic and imaging technologies provide physicians with vast amounts of data, yet prognostication remains largely subjective, leading to suboptimal clinical management. We developed a computational approach based on deep learning to predict the overall survival of patients diagnosed with brain tumors from microscopic images of tissue biopsies and genomic biomarkers. This method uses adaptive feedback to simultaneously learn the visual patterns and molecular biomarkers associated with patient outcomes. Our approach surpasses the prognostic accuracy of human experts using the current clinical standard for classifying brain tumors and presents an innovative approach for objective, accurate, and integrated prediction of patient outcomes. Cancer histology reflects underlying molecular processes and disease progression and contains rich phenotypic information that is predictive of patient outcomes. In this study, we show a computational approach for learning patient outcomes from digital pathology images using deep learning to combine the power of adaptive machine learning algorithms with traditional survival models. We illustrate how these survival convolutional neural networks (SCNNs) can integrate information from both histology images and genomic biomarkers into a single unified framework to predict time-to-event outcomes and show prediction accuracy that surpasses the current clinical paradigm for predicting the overall survival of patients diagnosed with glioma. We use statistical sampling techniques to address challenges in learning survival from histology images, including tumor heterogeneity and the need for large training cohorts. We also provide insights into the prediction mechanisms of SCNNs, using heat map visualization to show that SCNNs recognize important structures, like microvascular proliferation, that are related to prognosis and that are used by pathologists in grading. These results highlight the emerging role of deep learning in precision medicine and suggest an expanding utility for computational analysis of histology in the future practice of pathology.",
            "fieldsOfStudy": [
                "Computer Science",
                "Medicine",
                "Biology"
            ],
            "authors": [
                {
                    "authorId": "51519906",
                    "name": "Pooya Mobadersany"
                },
                {
                    "authorId": "2670023",
                    "name": "Safoora Yousefi"
                },
                {
                    "authorId": "50072002",
                    "name": "M. Amgad"
                },
                {
                    "authorId": "48087135",
                    "name": "D. Gutman"
                },
                {
                    "authorId": "1390166347",
                    "name": "J. Barnholtz-Sloan"
                },
                {
                    "authorId": "123270742",
                    "name": "Jos\u00e9 E. Vel\u00e1zquez Vega"
                },
                {
                    "authorId": "2614122",
                    "name": "D. Brat"
                },
                {
                    "authorId": "144584903",
                    "name": "L. Cooper"
                }
            ]
        },
        {
            "paperId": "3e307ba7fbd1910d5587dceb8bdcabf393aae07f",
            "title": "Learning Genomic Representations to Predict Clinical Outcomes in Cancer",
            "abstract": "Genomics are rapidly transforming medical practice and basic biomedical research, providing insights into disease mechanisms and improving therapeutic strategies, particularly in cancer. The ability to predict the future course of a patient's disease from high-dimensional genomic profiling will be essential in realizing the promise of genomic medicine, but presents significant challenges for state-of-the-art survival analysis methods. In this abstract we present an investigation in learning genomic representations with neural networks to predict patient survival in cancer. We demonstrate the advantages of this approach over existing survival analysis methods using brain tumor data.",
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "authors": [
                {
                    "authorId": "2670023",
                    "name": "Safoora Yousefi"
                },
                {
                    "authorId": "3469125",
                    "name": "Congzheng Song"
                },
                {
                    "authorId": "3079079",
                    "name": "Nelson Nauata"
                },
                {
                    "authorId": "144584903",
                    "name": "L. Cooper"
                }
            ]
        },
        {
            "paperId": "ba1e4ab4f8bfa2b9bf6487a660fde37b0e70c3bc",
            "title": "From Local Similarities to Global Coding: A Framework for Coding Applications",
            "abstract": "Feature coding has received great attention in recent years as a building block of many image processing algorithms. In particular, the importance of the locality assumption in coding approaches has been studied in many previous works. We review this assumption and claim that using the similarity of data points to a more global set of anchor points does not necessarily weaken the coding method, as long as the underlying structure of the anchor points is considered. We propose to capture the underlying structure by assuming a random walker over the anchor points. We also show that our method is a fast approximation to the diffusion map kernel. Experiments on various data sets show that with a knowledge of the underlying structure of anchor points, different state-of-the-art coding algorithms may boost their performance in different learning tasks by utilizing the proposed method.",
            "fieldsOfStudy": [
                "Medicine",
                "Computer Science",
                "Mathematics"
            ],
            "authors": [
                {
                    "authorId": "2966051",
                    "name": "Amirreza Shaban"
                },
                {
                    "authorId": "1688652",
                    "name": "H. Rabiee"
                },
                {
                    "authorId": "40465379",
                    "name": "Mahyar Najibi"
                },
                {
                    "authorId": "2670023",
                    "name": "Safoora Yousefi"
                }
            ]
        },
        {
            "paperId": "c7d165c9dbcb5f818f952f87e8dc08e1703a019f",
            "title": "A Continuous-time Mutually-Exciting Point Process Framework for Prioritizing Events in Social Media",
            "abstract": "The overwhelming amount and rate of information update in online social media is making it increasingly difficult for users to allocate their attention to their topics of interest, thus there is a strong need for prioritizing news feeds. The attractiveness of a post to a user depends on many complex contextual and temporal features of the post. For instance, the contents of the post, the responsiveness of a third user, and the age of the post may all have impact. So far, these static and dynamic features has not been incorporated in a unified framework to tackle the post prioritization problem. In this paper, we propose a novel approach for prioritizing posts based on a feature modulated multi-dimensional point process. Our model is able to simultaneously capture textual and sentiment features, and temporal features such as self-excitation, mutual-excitation and bursty nature of social interaction. As an evaluation, we also curated a real-world conversational benchmark dataset crawled from Facebook. In our experiments, we demonstrate that our algorithm is able to achieve the-state-of-the-art performance in terms of analyzing, predicting, and prioritizing events. In terms of interpretability of our method, we observe that features indicating individual user profile and linguistic characteristics of the events work best for prediction and prioritization of new events.",
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "authors": [
                {
                    "authorId": "1682124",
                    "name": "Mehrdad Farajtabar"
                },
                {
                    "authorId": "2670023",
                    "name": "Safoora Yousefi"
                },
                {
                    "authorId": "2823024",
                    "name": "L. Q. Tran"
                },
                {
                    "authorId": "1779453",
                    "name": "Le Song"
                },
                {
                    "authorId": "145203884",
                    "name": "H. Zha"
                }
            ]
        }
    ]
}