{
    "authorId": "47120782",
    "papers": [
        {
            "paperId": "1e4636a56fdaae8ab21bee404fa5a5737c3bd0b3",
            "title": "ACP-Incorporated Perturbation-Resistant Neural Dynamics Controller for Autonomous Vehicles",
            "abstract": "Autonomous vehicle control systems are unavoidably influenced by diverse noise perturbations from the unpredictable external environment and internal system. In this consideration, based on the model predictive control (MPC) strategy, a perturbation-resistant neural dynamics (PRND) controller equipped with the noise-suppression ability for the path-tracking control of autonomous vehicles is newly designed in this paper, under the framework of artificial systems, computational experiments, and parallel execution (ACP). In addition, theoretical analyses show that the proposed ACP-incorporated PRND controller can behave with exponential convergence and strong robustness under different noise scenarios. Lastly, computational experiments are conducted and parallelly executed on the CarSim-Simulink platform and E-Car physical platform to demonstrate the effectiveness and superiority of the proposed controller. Overall, this paper provides a new perspective for designing neural-dynamics-based controllers for autonomous vehicles, thereby guaranteeing reliable control performance and effectively resisting noise perturbations.",
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "authors": [
                {
                    "authorId": "83618038",
                    "name": "Ying Liufu"
                },
                {
                    "authorId": "2215502576",
                    "name": "Long Jin"
                },
                {
                    "authorId": "2057174591",
                    "name": "Mingsheng Shang"
                },
                {
                    "authorId": "47120782",
                    "name": "Xingxia Wang"
                },
                {
                    "authorId": "2148956730",
                    "name": "Fei-Yue Wang"
                }
            ]
        },
        {
            "paperId": "4826fa39fc97e3d29ade6bfc70374253e2ca0471",
            "title": "Physical-Informed Neural Network for MPC-Based Trajectory Tracking of Vehicles With Noise Considered",
            "abstract": "The trajectory tracking plays a vital role in unmanned driving technology. Although traditional control schemes may yield satisfactory outcomes in dealing with simple linear tasks, they may fall short when handling dynamic systems with time-varying characteristics or lack of ability to complete a given task with the disturbance of noise. Therefore, a predictive control scheme under the framework of artificial systems, computational experiments, and parallel execution (ACP) is proposed. Within the ACP framework, the scheme integrates a model predictive control (MPC) controller and a physical-informed neural network (PINN) model to tackle intricate trajectory tracking tasks effectively with noise considered. Moreover, soft constraints that can enhance model robustness and improve solution efficiency are considered in the scheme. Then, theoretical analyses on the PINN model are provided with rigorous mathematical proofs. Finally, experiments and comparisons with existing works are conducted to illustrate the effectiveness and superiority of the constructed PINN model for MPC-based trajectory tracking of vehicles.",
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "authors": [
                {
                    "authorId": "2215502576",
                    "name": "Long Jin"
                },
                {
                    "authorId": "2281077444",
                    "name": "Longqi Liu"
                },
                {
                    "authorId": "47120782",
                    "name": "Xingxia Wang"
                },
                {
                    "authorId": "2057174591",
                    "name": "Mingsheng Shang"
                },
                {
                    "authorId": "2148956730",
                    "name": "Fei-Yue Wang"
                }
            ]
        },
        {
            "paperId": "816b6deced411035df97981bb1f4986f4730c432",
            "title": "Social Radars for Social Vision of Intelligent Vehicles: A New Direction for Vehicle Research and Development",
            "abstract": "The low-altitude economy is playing a crucial role in promoting economic development, strengthening social security, and serving international security, thus becoming an increasingly vital engine for global development. As an essential technological backbone and application carrier of the low-altitude economy, intelligent vehicles are not only active on land but also increasingly needed to actively participate in the air and water. The integration of social radars and social vision will enable intelligent vehicles to perceive complex scenarios and task demands from a human perspective, providing more efficient and safer services for the low-altitude economy. This presents an exciting prospect for the application of social radars and social vision, as well as their integration with intelligent vehicles for envisaged service scenarios in the low-altitude economy.",
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "authors": [
                {
                    "authorId": "2186633108",
                    "name": "Lili Fan"
                },
                {
                    "authorId": "47120782",
                    "name": "Xingxia Wang"
                },
                {
                    "authorId": "2181373119",
                    "name": "Jing Yang"
                },
                {
                    "authorId": "1906125026",
                    "name": "Yuhang Liu"
                },
                {
                    "authorId": "2169376985",
                    "name": "Chengqi Lv"
                },
                {
                    "authorId": "2118681969",
                    "name": "Hui Yu"
                },
                {
                    "authorId": "2146393060",
                    "name": "Jiaqi Ma"
                },
                {
                    "authorId": "2148956730",
                    "name": "Fei-Yue Wang"
                }
            ]
        },
        {
            "paperId": "8b8a6a24df08bd5e8a5ae74b3be09805f613b97e",
            "title": "3D Unsupervised Learning by Distilling 2D Open-Vocabulary Segmentation Models for Autonomous Driving",
            "abstract": "Point cloud data labeling is considered a time-consuming and expensive task in autonomous driving, whereas unsupervised learning can avoid it by learning point cloud representations from unannotated data. In this paper, we propose UOV, a novel 3D Unsupervised framework assisted by 2D Open-Vocabulary segmentation models. It consists of two stages: In the first stage, we innovatively integrate high-quality textual and image features of 2D open-vocabulary models and propose the Tri-Modal contrastive Pre-training (TMP). In the second stage, spatial mapping between point clouds and images is utilized to generate pseudo-labels, enabling cross-modal knowledge distillation. Besides, we introduce the Approximate Flat Interaction (AFI) to address the noise during alignment and label confusion. To validate the superiority of UOV, extensive experiments are conducted on multiple related datasets. We achieved a record-breaking 47.73% mIoU on the annotation-free point cloud segmentation task in nuScenes, surpassing the previous best model by 10.70% mIoU. Meanwhile, the performance of fine-tuning with 1% data on nuScenes and SemanticKITTI reached a remarkable 51.75% mIoU and 48.14% mIoU, outperforming all previous pre-trained models.",
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "authors": [
                {
                    "authorId": "2148384650",
                    "name": "Boyi Sun"
                },
                {
                    "authorId": "2248102602",
                    "name": "Yuhang Liu"
                },
                {
                    "authorId": "47120782",
                    "name": "Xingxia Wang"
                },
                {
                    "authorId": "2144084084",
                    "name": "Bin Tian"
                },
                {
                    "authorId": "2118900146",
                    "name": "Long Chen"
                },
                {
                    "authorId": "2303425504",
                    "name": "Fei-Yue Wang"
                }
            ]
        },
        {
            "paperId": "eedf8c80b56e172913507236906b5d0f42b53e43",
            "title": "Sora for Intelligent Vehicles: A Step From Constraint-Based Simulation to Artificiofactual Experiments Through Dynamic Visualization",
            "abstract": "Scenario simulation plays an integral role in the development, application, and management of intelligent vehicles. However, planning agents and customizing scenarios for complex systems are laborious, making it challenging to implement high-performance simulations. The striking progress made by Sora, a large-scale text-to-video model, suggests a research opportunity for high-performance simulation through dynamic visualizations. This paper reports the prospective effects of Sora on the scenario simulation of intelligent vehicles. Specifically, we review the achievements of Sora, picture the perspectives of artificiofactual experiments on intelligent vehicles based on the performance of Sora-type techniques, and discuss how far are we now.",
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "authors": [
                {
                    "authorId": "2107991201",
                    "name": "Xumeng Wang"
                },
                {
                    "authorId": "2151740605",
                    "name": "Xiao Xue"
                },
                {
                    "authorId": "2260399806",
                    "name": "Ran Yan"
                },
                {
                    "authorId": "47120782",
                    "name": "Xingxia Wang"
                },
                {
                    "authorId": "2295072462",
                    "name": "Yining Di"
                },
                {
                    "authorId": "2154939545",
                    "name": "Wei Chen"
                },
                {
                    "authorId": "2148956730",
                    "name": "Fei-Yue Wang"
                }
            ]
        },
        {
            "paperId": "ffac6ce128c2cff3157291c03ad2f89524ec518f",
            "title": "Sora for Hierarchical Parallel Motion Planner: A Safe End-to-End Method Against OOD Events",
            "abstract": "End-to-end motion planners have shown great potential for enabling fully autonomous driving. However, when facing out-of-distribution (OOD) events, these planners might not guarantee the optimal prediction of control commands. To better enhance safety, an end-to-end method that benefits robust and general policy learning from potential OOD events is urgently desirable. In this perspective, Sore4PMP, a hierarchical parallel motion planner, is presented as a suitable solution. Based on raw perception data and descriptive prompts, Sore4PMP can first leverage the advanced generative capabilities of Sora to generate virtual OOD events, and then integrate these events into the decision-making process, thereby enhancing the robustness and generalization of autonomous vehicles (AVs) in emergency scenarios. With a comprehensive outlook, this perspective aims to provide a potential direction for the development of foundation models coupled with autonomous driving and finally promote the safety, efficiency, reliability, and sustainability of AVs.",
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "authors": [
                {
                    "authorId": "2134580871",
                    "name": "Siyu Teng"
                },
                {
                    "authorId": "2260399806",
                    "name": "Ran Yan"
                },
                {
                    "authorId": "2165301352",
                    "name": "Xiaotong Zhang"
                },
                {
                    "authorId": "2128125807",
                    "name": "Yuchen Li"
                },
                {
                    "authorId": "47120782",
                    "name": "Xingxia Wang"
                },
                {
                    "authorId": "2108070100",
                    "name": "Yutong Wang"
                },
                {
                    "authorId": "32847052",
                    "name": "Yonglin Tian"
                },
                {
                    "authorId": "2118681969",
                    "name": "Hui Yu"
                },
                {
                    "authorId": "2240418173",
                    "name": "Lingxi Li"
                },
                {
                    "authorId": "2280479289",
                    "name": "Long Chen"
                },
                {
                    "authorId": "2148956730",
                    "name": "Fei-Yue Wang"
                }
            ]
        },
        {
            "paperId": "011a8f7f84f9e88c7a2212ae858d36ecd47e7a61",
            "title": "Vehicular Visualization: Enhancing Mobility Decisions With Human\u2013Machine Interactions",
            "abstract": "In the age of intelligence, humans pursue a safe and convenient mobility experience. Intelligent vehicles have integrated various machine intelligence to support humans in making decisions on mobility. However, the support fails to meet human expectations because machine intelligence lacks a method to communicate with humans\u2014verify the understanding of human needs, and explain how machine intelligence works. In this study, we address this issue through vehicular visualizations. Specifically, we summarize the decision-making requirements of humans, introduce how can techniques of vehicular visualizations satisfy these needs, describe prospective application scenes, and discuss future directions of vehicular visualizations to inspire related scholars or developers.",
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "authors": [
                {
                    "authorId": "2107991201",
                    "name": "Xumeng Wang"
                },
                {
                    "authorId": "47120782",
                    "name": "Xingxia Wang"
                },
                {
                    "authorId": "2210931213",
                    "name": "Siji Ma"
                },
                {
                    "authorId": "92896059",
                    "name": "Wei Chen"
                },
                {
                    "authorId": "1682816",
                    "name": "Fei Wang"
                }
            ]
        },
        {
            "paperId": "1df68f795ae4b52a076f851725e113d40585fdc4",
            "title": "Chat with ChatGPT on Industry 5.0: Learning and Decision-Making for Intelligent Industries",
            "abstract": "HE current ChatGPT phenomenon has signaled a new era of Artificial Intelligence moving from Algorithmic Intelligence to Linguistic Intelligence",
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "authors": [
                {
                    "authorId": "27798809",
                    "name": "Feiyue Wang"
                },
                {
                    "authorId": "2181373119",
                    "name": "Jing Yang"
                },
                {
                    "authorId": "47120782",
                    "name": "Xingxia Wang"
                },
                {
                    "authorId": "2116822799",
                    "name": "Juanjuan Li"
                },
                {
                    "authorId": "47837643",
                    "name": "Qing\u2010Long Han"
                }
            ]
        },
        {
            "paperId": "265ad0ccdc993747d6b99d777b97e9e3db53b556",
            "title": "The ChatGPT After: Building Knowledge Factories for Knowledge Workers with Knowledge Automation",
            "abstract": "This perspective introduces the concept and framework of knowledge factories with knowledge machines for knowledge workers to achieve knowledge automation for Industry 5.0 and intelligent industries.",
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "authors": [
                {
                    "authorId": "2108070100",
                    "name": "Yutong Wang"
                },
                {
                    "authorId": "144129720",
                    "name": "Xiao Wang"
                },
                {
                    "authorId": "47120782",
                    "name": "Xingxia Wang"
                },
                {
                    "authorId": "2181373119",
                    "name": "Jing Yang"
                },
                {
                    "authorId": "2193987863",
                    "name": "Oliver Kwan"
                },
                {
                    "authorId": "2240418173",
                    "name": "Lingxi Li"
                },
                {
                    "authorId": "39586294",
                    "name": "Fei Wang"
                }
            ]
        },
        {
            "paperId": "356cc938e6b9c1ccc2256b48816e6b80ffd135e7",
            "title": "Software-Defined Active LiDARs for Autonomous Driving: A Parallel Intelligence-Based Adaptive Model",
            "abstract": "LiDAR is an indispensable sensor for autonomous driving that can provide precise 3D information about the environment. Among various types of LiDARs, mechanical LiDARs are the most commonly used on vehicles that uniformly perceive the scene utilizing rotating motors. However, accurate perception of foreground objects is considered as the most important task in automotive LiDARs, therefore the current operating mode of mechanical LiDARs wastes a significant amount of sensing resources on the useless background. Besides, the development of LiDAR hardware and software systems is currently split into two independent segments, lacking real-time interaction between physical entities and digital models in cyberspace. To address these issues, we propose software-defined active LiDARs for autonomous driving based on parallel intelligence. Active LiDARs redefine LiDAR's hardware operation through software systems to achieve adaptive sensing resource allocation, constituting a closed loop between physical space and cyberspace. During the working process, it calculates scenario heatmaps with the constructed high-definition maps (HD maps) in cyberspace at first. Then it takes prescriptive control of physical LiDARs based on heatmaps to improve sensing resource utilization. We build two adaptive LiDAR models in CARLA and construct a hardware prototype in the parallel sensing platform, DAWN. Active Point Cloud (APC), a new dataset collected in CARLA, is proposed and a 3D object detection task is selected to demonstrate the effectiveness of active LiDARs. Our experimental results show that active LiDARs can both improve raw data quality and model performance compared with mechanical LiDARs, especially for the perception of distant objects.",
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "authors": [
                {
                    "authorId": "1906125026",
                    "name": "Yuhang Liu"
                },
                {
                    "authorId": "2148384650",
                    "name": "Boyi Sun"
                },
                {
                    "authorId": "32847052",
                    "name": "Yonglin Tian"
                },
                {
                    "authorId": "47120782",
                    "name": "Xingxia Wang"
                },
                {
                    "authorId": "2208762249",
                    "name": "Yin Zhu"
                },
                {
                    "authorId": "2220962972",
                    "name": "Rouxing Huai"
                },
                {
                    "authorId": "2152571555",
                    "name": "Yu Shen"
                }
            ]
        }
    ]
}