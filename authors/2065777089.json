{
    "authorId": "2065777089",
    "papers": [
        {
            "paperId": "18f95c677e014391acd632cf2c8d5033cf6a1a20",
            "title": "PAPyA: Performance Analysis of Large RDF Graphs Processing Made Easy",
            "abstract": "Prescriptive Performance Analysis (PPA) has shown to be more useful than traditional descriptive and diagnostic analyses for making sense of Big Data (BD) frameworks' performance. In practice, when processing large (RDF) graphs on top of relational BD systems, several design decisions emerge and cannot be decided automatically, e.g., the choice of the schema, the partitioning technique, and the storage formats. PPA, and in particular ranking functions, helps enable actionable insights on performance data, leading practitioners to an easier choice of the best way to deploy BD frameworks, especially for graph processing. However, the amount of experimental work required to implement PPA is still huge. In this paper, we present PAPyA 1, a library for implementing PPA that allows (1) preparing RDF graphs data for a processing pipeline over relational BD systems, (2) enables automatic ranking of the performance in a user-defined solution space of experimental dimensions; (3) allows user-defined flexible extensions in terms of systems to test and ranking methods. We showcase PAPyA on a set of experiments based on the SparkSQL framework. PAPyA simplifies the performance analytics of BD systems for processing large (RDF) graphs.We provide PAPyA as a public open-source library under an MIT license that will be a catalyst for designing new research prescriptive analytical techniques for BD applications.",
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "authors": [
                {
                    "authorId": "2065777089",
                    "name": "Mohamed Ragab"
                },
                {
                    "authorId": "2184922672",
                    "name": "Adam Satria Adidarma"
                },
                {
                    "authorId": "50271459",
                    "name": "Riccardo Tommasini"
                }
            ]
        },
        {
            "paperId": "85c6db4e2eb186a8cd251220882342cdafd34ce1",
            "title": "An In-depth Investigation of Large-scale RDF Relational Schema Optimizations Using Spark-SQL",
            "abstract": "This paper discusses one of the most significant challenges of large-scale RDF data processing over Apache Spark, the relational schema optimization. The choice of RDF partitioning techniques and storage formats using SparkSQL significantly impacts query performance. The impact of the relational schemas and the underlying data storage formats is indisputable; they significantly affect the query performance. Nevertheless, the trade-offs in different configurations have not been a subject of intensive study in the literature. This paper presents an in-depth investigation for practitioners to understand such trade-offs and their best practices. It also reports on the pitfalls behind the implementation SPARQL optimizations over SparkSQL . Our experiments provide insights into these schemas\u2019 relative strengths by comparing three different partitioning techniques and four other storage formats. Our results draw a better understanding of the current State-Of-The-Art (S.O.T.A) and pave the way for a wide range of best practices and systematically tuning the performance of distributed systems to handle vast RDF data.",
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "authors": [
                {
                    "authorId": "2065777089",
                    "name": "Mohamed Ragab"
                },
                {
                    "authorId": "50271459",
                    "name": "Riccardo Tommasini"
                },
                {
                    "authorId": "17663383",
                    "name": "Feras M. Awaysheh"
                },
                {
                    "authorId": "145441140",
                    "name": "J. Ramos"
                }
            ]
        },
        {
            "paperId": "fd6cfd2287d5112d212733687ab140ee9fd779e3",
            "title": "Bench-Ranking: A First Step Towards Prescriptive Performance Analyses For Big Data Frameworks",
            "abstract": "Leveraging Big Data (BD) processing frameworks to process large-scale Resource Description Framework (RDF) datasets holds a great interest in optimizing query performance. Modern BD services are complicated data systems, where tuning the configurations notably affects the performance. Benchmarking different frameworks and configurations provides the community with best practices towards selecting the most suitable configurations. However, most of these benchmarking efforts are classified as descriptive or diagnostic analytics. Moreover, there is no standardization for comparing and contrasting these benchmarks based on quantitative ranking techniques. This paper aims to fill this timely research gap by proposing ranking criteria (called Bench-ranking) that provide prescriptive analytics via ranking functions. In particular, Bench-ranking starts by describing the current state-of-the-art single-dimensional ranking limitations. Next, we discuss the recent benchmarking requirements for sophisticated approaches over multi-dimensional ranking. Finally, we discuss the ranking criteria goodness by reviewing its conformance and coherence metrics. We validate Bench-ranking by conducting an empirical study using large RDF datasets under a relational BD engine, i.e., Apache Spark-SQL. The proposed ranking techniques provide the practitioners with clear insights to make an informed decision, especially with experimental trade-offs for such complex solution space.",
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "authors": [
                {
                    "authorId": "2065777089",
                    "name": "Mohamed Ragab"
                },
                {
                    "authorId": "17663383",
                    "name": "Feras M. Awaysheh"
                },
                {
                    "authorId": "50271459",
                    "name": "Riccardo Tommasini"
                }
            ]
        },
        {
            "paperId": "0e74d9dea6398e3eb6290ac8ea792692357dab95",
            "title": "Towards making sense of Spark-SQL performance for processing vast distributed RDF datasets",
            "abstract": "Recently, a wide range of Web applications (e.g. DBPedia, Uniprot, and Probase) are built on top of vast RDF knowledge bases and using the SPARQL query language. The continuous growth of these knowledge bases led to the investigation of new paradigms and technologies for storing, accessing, and querying RDF data. In practice, modern big data systems (e.g, Hadoop, Spark) can handle vast relational repositories, however, their application in the Semantic Web context is still limited. One possible reason is that such frameworks rely on distributed systems, which are good for relational data, however, their performance on dealing with graph data models like RDF has not been well-studied yet. In this paper, we present a systematic evaluation of the performance of SparkSQL engine for processing SPARQL queries. We stated it using three relevant RDF relational schemas, and two different storage backends, namely, Hive, and HDFS. In addition, we show the impact of using three different RDF-based partitioning techniques with our relational scenario. Additionally, we discuss the results of our experiments: (i) we present insights about the trade-offs that characterize different experimental configurations, and (ii) we identify the best and the worst ones for the SP2Bench's benchmark scenario.",
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "authors": [
                {
                    "authorId": "2065777089",
                    "name": "Mohamed Ragab"
                },
                {
                    "authorId": "50271459",
                    "name": "Riccardo Tommasini"
                },
                {
                    "authorId": "1716216761",
                    "name": "Sadiq Eyvazov"
                },
                {
                    "authorId": "1783693",
                    "name": "Sherif Sakr"
                }
            ]
        },
        {
            "paperId": "54116169e40dd36223e85ef036a82327b3bfd882",
            "title": "Comparing Schema Advancements for Distributed RDF Querying Using SparkSQL",
            "abstract": ". Linked Data reveals the need for big semantic data processing. The underlying literature already discusses numerous attempts at leveraging the relational engines of Big Data frameworks like Apache Spark to run SPARQL queries at scale. However, the choice of a relational schema to store RDF data may signi\ufb01cantly impact the query performance and hence various alternatives exist. In this paper, we investigate the improvement of two recent proposals, i.e., Extended Vertically Partitioned Tables and Wide Property Tables , w.r.t. the baseline approaches Vertically Partitioned Tables and Property Tables . To generalize our results, we observe how the two schemas behave together with di\ufb00erent RDF partitioning techniques and HDFS storage data formats. We run our experiments using SparkSQL over a 100-million triples dataset generated using SP 2 Bench .",
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "authors": [
                {
                    "authorId": "2065777089",
                    "name": "Mohamed Ragab"
                },
                {
                    "authorId": "50271459",
                    "name": "Riccardo Tommasini"
                },
                {
                    "authorId": "1783693",
                    "name": "Sherif Sakr"
                }
            ]
        },
        {
            "paperId": "8f973517436e21e4e6f54b37837a9f6681d06265",
            "title": "The future is big graphs",
            "abstract": "Ensuring the success of big graph processing for the next decade and beyond.",
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "authors": [
                {
                    "authorId": "1783693",
                    "name": "Sherif Sakr"
                },
                {
                    "authorId": "1699192",
                    "name": "A. Bonifati"
                },
                {
                    "authorId": "143842962",
                    "name": "H. Voigt"
                },
                {
                    "authorId": "1760940",
                    "name": "A. Iosup"
                },
                {
                    "authorId": "150169694",
                    "name": "Khaled Ammar"
                },
                {
                    "authorId": "2772109",
                    "name": "Renzo Angles"
                },
                {
                    "authorId": "1709661",
                    "name": "W. Aref"
                },
                {
                    "authorId": "144658846",
                    "name": "M. Arenas"
                },
                {
                    "authorId": "2919642",
                    "name": "Maciej Besta"
                },
                {
                    "authorId": "1687211",
                    "name": "P. Boncz"
                },
                {
                    "authorId": "2176381",
                    "name": "K. Daudjee"
                },
                {
                    "authorId": "2539248",
                    "name": "Emanuele Della Valle"
                },
                {
                    "authorId": "31359282",
                    "name": "Stefania Dumbrava"
                },
                {
                    "authorId": "1699014",
                    "name": "O. Hartig"
                },
                {
                    "authorId": "1679379",
                    "name": "Bernhard Haslhofer"
                },
                {
                    "authorId": "2290758",
                    "name": "T. Hegeman"
                },
                {
                    "authorId": "1687456",
                    "name": "J. Hidders"
                },
                {
                    "authorId": "1682407",
                    "name": "K. Hose"
                },
                {
                    "authorId": "1986996",
                    "name": "Adriana Iamnitchi"
                },
                {
                    "authorId": "1993949",
                    "name": "Vasiliki Kalavri"
                },
                {
                    "authorId": "2035501761",
                    "name": "Hugo Kapp"
                },
                {
                    "authorId": "144352362",
                    "name": "W. Martens"
                },
                {
                    "authorId": "9107867",
                    "name": "M. Tamer Ozsu"
                },
                {
                    "authorId": "2065161",
                    "name": "E. Peukert"
                },
                {
                    "authorId": "2748632",
                    "name": "Stefan Plantikow"
                },
                {
                    "authorId": "2065777089",
                    "name": "Mohamed Ragab"
                },
                {
                    "authorId": "1747805",
                    "name": "M. Ripeanu"
                },
                {
                    "authorId": "1783781",
                    "name": "S. Salihoglu"
                },
                {
                    "authorId": "40262967",
                    "name": "Christian Schulz"
                },
                {
                    "authorId": "2341999",
                    "name": "P. Selmer"
                },
                {
                    "authorId": "1703204",
                    "name": "Juan Sequeda"
                },
                {
                    "authorId": "2766552",
                    "name": "Joshua Shinavier"
                },
                {
                    "authorId": "2073266386",
                    "name": "G'abor Sz'arnyas"
                },
                {
                    "authorId": "50271459",
                    "name": "Riccardo Tommasini"
                },
                {
                    "authorId": "2606269",
                    "name": "Antonino Tumeo"
                },
                {
                    "authorId": "2860260",
                    "name": "Alexandru Uta"
                },
                {
                    "authorId": "1784556",
                    "name": "A. Varbanescu"
                },
                {
                    "authorId": "2702080",
                    "name": "Hsiang-Yun Wu"
                },
                {
                    "authorId": "2967413",
                    "name": "N. Yakovets"
                },
                {
                    "authorId": "144157459",
                    "name": "D. Yan"
                },
                {
                    "authorId": "2004672",
                    "name": "Eiko Yoneki"
                }
            ]
        },
        {
            "paperId": "a06876418a9ab36a3b631f1824610ada82c2342c",
            "title": "Large Scale Querying and Processing for Property Graphs",
            "abstract": "Recently, large scale graph data management, querying and processing have experienced a renaissance in several timely application domains (e.g., social networks, bibliographical networks and knowledge graphs). However, these applications still introduce new challenges with large-scale graph processing. Therefore, recently, we have witnessed a remarkable growth in the prevalence of work on graph processing in both academia and industry. Querying and processing large graphs is an interesting and challenging task. Recently, several centralized/distributed large-scale graph processing frameworks have been developed. However, they mainly focus on batch graph analytics. On the other hand, the state-of-the-art graph databases can\u2019t sustain for distributed efficient querying for large graphs with complex queries. In particular, online large scale graph querying engines are still limited. In this paper, we present a research plan shipped with the state-of-the-art techniques for large-scale property graph querying and processing. We present our goals and initial results for querying and processing large property graphs based on the emerging and promising Apache Spark framework, a defacto standard platform for big data processing. In principle, the design of this research plan is revolving around two main goals. The first goal focuses on designing an adequate and efficient graph-based storage backend that can be integrated with the Apache Spark framework. The second goal focuses on developing various Graph-aware optimization techniques (e.g., graph indexing, graph materialized views), and extending the default relational Spark Catalyst optimizer with Graph-aware cost-based optimizations. Achieving these contributions can significantly enhance the performance of executing graph queries on top of Apache Spark .",
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "authors": [
                {
                    "authorId": "2065777089",
                    "name": "Mohamed Ragab"
                }
            ]
        },
        {
            "paperId": "6304cc4a8f841babe670838f4a8e4023140af7c5",
            "title": "Bootstrapping the Publication of Linked Data Streams",
            "abstract": ". Data Velocity reached the Web. New protocols and APIs (e.g. WebSockets, and EventSource) are emerging, and the Web of Data is also evolving to tame Velocity without neglecting Variety . The RDF Stream Processing (RSP) community is actively addressing these challenges by proposing continuous query languages and working prototypes. Nevertheless, the problem of Streaming Linked Data publication is still an open challenge. In this paper, we present the \ufb01rst attempt to tackle this challenge by introducing a set of guidelines to publish streaming linked data by reusing existing resources such as TripleWave , R2RML / RML , VoCaLS , and RSP-QL . We design a publication life-cycle that follows the W3C best practices. Besides, we present an example for publishing the Global Database of Events, Language and Tone ( GDELT ) as a Streaming Linked Data resource. We open-sourced the code of our resource and made it available for public use.",
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "authors": [
                {
                    "authorId": "50271459",
                    "name": "Riccardo Tommasini"
                },
                {
                    "authorId": "2065777089",
                    "name": "Mohamed Ragab"
                },
                {
                    "authorId": "119796696",
                    "name": "Alessandro Falcetta"
                },
                {
                    "authorId": "2539248",
                    "name": "Emanuele Della Valle"
                },
                {
                    "authorId": "1783693",
                    "name": "Sherif Sakr"
                }
            ]
        },
        {
            "paperId": "b895c1ea44bb2963597fd22aa38bd07ba23fd510",
            "title": "Benchmarking Spark-SQL under Alliterative RDF Relational Storage Backends",
            "abstract": ". Recently, a wide range of Web applications (e.g. DBPedia , Uniprot , and Probase ) are built on top of vast RDF knowledge bases and using the SPARQL query language. The continuous growth of these knowledge bases led to the investigation of new paradigms and technologies for storing, accessing, and querying RDF data. In practice, modern big data systems (e.g, Hadoop, Spark) can handle vast relational repositories, however, their application in the Semantic Web context is still limited. One possible reason is that such frameworks rely on distributed systems, which are good for relational data, however, their performance on dealing with graph data models like RDF have not been well-studied yet. In this paper, we present a systematic comparison of there relevant RDF relational schemas, i.e., Single Statement Table, Property Tables or Vertically-Partitioned Tables queried using Apache Spark. We evaluate the performance of Spark SQL querying engine for processing SPARQL queries using three di\ufb00erent storage back-ends, namely, Post-greSQL, Hive, and HDFS. For the latter one, we compare four di\ufb00erent data formats (CSV, ORC, Avro, and Parquet). We drove our experiment using a representative query workloads from the SP 2 Bench benchmark scenario. The results of our experiments show many interesting insights about the impact of the relational encoding scheme, storage backends and storage formats on the performance of the query execution process.",
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "authors": [
                {
                    "authorId": "2065777089",
                    "name": "Mohamed Ragab"
                },
                {
                    "authorId": "50271459",
                    "name": "Riccardo Tommasini"
                },
                {
                    "authorId": "1783693",
                    "name": "Sherif Sakr"
                }
            ]
        },
        {
            "paperId": "bad8036c8c06abee26a0eb35cd3e6954e83b077c",
            "title": "MINARET: A Recommendation Framework for Scientific Reviewers",
            "abstract": "We are witnessing a continuous growth in the size of scientific communities and the number of scientific publications. This phenomenon requires a continuous effort for ensuring the quality of publications and a healthy scientific evaluation process. Peer reviewing is the de facto mechanism to assess the quality of scientific work. For journal editors, managing an efficient and effective manuscript peer review process is not a straightforward task. In particular, a main component in the journal editors\u2019 role is, for each submitted manuscript, to ensure selecting adequate reviewers who need to be: 1) Matching on their research interests with the topic of the submission, 2) Fair in their evaluation of the submission, i.e., no conflict of interest with the authors, 3) Qualified in terms of various aspects including scientific impact, previous review/authorship experience for the journal, quality of the reviews, etc. Thus, manually selecting and assessing the adequate reviewers is becoming tedious and time consuming task. We demonstrate MINARET, a recommendation framework for selecting scientific reviewers. The framework facilitates the job of journal editors for conducting an efficient and effective scientific review process. The framework exploits the valuable information available on the modern scholarly Websites (e.g., Google Scholar, ACM DL, DBLP, Publons) for identifying candidate reviewers relevant to the topic of the manuscript, filtering them (e.g. excluding those with potential conflict of interest), and ranking them based on several metrics configured by the editor (user). The framework extracts the required information for the recommendation process from the online resources on-the-fly which ensures the output recommendations to be dynamic and based on up-to-date information.",
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "authors": [
                {
                    "authorId": "1783693",
                    "name": "Sherif Sakr"
                },
                {
                    "authorId": "2065777089",
                    "name": "Mohamed Ragab"
                },
                {
                    "authorId": "2097409976",
                    "name": "M. Maher"
                },
                {
                    "authorId": "144185337",
                    "name": "Ahmed Awad"
                }
            ]
        }
    ]
}