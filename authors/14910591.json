{
    "authorId": "14910591",
    "papers": [
        {
            "paperId": "06cece9731273f604d69a73eea5e7ae57fee5056",
            "title": "Slide4N: Creating Presentation Slides from Computational Notebooks with Human-AI Collaboration",
            "abstract": "Data scientists often have to use other presentation tools (e.g., Microsoft PowerPoint) to create slides to communicate their analysis obtained using computational notebooks. Much tedious and repetitive work is needed to transfer the routines of notebooks (e.g., code, plots) to the presentable contents on slides (e.g., bullet points, figures). We propose a human-AI collaborative approach and operationalize it within Slide4N, an interactive AI assistant for data scientists to create slides from computational notebooks. Slide4N leverages advanced natural language processing techniques to distill key information from user-selected notebook cells and then renders them in appropriate slide layouts. The tool also provides intuitive interactions that allow further refinement and customization of the generated slides. We evaluated Slide4N with a two-part user study, where participants appreciated this human-AI collaborative approach compared to fully-manual or fully-automatic methods. The results also indicate the usefulness and effectiveness of Slide4N in slide creation tasks from notebooks.",
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "authors": [
                {
                    "authorId": "2128185918",
                    "name": "Fengjie Wang"
                },
                {
                    "authorId": "14910591",
                    "name": "Xuye Liu"
                },
                {
                    "authorId": "2214761987",
                    "name": "Oujing Liu"
                },
                {
                    "authorId": "15270465",
                    "name": "Ali Neshati"
                },
                {
                    "authorId": "2214737208",
                    "name": "Tengfei Ma"
                },
                {
                    "authorId": "2152184839",
                    "name": "Min Zhu"
                },
                {
                    "authorId": "49530796",
                    "name": "J. Zhao"
                }
            ]
        },
        {
            "paperId": "67449a56b63d5371596c078ca76ca93228ac59dc",
            "title": "How much can AI see in early pregnancy: A multi-center study of fetus head characterization in week 10-14 in ultrasound using deep learning",
            "abstract": "PURPOSE\nTo investigate if artificial intelligence can identify fetus intracranial structures in pregnancy week 11-14; to provide an automated method of standard and non-standard sagittal view classification in obstetric ultrasound examination METHOD AND MATERIALS: We proposed a newly designed scheme based on deep learning (DL) - Fetus Framework to identify nine fetus intracranial structures: thalami, midbrain, palate, 4th ventricle, cisterna magna, nuchal translucency (NT), nasal tip, nasal skin, and nasal bone. Fetus Framework was trained and tested on a dataset of 1528 2D sagittal-view ultrasound images from 1519 females collected from Shenzhen People's Hospital. Results from Fetus Framework were further used for standard/non-standard (S-NS) plane classification, a key step for NT measurement and Down Syndrome assessment. S-NS classification was also tested with 156 images from the Longhua branch of Shenzhen People's Hospital. Sensitivity, specificity, and area under the curve (AUC) were evaluated for comparison among Fetus Framework, three classic DL models, and human experts with 1-, 3- and 5-year ultrasound training. Furthermore, 4 physicians with more than 5 years of experience conducted a reader study of diagnosing fetal malformation on a dataset of 316 standard images confirmed by the Fetus framework and another dataset of 316 standard images selected by physicians. Accuracy, sensitivity, specificity, precision, and F1-Score of physicians' diagnosis on both sets are compared.\n\n\nRESULTS\nNine intracranial structures identified by Fetus Framework in validation are all consistent with that of senior radiologists. For S-NS sagittal view identification, Fetus Framework achieved an AUC of 0.996 (95%CI: 0.987, 1.000) in internal test, at par with classic DL models. In external test, FF reaches an AUC of 0.974 (95%CI: 0.952, 0.995), while ResNet-50 arrives at AUC\u223c0.883, 95% CI 0.828-0.939, Xception AUC\u223c0.890, 95% CI 0.834-0.946, and DenseNet-121 AUC\u223c0.894, 95% CI 0.839-0.949. For the internal test set, the sensitivity and specificity of the proposed framework are (0.905, 1), while the first-, third-, and fifth-year clinicians are (0.619, 0.986), (0.690, 0.958), and (0.798, 0.986), respectively. For the external test set, the sensitivity and specificity of FF is (0.989, 0.797), and first-, third-, and fifth-year clinicians are (0.533, 0.875), (0.609, 0.844), and (0.663, 0.781), respectively.On the fetal malformation classification task, all physicians achieved higher accuracy and F1-Score on Fetus selected standard images with statistical significance (p\u00a0<\u00a00.01).\n\n\nCONCLUSION\nWe proposed a new deep learning-based Fetus Framework for identifying key fetus intracranial structures. The framework was tested on data from two different medical centers. The results show consistency and improvement from classic models and human experts in standard and non-standard sagittal view classification during pregnancy week 11-13+6.\n\n\nCLINICAL RELEVANCE/APPLICATION\nWith further refinement in larger population, the proposed model can improve the efficiency and accuracy of early pregnancy test using ultrasound examination.",
            "fieldsOfStudy": [
                "Computer Science",
                "Medicine"
            ],
            "authors": [
                {
                    "authorId": "2154861732",
                    "name": "Yitao Jiang"
                },
                {
                    "authorId": "2155015019",
                    "name": "Qi Li"
                },
                {
                    "authorId": "47942990",
                    "name": "Yuli Zhou"
                },
                {
                    "authorId": "2108259221",
                    "name": "Yujuan Zhang"
                },
                {
                    "authorId": "2072685882",
                    "name": "Siyuan Shi"
                },
                {
                    "authorId": "2026202817",
                    "name": "Shaoli Yin"
                },
                {
                    "authorId": "14910591",
                    "name": "Xuye Liu"
                },
                {
                    "authorId": "151178282",
                    "name": "Qi-hui Peng"
                },
                {
                    "authorId": "1640074285",
                    "name": "Shaoting Huang"
                },
                {
                    "authorId": "2052274777",
                    "name": "Chen Cui"
                },
                {
                    "authorId": "2096517986",
                    "name": "Ruilian Zhe"
                },
                {
                    "authorId": "49394517",
                    "name": "Jinfeng Xu"
                },
                {
                    "authorId": "12915953",
                    "name": "F. Dong"
                }
            ]
        },
        {
            "paperId": "21d6bb1a79a69c207a5d1187ebfce5150b58e441",
            "title": "Graph-Augmented Code Summarization in Computational Notebooks",
            "abstract": "Computational notebooks allow data scientists to express their ideas through a combination of code and documentation. However, data scientists often pay attention only to the code and neglect the creation of the documentation in a notebook. In this work, we present a human-centered automation system, Themisto, that can support users to easily create documentation via three approaches: 1) We have developed and reported a GNN-augmented code documentation generation algorithm in a previous paper, which can generate documentation for a given source code; 2) Themisto also implements a query-based approach to retrieve the online API documentation as the summary for certain types of source code; 3) Lastly, Themistoalso enables a user prompt approach to motivate users to write documentation for some use cases that automation does not work well.",
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "authors": [
                {
                    "authorId": "1405923139",
                    "name": "A. Wang"
                },
                {
                    "authorId": "36743361",
                    "name": "Dakuo Wang"
                },
                {
                    "authorId": "14910591",
                    "name": "Xuye Liu"
                },
                {
                    "authorId": "2116666963",
                    "name": "Lingfei Wu"
                }
            ]
        },
        {
            "paperId": "315b453eb889ded846c1685b2cd3ac700f69459c",
            "title": "Documentation Matters: Human-Centered AI System to Assist Data Science Code Documentation in Computational Notebooks",
            "abstract": "Computational notebooks allow data scientists to express their ideas through a combination of code and documentation. However, data scientists often pay attention only to the code, and neglect creating or updating their documentation during quick iterations. Inspired by human documentation practices learned from 80 highly-voted Kaggle notebooks, we design and implement Themisto, an automated documentation generation system to explore how human-centered AI systems can support human data scientists in the machine learning code documentation scenario. Themisto facilitates the creation of documentation via three approaches: a deep-learning-based approach to generate documentation for source code, a query-based approach to retrieve online API documentation for source code, and a user prompt approach to nudge users to write documentation. We evaluated Themisto in a within-subjects experiment with 24 data science practitioners, and found that automated documentation generation techniques reduced the time for writing documentation, reminded participants to document code they would have ignored, and improved participants\u2019 satisfaction with their computational notebook.",
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "authors": [
                {
                    "authorId": "1405923139",
                    "name": "A. Wang"
                },
                {
                    "authorId": "36743361",
                    "name": "Dakuo Wang"
                },
                {
                    "authorId": "46178771",
                    "name": "Jaimie Drozdal"
                },
                {
                    "authorId": "1561777696",
                    "name": "Michael J. Muller"
                },
                {
                    "authorId": "2504744",
                    "name": "Soya Park"
                },
                {
                    "authorId": "1927553",
                    "name": "Justin D. Weisz"
                },
                {
                    "authorId": "14910591",
                    "name": "Xuye Liu"
                },
                {
                    "authorId": "3008832",
                    "name": "Lingfei Wu"
                },
                {
                    "authorId": "2391727",
                    "name": "Casey Dugan"
                }
            ]
        },
        {
            "paperId": "43dbd6ec6a7d0a4344f27e7508a9c2a239e92877",
            "title": "What Makes a Well-Documented Notebook? A Case Study of Data Scientists\u2019 Documentation Practices in Kaggle",
            "abstract": "Many data scientists use computational notebooks to test and present their work, as a notebook can weave code and documentation together (computational narrative), and support rapid iteration on code experiments. However, it is not easy to write good documentation in a data science notebook, partially because there is a lack of a corpus of well-documented notebooks as exemplars for data scientists to follow. To cope with this challenge, this work looks at Kaggle \u2014 a large online community for data scientists to host and participate in machine learning competitions \u2014 and considers highly-voted Kaggle notebooks as a proxy for well-documented notebooks. Through a qualitative analysis at both the notebook level and the markdown-cell level, we find these notebooks are indeed well documented in reference to previous literature. Our analysis also reveals nine categories of content that data scientists write in their documentation cells, and these documentation cells often interplay with different stages of the data science lifecycle. We conclude the paper with design implications and future research directions.",
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "authors": [
                {
                    "authorId": "1405923139",
                    "name": "A. Wang"
                },
                {
                    "authorId": "36743361",
                    "name": "Dakuo Wang"
                },
                {
                    "authorId": "46178771",
                    "name": "Jaimie Drozdal"
                },
                {
                    "authorId": "14910591",
                    "name": "Xuye Liu"
                },
                {
                    "authorId": "2504744",
                    "name": "Soya Park"
                },
                {
                    "authorId": "3395961",
                    "name": "Steve Oney"
                },
                {
                    "authorId": "47558994",
                    "name": "Christopher A. Brooks"
                }
            ]
        },
        {
            "paperId": "6e2b1038682cd116b2e38bec19b5721196c41eea",
            "title": "HAConvGNN: Hierarchical Attention Based Convolutional Graph Neural Network for Code Documentation Generation in Jupyter Notebooks",
            "abstract": "Jupyter notebook allows data scientists to write machine learning code together with its documentation in cells. In this paper, we propose a new task of code documentation generation (CDG) for computational notebooks. In contrast to the previous CDG tasks which focus on generating documentation for single code snippets, in a computational notebook, one documentation in a markdown cell often corresponds to multiple code cells, and these code cells have an inherent structure. We proposed a new model (HAConvGNN) that uses a hierarchical attention mechanism to consider the relevant code cells and the relevant code tokens information when generating the documentation. Tested on a new corpus constructed from well-documented Kaggle notebooks, we show that our model outperforms other baseline models.",
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "authors": [
                {
                    "authorId": "14910591",
                    "name": "Xuye Liu"
                },
                {
                    "authorId": "36743361",
                    "name": "Dakuo Wang"
                },
                {
                    "authorId": "1405923139",
                    "name": "A. Wang"
                },
                {
                    "authorId": "3008832",
                    "name": "Lingfei Wu"
                }
            ]
        },
        {
            "paperId": "9c3f22ed2c4f865a84a595dfa1390f431f9fb27a",
            "title": "Themisto: Towards Automated Documentation Generation in Computational Notebooks",
            "abstract": "Computational notebooks allow data scientists to express their ideas through a combination of code and documentation. However, data scientists often pay attention only to the code, and neglect creating or updating their documentation during quick iterations, which leads to challenges in sharing their notebooks with others and future selves. Inspired by human documentation practices from analyzing 80 highly-voted Kaggle notebooks, we design and implement Themisto, an automated documentation generation system to explore the Human-AI Collaboration opportunity in the code documentation scenario. Themisto facilitates the creation of different types of documentations via three approaches: a deep-learning-based approach to generate documentation for source code (fully automated), a query-based approach to retrieve the online API documentation for source code (fully automated), and a user prompt approach to motivate users to write more documentation (semi-automated). We evaluated Themisto in a within-subjects experiment with 24 data science practitioners, and found that automated documentation generation techniques reduced the time for writing documentation, reminded participants to document code they would have ignored, and improved participants\u2019 satisfaction with their computational notebook.",
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "authors": [
                {
                    "authorId": "1405923139",
                    "name": "A. Wang"
                },
                {
                    "authorId": "36743361",
                    "name": "Dakuo Wang"
                },
                {
                    "authorId": "46178771",
                    "name": "Jaimie Drozdal"
                },
                {
                    "authorId": "1561777696",
                    "name": "Michael J. Muller"
                },
                {
                    "authorId": "2504744",
                    "name": "Soya Park"
                },
                {
                    "authorId": "1927553",
                    "name": "Justin D. Weisz"
                },
                {
                    "authorId": "14910591",
                    "name": "Xuye Liu"
                },
                {
                    "authorId": "3008832",
                    "name": "Lingfei Wu"
                },
                {
                    "authorId": "2391727",
                    "name": "Casey Dugan"
                }
            ]
        },
        {
            "paperId": "c1f6777acbb7d7b22d683ce9eb19deda740c56b0",
            "title": "How Data Scientists Improve Generated Code Documentation in Jupyter Notebooks",
            "abstract": "Generative AI models are capable of creating high-fidelity outputs, sometimes indistinguishable from what could be produced by human effort. However, some domains possess an objective bar of quality, and the probabilistic nature of generative models suggests that there may be imperfections or flaws in their output. In software engineering, for example, code produced by a generative model may not compile, or it may contain bugs or logical errors. Various models of human-AI interaction, such as mixed-initiative user interfaces, suggest that human effort ought to be applied to a generative model\u2019s outputs in order to improve its quality. We report results from a controlled experiment in which data scientists used multiple models \u2013 including a GNN-based generative model \u2013 to generate and subsequently edit documentation for data science code within Jupyter notebooks. In analyzing their edit-patterns, we discovered various ways that humans made improvements to the generated documentation, and speculate that such edit data could be used to train generative models to not only identify which parts of their output might require human attention, but also how those parts could be improved.",
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "authors": [
                {
                    "authorId": "1561777696",
                    "name": "Michael J. Muller"
                },
                {
                    "authorId": "1405923139",
                    "name": "A. Wang"
                },
                {
                    "authorId": "2068083519",
                    "name": "Steven I. Ross"
                },
                {
                    "authorId": "1927553",
                    "name": "Justin D. Weisz"
                },
                {
                    "authorId": "145625761",
                    "name": "Mayank Agarwal"
                },
                {
                    "authorId": "2940762",
                    "name": "Kartik Talamadupula"
                },
                {
                    "authorId": "1764589",
                    "name": "Stephanie Houde"
                },
                {
                    "authorId": "2072809254",
                    "name": "Fernando Martinez"
                },
                {
                    "authorId": "2065495905",
                    "name": "John T. Richards"
                },
                {
                    "authorId": "46178771",
                    "name": "Jaimie Drozdal"
                },
                {
                    "authorId": "14910591",
                    "name": "Xuye Liu"
                },
                {
                    "authorId": "2752280",
                    "name": "David Piorkowski"
                },
                {
                    "authorId": "36743361",
                    "name": "Dakuo Wang"
                }
            ]
        }
    ]
}