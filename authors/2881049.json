{
    "authorId": "2881049",
    "papers": [
        {
            "paperId": "2039fb7bb2f99f586d3326e275e60c75653c6499",
            "title": "HaPPy: Harnessing the Wisdom from Multi-Perspective Graphs for Protein-Ligand Binding Affinity Prediction (Student Abstract)",
            "abstract": "Gathering information from multi-perspective graphs is an essential issue for many applications especially for proteinligand binding affinity prediction. Most of traditional approaches obtained such information individually with low interpretability. In this paper, we harness the rich information from multi-perspective graphs with a general model, which abstractly represents protein-ligand complexes with better interpretability while achieving excellent predictive performance. In addition, we specially analyze the protein-ligand binding affinity problem, taking into account the heterogeneity of proteins and ligands. Experimental evaluations demonstrate the effectiveness of our data representation strategy on public datasets by fusing information from different perspectives.",
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "authors": [
                {
                    "authorId": "2221859688",
                    "name": "Xianfeng Zhang"
                },
                {
                    "authorId": "2168143",
                    "name": "Yanhui Gu"
                },
                {
                    "authorId": "2149131224",
                    "name": "Guandong Xu"
                },
                {
                    "authorId": "2222320640",
                    "name": "Yafei Li"
                },
                {
                    "authorId": "2222342288",
                    "name": "Jinlan Wang"
                },
                {
                    "authorId": "2881049",
                    "name": "Zhenglu Yang"
                }
            ]
        },
        {
            "paperId": "446b38131e1f9605a8e43c81571e4d64a826084e",
            "title": "Named Entity Location Prediction Combining Twitter and Web",
            "abstract": "Knowledge bases are critical to many applications. However, they are greatly incomplete. Enriching knowledge bases with new entities and new location attributes becomes increasingly important. Given a named entity with tweets and Web documents where the entity appears, we aim to predict the entity city-level location combining the geographical location knowledge embedded in both Twitter and Web. This task is helpful for knowledge base enrichment and tweet location prediction. In this paper we propose NELPTW, the first unsupervised framework for <underline><bold>N</bold></underline>amed <underline><bold>E</bold></underline>ntity <underline><bold>L</bold></underline>ocation <underline><bold>P</bold></underline>rediction by leveraging the knowledge from <underline><bold>T</bold></underline>witter and <underline><bold>W</bold></underline>eb. Based on each data source, NELPTW utilizes a linear function ranking model to generate several rankings to the candidate location set for each entity. To combine the knowledge from two sources which have different reliability and importance for the location prediction, an unsupervised rank aggregation algorithm is developed to aggregate multiple rankings for each entity to obtain a better ranking. A learning algorithm based on the EM method is proposed to automatically learn the parameters of the ranking model without requiring any training labels. The experimental results over a real world Twitter and Web data set show that our framework significantly outperforms the baselines in terms of accuracy.",
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "authors": [
                {
                    "authorId": "119924024",
                    "name": "Yinan Liu"
                },
                {
                    "authorId": "2117226472",
                    "name": "Wei Shen"
                },
                {
                    "authorId": "1576489304",
                    "name": "Zonghai Yao"
                },
                {
                    "authorId": "2447408",
                    "name": "Jianyong Wang"
                },
                {
                    "authorId": "2881049",
                    "name": "Zhenglu Yang"
                },
                {
                    "authorId": "1721029",
                    "name": "Xiaojie Yuan"
                }
            ]
        },
        {
            "paperId": "02c13b4f08d5cdb0dbe7bcc1d401c6bb5ca4ed23",
            "title": "An Effective Multi-Label Feature Selection Model Towards Eliminating Noisy Features",
            "abstract": "Feature selection has devoted a consistently great amount of effort to dimension reduction for various machine learning tasks. Existing feature selection models focus on selecting the most discriminative features for learning targets. However, this strategy is weak in handling two kinds of features, that is, the irrelevant and redundant ones, which are collectively referred to as noisy features. These features may hamper the construction of optimal low-dimensional subspaces and compromise the learning performance of downstream tasks. In this study, we propose a novel multi-label feature selection approach by embedding label correlations (dubbed ELC) to address these issues. Particularly, we extract label correlations for reliable label space structures and employ them to steer feature selection. In this way, label and feature spaces can be expected to be consistent and noisy features can be effectively eliminated. An extensive experimental evaluation on public benchmarks validated the superiority of ELC.",
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "authors": [
                {
                    "authorId": "2152809962",
                    "name": "Jun Wang"
                },
                {
                    "authorId": "2110355197",
                    "name": "Yuan Xu"
                },
                {
                    "authorId": "3098203",
                    "name": "Hengpeng Xu"
                },
                {
                    "authorId": "2118237750",
                    "name": "Zhe Sun"
                },
                {
                    "authorId": "2881049",
                    "name": "Zhenglu Yang"
                },
                {
                    "authorId": "1790914",
                    "name": "Jinmao Wei"
                }
            ]
        },
        {
            "paperId": "099524cb3765e02090e0c07369bb418a03095781",
            "title": "Curriculum Pre-training for End-to-End Speech Translation",
            "abstract": "End-to-end speech translation poses a heavy burden on the encoder because it has to transcribe, understand, and learn cross-lingual semantics simultaneously. To obtain a powerful encoder, traditional methods pre-train it on ASR data to capture speech features. However, we argue that pre-training the encoder only through simple speech recognition is not enough, and high-level linguistic knowledge should be considered. Inspired by this, we propose a curriculum pre-training method that includes an elementary course for transcription learning and two advanced courses for understanding the utterance and mapping words in two languages. The difficulty of these courses is gradually increasing. Experiments show that our curriculum pre-training method leads to significant improvements on En-De and En-Fr speech translation benchmarks.",
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "authors": [
                {
                    "authorId": "8206308",
                    "name": "Chengyi Wang"
                },
                {
                    "authorId": "2142240763",
                    "name": "Yu Wu"
                },
                {
                    "authorId": "1803054",
                    "name": "Shujie Liu"
                },
                {
                    "authorId": "92660691",
                    "name": "Ming Zhou"
                },
                {
                    "authorId": "2881049",
                    "name": "Zhenglu Yang"
                }
            ]
        },
        {
            "paperId": "258d015243ba2f396f4094aa401ea38b6a423984",
            "title": "Generalized Relation Learning with Semantic Correlation Awareness for Link Prediction",
            "abstract": "Developing link prediction models to automatically complete knowledge graphs has recently been the focus of significant research interest. The current methods for the link prediction task have two natural problems: 1) the relation distributions in KGs are usually unbalanced, and 2) there are many unseen relations that occur in practical situations. These two problems limit the training effectiveness and practical applications of the existing link prediction models. We advocate a holistic understanding of KGs and we propose in this work a unified Generalized Relation Learning framework GRL to address the above two problems, which can be plugged into existing link prediction models. GRL conducts a generalized relation learning, which is aware of semantic correlations between relations that serve as a bridge to connect semantically similar relations. After training with GRL, the closeness of semantically similar relations in vector space and the discrimination of dissimilar relations are improved. We perform comprehensive experiments on six benchmarks to demonstrate the superior capability of GRL in the link prediction task. In particular, GRL is found to enhance the existing link prediction models making them insensitive to unbalanced relation distributions and capable of learning unseen relations.",
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "authors": [
                {
                    "authorId": "1611287648",
                    "name": "Yao Zhang"
                },
                {
                    "authorId": "2115463398",
                    "name": "Xu Zhang"
                },
                {
                    "authorId": "2152809962",
                    "name": "Jun Wang"
                },
                {
                    "authorId": "46822058",
                    "name": "Hongru Liang"
                },
                {
                    "authorId": "39165620",
                    "name": "Wenqiang Lei"
                },
                {
                    "authorId": "2118237750",
                    "name": "Zhe Sun"
                },
                {
                    "authorId": "1774986",
                    "name": "A. Jatowt"
                },
                {
                    "authorId": "2881049",
                    "name": "Zhenglu Yang"
                }
            ]
        },
        {
            "paperId": "6df6629d80ddd412144f71b093dc06b4e06d897f",
            "title": "GMH: A General Multi-hop Reasoning Model for KG Completion",
            "abstract": "Knowledge graphs are essential for numerous downstream natural language processing applications, but are typically incomplete with many facts missing. This results in research efforts on multi-hop reasoning task, which can be formulated as a search process and current models typically perform short distance reasoning. However, the long-distance reasoning is also vital with the ability to connect the superficially unrelated entities. To the best of our knowledge, there lacks a general framework that approaches multi-hop reasoning in mixed long-short distance reasoning scenarios. We argue that there are two key issues for a general multi-hop reasoning model: i) where to go, and ii) when to stop. Therefore, we propose a general model which resolves the issues with three modules: 1) the local-global knowledge module to estimate the possible paths, 2) the differentiated action dropout module to explore a diverse set of paths, and 3) the adaptive stopping search module to avoid over searching. The comprehensive results on three datasets demonstrate the superiority of our model with significant improvements against baselines in both short and long distance reasoning scenarios.",
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "authors": [
                {
                    "authorId": "1611287648",
                    "name": "Yao Zhang"
                },
                {
                    "authorId": "2115463398",
                    "name": "Xu Zhang"
                },
                {
                    "authorId": "2152809962",
                    "name": "Jun Wang"
                },
                {
                    "authorId": "46822058",
                    "name": "Hongru Liang"
                },
                {
                    "authorId": "1774986",
                    "name": "A. Jatowt"
                },
                {
                    "authorId": "39165620",
                    "name": "Wenqiang Lei"
                },
                {
                    "authorId": "2881049",
                    "name": "Zhenglu Yang"
                }
            ]
        },
        {
            "paperId": "89232937e3325a078e211015f2ec88660e8fcca0",
            "title": "Multi-modal Summarization for Video-containing Documents",
            "abstract": "Summarization of multimedia data becomes increasingly significant as it is the basis for many real-world applications, such as question answering, Web search, and so forth. Most existing multi-modal summarization works however have used visual complementary features extracted from images rather than videos, thereby losing abundant information. Hence, we propose a novel multi-modal summarization task to summarize from a document and its associated video. In this work, we also build a baseline general model with effective strategies, i.e., bi-hop attention and improved late fusion mechanisms to bridge the gap between different modalities, and a bi-stream summarization strategy to employ text and video summarization simultaneously. Comprehensive experiments show that the proposed model is beneficial for multi-modal summarization and superior to existing methods. Moreover, we collect a novel dataset and it provides a new resource for future study that results from documents and videos.",
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "authors": [
                {
                    "authorId": "153000866",
                    "name": "Xiyan Fu"
                },
                {
                    "authorId": "2152809962",
                    "name": "Jun Wang"
                },
                {
                    "authorId": "2881049",
                    "name": "Zhenglu Yang"
                }
            ]
        },
        {
            "paperId": "b386703e70f29d3af196975be667628a885eb7c2",
            "title": "Multi-Point Semantic Representation for Intent Classification",
            "abstract": "Detecting user intents from utterances is the basis of natural language understanding (NLU) task. To understand the meaning of utterances, some work focuses on fully representing utterances via semantic parsing in which annotation cost is labor-intentsive. While some researchers simply view this as intent classification or frequently asked questions (FAQs) retrieval, they do not leverage the shared utterances among different intents. We propose a simple and novel multi-point semantic representation framework with relatively low annotation cost to leverage the fine-grained factor information, decomposing queries into four factors, i.e., topic, predicate, object/condition, query type. Besides, we propose a compositional intent bi-attention model under multi-task learning with three kinds of attention mechanisms among queries, labels and factors, which jointly combines coarse-grained intent and fine-grained factor information. Extensive experiments show that our framework and model significantly outperform several state-of-the-art approaches with an improvement of 1.35%-2.47% in terms of accuracy.",
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "authors": [
                {
                    "authorId": null,
                    "name": "Jinghan Zhang"
                },
                {
                    "authorId": "47107411",
                    "name": "Yuxiao Ye"
                },
                {
                    "authorId": "1591125925",
                    "name": "Yue Zhang"
                },
                {
                    "authorId": "7653108",
                    "name": "Likun Qiu"
                },
                {
                    "authorId": "2052628846",
                    "name": "Bin Fu"
                },
                {
                    "authorId": "98177814",
                    "name": "Y. Li"
                },
                {
                    "authorId": "2881049",
                    "name": "Zhenglu Yang"
                },
                {
                    "authorId": null,
                    "name": "Jian Sun"
                }
            ]
        },
        {
            "paperId": "d9ec170160c69df9863f390d06bfefc213d0836f",
            "title": "Document Summarization with VHTM: Variational Hierarchical Topic-Aware Mechanism",
            "abstract": "Automatic text summarization focuses on distilling summary information from texts. This research field has been considerably explored over the past decades because of its significant role in many natural language processing tasks; however, two challenging issues block its further development: (1) how to yield a summarization model embedding topic inference rather than extending with a pre-trained one and (2) how to merge the latent topics into diverse granularity levels. In this study, we propose a variational hierarchical model to holistically address both issues, dubbed VHTM. Different from the previous work assisted by a pre-trained single-grained topic model, VHTM is the first attempt to jointly accomplish summarization with topic inference via variational encoder-decoder and merge topics into multi-grained levels through topic embedding and attention. Comprehensive experiments validate the superior performance of VHTM compared with the baselines, accompanying with semantically consistent topics.",
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "authors": [
                {
                    "authorId": "153000866",
                    "name": "Xiyan Fu"
                },
                {
                    "authorId": "2152809962",
                    "name": "Jun Wang"
                },
                {
                    "authorId": null,
                    "name": "Jinghan Zhang"
                },
                {
                    "authorId": "1790914",
                    "name": "Jinmao Wei"
                },
                {
                    "authorId": "2881049",
                    "name": "Zhenglu Yang"
                }
            ]
        },
        {
            "paperId": "f7d8ebe266bed69eaa30e8c06302364fee4fd31a",
            "title": "PiRhDy: Learning Pitch-, Rhythm-, and Dynamics-aware Embeddings for Symbolic Music",
            "abstract": "Definitive embeddings remain a fundamental challenge of computational musicology for symbolic music in deep learning today. Analogous to natural language, music can be modeled as a sequence of tokens. This motivates the majority of existing solutions to explore the utilization of word embedding models to build music embeddings. However, music differs from natural languages in two key aspects: (1) musical token is multi-faceted -- it comprises of pitch, rhythm and dynamics information; and (2) musical context is two-dimensional -- each musical token is dependent on both melodic and harmonic contexts. In this work, we provide a comprehensive solution by proposing a novel framework named PiRhDy that integrates pitch, rhythm, and dynamics information seamlessly. PiRhDy adopts a hierarchical strategy which can be decomposed into two steps: (1) token (i.e., note event) modeling, which separately represents pitch, rhythm, and dynamics and integrates them into a single token embedding; and (2) context modeling, which utilizes melodic and harmonic knowledge to train the token embedding. A thorough study was made on each component and sub-strategy of PiRhDy.We further validate our embeddings in three downstream tasks -- melody completion, accompaniment suggestion, and genre classification. Results indicate a significant advancement of the neural approach towards symbolic music as well as PiRhDy's potential as a pretrained tool for a broad range of symbolic music applications.",
            "fieldsOfStudy": [
                "Computer Science",
                "Engineering"
            ],
            "authors": [
                {
                    "authorId": "46822058",
                    "name": "Hongru Liang"
                },
                {
                    "authorId": "39165620",
                    "name": "Wenqiang Lei"
                },
                {
                    "authorId": "2110847",
                    "name": "P. Chan"
                },
                {
                    "authorId": "2881049",
                    "name": "Zhenglu Yang"
                },
                {
                    "authorId": "1753344",
                    "name": "Maosong Sun"
                },
                {
                    "authorId": "144078686",
                    "name": "Tat-Seng Chua"
                }
            ]
        }
    ]
}