{
    "authorId": "2275173839",
    "papers": [
        {
            "paperId": "25a84b841f4f8c565b212b130d848f2550292937",
            "title": "Be Aware of the Neighborhood Effect: Modeling Selection Bias under Interference",
            "abstract": "Selection bias in recommender system arises from the recommendation process of system filtering and the interactive process of user selection. Many previous studies have focused on addressing selection bias to achieve unbiased learning of the prediction model, but ignore the fact that potential outcomes for a given user-item pair may vary with the treatments assigned to other user-item pairs, named neighborhood effect. To fill the gap, this paper formally formulates the neighborhood effect as an interference problem from the perspective of causal inference and introduces a treatment representation to capture the neighborhood effect. On this basis, we propose a novel ideal loss that can be used to deal with selection bias in the presence of neighborhood effect. We further develop two new estimators for estimating the proposed ideal loss. We theoretically establish the connection between the proposed and previous debiasing methods ignoring the neighborhood effect, showing that the proposed methods can achieve unbiased learning when both selection bias and neighborhood effect are present, while the existing methods are biased. Extensive semi-synthetic and real-world experiments are conducted to demonstrate the effectiveness of the proposed methods.",
            "fieldsOfStudy": [
                "Computer Science",
                "Mathematics"
            ],
            "authors": [
                {
                    "authorId": "2051689367",
                    "name": "Haoxuan Li"
                },
                {
                    "authorId": "2051688235",
                    "name": "Chunyuan Zheng"
                },
                {
                    "authorId": "2046758017",
                    "name": "Sihao Ding"
                },
                {
                    "authorId": "2287982205",
                    "name": "Peng Wu"
                },
                {
                    "authorId": "2228992995",
                    "name": "Zhi Geng"
                },
                {
                    "authorId": "2275173839",
                    "name": "Fuli Feng"
                },
                {
                    "authorId": "2239071206",
                    "name": "Xiangnan He"
                }
            ]
        },
        {
            "paperId": "3a2cd1ac9a71912a37b6fb513e0ec69a3a74176f",
            "title": "Large Language Models for Recommendation: Progresses and Future Directions",
            "abstract": "Large language models (LLMs) have significantly influenced recommender systems. Both academia and industry have shown growing interest in developing LLMs for recommendation purposes, an approach commonly referred to as LLM4Rec. This involves efforts such as utilizing LLMs for generative item retrieval and ranking, along with the potential for creating universal LLMs for varied recommendation tasks, signaling a possible paradigm shift in recommender systems. This tutorial is designed to review the progression of LLM4Rec and provide an in-depth analysis of the prevailing studies. We will discuss how LLMs advance recommender systems in model architecture, learning paradigms, and capabilities like conversation, generalization, planning, and content generation. Additionally, the tutorial will highlight open problems and challenges in this nascent field, addressing concerns related to trustworthiness, efficiency, online training, and recommendation data modeling. Concluding with a summary of the takeaways from previous research, the tutorial will suggest avenues for future investigations. Our aim is to help the audience grasp the developments in LLM4Rec, as well as to spark inspiration for further research. By doing so, we expect to contribute to the growth and success of LLM4Rec, possibly leading to a fundamental change in recommender paradigms.",
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "authors": [
                {
                    "authorId": "2116265843",
                    "name": "Jizhi Zhang"
                },
                {
                    "authorId": "2188063534",
                    "name": "Keqin Bao"
                },
                {
                    "authorId": "2145957648",
                    "name": "Yang Zhang"
                },
                {
                    "authorId": "2117833732",
                    "name": "Wenjie Wang"
                },
                {
                    "authorId": "2275173839",
                    "name": "Fuli Feng"
                },
                {
                    "authorId": "2239071206",
                    "name": "Xiangnan He"
                }
            ]
        },
        {
            "paperId": "40fd47de355722f7968b2bc1fca8a69d5bbfa047",
            "title": "Improving Prostate Cancer Risk Prediction through Partial AUC Optimization",
            "abstract": "Prostate cancer risk prediction (PCRP) is crucial in guiding clinical decision-making and ensuring accurate diagnoses. The area under the receiver operating characteristic curve (AUC) is typically used for the evaluation of PCRP models. However, AUC considers regions with high false positive rates (FPRs), which are not applicable in clinical practice. To address this concern, we propose to use partial AUC (pAUC) as a more clinically meaningful metric which evaluates PCRP models with restricted FPR. Moreover, we propose a new PCRP framework named pAUCP, which optimizes pAUC to train PCRP models and adopts model ensemble to further enhance its usability. We construct clinical datasets obtained from two medical centers over an extended period to evaluate the proposed pAUCP framework. Extensive experiments demonstrate the rationality and superiority of the pAUCP framework, especially the cross-time and cross-center transferability of the obtained PCRP model.",
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "authors": [
                {
                    "authorId": "2165424018",
                    "name": "Xinyuan Zhu"
                },
                {
                    "authorId": "2302133000",
                    "name": "Xiaohan Ren"
                },
                {
                    "authorId": "2153422494",
                    "name": "Wentao Shi"
                },
                {
                    "authorId": "2267729999",
                    "name": "Changming Wang"
                },
                {
                    "authorId": "2246739128",
                    "name": "Xuehan Liu"
                },
                {
                    "authorId": "2301208091",
                    "name": "Yuqing Liu"
                },
                {
                    "authorId": "2267470873",
                    "name": "Tao Tao"
                },
                {
                    "authorId": "2275173839",
                    "name": "Fuli Feng"
                }
            ]
        },
        {
            "paperId": "435d1fd081c2ee3f9ade8081be6bdda87385a458",
            "title": "Fair Recommendations with Limited Sensitive Attributes: A Distributionally Robust Optimization Approach",
            "abstract": "As recommender systems are indispensable in various domains such as job searching and e-commerce, providing equitable recommendations to users with different sensitive attributes becomes an imperative requirement. Prior approaches for enhancing fairness in recommender systems presume the availability of all sensitive attributes, which can be difficult to obtain due to privacy concerns or inadequate means of capturing these attributes. In practice, the efficacy of these approaches is limited, pushing us to investigate ways of promoting fairness with limited sensitive attribute information. Toward this goal, it is important to reconstruct missing sensitive attributes. Nevertheless, reconstruction errors are inevitable due to the complexity of real-world sensitive attribute reconstruction problems and legal regulations. Thus, we pursue fair learning methods that are robust to reconstruction errors. To this end, we propose Distributionally Robust Fair Optimization (DRFO), which minimizes the worst-case unfairness over all potential probability distributions of missing sensitive attributes instead of the reconstructed one to account for the impact of the reconstruction errors. We provide theoretical and empirical evidence to demonstrate that our method can effectively ensure fairness in recommender systems when only limited sensitive attributes are accessible.",
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "authors": [
                {
                    "authorId": "2276424502",
                    "name": "Tianhao Shi"
                },
                {
                    "authorId": "2145957648",
                    "name": "Yang Zhang"
                },
                {
                    "authorId": "2116265843",
                    "name": "Jizhi Zhang"
                },
                {
                    "authorId": "2275173839",
                    "name": "Fuli Feng"
                },
                {
                    "authorId": "2239071206",
                    "name": "Xiangnan He"
                }
            ]
        },
        {
            "paperId": "4efd7cd724802d7ac3ccef972309691466d4637a",
            "title": "Decoding Matters: Addressing Amplification Bias and Homogeneity Issue for LLM-based Recommendation",
            "abstract": "Adapting Large Language Models (LLMs) for recommendation requires careful consideration of the decoding process, given the inherent differences between generating items and natural language. Existing approaches often directly apply LLMs' original decoding methods. However, we find these methods encounter significant challenges: 1) amplification bias -- where standard length normalization inflates scores for items containing tokens with generation probabilities close to 1 (termed ghost tokens), and 2) homogeneity issue -- generating multiple similar or repetitive items for a user. To tackle these challenges, we introduce a new decoding approach named Debiasing-Diversifying Decoding (D3). D3 disables length normalization for ghost tokens to alleviate amplification bias, and it incorporates a text-free assistant model to encourage tokens less frequently generated by LLMs for counteracting recommendation homogeneity. Extensive experiments on real-world datasets demonstrate the method's effectiveness in enhancing accuracy and diversity.",
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "authors": [
                {
                    "authorId": "2188063534",
                    "name": "Keqin Bao"
                },
                {
                    "authorId": "2116265843",
                    "name": "Jizhi Zhang"
                },
                {
                    "authorId": "2145957648",
                    "name": "Yang Zhang"
                },
                {
                    "authorId": "2307916329",
                    "name": "Xinyue Huo"
                },
                {
                    "authorId": "2307971167",
                    "name": "Chong Chen"
                },
                {
                    "authorId": "2275173839",
                    "name": "Fuli Feng"
                }
            ]
        },
        {
            "paperId": "8591c3e0239be3e089449d3899b94f0a9c75465a",
            "title": "Text-like Encoding of Collaborative Information in Large Language Models for Recommendation",
            "abstract": "When adapting Large Language Models for Recommendation (LLMRec), it is crucial to integrate collaborative information. Existing methods achieve this by learning collaborative embeddings in LLMs' latent space from scratch or by mapping from external models. However, they fail to represent the information in a text-like format, which may not align optimally with LLMs. To bridge this gap, we introduce BinLLM, a novel LLMRec method that seamlessly integrates collaborative information through text-like encoding. BinLLM converts collaborative embeddings from external models into binary sequences -- a specific text format that LLMs can understand and operate on directly, facilitating the direct usage of collaborative information in text-like format by LLMs. Additionally, BinLLM provides options to compress the binary sequence using dot-decimal notation to avoid excessively long lengths. Extensive experiments validate that BinLLM introduces collaborative information in a manner better aligned with LLMs, resulting in enhanced performance. We release our code at https://github.com/zyang1580/BinLLM.",
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "authors": [
                {
                    "authorId": "2145957648",
                    "name": "Yang Zhang"
                },
                {
                    "authorId": "2188063534",
                    "name": "Keqin Bao"
                },
                {
                    "authorId": "2310062077",
                    "name": "Ming Yang"
                },
                {
                    "authorId": "2117833732",
                    "name": "Wenjie Wang"
                },
                {
                    "authorId": "2275173839",
                    "name": "Fuli Feng"
                },
                {
                    "authorId": "2239071206",
                    "name": "Xiangnan He"
                }
            ]
        },
        {
            "paperId": "8d90a0813617b90d90b9cc7cde91211bde496a47",
            "title": "Leave No Patient Behind: Enhancing Medication Recommendation for Rare Disease Patients",
            "abstract": "Medication recommendation systems have gained significant attention in healthcare as a means of providing tailored and effective drug combinations based on patients' clinical information. However, existing approaches often suffer from fairness issues, as recommendations tend to be more accurate for patients with common diseases compared to those with rare conditions. In this paper, we propose a novel model called Robust and Accurate REcommendations for Medication (RAREMed), which leverages the pretrain-finetune learning paradigm to enhance accuracy for rare diseases. RAREMed employs a transformer encoder with a unified input sequence approach to capture complex relationships among disease and procedure codes. Additionally, it introduces two self-supervised pre-training tasks, namely Sequence Matching Prediction (SMP) and Self Reconstruction (SR), to learn specialized medication needs and interrelations among clinical codes. Experimental results on two real-world datasets demonstrate that RAREMed provides accurate drug sets for both rare and common disease patients, thereby mitigating unfairness in medication recommendation systems.",
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "authors": [
                {
                    "authorId": "2293453301",
                    "name": "Zihao Zhao"
                },
                {
                    "authorId": "2293673637",
                    "name": "Yi Jing"
                },
                {
                    "authorId": "2275173839",
                    "name": "Fuli Feng"
                },
                {
                    "authorId": "1491035012",
                    "name": "Jiancan Wu"
                },
                {
                    "authorId": "2265123543",
                    "name": "Chongming Gao"
                },
                {
                    "authorId": "2239071206",
                    "name": "Xiangnan He"
                }
            ]
        },
        {
            "paperId": "a07a41c42ce841fbbaac1563cb99fad9d97837bb",
            "title": "When I Fall in Love: Capturing Video-Oriented Social Relationship Evolution via Attentive GNN",
            "abstract": "With the booming of streaming media platforms, viewers now get used to watching dramas and movies via online platforms with more intelligent services. Usually, character relationships may dynamically evolve with stories promoting in long videos. Therefore, automatic tools to capture the social relation evolution among characters are urgently required to enrich the viewing experience. However, most existing works mainly focus on shorter isolated video clips. Considering the development of the plot, they may fail to effectively summarize relationships as holistic semantic representations for the whole video. To deal with these challenges, in this paper, we propose a novel Dynamic-Evolutionary Graph Attention Network (DE-GAT) framework to generate the evolving social relation graph among characters and capture the characters\u2019 relation evolutionary trajectory throughout the entire video. DE-GAT first integrates the multimodal cues, including visual and textual information in each video clip via the graph attention network (GAT). Expanding the temporal receptive field from clip-level to scenario-level, the most relevant factors of the evolution of social relationships can be explored. Eventually, all the scenario-level social graphs are merged to obtain the evolving global social graph for the entire movie. Extensive evaluations on the real-world MovieGraphs dataset have validated the positive impact of temporal receptive field expansion and multimodal cues on capturing evolving social relations.",
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "authors": [
                {
                    "authorId": "2047997844",
                    "name": "Penggang Qin"
                },
                {
                    "authorId": "2142349315",
                    "name": "Shiwei Wu"
                },
                {
                    "authorId": "2151647484",
                    "name": "Tong Xu"
                },
                {
                    "authorId": "2269690786",
                    "name": "Yanbin Hao"
                },
                {
                    "authorId": "2275173839",
                    "name": "Fuli Feng"
                },
                {
                    "authorId": "2118043140",
                    "name": "Chen Zhu"
                },
                {
                    "authorId": "2173129111",
                    "name": "Enhong Chen"
                }
            ]
        },
        {
            "paperId": "a15c8e255f69f6a2e42678886019d47fb0dab3c6",
            "title": "Exact and Efficient Unlearning for Large Language Model-based Recommendation",
            "abstract": "The evolving paradigm of Large Language Model-based Recommendation (LLMRec) customizes Large Language Models (LLMs) through parameter-efficient fine-tuning (PEFT) using recommendation data. The inclusion of user data in LLMs raises privacy concerns. To protect users, the unlearning process in LLMRec, specifically removing unusable data (e.g., historical behaviors) from established LLMRec models, becomes crucial. However, existing unlearning methods are insufficient for the unique characteristics of LLM-Rec, mainly due to high computational costs or incomplete data erasure. In this study, we introduce the Adapter Partition and Aggregation (APA) framework for exact and efficient unlearning while maintaining recommendation performance. APA achieves this by establishing distinct adapters for partitioned training data shards and retraining only the adapters impacted by unusable data for unlearning. To preserve recommendation performance and mitigate considerable inference costs, APA employs parameter-level adapter aggregation with sample-adaptive attention for individual testing samples. Extensive experiments substantiate the effectiveness and efficiency of our proposed framework",
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "authors": [
                {
                    "authorId": "2111297664",
                    "name": "ZhiYu Hu"
                },
                {
                    "authorId": "2145957648",
                    "name": "Yang Zhang"
                },
                {
                    "authorId": "2296834166",
                    "name": "Minghao Xiao"
                },
                {
                    "authorId": "2117833732",
                    "name": "Wenjie Wang"
                },
                {
                    "authorId": "2275173839",
                    "name": "Fuli Feng"
                },
                {
                    "authorId": "2239071206",
                    "name": "Xiangnan He"
                }
            ]
        },
        {
            "paperId": "ada30783ffb6e221430b0e0e9e21fe8af0b596e1",
            "title": "Lower-Left Partial AUC: An Effective and Efficient Optimization Metric for Recommendation",
            "abstract": "Optimization metrics are crucial for building recommendation systems at scale. However, an effective and efficient metric for practical use remains elusive. While Top-K ranking metrics are the gold standard for optimization, they suffer from significant computational overhead. Alternatively, the more efficient accuracy and AUC metrics often fall short of capturing the true targets of recommendation tasks, leading to suboptimal performance. To overcome this dilemma, we propose a new optimization metric, Lower-Left Partial AUC (LLPAUC), which is computationally efficient like AUC but strongly correlates with Top-K ranking metrics. Compared to AUC, LLPAUC considers only the partial area under the ROC curve in the Lower-Left corner to push the optimization focus on Top-K. We provide theoretical validation of the correlation between LLPAUC and Top-K ranking metrics and demonstrate its robustness to noisy user feedback. We further design an efficient point-wise recommendation loss to maximize LLPAUC and evaluate it on three datasets, validating its effectiveness and robustness.",
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "authors": [
                {
                    "authorId": "2153422494",
                    "name": "Wentao Shi"
                },
                {
                    "authorId": "2289863291",
                    "name": "Chenxu Wang"
                },
                {
                    "authorId": "2275173839",
                    "name": "Fuli Feng"
                },
                {
                    "authorId": "2145957648",
                    "name": "Yang Zhang"
                },
                {
                    "authorId": "2117833732",
                    "name": "Wenjie Wang"
                },
                {
                    "authorId": "2260622979",
                    "name": "Junkang Wu"
                },
                {
                    "authorId": "2239071206",
                    "name": "Xiangnan He"
                }
            ]
        }
    ]
}