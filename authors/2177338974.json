{
    "authorId": "2177338974",
    "papers": [
        {
            "paperId": "0fb235cc59cd7198b5a1494157b0250cfca04386",
            "title": "Detecting Harmful Online Conversational Content towards LGBTQIA+ Individuals",
            "abstract": "Online discussions, panels, talk page edits, etc., often contain harmful conversational content i.e., hate speech, death threats and offensive language, especially towards certain demographic groups. For example, individuals who identify as members of the LGBTQIA+ community and/or BIPOC (Black, Indigenous, People of Color) are at higher risk for abuse and harassment online. In this work, we first introduce a real-world dataset that will enable us to study and understand harmful online conversational content. Then, we conduct several exploratory data analysis experiments to gain deeper insights from the dataset. We later describe our approach for detecting harmful online Anti-LGBTQIA+ conversational content, and finally, we implement two baseline machine learning models (i.e., Support Vector Machine and Logistic Regression), and fine-tune 3 pre-trained large language models (BERT, RoBERTa, and HateBERT). Our findings verify that large language models can achieve very promising performance on detecting online Anti-LGBTQIA+ conversational content detection tasks.",
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "authors": [
                {
                    "authorId": "1380259269",
                    "name": "Jamell Dacon"
                },
                {
                    "authorId": "93719189",
                    "name": "Harry Shomer"
                },
                {
                    "authorId": "2177338974",
                    "name": "Shaylynn Crum-Dacon"
                },
                {
                    "authorId": "1736632",
                    "name": "Jiliang Tang"
                }
            ]
        }
    ]
}