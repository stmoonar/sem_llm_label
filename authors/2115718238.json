{
    "authorId": "2115718238",
    "papers": [
        {
            "paperId": "6cb99af50b91fed276b7b6cee4c91cea5d222ae3",
            "title": "PriMeSRL-Eval: A Practical Quality Metric for Semantic Role Labeling Systems Evaluation",
            "abstract": "Semantic role labeling (SRL) identifies the predicate-argument structure in a sentence. This task is usually accomplished in four steps: predicate identification, predicate sense disambiguation, argument identification, and argument classification. Errors introduced at one step propagate to later steps. Unfortunately, the existing SRL evaluation scripts do not consider the full effect of this error propagation aspect. They either evaluate arguments independent of predicate sense (CoNLL09) or do not evaluate predicate sense at all (CoNLL05), yielding an inaccurate SRL model performance on the argument classification task. In this paper, we address key practical issues with existing evaluation scripts and propose a more strict SRL evaluation metric PriMeSRL. We observe that by employing PriMeSRL, the quality evaluation of all SoTA SRL models drops significantly, and their relative rankings also change. We also show that PriMeSRLsuccessfully penalizes actual failures in SoTA SRL models.",
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "authors": [
                {
                    "authorId": "144377686",
                    "name": "Ishan Jindal"
                },
                {
                    "authorId": "13836343",
                    "name": "Alexandre Rademaker"
                },
                {
                    "authorId": "1399212475",
                    "name": "Khoi-Nguyen Tran"
                },
                {
                    "authorId": "2115718238",
                    "name": "Huaiyu Zhu"
                },
                {
                    "authorId": "35562751",
                    "name": "H. Kanayama"
                },
                {
                    "authorId": "1994333",
                    "name": "Marina Danilevsky"
                },
                {
                    "authorId": "1718694",
                    "name": "Yunyao Li"
                }
            ]
        },
        {
            "paperId": "83e3b3b19bbe92a85265bcee6634738206662f03",
            "title": "Universal Proposition Bank 2.0",
            "abstract": "Semantic role labeling (SRL) represents the meaning of a sentence in the form of predicate-argument structures. Such shallow semantic analysis is helpful in a wide range of downstream NLP tasks and real-world applications. As treebanks enabled the development of powerful syntactic parsers, the accurate predicate-argument analysis demands training data in the form of propbanks. Unfortunately, most languages simply do not have corresponding propbanks due to the high cost required to construct such resources. To overcome such challenges, Universal Proposition Bank 1.0 (UP1.0) was released in 2017, with high-quality propbank data generated via a two-stage method exploiting monolingual SRL and multilingual parallel data. In this paper, we introduce Universal Proposition Bank 2.0 (UP2.0), with significant enhancements over UP1.0: (1) propbanks with higher quality by using a state-of-the-art monolingual SRL and improved auto-generation of annotations; (2) expanded language coverage (from 7 to 9 languages); (3) span annotation for the decoupling of syntactic analysis; and (4) Gold data for a subset of the languages. We also share our experimental results that confirm the significant quality improvements of the generated propbanks. In addition, we present a comprehensive experimental evaluation on how different implementation choices impact the quality of the resulting data. We release these resources to the research community and hope to encourage more research on cross-lingual SRL.",
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "authors": [
                {
                    "authorId": "144377686",
                    "name": "Ishan Jindal"
                },
                {
                    "authorId": "13836343",
                    "name": "Alexandre Rademaker"
                },
                {
                    "authorId": "2185433526",
                    "name": "Micha\u0142 Ulewicz"
                },
                {
                    "authorId": "2180951336",
                    "name": "Linh H. Ha"
                },
                {
                    "authorId": "145199659",
                    "name": "Huyen Nguyen"
                },
                {
                    "authorId": "1399212475",
                    "name": "Khoi-Nguyen Tran"
                },
                {
                    "authorId": "2115718238",
                    "name": "Huaiyu Zhu"
                },
                {
                    "authorId": "1718694",
                    "name": "Yunyao Li"
                }
            ]
        },
        {
            "paperId": "0ce581e6ce34c31d342f56d1614e01d0a6dd3d4b",
            "title": "Development of an Enterprise-Grade Contract Understanding System",
            "abstract": "Contracts are arguably the most important type of business documents. Despite their significance in business, legal contract review largely remains an arduous, expensive and manual process. In this paper, we describe TECUS: a commercial system designed and deployed for contract understanding and used by a wide range of enterprise users for the past few years. We reflect on the challenges and design decisions when building TECUS. We also summarize the data science life cycle of TECUS and share lessons learned.",
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "authors": [
                {
                    "authorId": "31820819",
                    "name": "A. Agarwal"
                },
                {
                    "authorId": "1779119",
                    "name": "Laura Chiticariu"
                },
                {
                    "authorId": "2101315244",
                    "name": "Poornima Chozhiyath Raman"
                },
                {
                    "authorId": "1994333",
                    "name": "Marina Danilevsky"
                },
                {
                    "authorId": "2438612",
                    "name": "D. Ghazi"
                },
                {
                    "authorId": "2110762290",
                    "name": "Ankush Gupta"
                },
                {
                    "authorId": "52205085",
                    "name": "Shanmukha C. Guttula"
                },
                {
                    "authorId": "2208580",
                    "name": "Yannis Katsis"
                },
                {
                    "authorId": "3252167",
                    "name": "R. Krishnamurthy"
                },
                {
                    "authorId": "1573872877",
                    "name": "Yunyao Li"
                },
                {
                    "authorId": "2101320978",
                    "name": "Shubham Mudgal"
                },
                {
                    "authorId": "1821191",
                    "name": "Vitobha Munigala"
                },
                {
                    "authorId": "2057607891",
                    "name": "Nicholas Phan"
                },
                {
                    "authorId": "2101315127",
                    "name": "Dhaval Sonawane"
                },
                {
                    "authorId": "40615569",
                    "name": "S. Srinivasan"
                },
                {
                    "authorId": "39935833",
                    "name": "Sudarshan Rangarajan Thitte"
                },
                {
                    "authorId": "2537800",
                    "name": "M. Vasa"
                },
                {
                    "authorId": "1710483",
                    "name": "R. Venkatachalam"
                },
                {
                    "authorId": "2101322275",
                    "name": "Vinitha Yaski"
                },
                {
                    "authorId": "2115718238",
                    "name": "Huaiyu Zhu"
                }
            ]
        },
        {
            "paperId": "66978698693c0bfaa0859ca400fdce3acd4c7f7b",
            "title": "Improving Cross-lingual Text Classification with Zero-shot Instance-Weighting",
            "abstract": "Cross-lingual text classification (CLTC) is a challenging task made even harder still due to the lack of labeled data in low-resource languages. In this paper, we propose zero-shot instance-weighting, a general model-agnostic zero-shot learning framework for improving CLTC by leveraging source instance weighting. It adds a module on top of pre-trained language models for similarity computation of instance weights, thus aligning each source instance to the target language. During training, the framework utilizes gradient descent that is weighted by instance weights to update parameters. We evaluate this framework over seven target languages on three fundamental tasks and show its effectiveness and extensibility, by improving on F1 score up to 4% in single-source transfer and 8% in multi-source transfer. To the best of our knowledge, our method is the first to apply instance weighting in zero-shot CLTC. It is simple yet effective and easily extensible into multi-source transfer.",
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "authors": [
                {
                    "authorId": "46331602",
                    "name": "Irene Li"
                },
                {
                    "authorId": "40655309",
                    "name": "Prithviraj Sen"
                },
                {
                    "authorId": "2115718238",
                    "name": "Huaiyu Zhu"
                },
                {
                    "authorId": "1573872877",
                    "name": "Yunyao Li"
                },
                {
                    "authorId": "9215251",
                    "name": "Dragomir R. Radev"
                }
            ]
        },
        {
            "paperId": "2d8543ef010371eaa94b03df67e3636f4f62d821",
            "title": "Small but Mighty: New Benchmarks for Split and Rephrase",
            "abstract": "Split and Rephrase is a text simplification task of rewriting a complex sentence into simpler ones. As a relatively new task, it is paramount to ensure the soundness of its evaluation benchmark and metric. We find that the widely used benchmark dataset universally contains easily exploitable syntactic cues caused by its automatic generation process. Taking advantage of such cues, we show that even a simple rule-based model can perform on par with the state-of-the-art model. To remedy such limitations, we collect and release two crowdsourced benchmark datasets. We not only make sure that they contain significantly more diverse syntax, but also carefully control for their quality according to a well-defined set of criteria. While no satisfactory automatic metric exists, we apply fine-grained manual evaluation based on these criteria using crowdsourcing, showing that our datasets better represent the task and are significantly more challenging for the models.",
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "authors": [
                {
                    "authorId": "72436283",
                    "name": "Li Zhang"
                },
                {
                    "authorId": "2115718238",
                    "name": "Huaiyu Zhu"
                },
                {
                    "authorId": "1791585",
                    "name": "Siddhartha Brahma"
                },
                {
                    "authorId": "1573872877",
                    "name": "Yunyao Li"
                }
            ]
        },
        {
            "paperId": "5ce0189f038cd5c308459a8d861720ecc4340755",
            "title": "A Novel Workflow for Accurately and Efficiently Crowdsourcing Predicate Senses and Argument Labels",
            "abstract": "Resources for Semantic Role Labeling (SRL) are typically annotated by experts at great expense. Prior attempts to develop crowdsourcing methods have either had low accuracy or required substantial expert annotation. We propose a new multi-stage crowd workflow that substantially reduces expert involvement without sacrificing accuracy. In particular, we introduce a unique filter stage based on the key observation that crowd workers are able to almost perfectly filter out incorrect options for labels. Our three-stage workflow produces annotations with 95% accuracy for predicate labels and 93% for argument labels, which is comparable to expert agreement. Compared to prior work on crowdsourcing for SRL, we decrease expert effort by 4x, from 56% to 14% of cases. Our approach enables more scalable annotation of SRL, and could enable annotation of NLP tasks that have previously been considered too complex to effectively crowdsource.",
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "authors": [
                {
                    "authorId": "152771590",
                    "name": "Youxuan Jiang"
                },
                {
                    "authorId": "2115718238",
                    "name": "Huaiyu Zhu"
                },
                {
                    "authorId": "1727211",
                    "name": "Jonathan K. Kummerfeld"
                },
                {
                    "authorId": "1718694",
                    "name": "Yunyao Li"
                },
                {
                    "authorId": "2598433",
                    "name": "Walter S. Lasecki"
                }
            ]
        },
        {
            "paperId": "7870e74d03d34ea7f7049b457e8a4aae2eec1929",
            "title": "Improved Semantic Role Labeling using Parameterized Neighborhood Memory Adaptation",
            "abstract": "Deep neural models achieve some of the best results for semantic role labeling. Inspired by instance-based learning that utilizes nearest neighbors to handle low-frequency context-specific training samples, we investigate the use of memory adaptation techniques in deep neural models. We propose a parameterized neighborhood memory adaptive (PNMA) method that uses a parameterized representation of the nearest neighbors of tokens in a memory of activations and makes predictions based on the most similar samples in the training data. We empirically show that PNMA consistently improves the SRL performance of the base model irrespective of types of word embeddings. Coupled with contextualized word embeddings derived from BERT, PNMA improves over existing models for both span and dependency semantic parsing datasets, especially on out-of-domain text, reaching F1 scores of 80.2, and 84.97 on CoNLL2005, and CoNLL2009 datasets, respectively.",
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "authors": [
                {
                    "authorId": "144377686",
                    "name": "Ishan Jindal"
                },
                {
                    "authorId": "48361424",
                    "name": "R. Aharonov"
                },
                {
                    "authorId": "1791585",
                    "name": "Siddhartha Brahma"
                },
                {
                    "authorId": "2115718238",
                    "name": "Huaiyu Zhu"
                },
                {
                    "authorId": "1718694",
                    "name": "Yunyao Li"
                }
            ]
        },
        {
            "paperId": "fe556f3bef51f79a79d1aaaaec699c4986a1cda7",
            "title": "CLAR: A Cross-Lingual Argument Regularizer for Semantic Role Labeling",
            "abstract": "Semantic role labeling (SRL) identifies predicate-argument structure(s) in a given sentence. Although different languages have different argument annotations, polyglot training, the idea of training one model on multiple languages, has previously been shown to outperform monolingual baselines, especially for low resource languages. In fact, even a simple combination of data has been shown to be effective with polyglot training by representing the distant vocabularies in a shared representation space. Meanwhile, despite the dissimilarity in argument annotations between languages, certain argument labels do share common semantic meaning across languages (e.g. adjuncts have more or less similar semantic meaning across languages). To leverage such similarity in annotation space across languages, we propose a method called Cross-Lingual Argument Regularizer (CLAR). CLAR identifies such linguistic annotation similarity across languages and exploits this information to map the target language arguments using a transformation of the space on which source language arguments lie. By doing so, our experimental results show that CLAR consistently improves SRL performance on multiple languages over monolingual and polyglot baselines for low resource languages.",
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "authors": [
                {
                    "authorId": "144377686",
                    "name": "Ishan Jindal"
                },
                {
                    "authorId": "1718694",
                    "name": "Yunyao Li"
                },
                {
                    "authorId": "1791585",
                    "name": "Siddhartha Brahma"
                },
                {
                    "authorId": "2115718238",
                    "name": "Huaiyu Zhu"
                }
            ]
        },
        {
            "paperId": "d74e7c3dc138ced47812b7feca130abf8953bc23",
            "title": "Towards Universal Semantic Representation",
            "abstract": "Natural language understanding at the semantic level and independent of language variations is of great practical value. Existing approaches such as semantic role labeling (SRL) and abstract meaning representation (AMR) still have features related to the peculiarities of the particular language. In this work we describe various challenges and possible solutions in designing a semantic representation that is universal across a variety of languages.",
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "authors": [
                {
                    "authorId": "2115718238",
                    "name": "Huaiyu Zhu"
                },
                {
                    "authorId": "1718694",
                    "name": "Yunyao Li"
                },
                {
                    "authorId": "1779119",
                    "name": "Laura Chiticariu"
                }
            ]
        },
        {
            "paperId": "3373630200d661159352154dc8e9775e3eae6f39",
            "title": "Giving Text Analytics a Boost",
            "abstract": "The amount of textual data has reached a new scale and continues to grow at an unprecedented rate. IBM's SystemT software is a powerful text-analytics system that offers a query-based interface to reveal the valuable information that lies within these mounds of data. However, traditional server architectures are not capable of analyzing so-called big data efficiently, despite the high memory bandwidth that is available. The authors show that by using a streaming hardware accelerator implemented in reconfigurable logic, the throughput rates of the SystemT's information extraction queries can be improved by an order of magnitude. They also show how such a system can be deployed by extending SystemT's existing compilation flow and by using a multithreaded communication interface that can efficiently use the accelerator's bandwidth.",
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "authors": [
                {
                    "authorId": "1754531",
                    "name": "R. Polig"
                },
                {
                    "authorId": "1775185",
                    "name": "K. Atasu"
                },
                {
                    "authorId": "1779119",
                    "name": "Laura Chiticariu"
                },
                {
                    "authorId": "1798496",
                    "name": "C. Hagleitner"
                },
                {
                    "authorId": "1698579",
                    "name": "H. P. Hofstee"
                },
                {
                    "authorId": "47265115",
                    "name": "Frederick Reiss"
                },
                {
                    "authorId": "2115718238",
                    "name": "Huaiyu Zhu"
                },
                {
                    "authorId": "1986606",
                    "name": "Evangelia A. Sitaridi"
                }
            ]
        }
    ]
}