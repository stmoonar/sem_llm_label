{
    "authorId": "3009678",
    "papers": [
        {
            "paperId": "77c26299c6aebb065c2cae17dc8e44e9feaca508",
            "title": "GTI: A Scalable Graph-based Trajectory Imputation",
            "abstract": "GPS-enabled devices, including vehicles, smartphones, wearable and tracking devices, as well as various check-in and social network data are continuously producing tremendous amounts of trajectory data, which are used consistently in many applications such as urban planning and map inference. Existing techniques for trajectory data imputation rely heavily on the existing maps to perform map-matching operations. However, modern applications such as map construction and map update assume no map exists. In this paper, we propose GTI - a scalable graph-based trajectory imputation approach for trajectory data completion. GTI relies on cross-trajectory imputation, as it exploits \"mutual information\" of the aggregated knowledge of all input sparse trajectories to impute the missing data for each single one of them. GTI can act as a pre-processing step for any trajectory data management system or trajectory-based application, as it takes raw sparse trajectory data as its input and outputs dense imputed trajectory data that significantly increase the accuracy of different systems that consume trajectory data. We evaluate GTI on junction-scale as well as city-scale real datasets. In addition, GTI is used as a pre-processing step in multiple trajectory-based applications and it boosts the accuracy across these applications compared with the state-of-the-art work.",
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "authors": [
                {
                    "authorId": "2191731006",
                    "name": "Keivin Isufaj"
                },
                {
                    "authorId": "2749107",
                    "name": "M. Elshrif"
                },
                {
                    "authorId": "3009678",
                    "name": "Sofiane Abbar"
                },
                {
                    "authorId": "2275821681",
                    "name": "Mohamed Mokbel"
                }
            ]
        },
        {
            "paperId": "a474d0f9acc390689fd26cd7710992fa9a84d601",
            "title": "Let's speak trajectories",
            "abstract": "Trajectory-based applications have acquired significant attention over the past decade with the rising size of trajectory data generated by users. However, building trajectory-based applications is still cumbersome due to the lack of unified frameworks to tackle the underlying trajectory analysis challenges. Inspired by the tremendous success of the BERT deep learning model in solving various NLP tasks, our vision is to have a BERT-like system for a myriad of trajectory analysis operations. We envision that in a few years, we will have such system, where no one needs to worry again about each specific trajectory analysis operation. Whether it is trajectory imputation, similarity, clustering, or whatever, it would be one system that researchers, developers, and practitioners can deploy to get high accuracy for their trajectory operations.",
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "authors": [
                {
                    "authorId": "2186764",
                    "name": "Mashaal Musleh"
                },
                {
                    "authorId": "1756679",
                    "name": "M. Mokbel"
                },
                {
                    "authorId": "3009678",
                    "name": "Sofiane Abbar"
                }
            ]
        },
        {
            "paperId": "3d77385c36d3bc112e68dfcf6c3f54775d72ee07",
            "title": "Traffic routing in the ever-changing city of Doha",
            "abstract": "APRIL 2021 | VOL. 64 | NO. 4 | COMMUNICATIONS OF THE ACM 67 P H O T O B Y P H I L I P L A N G E /S H U T T E R S T O C K .C O M that lasted 10 minutes yesterday, could last 25 minutes today. Cab drivers in the city of Doha (Qatar\u2019s capital), who are mostly foreigners, also wish they could rely on popular navigation services such as Google Maps, Here, or Tomtom. Yet, all such systems fall short in coping up with the rapid urbanization and the ever-changing roads in Doha. This was actually depicted in a very popular caricature in one of the most widely distributed daily local newspapers showing Google maps as a limping turtle that is helplessly trying to catch a bunny representing the road changes in the city of Doha. Besides the general public who is not happy with the routes offered by navigation systems, other stakeholders from public and private sectors were struggling with the poor quality of existing digital maps. For example, the Ministry of Transport and Communication was facing issues getting access to the most accurate map of the road network, needed for their traffic modeling. Also, transportation, delivery, and logistics companies that heavily rely on accurate maps, routes, and travel time estimates were tired of the many lost drivers and missed rendezvous. Early work: Silent maps are not enough. The issue of inaccurate local maps has triggered an early work at Qatar Computing Research Institute (QCRI) in collabospeed, fare, route, as well as sampled GPS points for each trip\u2014a gold mine for our research agenda. But most importantly, we also learned from our partners about the real challenges they face, which helped us prioritize our projects. Map enrichments for traffic-aware routing. Our first project with Karwa was to enrich the topological maps with traffic information, that is, accurate edge weights for each road segment for each hour of the day. Inferring traffic information from a large number of vehicles can be relatively straightforward. However, the problem is much more challenging when the data is sparse and does not cover many roads with large frequency. We tackle these problems in Stanojevic et al. and derive a traffic layer with an accuracy comparable to the commercial maps using only sparse data available to us either from Karwa Taxi data as in Stanojevic et al. or from using commercial map APIs as in Stanojevic et ration with Qatar Mobility Innovation Center (QMIC) to come up with an accurate map for the city of Doha, Qatar. The idea was to use data collected from a fleet of vehicles that are continuously tracked, for accurate and timely detection of road changes, such as new roads, road closures, and detours. Though that early work was successful in coming up with a more accurate map than what navigation systems have, it was not enough to address the main problem of routing. Accurate topological maps do not say much about the time needed to go through each road segment\u2014a main functionality needed for any routing application. Data access and collaboration. To address the routing problem in the ever-changing roads of Doha, we partnered with the national taxi company Karwa. The collaboration gives us access to all taxi data (both historic and live) that took place in the country, including pick-up and dropoff locations, time, duration, O N D E CE MBE R 2 , 2010, Qatar was announced to host 2022 FIFA World Cup. That was time for celebrating the first-ever Middle Eastern country to organize the tournament. The 1.8M population of Qatar then (2.8M today) never imagined the journey their country was about to embarked. Indeed, in less than 10 years, the population grew by more than a half, pushing the available urban resources and services to their limit. At the same time, the country undertook an ambitious investment plan of $200B on various infrastructural projects including a brand new three-line metro network, six new stadiums, several new satellite cities, and an astonishing 4,300km of new roads, which tripled the size of the road network in only five years. While this enterprise boosted the socio-economical life of people in Qatar, it did disrupt the way they navigate the urban space and their mobility patterns in general. Simple commutes to work, drops and pickups of kids to and from schools, became challenging and impossible to plan with daily changes in the road layout, including temporary and permanent closures, deviations, new connections, conversions of roundabouts into signaled intersections, turn restrictions, to name but a few. A commute to school Traffic Routing in the Ever-Changing City of Doha",
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "authors": [
                {
                    "authorId": "3009678",
                    "name": "Sofiane Abbar"
                },
                {
                    "authorId": "2191495",
                    "name": "R. Stanojevic"
                },
                {
                    "authorId": "2057047288",
                    "name": "Shadab Mustafa"
                },
                {
                    "authorId": "1756679",
                    "name": "M. Mokbel"
                }
            ]
        },
        {
            "paperId": "60c23033dd11604230530df78b238fe2641ead62",
            "title": "P2PCF: A collaborative filtering based recommender system for peer to peer social networks",
            "abstract": "The recent privacy incidents reported in major media about global social networks raised real public concerns about centralized architectures. P2P social networks constitute an interesting paradigm to give back users control over their data and relations. While basic social network functionalities such as commenting, following, sharing, and publishing content are widely available, more advanced features related to information retrieval and recommendation are still challenging. This is due to the absence of a central server that has a complete view of the network. In this paper, we propose a new recommender system called P2PCF. We use collaborative filtering approach to recommend content in P2P social networks. P2PCF enables privacy preserving and tackles the cold start problem for both users and content. Our proposed approach assumes that the rating matrix is distributed within peers, in such a way that each peer only sees interactions made by her friends on her timeline. Recommendations are then computed locally within each peer before they are sent back to the requester. Our evaluations prove the effectiveness of our proposal compared to a centralized scheme in terms of recall and coverage.",
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "authors": [
                {
                    "authorId": "9054321",
                    "name": "Lyes Badis"
                },
                {
                    "authorId": "1761661",
                    "name": "Mourad Amad"
                },
                {
                    "authorId": "1803433",
                    "name": "D. A\u00efssani"
                },
                {
                    "authorId": "3009678",
                    "name": "Sofiane Abbar"
                }
            ]
        },
        {
            "paperId": "e5906570816b91f8e6277e5de112565d04f5cbc5",
            "title": "QARTA: An ML-based System for Accurate Map Services",
            "abstract": "Maps services are ubiquitous in widely used applications including navigation systems, ride sharing, and items/food delivery. Though there are plenty of efforts to support such services through designing more efficient algorithms, we believe that efficiency is no longer a bottleneck to these services. Instead, it is the accuracy of the underlying road network and query result. This paper presents QARTA; an open-source full-fledged system for highly accurate and scalable map services. QARTA employs machine learning techniques to construct its own highly accurate map, not only in terms of map topology but more importantly, in terms of edge weights. QARTA also employs machine learning techniques to calibrate its query answers based on contextual information, including transportation modality, location, and time of day/week. QARTA is currently deployed in all Taxis and the third largest food delivery company in the State of Qatar, replacing the commercial map service that was in use, and responding in real-time to hundreds of thousands of daily API calls. Experimental evaluation of QARTA shows its comparable or higher accuracy than commercial services.",
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "authors": [
                {
                    "authorId": "2186764",
                    "name": "Mashaal Musleh"
                },
                {
                    "authorId": "3009678",
                    "name": "Sofiane Abbar"
                },
                {
                    "authorId": "2191495",
                    "name": "R. Stanojevic"
                },
                {
                    "authorId": "1756679",
                    "name": "M. Mokbel"
                }
            ]
        },
        {
            "paperId": "e5a0bce0add0a05d30b266f66e67ad8985255b42",
            "title": "Learning Spatiotemporal Latent Factors of Traffic via Regularized Tensor Factorization: Imputing Missing Values and Forecasting",
            "abstract": "Intelligent transportation systems are a key component in smart cities, and the estimation and prediction of the spatiotemporal traffic state is critical to capture the dynamics of traffic congestion, i.e., its generation, propagation and mitigation, in order to increase operational efficiency and improve livability within smart cities. And while spatiotemporal data related to traffic is becoming common place due to the wide availability of cheap sensors and the rapid deployment of IoT platforms, the data still suffer some challenges related to sparsity, incompleteness, and noise which makes the traffic analytics difficult. In this article, we investigate the problem of missing data or noisy information in the context of real-time monitoring and forecasting of traffic congestion for road networks in a city. The road network is represented as a directed graph in which nodes are junctions (intersections) and edges are road segments. We assume that the city has deployed high-fidelity sensors for speed reading in a subset of edges; and the objective is to infer the speed readings for the remaining edges in the network; and to estimate the missing values in the segments for which sensors have stopped generating data due to technical problems (e.g., battery, network, etc.). We propose a tensor representation for the series of road network snapshots, and develop a regularized factorization method to estimate the missing values, while learning the latent factors of the network. The regularizer, which incorporates spatial properties of the road network, improves the quality of the results. The learned factors, with a graph-based temporal dependency, are then used in an autoregressive algorithm to predict the future state of the road network with a large horizon. Extensive numerical experiments with real traffic data from the cities of Doha (Qatar) and Aarhus (Denmark) demonstrate that the proposed approach is appropriate for imputing the missing data and predicting the traffic state. It is accurate and efficient and can easily be applied to other traffic datasets.",
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "authors": [
                {
                    "authorId": "1914237",
                    "name": "Abdelkader Baggag"
                },
                {
                    "authorId": "3009678",
                    "name": "Sofiane Abbar"
                },
                {
                    "authorId": "2109669367",
                    "name": "Ankit Sharma"
                },
                {
                    "authorId": "3391438",
                    "name": "Tahar Zanouda"
                },
                {
                    "authorId": "1415041918",
                    "name": "Abdulaziz Yousuf Al-Homaid"
                },
                {
                    "authorId": "146134310",
                    "name": "Abhiraj Mohan"
                },
                {
                    "authorId": "2065505953",
                    "name": "Jaideep Srivastava"
                }
            ]
        },
        {
            "paperId": "43a956d43254d5c575075c0f45bf9072c7f8bc4e",
            "title": "Contact tracing",
            "abstract": "As pandemic wide spread results in locking down vital facilities, digital contact tracing is deemed as a key for re-opening. However, current efforts in digital contact tracing, running as mobile apps on users' smartphones, fall short in being effective and present two major weaknesses related to accessibility and apparent privacy concern augmentation. Indeed, accessibility is affected by several factors such as smartphone penetration, age, or socio-economic conditions. The privacy concern on the other hand comes from the fear of having a piece of technology that is monitoring us all the time, everywhere, even when contact tracing is irrelevant. This paper lays out the vision and guidelines for the next era of digital contact tracing, where the contact tracing functionality is moved from being personal responsibility to be the responsibility of facilities that users visit daily. Our proposal tackles the two aforementioned shortcomings by disengaging users from using their own smartphones and requiring facilities to provide the technological devices needed for contact tracing. By doing so, we reassure users that their contacts are only considered in places where manual contact tracing is not effective, and cease being recorded as soon as they leave the facilities they visit. A privacy-preserving architecture is proposed, which can be mandated as a prerequisite for any facility to re-open during or after the pandemic. We finally outline research opportunities and challenges revolving around contact tracing system design and data management.",
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "authors": [
                {
                    "authorId": "1756679",
                    "name": "M. Mokbel"
                },
                {
                    "authorId": "3009678",
                    "name": "Sofiane Abbar"
                },
                {
                    "authorId": "2191495",
                    "name": "R. Stanojevic"
                }
            ]
        },
        {
            "paperId": "59eeef96557d6668e7856558bc48502ed1017926",
            "title": "Identity Linkage Across Diverse Social Networks",
            "abstract": "User identity linkage across online social networks has gained a significant interest in the last few years in diverse applications such as data fusion, de-duplication, personalized advertisement, user profiling, and expert recommendation. Existing techniques investigated the use of personal discrete attributes such as user name, gender, location, and email which are not always available. Other techniques explored the use of network relations. In our proposal, we attempt to design a generic framework for user identity linkage across diverse social networks based exclusively on the widely available textual user generated content. We intentionally selected two social networks, Twitter and Quora, which have different contribution models and serve different purposes, and explore different supervised and unsupervised techniques for matching profiles as well as different language models ranging from simple tf*idf vectorization to more sophisticated BERT embeddings. We discuss the limits of different choices and present some encouraging preliminary results. For example, we find that prolific users can be identified with 84% accuracy. We also present a framework we designed to create the largest publicly available annotated dataset for profile linkage in social networks.",
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "authors": [
                {
                    "authorId": "30135984",
                    "name": "Youcef Benkhedda"
                },
                {
                    "authorId": "50742466",
                    "name": "F. Azouaou"
                },
                {
                    "authorId": "3009678",
                    "name": "Sofiane Abbar"
                }
            ]
        },
        {
            "paperId": "a80588b643b84fdc075f309925574751a2f41bca",
            "title": "STAD: Spatio-Temporal Adjustment of Traffic-Oblivious Travel-Time Estimation",
            "abstract": "Travel time estimation is an important component in modern transportation applications. The state of the art techniques for travel time estimation use GPS traces to learn the weights of a road network, often modeled as a directed graph, then apply Dijkstra-like algorithms to find shortest paths. Travel time is then computed as the sum of edge weights on the returned path. In order to enable time-dependency, existing systems compute multiple weighted graphs corresponding to different time windows. These graphs are often optimized offline before they are deployed into production routing engines, causing a serious engineering overhead. In this paper, we present STAD, a system that adjusts \u2013 on the fly \u2013 travel time estimates for any trip request expressed in the form of origin, destination, and departure time. STAD uses machine learning and sparse trips data to learn the imperfections of any basic routing engine, before it turns it into a full-fledged time-dependent system capable of adjusting travel times to real traffic conditions in a city. STAD leverages the spatio-temporal properties of traffic by combining spatial features such as departing and destination geographic zones with temporal features such as departing time and day to significantly improve the travel time estimates of the basic routing engine. Experiments on real trip datasets from Doha, New York City, and Porto show a reduction in median absolute errors of 14% in the first two cities and 29% in the latter. We also show that STAD performs better than different commercial and research baselines in all three cities.",
            "fieldsOfStudy": [
                "Computer Science",
                "Physics",
                "Mathematics"
            ],
            "authors": [
                {
                    "authorId": "3009678",
                    "name": "Sofiane Abbar"
                },
                {
                    "authorId": "2191495",
                    "name": "R. Stanojevic"
                },
                {
                    "authorId": "1756679",
                    "name": "M. Mokbel"
                }
            ]
        },
        {
            "paperId": "0e6fdee979d9671b922ef2c49d1d97059ad13940",
            "title": "RoadTagger: Robust Road Attribute Inference with Graph Neural Networks",
            "abstract": "Inferring road attributes such as lane count and road type from satellite imagery is challenging. Often, due to the occlusion in satellite imagery and the spatial correlation of road attributes, a road attribute at one position on a road may only be apparent when considering far-away segments of the road. Thus, to robustly infer road attributes, the model must integrate scattered information and capture the spatial correlation of features along roads. Existing solutions that rely on image classifiers fail to capture this correlation, resulting in poor accuracy. We find this failure is caused by a fundamental limitation \u2013 the limited effective receptive field of image classifiers.To overcome this limitation, we propose RoadTagger, an end-to-end architecture which combines both Convolutional Neural Networks (CNNs) and Graph Neural Networks (GNNs) to infer road attributes. Using a GNN allows information to propagate on the road network graph and eliminates the receptive field limitation of image classifiers. We evaluate RoadTagger on both a large real-world dataset covering 688 km2 area in 20 U.S. cities and a synthesized dataset. In the evaluation, RoadTagger improves inference accuracy over the CNN image classifier based approaches. In addition, RoadTagger is robust to disruptions in the satellite imagery and is able to learn complicated inductive rules for aggregating scattered information along the road network.",
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "authors": [
                {
                    "authorId": "3143190",
                    "name": "Songtao He"
                },
                {
                    "authorId": "2995635",
                    "name": "F. Bastani"
                },
                {
                    "authorId": "1388084683",
                    "name": "Satvat Jagwani"
                },
                {
                    "authorId": "2113345338",
                    "name": "Edward Park"
                },
                {
                    "authorId": "3009678",
                    "name": "Sofiane Abbar"
                },
                {
                    "authorId": "79404966",
                    "name": "Mohammad Alizadeh"
                },
                {
                    "authorId": "145034082",
                    "name": "H. Balakrishnan"
                },
                {
                    "authorId": "50793091",
                    "name": "S. Chawla"
                },
                {
                    "authorId": "144478906",
                    "name": "S. Madden"
                },
                {
                    "authorId": "21160985",
                    "name": "M. Sadeghi"
                }
            ]
        },
        {
            "paperId": "da80191ea200576effe9f184edc7a490b1b0d843",
            "title": "Inferring and improving street maps with data-driven automation",
            "abstract": "Automatic map inference, data refinement, and machine-assisted map editing promises more accurate map datasets.",
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "authors": [
                {
                    "authorId": "2995635",
                    "name": "F. Bastani"
                },
                {
                    "authorId": "3143190",
                    "name": "Songtao He"
                },
                {
                    "authorId": "1388084683",
                    "name": "Satvat Jagwani"
                },
                {
                    "authorId": "2113345338",
                    "name": "Edward Park"
                },
                {
                    "authorId": "3009678",
                    "name": "Sofiane Abbar"
                },
                {
                    "authorId": "79404966",
                    "name": "Mohammad Alizadeh"
                },
                {
                    "authorId": "145034082",
                    "name": "H. Balakrishnan"
                },
                {
                    "authorId": "50793091",
                    "name": "S. Chawla"
                },
                {
                    "authorId": "2053630301",
                    "name": "Sam Madden"
                },
                {
                    "authorId": "21160985",
                    "name": "M. Sadeghi"
                }
            ]
        },
        {
            "paperId": "ef96e33ed6c147dbba2b63d43fe69669f1ac542d",
            "title": "MapReuse: Recycling Routing API Queries",
            "abstract": "Commercial maps often offer traffic awareness which is critical for many location based services. On the other hand free and open map services (such as government maps or OSM) are traffic oblivious and hence are of limited value for such services. In this paper we show that coarse information available from a commercial map routing API, can be dissected into fine-grained per-road-segment traffic information which can be reused in any application requiring traffic-awareness. Our system MapReuse queries a commercial map for a (relatively small) number of routes, and uses the returned routes and expected travel times, to infer travel time on each individual edge of the road network. Such fine-grained travel time information can be used not only to infer travel time on any given route but also to compute complex spatial queries (such as traffic-aware isochrone map) for free. We test our system on four representative metropolitan areas: Bogota, Doha, NYC and Rome, and report very encouraging results. Namely, we observe the median and mean percentage errors of MapReuse, measured against the travel times reported by the commercial map, to be in the range of 4% to 8%, implying that MapReuse is capable to accurately reconstruct the traffic conditions in all four studied cities.",
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "authors": [
                {
                    "authorId": "2191495",
                    "name": "R. Stanojevic"
                },
                {
                    "authorId": "3009678",
                    "name": "Sofiane Abbar"
                },
                {
                    "authorId": "1756679",
                    "name": "M. Mokbel"
                }
            ]
        },
        {
            "paperId": "302f1891fe12960b52291061291fa6b7bc93bb6a",
            "title": "Robust Road Map Inference through Network Alignment of Trajectories",
            "abstract": "In this paper we address the challenge of inferring the road network of a city from crowd-sourced GPS traces. While the problem has been addressed before, our solution has the following unique characteristics: (i) we formulate the road network inference problem as a network alignment optimization problem where both the nodes and edges of the network have to be inferred, (ii) we propose both an offline (Kharita) and an online (Kharita\u2217) algorithm which are intuitive and capture the key aspects of the optimization formulation but are scalable and accurate. The Kharita\u2217 in particular is, to the best of our knowledge, the first known online algorithm for map inference, (iii) we test our approach on two real data sets and both our code and data sets have been made available for research reproducibility.",
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "authors": [
                {
                    "authorId": "2191495",
                    "name": "R. Stanojevic"
                },
                {
                    "authorId": "3009678",
                    "name": "Sofiane Abbar"
                },
                {
                    "authorId": "2934941",
                    "name": "Saravanan Thirumuruganathan"
                },
                {
                    "authorId": "50793091",
                    "name": "S. Chawla"
                },
                {
                    "authorId": "2428603",
                    "name": "F. Filali"
                },
                {
                    "authorId": "9561406",
                    "name": "Ahid Aleimat"
                }
            ]
        },
        {
            "paperId": "37bba8ea75a7c3398f89b8b4f416695c1b220ec4",
            "title": "Learning Spatiotemporal Latent Factors of Traffic via a Regularized Tensor Factorization: Imputing Missing Values and Forecasting",
            "abstract": "Spatiotemporal data related to traffic has become common place due to the wide availability of cheap sensors and the rapid deployment of IoT platforms. Yet, this data suffer several challenges related to sparsity, incompleteness, and noise, which makes traffic analytics difficult. In this paper, we investigate the problem of missing data or noisy information in the context of real-time monitoring and forecasting of traffic congestion for road networks. The road network is represented as a directed graph in which nodes are junctions and edges are road segments. We assume that the city has deployed high-fidelity sensors for speed reading in a subset of edges. Our objective is to infer speed readings for the remaining edges in the network as well as missing values to malfunctioning sensors. We propose a tensor representation for the series of road network snapshots, and develop a regularized factorization method to estimate the missing values, while learning the latent factors of the network. The regularizer, which incorporates spatial properties of the road network, improves the quality of the results. The learned factors along with a graph-based temporal dependency are used in an autoregressive algorithm to predict the future state of the road network with long horizon. Extensive numerical experiments with real traffic data from the cities of Doha(Qatar) and Aarhus (Denmark) demonstrate that the proposed approach is appropriate for imputing missing data and predicting traffic state.Main contributions. The main contributions are:We propose a novel temporal regularized tensor factorization framework (TRTF) for high-dimensional traffic data. TRTF provides a principled approach to account for both the spatial structure and the temporal dependencies.We introduce a novel data-driven graph-based autoregressive model, where the weights are learned from the data. Hence, the regularizer can account for both positive and negative correlations.We show that incorporating temporal embeddings into CP-WOPT leads to accurate multi-step forecasting, compared to state of the art matrix factorization based methods.We conduct extensive experiments on real traffic congestion datasets from two different cities and show the superiority of TRTF for both tasks of missing value completion and multi-step forecasting under different experimental settings. For instance,TRTF outperforms LSM-RN by 24% and TRMF by 29%.Conclusion. We present in this paper TRTF, an algorithm for temporal regularized tensor decomposition. We show how the algorithm can be used for several traffic related tasks such as missing value completion and forecasting. The proposed algorithm incorporates both spa-tial and temporal properties into the tensor decomposition procedures such as CP-WOPT, yielding to learning better factors. We also, extend TRTF with an auto-regressive procedure to allow for multi step-ahead forecasting of future values. We compare our method to recently developed algorithms that deal with the same type of problems using regularized matrix factorization,and show that under many circumstances, TRTF does provide better results. This is particularly true in cases where the data suffers from high proportions of missing values, which is common in the traffic context. For instance, TRTF achieves a 20% gain in MAPE score compared to the second best algorithm (CP-WOPT) in completing missing values in the case of extreme sparsity observed in Doha. As future work, we will first focus on adding non-negativity constraints to TRTF, although the highest fraction of negative values generated by our method throughout all the experiments did not exceed 0.7%. Our second focus will be to optimize TRTF training phase in order to increase its scalability to handle large dense tensors, and to implement it on a parallel environment.",
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "authors": [
                {
                    "authorId": "1914237",
                    "name": "Abdelkader Baggag"
                },
                {
                    "authorId": "3391438",
                    "name": "Tahar Zanouda"
                },
                {
                    "authorId": "3009678",
                    "name": "Sofiane Abbar"
                },
                {
                    "authorId": "2428603",
                    "name": "F. Filali"
                }
            ]
        },
        {
            "paperId": "652cf900d9ef019098d9d88052377b222b735c41",
            "title": "Machine-assisted map editing",
            "abstract": "Mapping road networks today is labor-intensive. As a result, road maps have poor coverage outside urban centers in many countries. Systems to automatically infer road network graphs from aerial imagery and GPS trajectories have been proposed to improve coverage of road maps. However, because of high error rates, these systems have not been adopted by mapping communities. We propose machine-assisted map editing, where automatic map inference is integrated into existing, human-centric map editing workflows. To realize this, we build Machine-Assisted iD (MAiD), where we extend the web-based OpenStreetMap editor, iD, with machine-assistance functionality. We complement MAiD with a novel approach for inferring road topology from aerial imagery that combines the speed of prior segmentation approaches with the accuracy of prior iterative graph construction methods. We design MAiD to tackle the addition of major, arterial roads in regions where existing maps have poor coverage, and the incremental improvement of coverage in regions where major roads are already mapped. We conduct two user studies and find that, when participants are given a fixed time to map roads, they are able to add as much as 3.5x more roads with MAiD.",
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "authors": [
                {
                    "authorId": "2995635",
                    "name": "F. Bastani"
                },
                {
                    "authorId": "3143190",
                    "name": "Songtao He"
                },
                {
                    "authorId": "3009678",
                    "name": "Sofiane Abbar"
                },
                {
                    "authorId": "79404966",
                    "name": "Mohammad Alizadeh"
                },
                {
                    "authorId": "145034082",
                    "name": "H. Balakrishnan"
                },
                {
                    "authorId": "50793091",
                    "name": "S. Chawla"
                },
                {
                    "authorId": "144478906",
                    "name": "S. Madden"
                }
            ]
        },
        {
            "paperId": "79b68b1bd2fd1d91cec753703c3fa2d63406623c",
            "title": "Innovation diffusion for renewable energy technologies",
            "abstract": "We present an analysis of innovation diffusion models for solar energy technologies based on the spread of information in real-world social networks. Three dynamic innovation diffusion networks are simulated through diverse configurations of the Barab\u00e1si Albert model with a linear threshold approach to information spread, using a dataset of Twitter messages about solar and renewable energy as reference information diffusion network. The characteristics of the simulated dynamic innovation diffusion networks (e.g. number of informed nodes) are then compared with those of the reference information diffusion network to establish which innovation diffusion model yields the best fit. The results of this analysis provide a solution for the development of the innovation diffusion component for renewable energy adoption models. We demonstrate the feasibility of including the innovation diffusion factor into an agent-based model of the solar PV market, which is applied to Qatar market.",
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "authors": [
                {
                    "authorId": "2078361652",
                    "name": "A. Boumaiza"
                },
                {
                    "authorId": "3009678",
                    "name": "Sofiane Abbar"
                },
                {
                    "authorId": "46184582",
                    "name": "Nassma Mohandes"
                },
                {
                    "authorId": "46172145",
                    "name": "A. Sanfilippo"
                }
            ]
        },
        {
            "paperId": "82d66fa2666e3e8798085fdc0155e6b45b707f32",
            "title": "RoadTracer: Automatic Extraction of Road Networks from Aerial Images",
            "abstract": "Mapping road networks is currently both expensive and labor-intensive. High-resolution aerial imagery provides a promising avenue to automatically infer a road network. Prior work uses convolutional neural networks (CNNs) to detect which pixels belong to a road (segmentation), and then uses complex post-processing heuristics to infer graph connectivity. We show that these segmentation methods have high error rates because noisy CNN outputs are difficult to correct. We propose RoadTracer, a new method to automatically construct accurate road network maps from aerial images. RoadTracer uses an iterative search process guided by a CNN-based decision function to derive the road network graph directly from the output of the CNN. We compare our approach with a segmentation method on fifteen cities, and find that at a 5% error rate, RoadTracer correctly captures 45% more junctions across these cities.",
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "authors": [
                {
                    "authorId": "2995635",
                    "name": "F. Bastani"
                },
                {
                    "authorId": "3143190",
                    "name": "Songtao He"
                },
                {
                    "authorId": "3009678",
                    "name": "Sofiane Abbar"
                },
                {
                    "authorId": "79404966",
                    "name": "Mohammad Alizadeh"
                },
                {
                    "authorId": "145034082",
                    "name": "H. Balakrishnan"
                },
                {
                    "authorId": "50793091",
                    "name": "S. Chawla"
                },
                {
                    "authorId": "144478906",
                    "name": "S. Madden"
                },
                {
                    "authorId": "1765659",
                    "name": "D. DeWitt"
                }
            ]
        },
        {
            "paperId": "8fb9a1160c3919759f59a5fb1b6c3488fa6683f8",
            "title": "Unthule: An Incremental Graph Construction Process for Robust Road Map Extraction from Aerial Images",
            "abstract": "The availability of highly accurate maps has become crucial due to the increasing importance of location-based mobile applications as well as autonomous vehicles. However, mapping roads is currently an expensive and human-intensive process. High-resolution aerial imagery provides a promising avenue to automatically infer a road network. Prior work uses convolutional neural networks (CNNs) to detect which pixels belong to a road (segmentation), and then uses complex post-processing heuristics to infer graph connectivity. We show that these segmentation methods have high error rates (poor precision) because noisy CNN outputs are difficult to correct. \nWe propose a novel approach, Unthule, to construct highly accurate road maps from aerial images. In contrast to prior work, Unthule uses an incremental search process guided by a CNN-based decision function to derive the road network graph directly from the output of the CNN. We train the CNN to output the direction of roads traversing a supplied point in the aerial imagery, and then use this CNN to incrementally construct the graph. We compare our approach with a segmentation method on fifteen cities, and find that Unthule has a 45% lower error rate in identifying junctions across these cities.",
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "authors": [
                {
                    "authorId": "2995635",
                    "name": "F. Bastani"
                },
                {
                    "authorId": "3143190",
                    "name": "Songtao He"
                },
                {
                    "authorId": "3009678",
                    "name": "Sofiane Abbar"
                },
                {
                    "authorId": "79404966",
                    "name": "Mohammad Alizadeh"
                },
                {
                    "authorId": "145034082",
                    "name": "H. Balakrishnan"
                },
                {
                    "authorId": "50793091",
                    "name": "S. Chawla"
                },
                {
                    "authorId": "1765659",
                    "name": "D. DeWitt"
                },
                {
                    "authorId": "144478906",
                    "name": "S. Madden"
                }
            ]
        },
        {
            "paperId": "96a6f8a4d4b314430f41dc55cb612ab235f7243b",
            "title": "W-edge: weighing the edges of the road network",
            "abstract": "Understanding link travel times (LTT) has received significant attention in transportation and spatial computing literature but they often remain behind closed doors, primarily because the data used for capturing them is considered confidential. Consequently, free and open maps such as OpenStreetMap (OSM) or TIGER, while being remarkably accurate in capturing geometry and topology of the road network are oblivious to actual travel times. Without LTTs computing the optimal routes or estimated time of arrival is challenging and prone to substantial errors. In this work we set to enrich the underlying map information with LTT by using a most basic data about urban trajectories, which also becomes increasingly available for public use: set of origin/destination location/timestamp pairs. Our system, W-edge utilizes such basic trip information to calculate LTT to each individual road segment, effectively assigning a weight to individual edges of the underlying road network. We demonstrate that using appropriately trained edge weights, the errors in estimating travel times are up to 60% lower than the errors observed in OSRM or GraphHopper, two prominent OSM-based, traffic-oblivious, routing engines.",
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "authors": [
                {
                    "authorId": "2191495",
                    "name": "R. Stanojevic"
                },
                {
                    "authorId": "3009678",
                    "name": "Sofiane Abbar"
                },
                {
                    "authorId": "1756679",
                    "name": "M. Mokbel"
                }
            ]
        },
        {
            "paperId": "c70fd8f410af1a0c96f354bb76a25d5891fae5be",
            "title": "To Post or Not to Post: Using Online Trends to Predict Popularity of Offline Content",
            "abstract": "Predicting the popularity of online content has attracted much attention in the past few years. In news rooms, for instance, journalists and editors are keen to know, as soon as possible, the articles that will bring the most traffic into their website. In this paper, we propose a new approach for predicting the popularity of news articles before they go online. Our approach complements existing content-based methods, and is based on a number of observations regarding article similarity and topicality. First, the popularity of a new article is correlated with the popularity of similar articles of recent publication. Second, the popularity of the new article is related to the recent historical popularity of its main topic. Based on these observations, we use time series forecasting to predict the number of visits an article will receive. Our experiments, conducted on a real data collection of articles in an international news website, demonstrate the effectiveness and efficiency of the proposed method.",
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "authors": [
                {
                    "authorId": "3009678",
                    "name": "Sofiane Abbar"
                },
                {
                    "authorId": "2065333595",
                    "name": "C. Castillo"
                },
                {
                    "authorId": "46172145",
                    "name": "A. Sanfilippo"
                }
            ]
        },
        {
            "paperId": "d1567a8d7b0115b05510fa492997c5e5e8b40a1b",
            "title": "QEvents: RealTime Recommendation of Neighboring Events",
            "abstract": "Technology always seeks to improve the little details in our lives for a faster and a more efficient life-pace. One of these little problems we face in our daily lives is finding relevant events. For example you visit a place like Katara with your kids and you spend your time in vain looking for a fun event, and after you leave the venue a friend of yours tells you about this interesting \u201cHenna and face painting workshop organized in building 25.\u201d. To solve this problem we propose QEvents. QEvents is a platform that provides users with real-time recommendations about events happening around their location and that best match their preferences. QEvents renders the events in a map-centric dashboard to allow easy browsing and user-friendly interactions. QEvents continuously listens to online channels that broadcast information about events taking place in Qatar, including specialized websites (e.g. eventsdoha.com), social media (e.g. Twitter), and news (e.g. dohanews.com). The main challenge QEvents strives to solve is how to extract important features such as title, location, and time from free text describing the events. We will show in this paper how one could leverage existing technologies such as Topic modeling, Named Entity Recognition, and advanced text parsing to transform a plain event listing website into a dynamic and alive service capable of recognizing events\u2019 location, title, category, as well as starting and ending time, and nicely rendering them in a map-centric visualization allowing a more natural exploration.",
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "authors": [
                {
                    "authorId": "2182063254",
                    "name": "Heba Hussein"
                },
                {
                    "authorId": "3009678",
                    "name": "Sofiane Abbar"
                },
                {
                    "authorId": "70364985",
                    "name": "M. Arulalan"
                }
            ]
        },
        {
            "paperId": "0e34db22c06f87af2475748468ed6f24acd9012b",
            "title": "QT2S: A System for Monitoring Road Traffic Via Fine Grounding of Tweets",
            "abstract": "\n \n Social media platforms provide continuous access to user generated content that enables real-time monitoring of user behavior and of events. The geographical dimension of such user behavior and events has recently caught a lot of attention in several domains: mobility, humanitarian, or infrastructural. While resolving the location of a user can be straightforward, depending on the affordances of their device and/or of the application they are using, in most cases, locating a user demands a larger effort, such as exploiting textual features. On Twitter for instance, only 2% of all tweets are geo-referenced. In this paper, we present a system for zoomed-in grounding (below city level) for short messages (for example, tweets). The system combines different natural language processing and machine learning techniques to increase the number of geo-grounded tweets, which is essential to many applications such as disaster response and real-time traffic monitoring.\n \n",
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "authors": [
                {
                    "authorId": "9931612",
                    "name": "Noora Al Emadi"
                },
                {
                    "authorId": "3009678",
                    "name": "Sofiane Abbar"
                },
                {
                    "authorId": "1390131709",
                    "name": "Javier Borge-Holthoefer"
                },
                {
                    "authorId": "144204682",
                    "name": "Francisco Guzm\u00e1n"
                },
                {
                    "authorId": "145077269",
                    "name": "F. Sebastiani"
                }
            ]
        },
        {
            "paperId": "60a9616a5556ac1f66adae588c8285c4fbb4308d",
            "title": "The Quantified City: Sensing Dynamics in Urban Setting",
            "abstract": "The world is witnessing a period of extreme growth and urbanization; cities in the 21st century became nerve centers creating economic opportunities and cultural values which make cities grow exponentially. With this rapid urban population growth, city infrastructure is facing major problems, from the need to scale urban systems to sustaining the quality of services for citizen at scale. Understanding the dynamics of cities is critical towards informed strategic urban planning. This paper showcases QuantifiedCity, a system aimed at understanding the complex dynamics taking place in cities. Often, these dynamics involve humans, services, and infrastructures and are observed in different spaces: physical (IoT-based) sensing and human (social-based) sensing. The main challenges the system strives to address are related to data integration and fusion to enable an effective and semantically relevant data grouping. This is achieved by considering the spatio-temporal space as a blocking function for any data generated in the city. Our system consists of three layer for data acquisition, data analysis, and data visualization; each of which embeds a variety of modules to better achieve its purpose (e.g., data crawling, data cleaning, topic modeling, sentiment analysis, named entity recognition, event detection, time series analysis, etc.) End users can browse the dynamics through three main dimensions: location, time, and event. For each dimension, the system renders a set of map-centric widgets that summarize the underlying related dynamics. This paper highlights the need for such a holistic platform, identifies the strengths of the \"Quantified City\" concept, and showcases a working demo through a real-life scenario.",
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "authors": [
                {
                    "authorId": "3391438",
                    "name": "Tahar Zanouda"
                },
                {
                    "authorId": "9931612",
                    "name": "Noora Al Emadi"
                },
                {
                    "authorId": "3009678",
                    "name": "Sofiane Abbar"
                },
                {
                    "authorId": "2065505953",
                    "name": "Jaideep Srivastava"
                }
            ]
        },
        {
            "paperId": "ae7dde76f7007fa5f5952b3ded7d5c432fc3fa7a",
            "title": "Kharita: Robust Map Inference using Graph Spanners",
            "abstract": "The widespread availability of GPS information in everyday devices such as cars, smartphones and smart watches make it possible to collect large amount of geospatial trajectory information. A particularly important, yet technically challenging, application of this data is to identify the underlying road network and keep it updated under various changes. In this paper, we propose efficient algorithms that can generate accurate maps in both batch and online settings. Our algorithms utilize techniques from graph spanners so that they produce maps can effectively handle a wide variety of road and intersection shapes. We conduct a rigorous evaluation of our algorithms over two real-world datasets and under a wide variety of performance metrics. Our experiments show a significant improvement over prior work. In particular, we observe an increase in Biagioni f-score of up to 20% when compared to the state of the art while reducing the execution time by an order of magnitude. We also make our source code open source for reproducibility and enable other researchers to build on our work.",
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "authors": [
                {
                    "authorId": "2191495",
                    "name": "R. Stanojevic"
                },
                {
                    "authorId": "3009678",
                    "name": "Sofiane Abbar"
                },
                {
                    "authorId": "2934941",
                    "name": "Saravanan Thirumuruganathan"
                },
                {
                    "authorId": "50793091",
                    "name": "S. Chawla"
                },
                {
                    "authorId": "2428603",
                    "name": "F. Filali"
                },
                {
                    "authorId": "9561406",
                    "name": "Ahid Aleimat"
                }
            ]
        },
        {
            "paperId": "0ede3897696b372678c662db80b2ca0a4565a30f",
            "title": "Fetishizing Food in Digital Age: #foodporn Around the World",
            "abstract": "\n \n What food is so good as to be considered pornographic? Worldwide, the popular #foodporn hashtag has been used to share appetizing pictures of peoples' favorite culinary experiences. But social scientists ask whether #foodporn promotes an unhealthy relationship with food, as pornography would contribute to an unrealistic view of sexuality. In this study, we examine nearly 10 million Instagram posts by 1.7 million users worldwide. An overwhelming (and uniform across the nations) obsession with chocolate and cake shows the domination of sugary dessert over local cuisines. Yet, we find encouraging traits in the association of emotion and health-related topics with #foodporn, suggesting food can serve as motivation for a healthy lifestyle. Social approval also favors the healthy posts, with users posting with healthy hashtags having an average of 1,000 more followers than those with unhealthy ones. Finally, we perform a demographic analysis which shows nation-wide trends of behavior, such as a strong relationship (r=0.51) between the GDP per capita and the attention to healthiness of their favorite food. Our results expose a new facet of food \"pornography\", revealing potential avenues for utilizing this precarious notion for promoting healthy lifestyles.\n \n",
            "fieldsOfStudy": [
                "Computer Science",
                "Sociology"
            ],
            "authors": [
                {
                    "authorId": "3329961",
                    "name": "Yelena Mejova"
                },
                {
                    "authorId": "3009678",
                    "name": "Sofiane Abbar"
                },
                {
                    "authorId": "1763096",
                    "name": "H. Haddadi"
                }
            ]
        },
        {
            "paperId": "17c6295a0ace5919b1f8fa6c35180461cb631433",
            "title": "Using Twitter to Understand Public Interest in Climate Change: The Case of Qatar",
            "abstract": "\n \n Climate change has received an extensive attention from public opinion in the last couple of years, after being considered for decades as an exclusive scientific debate. Governments and world-wide organizations such as the United Nations are working more than ever on raising and maintaining public awareness toward this global issue. In the present study, we examine and analyze Climate Change conversations in Qatar's Twittersphere, and sense public awareness towards this global and shared problem in general, and its various related topics in particular. Such topics include but are not limited to politics, economy, disasters, energy and sandstorms. To address this concern, we collect and analyze a large dataset of 109 million tweets posted by 98K distinct users living in Qatar -- one of the largest emitters of CO2 worldwide. We use a taxonomy of climate change topics created as part of the United Nations Pulse project to capture the climate change discourse in more than 36K tweets. We also examine which topics people refer to when they discuss climate change, and perform different analysis to understand the temporal dynamics of public interest toward these topics.\n \n",
            "fieldsOfStudy": [
                "Computer Science",
                "Political Science"
            ],
            "authors": [
                {
                    "authorId": "3009678",
                    "name": "Sofiane Abbar"
                },
                {
                    "authorId": "3391438",
                    "name": "Tahar Zanouda"
                },
                {
                    "authorId": "1403176402",
                    "name": "Laure Berti-\u00c9quille"
                },
                {
                    "authorId": "1390131709",
                    "name": "Javier Borge-Holthoefer"
                }
            ]
        },
        {
            "paperId": "4c89fd64a27bd081a5edb8528c16fec14567bdb1",
            "title": "Privacy and twitter in qatar: traditional values in the digital world",
            "abstract": "We explore the meaning of \"privacy\" from the perspective of Qatari nationals as it manifests in digital environments. Although privacy is an essential and widely respected value in many cultures, the way in which it is understood and enacted depends on context. It is especially vital to understand user behaviors regarding privacy in the digital sphere, where individuals increasingly publish personal information. Our mixed-methods analysis of 18K Twitter posts that mention \"privacy\" focuses on the face-to-face and digital contexts in which privacy is mentioned, and how those contexts lead to varied ideologies regarding privacy. We find that in the Arab Gulf, the need for privacy is often supported by Quranic text, advice on how to protect privacy is frequently discussed, and the use of paternalistic language by men when discussing women's privacy is common. Above all, privacy is framed as a communal attribute, including not only the individual, but the behavior of those around them; it even extends beyond one's lifespan. We contribute an analysis and description of these previously unexplored interpretations of privacy, which play a role in how users navigate social media.",
            "fieldsOfStudy": [
                "Computer Science",
                "Sociology"
            ],
            "authors": [
                {
                    "authorId": "1847907",
                    "name": "Norah Abokhodair"
                },
                {
                    "authorId": "3009678",
                    "name": "Sofiane Abbar"
                },
                {
                    "authorId": "3681090",
                    "name": "Sarah Vieweg"
                },
                {
                    "authorId": "3329961",
                    "name": "Yelena Mejova"
                }
            ]
        },
        {
            "paperId": "5aef28e620759285184577577af34f7640dc7039",
            "title": "Robustness and Resilience of cities around the world",
            "abstract": "The concept of city or urban resilience has emerged as one of the key challenges for the next decades. As a consequence, institutions like the United Nations or Rockefeller Foundation have embraced initiatives that increase or improve it. These efforts translate into funded programs both for action on the ground and to develop quantification of resilience, under the for of an index. Ironically, on the academic side there is no clear consensus regarding how resilience should be quantified, or what it exactly refers to in the urban context. Here we attempt to link both extremes providing an example of how to exploit large, publicly available, worldwide urban datasets, to produce objective insight into one of the possible dimensions of urban resilience. We do so via well-established methods in complexity science, such as percolation theory --which has a long tradition at providing valuable information on the vulnerability in complex systems. Our findings uncover large differences among studied cities, both regarding their infrastructural fragility and the imbalances in the distribution of critical services.",
            "fieldsOfStudy": [
                "Computer Science",
                "Physics",
                "Sociology"
            ],
            "authors": [
                {
                    "authorId": "3009678",
                    "name": "Sofiane Abbar"
                },
                {
                    "authorId": "3391438",
                    "name": "Tahar Zanouda"
                },
                {
                    "authorId": "1390131709",
                    "name": "Javier Borge-Holthoefer"
                }
            ]
        },
        {
            "paperId": "ea206002e29d21bafcfa76afe5a9d230c6529b7f",
            "title": "Identifying Virality Attributes of Arabic Language News Articles",
            "abstract": "Our research is focused on expanding the reach and impact of Arabic language news articles by attracting more readers. In pursuit of this research goal, we analyze attributes that result in certain news articles becoming viral, relative to other news articles that do not become viral or so viral. Specifically, we focus on Arabic language news articles, as Arabic language articles have unique linguistic, cultural, and social constrains relative to most Western languages news stories. In order to understand virality, we take two approaches, a time series and linguistical, in an Arabic language data of more than 1,000 news articles with associated temporal traffic data. For data collection, we select (Kasra, \u201ca breaking\u201d) (http://kasra.co/) is an Arabic language online news site that targets Arabic language speakers worldwide, but particularly in the Middle East North Africa (MENA) region. We gathered more than 3,000 articles, originally, then gathered traffic data for this set of articles, reducing the set to more than 1,000 with complete traffic data. We focus first on the temporal attributes in order to categorize clusters of virality with this set of articles. Then, with topical analysis, we seek to identify linguistical aspects common to articles within each virality cluster identified by time series. Based on results from the time series analysis, we cluster articles based on common temporal characteristics of traffic access. Once clustered by time series, we analyze each cluster for content attributes, topical and linguistical, in order to identify specific attributes that may be causing the virality of articles within each times-series cluster. To compute dissimilarity for time-series, we utilize and evaluate the performance of several state-of-the-art time series dissimilarity-based clustering approaches, such as dynamic time warping, discrete wavelet transformation, and others. To identify the dissimilarity algorithm with the most discriminating power, we conduct a principal component analysis (PCA), which is a statistical technique used to highlight variations and patterns in a dataset. Based on findings from our PCA, we select discrete wavelet transformation-based dissimilarity as the best times-series algorithm for our research because the resulting principal axes explain more proportion of variability (75.43 percent) relative to the other time-series algorithms that we had employed. We identify five virality clusters using times series. For topic modeling, we employ Latent Dirichlet allocation (LDA) for this portion of the research. LDA is a generative probabilistic model for collections of discrete data, such as text, LDA explains similarities among groups of observations within a data set. For text modeling, the topic probabilities of LDA provide an explicit representation of a document. For the topical classification analysis, we use Linguistic Inquiry and Word Count (LIWC), which is a sentiment analysis tool. LIWC is a text processing program based on occurrences of words in several categories covering writing style and psychological meaning. Prior empirical work shows the value of a LIWC linguistic analysis for detecting meanings in various experimental settings, including attention focus, thinking style, and social relationships. In terms of results, surprising, the article topic is not predictive of virality of Arabic language news articles. Instead we find that linguistical aspects and style of the news article is the most predictive attribute for predicting virality for Arabic news articles. In analyzing the attributes of virality in Arabic language news articles, our research finds that, perhaps counter intuitively, the topic of the article does not impact the virality. Instead, we find that style of the article is the most impactful attribute for predicting virality for Arabic news articles. Building on these findings, we will leverage aspects of the news articles with other factors to develop tools to assist content creators to more effectively reach their user segment. Our research results will assist in understanding the virality of Arabic news and ultimately improve readership and dissemination of Arabic language news articles.",
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "authors": [
                {
                    "authorId": "2399803",
                    "name": "Sejeong Kwon"
                },
                {
                    "authorId": "3009678",
                    "name": "Sofiane Abbar"
                },
                {
                    "authorId": "144715575",
                    "name": "B. Jansen"
                }
            ]
        },
        {
            "paperId": "51390b2333c2448952514c4ff64b762ea0b742a7",
            "title": "Dietary Habits of an Expat Nation: Case of Qatar",
            "abstract": "We introduce an exhaustive collection of Instagram posts tied to locations in the Gulf nation of Qatar, and explore its potential as a source for the study of the native and expat populations, in particular their dietary and health activity. Obesity has taken an epidemic proportion in such fast-developing countries, and we show that, for example, for Arabic-speakers posting from restaurants strongly correlates with posting from sweets shops. Furthermore, posts in Arabic attract almost three times as much liking and commenting as posts in English. However, we also show that social media has substantial limitations in accurately reflecting the expat population, with languages of India and Nepal -- whose expat populations outnumber the locals -- being drastically under-represented.",
            "fieldsOfStudy": [
                "Computer Science",
                "Sociology"
            ],
            "authors": [
                {
                    "authorId": "3329961",
                    "name": "Yelena Mejova"
                },
                {
                    "authorId": "1763096",
                    "name": "H. Haddadi"
                },
                {
                    "authorId": "3009678",
                    "name": "Sofiane Abbar"
                },
                {
                    "authorId": "3225824",
                    "name": "A. Ghahghaei"
                },
                {
                    "authorId": "1684687",
                    "name": "Ingmar Weber"
                }
            ]
        },
        {
            "paperId": "0b663b6ffa9639c70fa9bb24cf59cfc25486c1fe",
            "title": "Ranking item features by mining online user-item interactions",
            "abstract": "We assume a database of items in which each item is described by a set of attributes, some of which could be multi-valued. We refer to each of the distinct attribute values as a feature. We also assume that we have information about the interactions (such as visits or likes) between a set of users and those items. In our paper, we would like to rank the features of an item using user-item interactions. For instance, if the items are movies, features could be actors, directors or genres, and user-item interaction could be user liking the movie. These information could be used to identify the most important actors for each movie. While users are drawn to an item due to a subset of its features, a user-item interaction only provides an expression of user preference over the entire item, and not its component features. We design algorithms to rank the features of an item depending on whether interaction information is available at aggregated or individual level granularity and extend them to rank composite features (set of features). Our algorithms are based on constrained least squares, network flow and non-trivial adaptations to non-negative matrix factorization. We evaluate our algorithms using both real-world and synthetic datasets.",
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "authors": [
                {
                    "authorId": "3009678",
                    "name": "Sofiane Abbar"
                },
                {
                    "authorId": "123014225",
                    "name": "Habibur Rahman"
                },
                {
                    "authorId": "2934941",
                    "name": "Saravanan Thirumuruganathan"
                },
                {
                    "authorId": "153191671",
                    "name": "Carlos Castillo"
                },
                {
                    "authorId": "145080425",
                    "name": "Gautam Das"
                }
            ]
        },
        {
            "paperId": "341746ac930f0053625d7a7677099fa96a49d769",
            "title": "Beyond Itemsets: Mining Frequent Featuresets over Structured Items",
            "abstract": "We assume a dataset of transactions generated by a set of users over structured items where each item could be described through a set of features. In this paper, we are interested in identifying the frequent featuresets (set of features) by mining item transactions. For example, in a news website, items correspond to news articles, the features are the named-entities/topics in the articles and an item transaction would be the set of news articles read by a user within the same session. We show that mining frequent featuresets over structured item transactions is a novel problem and show that straightforward extensions of existing frequent itemset mining techniques provide unsatisfactory results. This is due to the fact that while users are drawn to each item in the transaction due to a subset of its features, the transaction by itself does not provide any information about such underlying preferred features of users. In order to overcome this hurdle, we propose a featureset uncertainty model where each item transaction could have been generated by various featuresets with different probabilities. We describe a novel approach to transform item transactions into uncertain transaction over featuresets and estimate their probabilities using constrained least squares based approach. We propose diverse algorithms to mine frequent featuresets. Our experimental evaluation provides a comparative analysis of the different approaches proposed.",
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "authors": [
                {
                    "authorId": "2934941",
                    "name": "Saravanan Thirumuruganathan"
                },
                {
                    "authorId": "123014225",
                    "name": "Habibur Rahman"
                },
                {
                    "authorId": "3009678",
                    "name": "Sofiane Abbar"
                },
                {
                    "authorId": "145080425",
                    "name": "Gautam Das"
                }
            ]
        },
        {
            "paperId": "cf76cc8d960a28603714ed6558f90b3a61ffd580",
            "title": "You Tweet What You Eat: Studying Food Consumption Through Twitter",
            "abstract": "Food is an integral part of our lives, cultures, and well-being, and is of major interest to public health. The collection of daily nutritional data involves keeping detailed diaries or periodic surveys and is limited in scope and reach. Alternatively, social media is infamous for allowing its users to update the world on the minutiae of their daily lives, including their eating habits. In this work we examine the potential of Twitter to provide insight into US-wide dietary choices by linking the tweeted dining experiences of 210K users to their interests, demographics, and social networks. We validate our approach by relating the caloric values of the foods mentioned in the tweets to the state-wide obesity rates, achieving a Pearson correlation of 0.77 across the 50 US states and the District of Columbia. We then build a model to predict county-wide obesity and diabetes statistics based on a combination of demographic variables and food names mentioned on Twitter. Our results show significant improvement over previous CHI research (Culotta 2014). We further link this data to societal and economic factors, such as education and income, illustrating that areas with higher education levels tweet about food that is significantly less caloric. Finally, we address the somewhat controversial issue of the social nature of obesity (Christakis & Fowler 2007) by inducing two social networks using mentions and reciprocal following relationships.",
            "fieldsOfStudy": [
                "Computer Science",
                "Psychology",
                "Physics"
            ],
            "authors": [
                {
                    "authorId": "3009678",
                    "name": "Sofiane Abbar"
                },
                {
                    "authorId": "3329961",
                    "name": "Yelena Mejova"
                },
                {
                    "authorId": "1684687",
                    "name": "Ingmar Weber"
                }
            ]
        },
        {
            "paperId": "1ad2e5534204a23b910785fded53d9a0b7ef677c",
            "title": "Diverse near neighbor problem",
            "abstract": "Motivated by the recent research on diversity-aware search, we investigate the k-diverse near neighbor reporting problem. The problem is defined as follows: given a query point q, report the maximum diversity set S of k points in the ball of radius r around q. The diversity of a set S is measured by the minimum distance between any pair of points in $S$ (the higher, the better). We present two approximation algorithms for the case where the points live in a d-dimensional Hamming space. Our algorithms guarantee query times that are sub-linear in n and only polynomial in the diversity parameter k, as well as the dimension d. For low values of k, our algorithms achieve sub-linear query times even if the number of points within distance r from a query $q$ is linear in $n$. To the best of our knowledge, these are the first known algorithms of this type that offer provable guarantees.",
            "fieldsOfStudy": [
                "Computer Science",
                "Mathematics"
            ],
            "authors": [
                {
                    "authorId": "3009678",
                    "name": "Sofiane Abbar"
                },
                {
                    "authorId": "1403657578",
                    "name": "S. Amer-Yahia"
                },
                {
                    "authorId": "1688317",
                    "name": "P. Indyk"
                },
                {
                    "authorId": "145700959",
                    "name": "S. Mahabadi"
                },
                {
                    "authorId": "1757762",
                    "name": "Kasturi R. Varadarajan"
                }
            ]
        },
        {
            "paperId": "d05b74a72d9799498958143a3255a76edb91470e",
            "title": "Real-time recommendation of diverse related articles",
            "abstract": "News articles typically drive a lot of traffic in the form of comments posted by users on a news site. Such user-generated content tends to carry additional information such as entities and sentiment. In general, when articles are recommended to users, only popularity (e.g., most shared and most commented), recency, and sometimes (manual) editors' picks (based on daily hot topics), are considered. We formalize a novel recommendation problem where the goal is to find the closest most diverse articles to the one the user is currently browsing. Our diversity measure incorporates entities and sentiment extracted from comments. Given the real-time nature of our recommendations, we explore the applicability of nearest neighbor algorithms to solve the problem. Our user study on real opinion articles from aljazeera.net and reuters.com validates the use of entities and sentiment extracted from articles and their comments to achieve news diversity when compared to content-based diversity. Finally, our performance experiments show the real-time feasibility of our solution.",
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "authors": [
                {
                    "authorId": "3009678",
                    "name": "Sofiane Abbar"
                },
                {
                    "authorId": "1403657578",
                    "name": "S. Amer-Yahia"
                },
                {
                    "authorId": "1688317",
                    "name": "P. Indyk"
                },
                {
                    "authorId": "145700959",
                    "name": "S. Mahabadi"
                }
            ]
        },
        {
            "paperId": "0814210a135e052e036bdf40fd0c63a54541217a",
            "title": "MAQSA: a system for social analytics on news",
            "abstract": "We present MAQSA, a system for social analytics on news. MAQSA provides an interactive topic-centric dashboard that summarizes news articles and social activity (e.g., comments and tweets) around them. MAQSA helps editors and publishers in newsrooms understand user engagement and audience sentiment evolution on various topics of interest. It also helps news consumers explore public reaction on articles relevant to a topic and refine their exploration via related entities, topics, articles and tweets. Given a topic, e.g., \"Gulf Oil Spill,\" or \"The Arab Spring\", MAQSA combines three key dimensions: time, geographic location, and topic to generate a detailed activity dashboard around relevant articles. The dashboard contains an annotated comment timeline and a social graph of comments. It utilizes commenters' locations to build maps of comment sentiment and topics by region of the world. Finally, to facilitate exploration, MAQSA provides listings of related entities, articles, and tweets. It algorithmically processes large collections of articles and tweets, and enables the dynamic specification of topics and dates for exploration. In this demo, participants will be invited to explore the social dynamics around articles on oil spills, the Libyan revolution, and the Arab Spring. In addition, participants will be able to define and explore their own topics dynamically.",
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "authors": [
                {
                    "authorId": "1403657578",
                    "name": "S. Amer-Yahia"
                },
                {
                    "authorId": "1845917958",
                    "name": "Samreen Anjum"
                },
                {
                    "authorId": "2009092",
                    "name": "Amira Ghenai"
                },
                {
                    "authorId": "40588385",
                    "name": "Aysha Siddique"
                },
                {
                    "authorId": "3009678",
                    "name": "Sofiane Abbar"
                },
                {
                    "authorId": "144478906",
                    "name": "S. Madden"
                },
                {
                    "authorId": "145632757",
                    "name": "Adam Marcus"
                },
                {
                    "authorId": "102697193",
                    "name": "Mohammed El-Haddad"
                }
            ]
        },
        {
            "paperId": "a8b2f80ada66a52bd62b3eba922d877a896ab6b4",
            "title": "The impact of negative preferences on a recommendation process",
            "abstract": "Modern recommender systems rely on user feedback to provide high quality recommendations. User feedback communicates information about the user interests and preferences. However, in most existing recommender systems, only the positive preferences are taken into account in the recommendation process. We are trying, through this paper, to show the impact of negatives preferences on the recommendation process. To do this, we propose a system for recommending movies which combines positive and negative preferences to estimate the utility of a given movie for a given user. Our first experiments show that taking into account the negative preferences has a positive impact on the relevance of the recommendations made by the system.",
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "authors": [
                {
                    "authorId": "2222776102",
                    "name": "Latifa Baba Hamed"
                },
                {
                    "authorId": "3009678",
                    "name": "Sofiane Abbar"
                },
                {
                    "authorId": "2247916000",
                    "name": "Amine Haouari"
                }
            ]
        },
        {
            "paperId": "2429873b76425596bab251e0583b4c21aab8bd1f",
            "title": "Introducing contexts into personalized web applications",
            "abstract": "Profiles and contexts are the main concepts used by modern applications (e.g. e-commerce and recommender systems) to adapt content delivery services to the users' needs, preferences and environment. Although the definitions of the two terms slightly differ from one application to another, there is a general agreement to distinguish them and use them separately or jointly in a given application. When used jointly, the relationship between the two concepts remains often unclear. This paper aims at providing a personalization model that encompasses profile, context, and a formal relationships between the two. This relationship, called con-textualization, is represented by a set of ranked mappings, automatically extracted from a usage history (log file of user actions). Profile, context and contextualization constitute three structuring elements over which any personalized system should be built. The proposal is supported by a design platform which helps in instantiating profiles and contexts and in generating contextual mappings between them. An instantiation of the meta model is given for an advanced recommender system, called context-aware recommender system (or CARS for short). This instantiation is followed by an experiment highlighting the benefit of contextualization.",
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "authors": [
                {
                    "authorId": "3009678",
                    "name": "Sofiane Abbar"
                },
                {
                    "authorId": "1750088",
                    "name": "M. Bouzeghoub"
                },
                {
                    "authorId": "3148280",
                    "name": "St\u00e9phane Lopes"
                }
            ]
        },
        {
            "paperId": "ad03f487292e84652a654c5f529fda9ece21a0b7",
            "title": "A contextualization service for a Personalized Access Model",
            "abstract": "Personalization paradigm aims at providing users with the most relevant content and services according to many factors such as interest center or location at the querying time. All this knowledge and requirements are organized into user profiles and contexts. A user profile encompasses metadata describing the user whereas a context groups information about the environment of interaction between the user and the system. An interesting problem is therefore to identify which part of the profile is significant in a given context. This paper proposes a contextualization service which allows defining relationships between user preferences and contexts. Further, we propose an approach for the automatic discovery of these mappings by analyzing user behavior extracted from log files.",
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "authors": [
                {
                    "authorId": "3009678",
                    "name": "Sofiane Abbar"
                },
                {
                    "authorId": "1750088",
                    "name": "M. Bouzeghoub"
                },
                {
                    "authorId": "35226856",
                    "name": "Dimitre Kostadinov"
                },
                {
                    "authorId": "3148280",
                    "name": "St\u00e9phane Lopes"
                }
            ]
        },
        {
            "paperId": "d6f8a959d9649794b8424d6aefdf6d6da0562813",
            "title": "Context-Aware Recommender Systems: A Service-Oriented Approach",
            "abstract": "Recommender systems are ecient tools that overcome the information overload problem by providing users with the most relevant contents. This is generally done through user\u2019s preferences/ratings acquired from log les of his former sessions. Besides these preferences, taking into account the interaction context of the user will improve the relevancy of recommendation process. In this paper, we propose a context-aware recommender system based on both user prole and context. The approach we present is based on a previous work on data personalization which leads to the denition of a Personalized Access Model that provides a set of personalization services. We show how these services can be deployed in order to provide advanced context-aware recommender systems.",
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "authors": [
                {
                    "authorId": "3009678",
                    "name": "Sofiane Abbar"
                },
                {
                    "authorId": "1750088",
                    "name": "M. Bouzeghoub"
                },
                {
                    "authorId": "2071044061",
                    "name": "St\u00e9phane Lopez"
                }
            ]
        },
        {
            "paperId": "2a78be11b2dbdf46dcb9971dc332bb293b2fb508",
            "title": "A personalized access model: concepts and services for content delivery platforms",
            "abstract": "Access to relevant information, adapted to user's needs, preferences and environment, is a challenge in many applications running in content delivery platforms, like IPTV, VoD and mobile Video. In order to provide users with personalized content, applications use various techniques such as content recommendation, content filtering, preference-driven queries, etc. These techniques exploit different knowledge organized into profiles and contexts. However, there is not a common understanding of these concepts and there is no clear foundation of what a personalized access model should be. This paper contributes to this concern by providing, through a meta model, a clear distinction between profile and context, and by providing a set of services which constitutes a basement to the definition of a personalized access model (PAM). Our PAM definition allows applications to interoperate in multiple personalization scenarios, including, preference-based recommendation, context-aware content delivery, personalized access to multiple contents, etc. Concepts and services proposed are tightly defined with respect to real applications requirements provided by Alcatel-Lucent.",
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "authors": [
                {
                    "authorId": "3009678",
                    "name": "Sofiane Abbar"
                },
                {
                    "authorId": "1750088",
                    "name": "M. Bouzeghoub"
                },
                {
                    "authorId": "35226856",
                    "name": "Dimitre Kostadinov"
                },
                {
                    "authorId": "3148280",
                    "name": "St\u00e9phane Lopes"
                },
                {
                    "authorId": "1760367",
                    "name": "A. Aghasaryan"
                },
                {
                    "authorId": "1398747113",
                    "name": "S. Betg\u00e9-Brezetz"
                }
            ]
        }
    ]
}