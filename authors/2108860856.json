{
    "authorId": "2108860856",
    "papers": [
        {
            "paperId": "322cb586ac1334ee61611acd497276ebe74de014",
            "title": "AFS Graph: Multidimensional Axiomatic Fuzzy Set Knowledge Graph for Open-Domain Question Answering",
            "abstract": "Open-domain question answering (QA) tasks require a model to retrieve inference chains associated with the answer from massive documents. The core of a QA model is the information filtering ability and reasoning ability. This article proposes a semantic knowledge reasoning graph model based on the multidimensional axiomatic fuzzy set (AFS), which can generate the knowledge graph (KG) and build reasoning paths for reading comprehension tasks through unsupervised learning. Moreover, taking advantage of the interpretable AFS framework enables the proposed model to have the ability to learn and analyze the semantic relationships between candidate documents. Meanwhile, the utilization of the multidimensional AFS acquires semantic descriptions of candidate documents more concise and flexible. The similarity degree between paragraphs is calculated according to the AFS description to generate the graph. Interpretable chains of reasoning provided by the AFS knowledge graph (AFS Graph) will serve as the basis for the answer prediction. Compared with the previous methods, the AFS Graph model presented in this article improves interpretability and reasoning ability. Experimental results show that the proposed model can achieve the state-of-the-art performance on datasets of HotpotQA, SQuAD, and Natural Questions Open.",
            "fieldsOfStudy": [
                "Medicine",
                "Computer Science"
            ],
            "authors": [
                {
                    "authorId": "1384395664",
                    "name": "Qi Lang"
                },
                {
                    "authorId": "2108860856",
                    "name": "Xiaodong Liu"
                },
                {
                    "authorId": "50677717",
                    "name": "Wenjuan Jia"
                }
            ]
        },
        {
            "paperId": "0e23cc159fd2fb34550600d60dd9148c93636183",
            "title": "Taming Sparsely Activated Transformer with Stochastic Experts",
            "abstract": "Sparsely activated models (SAMs), such as Mixture-of-Experts (MoE), can easily scale to have outrageously large amounts of parameters without significant increase in computational cost. However, SAMs are reported to be parameter inefficient such that larger models do not always lead to better performance. While most on-going research focuses on improving SAMs models by exploring methods of routing inputs to experts, our analysis reveals that such research might not lead to the solution we expect, i.e., the commonly-used routing methods based on gating mechanisms do not work better than randomly routing inputs to experts. In this paper, we propose a new expert-based model, THOR (Transformer witH StOchastic ExpeRts). Unlike classic expert-based models, such as the Switch Transformer, experts in THOR are randomly activated for each input during training and inference. THOR models are trained using a consistency regularized loss, where experts learn not only from training data but also from other experts as teachers, such that all the experts make consistent predictions. We validate the effectiveness of THOR on machine translation tasks. Results show that THOR models are more parameter efficient in that they significantly outperform the Transformer and MoE models across various settings. For example, in multilingual translation, THOR outperforms the Switch Transformer by 2 BLEU scores, and obtains the same BLEU score as that of a state-of-the-art MoE model that is 18 times larger. Our code is publicly available at: https://github.com/microsoft/Stochastic-Mixture-of-Experts.",
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "authors": [
                {
                    "authorId": "52194893",
                    "name": "Simiao Zuo"
                },
                {
                    "authorId": "2108860856",
                    "name": "Xiaodong Liu"
                },
                {
                    "authorId": "49097406",
                    "name": "Jian Jiao"
                },
                {
                    "authorId": "2152658577",
                    "name": "Young Jin Kim"
                },
                {
                    "authorId": "143925074",
                    "name": "Hany Hassan"
                },
                {
                    "authorId": "2124601065",
                    "name": "Ruofei Zhang"
                },
                {
                    "authorId": "36345161",
                    "name": "T. Zhao"
                },
                {
                    "authorId": "48441311",
                    "name": "Jianfeng Gao"
                }
            ]
        },
        {
            "paperId": "375cc986ab185c161b80b4f13f4d8f9e6521eedf",
            "title": "UnitedQA: A Hybrid Approach for Open Domain Question Answering",
            "abstract": "To date, most of recent work under the retrieval-reader framework for open-domain QA focuses on either extractive or generative reader exclusively. In this paper, we study a hybrid approach for leveraging the strengths of both models. We apply novel techniques to enhance both extractive and generative readers built upon recent pretrained neural language models, and find that proper training methods can provide large improvement over previous state-of-the-art models. We demonstrate that a simple hybrid approach by combining answers from both readers can efficiently take advantages of extractive and generative answer inference strategies and outperforms single models as well as homogeneous ensembles. Our approach outperforms previous state-of-the-art models by 3.3 and 2.7 points in exact match on NaturalQuestions and TriviaQA respectively.",
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "authors": [
                {
                    "authorId": "47413820",
                    "name": "Hao Cheng"
                },
                {
                    "authorId": "1752875",
                    "name": "Yelong Shen"
                },
                {
                    "authorId": "2108860856",
                    "name": "Xiaodong Liu"
                },
                {
                    "authorId": "2107782398",
                    "name": "Pengcheng He"
                },
                {
                    "authorId": "2109136147",
                    "name": "Weizhu Chen"
                },
                {
                    "authorId": "1800422",
                    "name": "Jianfeng Gao"
                }
            ]
        },
        {
            "paperId": "3ede448b85b71790eda31de51ce663e5980eab78",
            "title": "Knowledge-Rich Self-Supervised Entity Linking",
            "abstract": "Entity linking faces signi\ufb01cant challenges, such as proli\ufb01c variations and prevalent ambiguities, especially in high-value domains with myriad entities. Standard classi\ufb01cation approaches suffer from the annotation bottle-neck and cannot effectively handle unseen entities. Zero-shot entity linking has emerged as a promising direction for generalizing to new entities, but it still requires example gold entity mentions during training and canonical descriptions for all entities, both of which are rarely available outside of Wikipedia. In this paper, we explore Knowledge-RIch Self-Supervision ( KRISS ) for entity linking, by leveraging readily available domain knowledge. In training, it generates self-supervised mention examples on unlabeled text using a domain ontology and trains a contextual encoder using contrastive learning. For inference, it samples self-supervised mentions as prototypes for each entity and conducts linking by mapping the test mention to the most similar prototype. Our approach subsumes zero-shot and few-shot methods, and can easily incorporate entity descriptions and gold mention labels if available. Using biomedicine as a case study, we conducted extensive experiments on seven standard datasets spanning biomedical literature and clinical notes. With-out using any labeled information, our method produces KRISSBERT , a universal entity linker for four million UMLS entities, which attains new state of the art across the board, outper-forming prior best self-supervised methods by as much as over 20 absolute points in accuracy.",
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "authors": [
                {
                    "authorId": "41209309",
                    "name": "Sheng Zhang"
                },
                {
                    "authorId": "47413820",
                    "name": "Hao Cheng"
                },
                {
                    "authorId": "3404827",
                    "name": "Shikhar Vashishth"
                },
                {
                    "authorId": "2109566188",
                    "name": "Cliff Wong"
                },
                {
                    "authorId": "46851930",
                    "name": "Jinfeng Xiao"
                },
                {
                    "authorId": "2108860856",
                    "name": "Xiaodong Liu"
                },
                {
                    "authorId": "40466858",
                    "name": "Tristan Naumann"
                },
                {
                    "authorId": "48441311",
                    "name": "Jianfeng Gao"
                },
                {
                    "authorId": "1759772",
                    "name": "Hoifung Poon"
                }
            ]
        },
        {
            "paperId": "5a166cfd781ac871cd4fc26fd8b7fb0e0a1fa795",
            "title": "Open Domain Question Answering over Virtual Documents: A Unified Approach for Data and Text",
            "abstract": "Due to its potential for a universal interface 001 over both data and text, data-to-text genera-002 tion is becoming increasingly popular. How-003 ever, few prior work has focused on its ap-004 plication to downstream tasks, e.g. using the 005 converted data for grounding or reasoning. 006 In this work, we bridge this gap and use 007 the data-to-text method as a means for en-008 coding structured knowledge for knowledge-009 intensive applications, i.e. open-domain ques-010 tion answering (ODQA). Speci\ufb01cally, we pro-011 pose a verbalizer-retriever-reader framework 012 for ODQA over data and text where verbal-013 ized tables from Wikipedia and graphs from 014 Wikidata are used as augmented knowledge 015 sources. We show that our U ni\ufb01ed D ata and 016 T ext QA , UDT-QA , can effectively bene\ufb01t 017 from the expanded knowledge index, leading 018 to large gains over text-only baselines. No-019 tably, our approach sets the single-model state-020 of-the-art on Natural Questions. Furthermore, 021 our analyses indicate that verbalized knowl-022 edge is preferred for answer reasoning for both 023 adapted and hot-swap settings. 024",
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "authors": [
                {
                    "authorId": "22244290",
                    "name": "Kaixin Ma"
                },
                {
                    "authorId": "47413820",
                    "name": "Hao Cheng"
                },
                {
                    "authorId": "2108860856",
                    "name": "Xiaodong Liu"
                },
                {
                    "authorId": "144287919",
                    "name": "Eric Nyberg"
                },
                {
                    "authorId": "48441311",
                    "name": "Jianfeng Gao"
                }
            ]
        },
        {
            "paperId": "64c8350a66ada14ecc0baa3446c75884cc27e3dd",
            "title": "Human Parity on CommonsenseQA: Augmenting Self-Attention with External Attention",
            "abstract": "Most of today's AI systems focus on using self-attention mechanisms and transformer architectures on large amounts of diverse data to achieve impressive performance gains. In this paper, we propose to augment the transformer architecture with an external attention mechanism to bring external knowledge and context to bear.\n\n By integrating external information into the prediction process, we hope to reduce the need for ever-larger models and increase the democratization of AI systems.\n\n We find that the proposed external attention mechanism can significantly improve the performance of existing AI systems, allowing practitioners to easily customize foundation AI models to many diverse downstream applications. \n\n In particular, we focus on the task of Commonsense Reasoning, demonstrating that the proposed external attention mechanism can augment existing transformer models and significantly improve the model's reasoning capabilities. The proposed system, Knowledgeable External Attention for commonsense Reasoning (KEAR), reaches human parity on the open CommonsenseQA research benchmark with an accuracy of 89.4% in comparison to the human accuracy of 88.9%.",
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "authors": [
                {
                    "authorId": "2110197273",
                    "name": "Yichong Xu"
                },
                {
                    "authorId": "8652308",
                    "name": "Chenguang Zhu"
                },
                {
                    "authorId": "2992833",
                    "name": "Shuohang Wang"
                },
                {
                    "authorId": "2109508754",
                    "name": "Siqi Sun"
                },
                {
                    "authorId": "47413820",
                    "name": "Hao Cheng"
                },
                {
                    "authorId": "2108860856",
                    "name": "Xiaodong Liu"
                },
                {
                    "authorId": "48441311",
                    "name": "Jianfeng Gao"
                },
                {
                    "authorId": "50462546",
                    "name": "Pengcheng He"
                },
                {
                    "authorId": "48262024",
                    "name": "Michael Zeng"
                },
                {
                    "authorId": "144531812",
                    "name": "Xuedong Huang"
                }
            ]
        },
        {
            "paperId": "8d48441fcf5dd900955036761972cecd18110813",
            "title": "NeurIPS 2020 EfficientQA Competition: Systems, Analyses and Lessons Learned",
            "abstract": "We review the EfficientQA competition from NeurIPS 2020. The competition focused on open-domain question answering (QA), where systems take natural language questions as input and return natural language answers. The aim of the competition was to build systems that can predict correct answers while also satisfying strict on-disk memory budgets. These memory budgets were designed to encourage contestants to explore the trade-off between storing retrieval corpora or the parameters of learned models. In this report, we describe the motivation and organization of the competition, review the best submissions, and analyze system predictions to inform a discussion of evaluation for open-domain QA.",
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "authors": [
                {
                    "authorId": "48872685",
                    "name": "Sewon Min"
                },
                {
                    "authorId": "1389036863",
                    "name": "Jordan L. Boyd-Graber"
                },
                {
                    "authorId": "114577307",
                    "name": "Chris Alberti"
                },
                {
                    "authorId": "50536468",
                    "name": "Danqi Chen"
                },
                {
                    "authorId": "2890423",
                    "name": "Eunsol Choi"
                },
                {
                    "authorId": "123052390",
                    "name": "Michael Collins"
                },
                {
                    "authorId": "2091768",
                    "name": "Kelvin Guu"
                },
                {
                    "authorId": "2548384",
                    "name": "Hannaneh Hajishirzi"
                },
                {
                    "authorId": "2544107",
                    "name": "Kenton Lee"
                },
                {
                    "authorId": "52578817",
                    "name": "J. Palomaki"
                },
                {
                    "authorId": "2402716",
                    "name": "Colin Raffel"
                },
                {
                    "authorId": "145625142",
                    "name": "Adam Roberts"
                },
                {
                    "authorId": "15652489",
                    "name": "T. Kwiatkowski"
                },
                {
                    "authorId": "145222654",
                    "name": "Patrick Lewis"
                },
                {
                    "authorId": "39417610",
                    "name": "Yuxiang Wu"
                },
                {
                    "authorId": "103131985",
                    "name": "Heinrich Kuttler"
                },
                {
                    "authorId": "2111591",
                    "name": "Linqing Liu"
                },
                {
                    "authorId": "3051815",
                    "name": "Pasquale Minervini"
                },
                {
                    "authorId": "1918552",
                    "name": "Pontus Stenetorp"
                },
                {
                    "authorId": "48662861",
                    "name": "Sebastian Riedel"
                },
                {
                    "authorId": "16110760",
                    "name": "Sohee Yang"
                },
                {
                    "authorId": "4418074",
                    "name": "Minjoon Seo"
                },
                {
                    "authorId": "1410231361",
                    "name": "Gautier Izacard"
                },
                {
                    "authorId": "40052301",
                    "name": "F. Petroni"
                },
                {
                    "authorId": "26360550",
                    "name": "Lucas Hosseini"
                },
                {
                    "authorId": "41019080",
                    "name": "Nicola De Cao"
                },
                {
                    "authorId": "3024698",
                    "name": "Edouard Grave"
                },
                {
                    "authorId": "2303128",
                    "name": "Ikuya Yamada"
                },
                {
                    "authorId": "2046634",
                    "name": "Sonse Shimaoka"
                },
                {
                    "authorId": "144410141",
                    "name": "Masatoshi Suzuki"
                },
                {
                    "authorId": "1734833687",
                    "name": "Shumpei Miyawaki"
                },
                {
                    "authorId": "144382404",
                    "name": "Shun Sato"
                },
                {
                    "authorId": "2143210266",
                    "name": "Ryo Takahashi"
                },
                {
                    "authorId": "153211541",
                    "name": "Jun Suzuki"
                },
                {
                    "authorId": "1388781179",
                    "name": "Martin Fajcik"
                },
                {
                    "authorId": "73665149",
                    "name": "Martin Docekal"
                },
                {
                    "authorId": "2044202425",
                    "name": "Karel Ondrej"
                },
                {
                    "authorId": "143917717",
                    "name": "P. Smrz"
                },
                {
                    "authorId": "47413820",
                    "name": "Hao Cheng"
                },
                {
                    "authorId": "1752875",
                    "name": "Yelong Shen"
                },
                {
                    "authorId": "2108860856",
                    "name": "Xiaodong Liu"
                },
                {
                    "authorId": "50462546",
                    "name": "Pengcheng He"
                },
                {
                    "authorId": "2109136147",
                    "name": "Weizhu Chen"
                },
                {
                    "authorId": "48441311",
                    "name": "Jianfeng Gao"
                },
                {
                    "authorId": "9185192",
                    "name": "Barlas O\u011fuz"
                },
                {
                    "authorId": "1769736",
                    "name": "Xilun Chen"
                },
                {
                    "authorId": "2067091563",
                    "name": "Vladimir Karpukhin"
                },
                {
                    "authorId": "3139260",
                    "name": "Stanislav Peshterliev"
                },
                {
                    "authorId": "113568063",
                    "name": "Dmytro Okhonko"
                },
                {
                    "authorId": "8804828",
                    "name": "M. Schlichtkrull"
                },
                {
                    "authorId": "2118343423",
                    "name": "Sonal Gupta"
                },
                {
                    "authorId": "2263803",
                    "name": "Yashar Mehdad"
                },
                {
                    "authorId": "144105277",
                    "name": "Wen-tau Yih"
                }
            ]
        },
        {
            "paperId": "8e88f835acdabf16eda88ece9c5acedac64a6274",
            "title": "Adversarial Regularization as Stackelberg Game: An Unrolled Optimization Approach",
            "abstract": "Adversarial regularization has been shown to improve the generalization performance of deep learning models in various natural language processing tasks. Existing works usually formulate the method as a zero-sum game, which is solved by alternating gradient descent/ascent algorithms. Such a formulation treats the adversarial and the defending players equally, which is undesirable because only the defending player contributes to the generalization performance. To address this issue, we propose Stackelberg Adversarial Regularization (SALT), which formulates adversarial regularization as a Stackelberg game. This formulation induces a competition between a leader and a follower, where the follower generates perturbations, and the leader trains the model subject to the perturbations. Different from conventional approaches, in SALT, the leader is in an advantageous position. When the leader moves, it recognizes the strategy of the follower and takes the anticipated follower\u2019s outcomes into consideration. Such a leader\u2019s advantage enables us to improve the model fitting to the unperturbed data. The leader\u2019s strategic information is captured by the Stackelberg gradient, which is obtained using an unrolling algorithm. Our experimental results on a set of machine translation and natural language understanding tasks show that SALT outperforms existing adversarial regularization baselines across all tasks. Our code is publicly available.",
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "authors": [
                {
                    "authorId": "52194893",
                    "name": "Simiao Zuo"
                },
                {
                    "authorId": "98703980",
                    "name": "Chen Liang"
                },
                {
                    "authorId": "2152630772",
                    "name": "Haoming Jiang"
                },
                {
                    "authorId": "2108860856",
                    "name": "Xiaodong Liu"
                },
                {
                    "authorId": "50462546",
                    "name": "Pengcheng He"
                },
                {
                    "authorId": "48441311",
                    "name": "Jianfeng Gao"
                },
                {
                    "authorId": "2109136147",
                    "name": "Weizhu Chen"
                },
                {
                    "authorId": "36345161",
                    "name": "T. Zhao"
                }
            ]
        },
        {
            "paperId": "cc86a4f3a187f08df763b8e70fb543d2c435d83e",
            "title": "CLUES: Few-Shot Learning Evaluation in Natural Language Understanding",
            "abstract": "Most recent progress in natural language understanding (NLU) has been driven, in part, by benchmarks such as GLUE, SuperGLUE, SQuAD, etc. In fact, many NLU models have now matched or exceeded\"human-level\"performance on many tasks in these benchmarks. Most of these benchmarks, however, give models access to relatively large amounts of labeled data for training. As such, the models are provided far more data than required by humans to achieve strong performance. That has motivated a line of work that focuses on improving few-shot learning performance of NLU models. However, there is a lack of standardized evaluation benchmarks for few-shot NLU resulting in different experimental settings in different papers. To help accelerate this line of work, we introduce CLUES (Constrained Language Understanding Evaluation Standard), a benchmark for evaluating the few-shot learning capabilities of NLU models. We demonstrate that while recent models reach human performance when they have access to large amounts of labeled data, there is a huge gap in performance in the few-shot setting for most tasks. We also demonstrate differences between alternative model families and adaptation techniques in the few shot setting. Finally, we discuss several principles and choices in designing the experimental settings for evaluating the true few-shot learning performance and suggest a unified standardized approach to few-shot learning evaluation. We aim to encourage research on NLU models that can generalize to new tasks with a small number of examples. Code and data for CLUES are available at https://github.com/microsoft/CLUES.",
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "authors": [
                {
                    "authorId": "2153292652",
                    "name": "Subhabrata Mukherjee"
                },
                {
                    "authorId": "2108860856",
                    "name": "Xiaodong Liu"
                },
                {
                    "authorId": "2250250",
                    "name": "Guoqing Zheng"
                },
                {
                    "authorId": "2195458",
                    "name": "Saghar Hosseini"
                },
                {
                    "authorId": "47413820",
                    "name": "Hao Cheng"
                },
                {
                    "authorId": "2109540863",
                    "name": "Greg Yang"
                },
                {
                    "authorId": "2064103138",
                    "name": "Christopher Meek"
                },
                {
                    "authorId": "2072795428",
                    "name": "A. Awadallah"
                },
                {
                    "authorId": "48441311",
                    "name": "Jianfeng Gao"
                }
            ]
        },
        {
            "paperId": "d52976a07b1eeb97e8a031605bb02d8cd7833a63",
            "title": "ARCH: Efficient Adversarial Regularized Training with Caching",
            "abstract": "Adversarial regularization can improve model generalization in many natural language processing tasks. However, conventional approaches are computationally expensive since they need to generate a perturbation for each sample in each epoch. We propose a new adversarial regularization method ARCH (adversarial regularization with caching), where perturbations are generated and cached once every several epochs. As caching all the perturbations imposes memory usage concerns, we adopt a K-nearest neighbors-based strategy to tackle this issue. The strategy only requires caching a small amount of perturbations, without introducing additional training time. We evaluate our proposed method on a set of neural machine translation and natural language understanding tasks. We observe that ARCH significantly eases the computational burden (saves up to 70% of computational time in comparison with conventional approaches). More surprisingly, by reducing the variance of stochastic gradients, ARCH produces a notably better (in most of the tasks) or comparable model generalization. Our code is available at https://github.com/SimiaoZuo/Caching-Adv.",
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "authors": [
                {
                    "authorId": "52194893",
                    "name": "Simiao Zuo"
                },
                {
                    "authorId": "98703980",
                    "name": "Chen Liang"
                },
                {
                    "authorId": "2152630772",
                    "name": "Haoming Jiang"
                },
                {
                    "authorId": "50462546",
                    "name": "Pengcheng He"
                },
                {
                    "authorId": "2108860856",
                    "name": "Xiaodong Liu"
                },
                {
                    "authorId": "48441311",
                    "name": "Jianfeng Gao"
                },
                {
                    "authorId": "2109136147",
                    "name": "Weizhu Chen"
                },
                {
                    "authorId": "36345161",
                    "name": "T. Zhao"
                }
            ]
        }
    ]
}