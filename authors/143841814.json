{
    "authorId": "143841814",
    "papers": [
        {
            "paperId": "26ded76f93f5b1180010ff98b90b8eacce536a52",
            "title": "Fairness for both Readers and Authors: Evaluating Summaries of User Generated Content",
            "abstract": "Summarization of textual content has many applications, ranging from summarizing long documents to recent efforts towards summarizing user generated text (e.g., tweets, Facebook or Reddit posts). Traditionally, the focus of summarization has been to generate summaries which can best satisfy the readers. In this work, we look at summarization of user-generated content as a two-sided problem where satisfaction of both readers and authors is crucial. Through three surveys, we show that for user-generated content, traditional evaluation approach of measuring similarity between reference summaries and algorithmic summaries cannot capture author satisfaction. We propose an author satisfaction-based evaluation metric CROSSEM which, we show empirically, can potentially complement the current evaluation paradigm. We further propose the idea of inequality in satisfaction, to account for individual fairness amongst readers and authors. To our knowledge, this is the first attempt towards developing a fair summary evaluation framework for user generated content, and is likely to spawn lot of future research in this space.",
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "authors": [
                {
                    "authorId": "2176922612",
                    "name": "Garima Chhikara"
                },
                {
                    "authorId": "153408379",
                    "name": "Kripabandhu Ghosh"
                },
                {
                    "authorId": "143841814",
                    "name": "Saptarshi Ghosh"
                },
                {
                    "authorId": "2676839",
                    "name": "Abhijnan Chakraborty"
                }
            ]
        },
        {
            "paperId": "36696abcc896118e7eb2c112c6b52e3622cb47be",
            "title": "Discretization Using Combination of Heuristics for High Accuracy With Huge Noise Reduction",
            "abstract": "Over the years, several algorithms for discretization have been devised, but the problem of efficient, accurate discretization still remains an open problem. This paper proposes a novel discretization algorithm, called SPID5, based on combination of two heuristics, one being local and the other global, both being supervised and their combination resulting in a significant synergy. The local heuristic is the well-known information gain of the continuous attributes, and the global heuristic is a novel concept of iterative reduction of noise in the data set. The reduction of noise is achieved by reducing successively pseudo deletion count of the data set to be discretized. The performance of SPID5 algorithm is compared with that of three well-known and time-tested discretization algorithms, using six state-of-the-art classifiers and 35 real-world data sets from the standard UCI data repository. Performance of SPID5 compares favorably with that of all the three existing discretization algorithms it is compared with, not only in terms of classification accuracy but also in terms of noise reduction in the data sets.",
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "authors": [
                {
                    "authorId": "2034434",
                    "name": "Somnath Pal"
                },
                {
                    "authorId": "143841814",
                    "name": "Saptarshi Ghosh"
                },
                {
                    "authorId": "144457011",
                    "name": "Himika Biswas"
                },
                {
                    "authorId": "1752966181",
                    "name": "Mitesh Patwari"
                }
            ]
        },
        {
            "paperId": "5421669adc5cb4755923dee77018fe28bddfe42b",
            "title": "Social Media for Post-Disaster Relief: Mapping Needs and Availabilities to UNOCHA Resource Classes",
            "abstract": "In the aftermath of a natural disaster, the key objective is to save human life by providing life-saving resources in real-time. However, the major challenge in coordinating relief operations is the lack of real-time information on resource-needs and resource-availabilities in the disaster-affected region. For the last few decades, Online Social Media (OSM) has become an important source of such real-time information during disasters. Specifically, for disaster events that occur in urban regions, due to the ubiquity of smartphones and availability of stable internet service, the affected population is more inclined to post the information regarding resource-needs and resource-availabilities in OSM. Hence, for disaster events that occur in urban regions, we propose to use Online Social Media as a source of such real-time information. In the present study, we specifically discuss the challenge of mapping social media posts (microblogs) to resource classes as per UNOCHA guidelines. Subsequently, we have attempted to automate the class-wise resource segregation of the tweets using a multi-label classification approach. To this end, we have experimented with several traditional and neural network based classifiers. We have also utilised the transfer learning approach through BERT pre-trained model. We have found the BERT pre-trained model has outperformed all traditional as well as neural network based classifiers in terms of F-Score.",
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "authors": [
                {
                    "authorId": "2140517816",
                    "name": "Amitrajit Bose"
                },
                {
                    "authorId": "2151013162",
                    "name": "Sivangi Tandon"
                },
                {
                    "authorId": "39954837",
                    "name": "Moumita Basu"
                },
                {
                    "authorId": "143841814",
                    "name": "Saptarshi Ghosh"
                }
            ]
        },
        {
            "paperId": "7028246159a56dff4f3e09a0355880edaa7148d9",
            "title": "What You Like: Generating Explainable Topical Recommendations for Twitter Using Social Annotations",
            "abstract": "With over 500 million tweets posted per day, in Twitter, it is difficult for Twitter users to discover interesting content from the deluge of uninteresting posts. In this work, we present a novel, explainable, topical recommendation system, that utilizes social annotations, to help Twitter users discover tweets, on topics of their interest. A major challenge in using traditional rating dependent recommendation systems, like collaborative filtering and content based systems, in high volume social networks is that, due to attention scarcity most items do not get any ratings. Additionally, the fact that most Twitter users are passive consumers, with 44% users never tweeting, makes it very difficult to use user ratings for generating recommendations. Further, a key challenge in developing recommendation systems is that in many cases users reject relevant recommendations if they are totally unfamiliar with the recommended item. Providing a suitable explanation, for why the item is recommended, significantly improves the acceptability of recommendation. By virtue of being a topical recommendation system our method is able to present simple topical explanations for the generated recommendations. Comparisons with state-of-the-art matrix factorization based collaborative filtering, content based and social recommendations demonstrate the efficacy of the proposed approach.",
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "authors": [
                {
                    "authorId": "18989661",
                    "name": "P. Bhattacharya"
                },
                {
                    "authorId": "143841814",
                    "name": "Saptarshi Ghosh"
                },
                {
                    "authorId": "2625318",
                    "name": "M. B. Zafar"
                },
                {
                    "authorId": "2116088920",
                    "name": "Soumya K. Ghosh"
                },
                {
                    "authorId": "4213990",
                    "name": "Niloy Ganguly"
                }
            ]
        },
        {
            "paperId": "78ed7836493f3a1b487f4738587427093bb52a70",
            "title": "Analyzing Regrettable Communications on Twitter: Characterizing Deleted Tweets and Their Authors",
            "abstract": "Over 500 million tweets are posted in Twitter each day, out of which about 11% tweets are deleted by the users posting them. This phenomenon of widespread deletion of tweets leads to a number of questions: what kind of content posted by users makes them want to delete them later? %Are all users equally active in deleting their tweets or Are users of certain predispositions more likely to post regrettable tweets, deleting them later? In this paper we provide a detailed characterization of tweets posted and then later deleted by their authors. We collected tweets from over 200 thousand Twitter users during a period of four weeks. Our characterization shows significant personality differences between users who delete their tweets and those who do not. We find that users who delete their tweets are more likely to be extroverted and neurotic while being less conscientious. Also, we find that deleted tweets while containing less information and being less conversational, contain significant indications of regrettable content. Since users of online communication do not have instant social cues (like listener's body language) to gauge the impact of their words, they are often delayed in employing repair strategies. Finally, we build a classifier which takes textual, contextual, as well as user features to predict if a tweet will be deleted or not. The classifier achieves a F1-score of 0.78 and the precision increases when we consider response features of the tweets.",
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "authors": [
                {
                    "authorId": "18989661",
                    "name": "P. Bhattacharya"
                },
                {
                    "authorId": "143841814",
                    "name": "Saptarshi Ghosh"
                },
                {
                    "authorId": "4213990",
                    "name": "Niloy Ganguly"
                }
            ]
        },
        {
            "paperId": "7bb09bedd2d356667dc8aa286b62425c0246cd60",
            "title": "CAVES: A Dataset to facilitate Explainable Classification and Summarization of Concerns towards COVID Vaccines",
            "abstract": "Convincing people to get vaccinated against COVID-19 is a key societal challenge in the present times. As a first step towards this goal, many prior works have relied on social media analysis to understand the specific concerns that people have towards these vaccines, such as potential side-effects, ineffectiveness, political factors, and so on. Though there are datasets that broadly classify social media posts into Anti-vax and Pro-Vax labels, there is no dataset (to our knowledge) that labels social media posts according to the specific anti-vaccine concerns mentioned in the posts. In this paper, we have curated CAVES, the first large-scale dataset containing about 10k COVID-19 anti-vaccine tweets labelled into various specific anti-vaccine concerns in a multi-label setting. This is also the first multi-label classification dataset that provides explanations for each of the labels. Additionally, the dataset also provides class-wise summaries of all the tweets. We also perform preliminary experiments on the dataset and show that this is a very challenging dataset for multi-label explainable classification and tweet summarization, as is evident by the moderate scores achieved by some state-of-the-art models.",
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "authors": [
                {
                    "authorId": "1388367454",
                    "name": "Soham Poddar"
                },
                {
                    "authorId": "2163948982",
                    "name": "Azlaan Mustafa Samad"
                },
                {
                    "authorId": "2182282",
                    "name": "Rajdeep Mukherjee"
                },
                {
                    "authorId": "4213990",
                    "name": "Niloy Ganguly"
                },
                {
                    "authorId": "143841814",
                    "name": "Saptarshi Ghosh"
                }
            ]
        },
        {
            "paperId": "a84a96afbaf78d5a62706d67ebcbb83bb76db800",
            "title": "FaiRIR: Mitigating Exposure Bias From Related Item Recommendations in Two-Sided Platforms",
            "abstract": "Related item recommendations (RIRs) are ubiquitous in most online platforms today, including e-commerce and content streaming sites. These recommendations not only help users compare items related to a given item but also play a major role in bringing traffic to individual items, thus deciding the exposure that different items receive. With a growing number of people depending on such platforms to earn their livelihood, it is important to understand whether different items are receiving their desired exposure. To this end, our experiments on multiple real-world RIR datasets reveal that the existing RIR algorithms often result in very skewed exposure distribution of items, and the quality of items is not a plausible explanation for such skew in exposure. To mitigate this exposure bias, we introduce multiple flexible interventions [fair related item recommendation (FaiRIR)] in the RIR pipeline. We instantiate these mechanisms with two well-known algorithms for constructing RIRs\u2014rating singular value decomposition (SVD) and item2vec\u2014and show on real-world data that our mechanisms allow for a fine-grained control on exposure distribution, often at a small or no cost in terms of recommendation quality, measured in terms of relatedness and user satisfaction.",
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "authors": [
                {
                    "authorId": "7660878",
                    "name": "A. Dash"
                },
                {
                    "authorId": "2676839",
                    "name": "Abhijnan Chakraborty"
                },
                {
                    "authorId": "143841814",
                    "name": "Saptarshi Ghosh"
                },
                {
                    "authorId": "33392067",
                    "name": "Animesh Mukherjee"
                },
                {
                    "authorId": "1958921",
                    "name": "K. Gummadi"
                }
            ]
        },
        {
            "paperId": "b24e95e45f6717b2ef5a79f52c0ae7d753c20083",
            "title": "Alexa, in you, I trust! Fairness and Interpretability Issues in E-commerce Search through Smart Speakers",
            "abstract": "In traditional (desktop) e-commerce search, a customer issues a specific query and the system returns a ranked list of products in order of relevance to the query. An increasingly popular alternative in e-commerce search is to issue a voice-query to a smart speaker (e.g., Amazon Echo) powered by a voice assistant (VA, e.g., Alexa). In this situation, the VA usually spells out the details of only one product, an explanation citing the reason for its selection, and a default action of adding the product to the customer\u2019s cart. This reduced autonomy of the customer in the choice of a product during voice-search makes it necessary for a VA to be far more responsible and trustworthy in its explanation and default action. In this paper, we ask whether the explanation presented for a product selection by the Alexa VA installed on an Amazon Echo device is consistent with human understanding as well as with the observations on other traditional mediums (e.g., desktop e-commerce search). Through a user survey, we find that in 81% cases the interpretation of \u2018a top result\u2019 by the users is different from that of Alexa. While investigating for the fairness of the default action, we observe that over a set of as many as 1000 queries, in \u2248 68% cases, there exist one or more products which are more relevant (as per Amazon\u2019s own desktop search results) than the product chosen by Alexa. Finally, we conducted a survey over 30 queries for which the Alexa-selected product was different from the top desktop search result, and observed that in \u2248 73% cases, the participants preferred the top desktop search result as opposed to the product chosen by Alexa. Our results raise several concerns and necessitates more discussions around the related fairness and interpretability issues of VAs for e-commerce search.",
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "authors": [
                {
                    "authorId": "7660878",
                    "name": "A. Dash"
                },
                {
                    "authorId": "2676839",
                    "name": "Abhijnan Chakraborty"
                },
                {
                    "authorId": "143841814",
                    "name": "Saptarshi Ghosh"
                },
                {
                    "authorId": "33392067",
                    "name": "Animesh Mukherjee"
                },
                {
                    "authorId": "1958921",
                    "name": "K. Gummadi"
                }
            ]
        },
        {
            "paperId": "0c42c65214828e8e1de45803e13fef2a7a87455c",
            "title": "An Unsupervised Normalization Algorithm for Noisy Text: A Case Study for Information Retrieval and Stance Detection",
            "abstract": "A large fraction of textual data available today contains various types of \u201cnoise,\u201d such as OCR noise in digitized documents, noise due to informal writing style of users on microblogging sites, and so on. To enable tasks such as search/retrieval and classification over all the available data, we need robust algorithms for text normalization, i.e., for cleaning different kinds of noise in the text. There have been several efforts towards cleaning or normalizing noisy text; however, many of the existing text normalization methods are supervised and require language-dependent resources or large amounts of training data that is difficult to obtain. We propose an unsupervised algorithm for text normalization that does not need any training data/human intervention. The proposed algorithm is applicable to text over different languages and can handle both machine-generated and human-generated noise. Experiments over several standard datasets show that text normalization through the proposed algorithm enables better retrieval and stance detection, as compared to that using several baseline text normalization methods.",
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "authors": [
                {
                    "authorId": "2154709339",
                    "name": "Anurag Roy"
                },
                {
                    "authorId": "66355017",
                    "name": "Shalmoli Ghosh"
                },
                {
                    "authorId": "153408379",
                    "name": "Kripabandhu Ghosh"
                },
                {
                    "authorId": "143841814",
                    "name": "Saptarshi Ghosh"
                }
            ]
        },
        {
            "paperId": "337d65da2f60175e81a7d5d0541f35270d126a3a",
            "title": "Dissemination Biases of Social Media Channels: On the Topical Coverage of Socially Shared News",
            "abstract": "\n \n In a marked departure from traditional offline media, where all subscribers of a particular news media source (e.g., New York Times) used to get the same news stories through printed newspapers, online news media presents multiple options for the readers to consume news. For example, the subscribers of a media source can get news directly from the news website, or from what their peers share over social media sites like Facebook and Twitter. It is, however, unclear whether there are any differences in the news disseminated on these different online channels. In this work, we analyze data from a popular online news media site (nytimes.com), and show that each of these different channels tends to highlight some types of stories more than other stories. We believe that consumers of online news as well as media organizations need to be aware of such differences in various online news dissemination channels.\n \n",
            "fieldsOfStudy": [
                "Computer Science",
                "Sociology"
            ],
            "authors": [
                {
                    "authorId": "2676839",
                    "name": "Abhijnan Chakraborty"
                },
                {
                    "authorId": "143841814",
                    "name": "Saptarshi Ghosh"
                },
                {
                    "authorId": "4213990",
                    "name": "Niloy Ganguly"
                },
                {
                    "authorId": "1958921",
                    "name": "K. Gummadi"
                }
            ]
        }
    ]
}