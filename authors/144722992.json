{
    "authorId": "144722992",
    "papers": [
        {
            "paperId": "e8776fd7ed1d5c26de6df9e6d33213ffa2d24328",
            "title": "Sketch-Flip-Merge: Mergeable Sketches for Private Distinct Counting",
            "abstract": "Data sketching is a critical tool for distinct counting, enabling multisets to be represented by compact summaries that admit fast cardinality estimates. Because sketches may be merged to summarize multiset unions, they are a basic building block in data warehouses. Although many practical sketches for cardinality estimation exist, none provide privacy when merging. We propose the first practical cardinality sketches that are simultaneously mergeable, differentially private (DP), and have low empirical errors. These introduce a novel randomized algorithm for performing logical operations on noisy bits, a tight privacy analysis, and provably optimal estimation. Our sketches dramatically outperform existing theoretical solutions in simulations and on real-world data.",
            "fieldsOfStudy": [
                "Computer Science",
                "Mathematics"
            ],
            "authors": [
                {
                    "authorId": "48506830",
                    "name": "J. Hehir"
                },
                {
                    "authorId": "144722992",
                    "name": "Daniel Ting"
                },
                {
                    "authorId": "1709589",
                    "name": "Graham Cormode"
                }
            ]
        },
        {
            "paperId": "181b954bf2d4cc327ddfd1c356aa427822bcf388",
            "title": "Order-Invariant Cardinality Estimators Are Differentially Private",
            "abstract": "We consider privacy in the context of streaming algorithms for cardinality estimation. We show that a large class of algorithms all satisfy $\\epsilon$-differential privacy, so long as (a) the algorithm is combined with a simple down-sampling procedure, and (b) the cardinality of the input stream is $\\Omega(k/\\epsilon)$. Here, $k$ is a certain parameter of the sketch that is always at most the sketch size in bits, but is typically much smaller. We also show that, even with no modification, algorithms in our class satisfy $(\\epsilon, \\delta)$-differential privacy, where $\\delta$ falls exponentially with the stream cardinality. Our analysis applies to essentially all popular cardinality estimation algorithms, and substantially generalizes and tightens privacy bounds from earlier works.",
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "authors": [
                {
                    "authorId": "51118486",
                    "name": "Charles Dickens"
                },
                {
                    "authorId": "32523323",
                    "name": "J. Thaler"
                },
                {
                    "authorId": "144722992",
                    "name": "Daniel Ting"
                }
            ]
        },
        {
            "paperId": "374d93bea92cbaddcdd9f83b956fe86bcf4e254f",
            "title": "Statistical Schema Learning with Occam's Razor",
            "abstract": "A judiciously normalized database schema can increase data interpretability, reduce data size, and improve data integrity. However, real world data sets are often stored or shared in a denormalized state. We examine the problem of automatically creating a good schema for a denormalized table, approaching it as an unsupervised machine learning problem which must learn an optimal schema from the data. This differs from past rule-based approaches that focus on normalization into a canonical form. We define a principled schema optimization criterion, based on Occam's razor, that is robust to noise and extensible---allowing users to easily specify desirable properties of the resulting schema. We develop an efficient learning algorithm for this criterion and empirically demonstrate that it is 3 to 100 times faster than previous work and produces higher quality schemas with 1/5th the errors.",
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "authors": [
                {
                    "authorId": "2519617",
                    "name": "Justin Talbot"
                },
                {
                    "authorId": "144722992",
                    "name": "Daniel Ting"
                }
            ]
        },
        {
            "paperId": "44e12d09bb57e552d13eab90cc754988fe0cab3e",
            "title": "(Nearly) All Cardinality Estimators Are Differentially Private",
            "abstract": "We consider privacy in the context of streaming algorithms for cardinality estimation. We show that a large class of algorithms all satisfy \u01eb -di\ufb00erential privacy, so long as (a) the algorithm is combined with a simple down-sampling procedure, and (b) the cardinality of the input stream is \u2126( k/\u01eb ). Here, k is a certain parameter of the sketch that is always at most the sketch size in bits, but is typically much smaller. We also show that, even with no modi\ufb01cation, algorithms in our class satisfy ( \u01eb, \u03b4 )-di\ufb00erential privacy, where \u03b4 falls exponentially with the stream cardinality. Our analysis applies to essentially all popular cardinality estimation algorithms, and substantially generalizes and tightens privacy bounds from earlier works.",
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "authors": [
                {
                    "authorId": null,
                    "name": "Charlie Dickens"
                },
                {
                    "authorId": "32523323",
                    "name": "J. Thaler"
                },
                {
                    "authorId": "144722992",
                    "name": "Daniel Ting"
                }
            ]
        },
        {
            "paperId": "80c99d924a4d8bd4850309cf04dbbd87a9f8368c",
            "title": "More Accurate Streaming Cardinality Estimation With Vectorized Counters",
            "abstract": "Cardinality estimation, also known as count-distinct, is the problem of finding the number of different elements in a set with repeated elements. Among the many approximate algorithms proposed for this task, HyperLogLog (HLL) has established itself as the state of the art due to its ability to accurately estimate cardinality over a large range of values using a small memory footprint. When elements arrive in a stream, as in the case of most networking applications, improved techniques are possible. We specifically propose a new algorithm that improves the accuracy of cardinality estimation by grouping counters, and by using their new organization to further track all updates within a given counter size range (compared with just the last update as in the standard HLL). Results show that when using the same number of counters, one configuration of the new scheme reduces the relative error by approximately 0.86x using the same amount of memory as the streaming HLL and another configuration achieves a similar accuracy reducing the memory needed by approximately 0.85x.",
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "authors": [
                {
                    "authorId": "23126486",
                    "name": "V. Bruschi"
                },
                {
                    "authorId": "3228297",
                    "name": "P. Reviriego"
                },
                {
                    "authorId": "1697246",
                    "name": "S. Pontarelli"
                },
                {
                    "authorId": "144722992",
                    "name": "Daniel Ting"
                },
                {
                    "authorId": "2057681981",
                    "name": "Giuseppe Bianchi"
                }
            ]
        },
        {
            "paperId": "d056edc75cfe3657932a02f28f14d964fefbfcfa",
            "title": "Simple, Optimal Algorithms for Random Sampling Without Replacement",
            "abstract": "Consider the fundamental problem of drawing a simple random sample of size k without replacement from [n] := {1, . . . , n}. Although a number of classical algorithms exist for this problem, we construct algorithms that are even simpler, easier to implement, and have optimal space and time complexity.",
            "fieldsOfStudy": [
                "Computer Science",
                "Mathematics"
            ],
            "authors": [
                {
                    "authorId": "144722992",
                    "name": "Daniel Ting"
                }
            ]
        },
        {
            "paperId": "31250c1410387b8a92d082b2e84fa4ac4c98db76",
            "title": "Manifold Learning via Manifold Deflation",
            "abstract": "Nonlinear dimensionality reduction methods provide a valuable means to visualize and interpret high-dimensional data. However, many popular methods can fail dramatically, even on simple two-dimensional manifolds, due to problems such as vulnerability to noise, repeated eigendirections, holes in convex bodies, and boundary bias. We derive an embedding method for Riemannian manifolds that iteratively uses single-coordinate estimates to eliminate dimensions from an underlying differential operator, thus \"deflating\" it. These differential operators have been shown to characterize any local, spectral dimensionality reduction method. The key to our method is a novel, incremental tangent space estimator that incorporates global structure as coordinates are added. We prove its consistency when the coordinates converge to true coordinates. Empirically, we show our algorithm recovers novel and interesting embeddings on real-world and synthetic datasets.",
            "fieldsOfStudy": [
                "Computer Science",
                "Mathematics"
            ],
            "authors": [
                {
                    "authorId": "144722992",
                    "name": "Daniel Ting"
                },
                {
                    "authorId": "1694621",
                    "name": "Michael I. Jordan"
                }
            ]
        },
        {
            "paperId": "4d05e1ad2bbb6ebe551712ac00867bccb0943c68",
            "title": "Data Sketching for Real Time Analytics: Theory and Practice",
            "abstract": "Speed, cost, and scale. These are 3 of the biggest challenges in analyzing big data. While modern data systems continue to push the boundaries of scale, the problems of speed and cost are fundamentally tied to the size of data being scanned or processed. Processing thousands of queries that each access terabytes of data with sub-second latency remains infeasible. Data sketching techniques provide means to drastically reduce this size, allowing for real-time or interactive data analysis with reduced costs but with approximate answers. This tutorial covers a number of useful data sketching and sampling methods and demonstrate their use using the Apache DataSketches project. We focus particularly on common problems in analytic problems such as counting distinct items, quantiles, histograms, heavy hitters, and aggregations with large group bys. For these, we covers algorithms, techniques, and theory that can aid both practitioners and theorists in constructing sketches and designing systems that achieve desired error guarantees. For practitioners and implementers, we show how some of these sketches can be easily instantiated using the Apache Datasketches project.",
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "authors": [
                {
                    "authorId": "144722992",
                    "name": "Daniel Ting"
                },
                {
                    "authorId": "2070218397",
                    "name": "J. Malkin"
                },
                {
                    "authorId": "39384151",
                    "name": "Lee Rhodes"
                }
            ]
        },
        {
            "paperId": "9e2f0e874f42d54ab5b15dc9d4789e8a725cd4f7",
            "title": "Conditional Cuckoo Filters",
            "abstract": "Bloom filters, cuckoo filters, and other approximate set membership sketches have a wide range of applications. Oftentimes, expensive operations can be skipped if an item is not in a data set. These filters provide an inexpensive, memory efficient way to test if an item is in a set and avoid unnecessary operations. Existing sketches only allow membership testing for a single set. However, in some applications such as join processing, the relevant set is not fixed and is determined by a set of predicates. We propose the Conditional Cuckoo Filter, a simple modification of the cuckoo filter that allows for set membership testing given predicates on a pre-computed sketch. This filter also introduces a novel chaining technique that enables cuckoo filters to handle insertion of duplicate keys. We evaluate our methods on a join processing application and show that they significantly reduce the number of tuples that a join must process.",
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "authors": [
                {
                    "authorId": "144722992",
                    "name": "Daniel Ting"
                },
                {
                    "authorId": "2052400370",
                    "name": "Rick Cole"
                }
            ]
        },
        {
            "paperId": "c9ec28feeb755c342079904ae900f93487969bbf",
            "title": "HyperLogLog (HLL) Security: Inflating Cardinality Estimates",
            "abstract": "Counting the number of distinct elements on a set is needed in many applications, for example to track the number of unique users in Internet services or the number of distinct flows on a network. In many cases, an estimate rather than the exact value is sufficient and thus many algorithms for cardinality estimation that significantly reduce the memory and computation requirements have been proposed. Among them, Hyperloglog has been widely adopted in both software and hardware implementations. The security of Hyperloglog has been recently studied showing that an attacker can create a set of elements that produces a cardinality estimate that is much smaller than the real cardinality of the set. This set can be used for example to evade detection systems that use Hyperloglog. In this paper, the security of Hyperloglog is considered from the opposite angle: the attacker wants to create a small set that when inserted on the Hyperloglog produces a large cardinality estimate. This set can be used to trigger false alarms in detection systems that use Hyperloglog but more interestingly, it can be potentially used to inflate the visits to websites or the number of hits of online advertisements. Our analysis shows that an attacker can create a set with a number of elements equal to the number of registers used in the Hyperloglog implementation that produces any arbitrary cardinality estimate. This has been validated in two commercial implementations of Hyperloglog: Presto and Redis. Based on those results, we also consider the protection of Hyperloglog against such an attack.",
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "authors": [
                {
                    "authorId": "3228297",
                    "name": "P. Reviriego"
                },
                {
                    "authorId": "2027607842",
                    "name": "Pablo Adell"
                },
                {
                    "authorId": "144722992",
                    "name": "Daniel Ting"
                }
            ]
        }
    ]
}