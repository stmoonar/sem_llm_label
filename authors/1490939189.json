{
    "authorId": "1490939189",
    "papers": [
        {
            "paperId": "11550fac7a49aa663bc19d45be59e7ac0cddb43a",
            "title": "Modality Coupling for Privacy Image Classification",
            "abstract": "Privacy image classification (PIC) has attracted increasing attention as it can help people make appropriate privacy decisions when sharing images. Most recently, some pioneer research efforts have been made to utilize multimodal information for PIC, since multi-modality can provide richer information than single modality. Those research efforts on multimodal PIC are under the assumption of independently identically distribution. However, connections between different modalities commonly exist in real-world cases. Taking the modalities of scene and object as example, in the scene of \u2018library/indoor\u2019, the object \u2018book jacket\u2019 resides with high probabilities. To this end, in this paper, a novel PIC approach, called CoupledPIC, is proposed to bridge this gap by comprehensively capturing the coupling relations between different modalities. In CoupledPIC, two submodules are designed to capture explicit and implicit coupling relations between different modalities respectively. The explicit modality coupling is learned with a tensor fusion networks based submodule, via the direct interaction of features. For the implicit modality coupling, a graph convolutional networks based submodule is proposed to learn on both the initial graphs and attention guided graphs, via information aggregation on graphs. Extensive experiments on the public benchmark, PicAlert, demonstrate the effectiveness of the proposed CoupledPIC, yielding significant improvement by modeling inter-modality coupling information.",
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "authors": [
                {
                    "authorId": "2227971752",
                    "name": "Yucheng Liu"
                },
                {
                    "authorId": "2162698867",
                    "name": "Yonggang Huang"
                },
                {
                    "authorId": "1490939189",
                    "name": "Shoujin Wang"
                },
                {
                    "authorId": "2918103",
                    "name": "Wenpeng Lu"
                },
                {
                    "authorId": "2119106852",
                    "name": "Huiyan Wu"
                }
            ]
        },
        {
            "paperId": "9ded2e4b08a95e6f023c9c45df48a9ceb0afe56f",
            "title": "Causal Intervention for Abstractive Related Work Generation",
            "abstract": "Abstractive related work generation has attracted increasing attention in generating coherent related work that better helps readers grasp the background in the current research. However, most existing abstractive models ignore the inherent causality of related work generation, leading to low quality of generated related work and spurious correlations that affect the models' generalizability. In this study, we argue that causal intervention can address these limitations and improve the quality and coherence of the generated related works. To this end, we propose a novel Causal Intervention Module for Related Work Generation (CaM) to effectively capture causalities in the generation process and improve the quality and coherence of the generated related works. Specifically, we first model the relations among sentence order, document relation, and transitional content in related work generation using a causal graph. Then, to implement the causal intervention and mitigate the negative impact of spurious correlations, we use do-calculus to derive ordinary conditional probabilities and identify causal effects through CaM. Finally, we subtly fuse CaM with Transformer to obtain an end-to-end generation model. Extensive experiments on two real-world datasets show that causal interventions in CaM can effectively promote the model to learn causal relations and produce related work of higher quality and coherence.",
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "authors": [
                {
                    "authorId": "2319414948",
                    "name": "Jiachang Liu"
                },
                {
                    "authorId": "2145908596",
                    "name": "Qi Zhang"
                },
                {
                    "authorId": "152856111",
                    "name": "Chongyang Shi"
                },
                {
                    "authorId": "1394609613",
                    "name": "Usman Naseem"
                },
                {
                    "authorId": "1490939189",
                    "name": "Shoujin Wang"
                },
                {
                    "authorId": "1807998",
                    "name": "I. Tsang"
                }
            ]
        },
        {
            "paperId": "aa7295ecffb25c6f78fea793acfd24a3e8f7ddc0",
            "title": "Rumor Detection with Hierarchical Representation on Bipartite Adhoc Event Trees",
            "abstract": "The rapid growth of social media has caused tremendous effects on information propagation, raising extreme challenges in detecting rumors. Existing rumor detection methods typically exploit the reposting propagation of a rumor candidate for detection by regarding all reposts to a rumor candidate as a temporal sequence and learning semantics representations of the repost sequence. However, extracting informative support from the topological structure of propagation and the influence of reposting authors for debunking rumors is crucial, which generally has not been well addressed by existing methods. In this article, we organize a claim post in circulation as an ad hoc event tree, extract event elements, and convert it into bipartite ad hoc event trees in terms of both posts and authors, i.e., author tree and post tree. Accordingly, we propose a novel rumor detection model with hierarchical representation on the bipartite ad hoc event trees called BAET. Specifically, we introduce word embedding and feature encoder for the author and post tree, respectively, and design a root-aware attention module to perform node representation. Then we adopt the tree-like RNN model to capture the structural correlations and propose a tree-aware attention module to learn tree representation for the author tree and post tree, respectively. Extensive experimental results on two public Twitter datasets demonstrate the effectiveness of BAET in exploring and exploiting the rumor propagation structure and the superior detection performance of BAET over state-of-the-art baseline methods.",
            "fieldsOfStudy": [
                "Computer Science",
                "Medicine"
            ],
            "authors": [
                {
                    "authorId": "2145908596",
                    "name": "Qi Zhang"
                },
                {
                    "authorId": "2124143325",
                    "name": "Yayi Yang"
                },
                {
                    "authorId": "152856111",
                    "name": "Chongyang Shi"
                },
                {
                    "authorId": "50733091",
                    "name": "Angelyn R. Lao"
                },
                {
                    "authorId": "2118850040",
                    "name": "Liang Hu"
                },
                {
                    "authorId": "1490939189",
                    "name": "Shoujin Wang"
                },
                {
                    "authorId": "1394609613",
                    "name": "Usman Naseem"
                }
            ]
        },
        {
            "paperId": "cf1e1f9b57c3f5340806265aa58deeb4407945fc",
            "title": "Efficient Interactive Recommendation via Huffman Tree-based Policy Learning",
            "abstract": "Interactive recommender systems (IRSs) are an essential part of our daily life, as they can suggest items to persistently satisfy our demands. Due to the interactive nature, conventional static recommendation methods such as matrix factorization, and content-based filtering are ineffective to capture the dynamic preferences of users. Recently, reinforcement learning (RL) has shown great potential in addressing the challenges in IRSs, since it can capture users\u2019 dynamic preferences and model the long-term profit of user-item interactions. However, millions of items in real-world IRSs lead to a large discrete action space in the RL setting, rendering RL-based IRSs inefficient and hindering their widespread application. Such an inefficiency issue has not been well addressed in the literature. In order to address this issue, we propose a novel Huffman Tree Policy Recommendation (HTPR) framework. Specifically, a novel policy learning network based on a newly designed Huffman tree is proposed for policy representation learning, which effectively improves the learning efficiency. Moreover, a novel parameter-sharing scheme is devised to further reduce unnecessary computations. Extensive experiments on two real-world benchmark datasets demonstrate the superiority of HTPR over the state-of-the-art IRS methods in terms of both recommendation accuracy and efficiency.",
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "authors": [
                {
                    "authorId": "9645178",
                    "name": "Longxiang Shi"
                },
                {
                    "authorId": "47294308",
                    "name": "Zilin Zhang"
                },
                {
                    "authorId": "1490939189",
                    "name": "Shoujin Wang"
                },
                {
                    "authorId": "2171843985",
                    "name": "Binbin Zhou"
                },
                {
                    "authorId": "49227857",
                    "name": "Ming-hui Wu"
                },
                {
                    "authorId": "3443627",
                    "name": "Cheng Yang"
                },
                {
                    "authorId": "66841497",
                    "name": "Shijian Li"
                }
            ]
        },
        {
            "paperId": "d9feb917c57a8aa6575db9a1b357e940162a5306",
            "title": "Medical Question Summarization with Entity-driven Contrastive Learning",
            "abstract": "By summarizing longer consumer health questions into shorter and essential ones, medical question-answering systems can more accurately understand consumer intentions and retrieve suitable answers. However, medical question summarization is very challenging due to obvious distinctions in health trouble descriptions from patients and doctors. Although deep learning has been applied to successfully address the medical question summarization (MQS) task, two challenges remain: how to correctly capture question focus to model its semantic intention, and how to obtain reliable datasets to fairly evaluate performance. To address these challenges, this article proposes a novel medical question summarization framework based on entity-driven contrastive learning (ECL). ECL employs medical entities present in frequently asked questions (FAQs) as focuses and devises an effective mechanism to generate hard negative samples. This approach compels models to focus on essential information and consequently generate more accurate question summaries. Furthermore, we have discovered that some MQS datasets, such as the iCliniq dataset with a 33% duplicate rate, have significant data leakage issues. To ensure an impartial evaluation of the related methods, this article carefully examines leaked samples to reorganize more reasonable datasets. Extensive experiments demonstrate that our ECL method outperforms the existing methods and achieves new state-of-the-art performance, i.e., 52.85, 43.16, 41.31, 43.52 in terms of ROUGE-1 metric on MeQSum, CHQ-Summ, iCliniq, HealthCareMagic dataset, respectively. The code and datasets are available at https://github.com/yrbobo/MQS-ECL",
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "authors": [
                {
                    "authorId": "2214579128",
                    "name": "Sibo Wei"
                },
                {
                    "authorId": "2918103",
                    "name": "Wenpeng Lu"
                },
                {
                    "authorId": "1384583219",
                    "name": "Xueping Peng"
                },
                {
                    "authorId": "1490939189",
                    "name": "Shoujin Wang"
                },
                {
                    "authorId": "2214603825",
                    "name": "Yi-Fei Wang"
                },
                {
                    "authorId": "2107988937",
                    "name": "Weiyu Zhang"
                }
            ]
        },
        {
            "paperId": "114a816dcd716c1069f0936b66784ec8c40cedf2",
            "title": "Beyond CNNs: Exploiting Further Inherent Symmetries in Medical Image Segmentation",
            "abstract": "Automatic tumor or lesion segmentation is a crucial step in medical image analysis for computer-aided diagnosis. Although the existing methods based on convolutional neural networks (CNNs) have achieved the state-of-the-art performance, many challenges still remain in medical tumor segmentation. This is because, although the human visual system can detect symmetries in 2-D images effectively, regular CNNs can only exploit translation invariance, overlooking further inherent symmetries existing in medical images, such as rotations and reflections. To solve this problem, we propose a novel group equivariant segmentation framework by encoding those inherent symmetries for learning more precise representations. First, kernel-based equivariant operations are devised on each orientation, which allows it to effectively address the gaps of learning symmetries in existing approaches. Then, to keep segmentation networks globally equivariant, we design distinctive group layers with layer-wise symmetry constraints. Finally, based on our novel framework, extensive experiments conducted on real-world clinical data demonstrate that a group equivariant Res-UNet (called GER-UNet) outperforms its regular CNN-based counterpart and the state-of-the-art segmentation methods in the tasks of hepatic tumor segmentation, COVID-19 lung infection segmentation, and retinal vessel detection. More importantly, the newly built GER-UNet also shows potential in reducing the sample complexity and the redundancy of filters, upgrading current segmentation CNNs, and delineating organs on other medical imaging modalities.",
            "fieldsOfStudy": [
                "Engineering",
                "Computer Science",
                "Medicine"
            ],
            "authors": [
                {
                    "authorId": "46539006",
                    "name": "Shuchao Pang"
                },
                {
                    "authorId": "40147943",
                    "name": "Anan Du"
                },
                {
                    "authorId": "145572420",
                    "name": "M. Orgun"
                },
                {
                    "authorId": "2152541925",
                    "name": "Yan Wang"
                },
                {
                    "authorId": "1713128",
                    "name": "Quan Z. Sheng"
                },
                {
                    "authorId": "1490939189",
                    "name": "Shoujin Wang"
                },
                {
                    "authorId": "1809350",
                    "name": "Xiaoshui Huang"
                },
                {
                    "authorId": "2158009542",
                    "name": "Zhewen Yu"
                }
            ]
        },
        {
            "paperId": "47372d1de03018e09caad51efe9887aa5386ce3b",
            "title": "Vehicle Check-In Data-driven POI Recommendation Based on Improved SVD and Graph Convolutional Network",
            "abstract": "The application of automobile tool software is becoming increasingly widespread, and its functions are becoming increasingly diverse. Using vehicle traffic data to give users with recommendations for Points-of-interest (POI) is becoming an intriguing research challenge. However, the current POI recommendation is either a sequence-based method, ignoring the interaction information between users and POIs. Or it needs a lot of model training time to use graph correlation method to mine the interaction between users or vehicles and POIs. In order to address these issues, we propose a method for vehicle check-in data-driven POI recommendation based on improved Singular Value Decomposition (SVD) and Graph Convolutional Network (GCN). First, we apply SVD to replace the neighborhood aggregation update method in traditional GCN, update the node embedding with fewer parameters and faster speed. Second, we propose an information enhancement strategy to make up for the information loss caused by the SVD. Experiments on large vehicle check-in datasets demonstrate that our method is both faster and more effective when making POI recommendations.",
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "authors": [
                {
                    "authorId": "2053961889",
                    "name": "Yuwen Liu"
                },
                {
                    "authorId": "2155862502",
                    "name": "Jie Zhang"
                },
                {
                    "authorId": "51902534",
                    "name": "Ruihan Dou"
                },
                {
                    "authorId": "2143744718",
                    "name": "Xiaokang Zhou"
                },
                {
                    "authorId": "145921385",
                    "name": "Xiaolong Xu"
                },
                {
                    "authorId": "1490939189",
                    "name": "Shoujin Wang"
                },
                {
                    "authorId": "2166818520",
                    "name": "Lianyong Qi"
                }
            ]
        },
        {
            "paperId": "a476002d375d56c8e4f067a19e94594b41bcb9a1",
            "title": "Chinese Sentence Matching with Multiple Alignments and Feature Augmentation",
            "abstract": "Chinese sentence matching is a critical and yet challenging task in natural language processing. Recent work on modeling sentence semantic relations with deep neural models has shown its great potential in improving the performance of sentence matching. However, existing sentence matching methods usually focus on generating word-level sentence representation, which neglects the character-level information and leads to weak semantic representations. Also, they usually capture the interactive features with an attention-based alignment, which are typically implemented on sentence level and neglect the interactions among characters, words and sentences. This paper proposes a novel Chinese sentence matching model with Multiple Alignments and Feature Augmentation (MAFA). Specifically, the model first employs the multi-level embedding layer to accept the character and word sequences of sentences, and introduces the multiple alignment layer to capture the interactions among characters, words and sentences in turn. Then, the feature augmentation layer is applied to combine the interactive features to generate the final semantic matching representations. Finally, the prediction layer is utilized to judge the matching degree of the input sentences. Substantial and extensive experiments are conducted on two real-world data sets to show that MAFA significantly outperforms the competing methods and achieve comnarable nerformance with BERT-based methods.",
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "authors": [
                {
                    "authorId": "2186558811",
                    "name": "Youhui Zuo"
                },
                {
                    "authorId": "1384583219",
                    "name": "Xueping Peng"
                },
                {
                    "authorId": "2918103",
                    "name": "Wenpeng Lu"
                },
                {
                    "authorId": "1490939189",
                    "name": "Shoujin Wang"
                },
                {
                    "authorId": null,
                    "name": "Zhao Li"
                },
                {
                    "authorId": "2107988937",
                    "name": "Weiyu Zhang"
                },
                {
                    "authorId": "2186555916",
                    "name": "Yi Zhai"
                }
            ]
        },
        {
            "paperId": "b265ab6af7570f856f2f4167a502f7c436692c6b",
            "title": "Word Sense Disambiguation with Knowledge-Enhanced and Local Self-Attention-based Extractive Sense Comprehension",
            "abstract": "Word sense disambiguation (WSD), identifying the most suitable meaning of ambiguous words in the given contexts according to a predefined sense inventory, is one of the most classical and challenging tasks in natural language processing. Benefiting from the powerful ability of deep neural networks, WSD has achieved a great advancement in recent years. Reformulating WSD as a text span extraction task is an effective approach, which accepts a sentence context of an ambiguous word together with all definitions of its candidate senses simultaneously, and requires to extract the text span corresponding with the right sense. However, the approach merely depends on a short definition to learn sense representation, which neglects abundant semantic knowledge from related senses and leads to data-inefficient learning and suboptimal WSD performance. To address the limitations, we propose a novel WSD method with Knowledge-Enhanced and Local Self-Attention-based Extractive Sense Comprehension (KELESC). Specifically, a knowledge-enhanced method is proposed to enrich semantic representation by incorporating additional examples and definitions of the related senses in WordNet. Then, in order to avoid the huge computing complexity induced by the additional information, a local self-attention mechanism is utilized to constrain attention to be local, which allows longer input texts without large-scale computing burdens. Extensive experimental results demonstrate that KELESC achieves better performance than baseline models on public benchmark datasets.",
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "authors": [
                {
                    "authorId": "2027669124",
                    "name": "Guobiao Zhang"
                },
                {
                    "authorId": "2918103",
                    "name": "Wenpeng Lu"
                },
                {
                    "authorId": "1384583219",
                    "name": "Xueping Peng"
                },
                {
                    "authorId": "1490939189",
                    "name": "Shoujin Wang"
                },
                {
                    "authorId": "2143177390",
                    "name": "Baoshuo Kan"
                },
                {
                    "authorId": "2088580920",
                    "name": "Rui Yu"
                }
            ]
        },
        {
            "paperId": "14ad72eac20222b812e6ab8c08068901b3dca2e5",
            "title": "Concept Representation by Learning Explicit and Implicit Concept Couplings",
            "abstract": "Generating the precise semantic representation of a word or concept is a fundamental task in natural language processing. Recent studies which incorporate semantic knowledge into word embedding have shown their potential in improving the semantic representation of a concept. However, existing approaches only achieved limited performance improvement as they usually 1) model a word\u2019s semantics from some explicit aspects while ignoring the intrinsic aspects of the word, 2) treat semantic knowledge as a supplement of word embeddings, and 3) consider partial relations between concepts while ignoring rich coupling relations between them, such as explicit concept co-occurrences in descriptive texts in a corpus as well as concept hyperlink relations in a knowledge network, and implicit couplings between concept co-occurrences and hyperlinks. In human consciousness, a concept is always associated with various couplings that exist within/between descriptive texts and knowledge networks, which inspires us to capture as many concept couplings as possible for building a more informative concept representation. We thus propose a neural coupled concept representation (CoupledCR) framework and its instantiation: a coupled concept embedding (CCE) model. CCE first learns two types of explicit couplings that are based on concept co-occurrences and hyperlink relations, respectively, and then learns a type of high-level implicit couplings between these two types of explicit couplings for better concept representation. Extensive experimental results on six real-world datasets show that CCE significantly outperforms eight state-of-the-art word embeddings and semantic representation methods.",
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "authors": [
                {
                    "authorId": "2918103",
                    "name": "Wenpeng Lu"
                },
                {
                    "authorId": "13584916",
                    "name": "Yuteng Zhang"
                },
                {
                    "authorId": "1490939189",
                    "name": "Shoujin Wang"
                },
                {
                    "authorId": "4590286",
                    "name": "Heyan Huang"
                },
                {
                    "authorId": "50384137",
                    "name": "Qian Liu"
                },
                {
                    "authorId": "2114030328",
                    "name": "Sheng Luo"
                }
            ]
        }
    ]
}