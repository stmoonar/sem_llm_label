{
    "authorId": "145837716",
    "papers": [
        {
            "paperId": "bffcdc014202875e5915a13f253283ad40f9fc3c",
            "title": "Extracting Top- Frequent and Diversified Patterns in Knowledge Graphs<inline-formula><tex-math notation=\"LaTeX\"/><alternatives><mml:math><mml:mi/></mml:math><inline-graphic xlink:href=\"zeng-ieq1-3233594.gif\"/></alternatives></inline-formula>",
            "abstract": "A knowledge graph contains many real-world facts that can be used to support various analytical tasks, e.g., exceptional fact discovery and the check of claims. In this work, we attempt to extract top-<inline-formula><tex-math notation=\"LaTeX\">$k$</tex-math><alternatives><mml:math><mml:mi>k</mml:mi></mml:math><inline-graphic xlink:href=\"zeng-ieq3-3233594.gif\"/></alternatives></inline-formula> frequent and diversified patterns from knowledge graph by well capturing user interest. Specifically, we first formalize the core-based top-<inline-formula><tex-math notation=\"LaTeX\">$k$</tex-math><alternatives><mml:math><mml:mi>k</mml:mi></mml:math><inline-graphic xlink:href=\"zeng-ieq4-3233594.gif\"/></alternatives></inline-formula> frequent pattern discovery problem, which finds the top-<inline-formula><tex-math notation=\"LaTeX\">$k$</tex-math><alternatives><mml:math><mml:mi>k</mml:mi></mml:math><inline-graphic xlink:href=\"zeng-ieq5-3233594.gif\"/></alternatives></inline-formula> frequent patterns that are extended from a core pattern specified by user query and have the highest frequency. In addition, to diversify the top-<inline-formula><tex-math notation=\"LaTeX\">$k$</tex-math><alternatives><mml:math><mml:mi>k</mml:mi></mml:math><inline-graphic xlink:href=\"zeng-ieq6-3233594.gif\"/></alternatives></inline-formula> frequent patterns, we define a distance function to measure the dissimilarity between two patterns, and return top-<inline-formula><tex-math notation=\"LaTeX\">$k$</tex-math><alternatives><mml:math><mml:mi>k</mml:mi></mml:math><inline-graphic xlink:href=\"zeng-ieq7-3233594.gif\"/></alternatives></inline-formula> patterns in which the pairwise diversity of any two resultant patterns exceeds a given threshold. As the search space of candidate patterns is exponential w.r.t. the number of nodes and edges in the knowledge graph, discovering frequent and diversified patterns is computationally challenging. To achieve high efficiency, we propose a suite of techniques, including (1) We devise a meta-index to avoid generating invalid candidate patterns; (2) We propose an upper bound of the frequency score (i.e., <inline-formula><tex-math notation=\"LaTeX\">$\\mathsf {MNI}$</tex-math><alternatives><mml:math><mml:mi mathvariant=\"sans-serif\">MNI</mml:mi></mml:math><inline-graphic xlink:href=\"zeng-ieq8-3233594.gif\"/></alternatives></inline-formula>) of the candidate pattern, which is used to prune unqualified candidates earlier and prioritize the enumeration order of patterns; (3) We design an advanced join-based approach to compute the <inline-formula><tex-math notation=\"LaTeX\">$\\mathsf {MNI}$</tex-math><alternatives><mml:math><mml:mi mathvariant=\"sans-serif\">MNI</mml:mi></mml:math><inline-graphic xlink:href=\"zeng-ieq9-3233594.gif\"/></alternatives></inline-formula> of candidate patterns efficiently; and (4) We develop a lower bound for distance function and incrementally compute the pairwise diversity among the patterns. Using real-world knowledge graphs, we experimentally verify the efficiency and effectiveness of our proposed techniques. We also demonstrate the utility of the extracted patterns by case studies.",
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "authors": [
                {
                    "authorId": "2072982165",
                    "name": "Jian Zeng"
                },
                {
                    "authorId": "1830414684",
                    "name": "Leong Hou U"
                },
                {
                    "authorId": "145837716",
                    "name": "Xiao Yan"
                },
                {
                    "authorId": "2221337816",
                    "name": "Yan Li"
                },
                {
                    "authorId": "2111857152",
                    "name": "Mingji Han"
                },
                {
                    "authorId": "2084612700",
                    "name": "Bo Tang"
                }
            ]
        },
        {
            "paperId": "3f57f297eb80171f9c2a900d087cfcac943c4c1e",
            "title": "DGI: An Easy and Efficient Framework for GNN Model Evaluation",
            "abstract": "While many systems have been developed to train graph neural networks (GNNs), efficient model evaluation, which computes node embedding according to a given model, remains to be addressed. For instance, using the widely adopted node-wise approach, model evaluation can account for over 90% of the time in the end-to-end training process due to neighbor explosion, which means that a node accesses its multi-hop neighbors. The layer-wise approach avoids neighbor explosion by conducting computation layer by layer in GNN models. However, layer-wise model evaluation takes considerable implementation efforts because users need to manually decompose the GNN model into layers, and different implementations are required for GNN models with different structures. In this paper, we present DGI -a framework for easy and efficient GNN model evaluation, which automatically translates the training code of a GNN model for layer-wise evaluation to minimize user effort. DGI is general for different GNN models and evaluation requests (e.g., computing embedding for all or some of the nodes), and supports out-of-core execution on large graphs that cannot fit in CPU memory. Under the hood, DGI traces the computation graph of GNN model, partitions the computation graph into layers that are suitable for layer-wise evaluation according to tailored rules, and executes each layer efficiently by reordering the computation tasks and managing device memory consumption. Experiment results show that DGI matches hand-written implementations of layer-wise evaluation in efficiency and consistently outperforms node-wise evaluation across different datasets and hardware settings, and the speedup can be over 1,000x.",
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "authors": [
                {
                    "authorId": "2113653096",
                    "name": "Peiqi Yin"
                },
                {
                    "authorId": "145837716",
                    "name": "Xiao Yan"
                },
                {
                    "authorId": "9695889",
                    "name": "Jinjing Zhou"
                },
                {
                    "authorId": "2167292330",
                    "name": "Qiang Fu"
                },
                {
                    "authorId": "35349851",
                    "name": "Zhenkun Cai"
                },
                {
                    "authorId": "1717691",
                    "name": "James Cheng"
                },
                {
                    "authorId": "2084612700",
                    "name": "Bo Tang"
                },
                {
                    "authorId": "2108593481",
                    "name": "Minjie Wang"
                }
            ]
        },
        {
            "paperId": "5b671f29e7830283d983a7f18f745b12abd490f8",
            "title": "DSP: Efficient GNN Training with Multiple GPUs",
            "abstract": "Jointly utilizing multiple GPUs to train graph neural networks (GNNs) is crucial for handling large graphs and achieving high efficiency. However, we find that existing systems suffer from high communication costs and low GPU utilization due to improper data layout and training procedures. Thus, we propose a system dubbed Distributed Sampling and Pipelining (DSP) for multi-GPU GNN training. DSP adopts a tailored data layout to utilize the fast NVLink connections among the GPUs, which stores the graph topology and popular node features in GPU memory. For efficient graph sampling with multiple GPUs, we introduce a collective sampling primitive (CSP), which pushes the sampling tasks to data to reduce communication. We also design a producer-consumer-based pipeline, which allows tasks from different mini-batches to run congruently to improve GPU utilization. We compare DSP with state-of-the-art GNN training frameworks, and the results show that DSP consistently outperforms the baselines under different datasets, GNN models and GPU counts. The speedup of DSP can be up to 26x and is over 2x in most cases.",
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "authors": [
                {
                    "authorId": "35349851",
                    "name": "Zhenkun Cai"
                },
                {
                    "authorId": "2165760706",
                    "name": "Qihui Zhou"
                },
                {
                    "authorId": "145837716",
                    "name": "Xiao Yan"
                },
                {
                    "authorId": "122579067",
                    "name": "Da Zheng"
                },
                {
                    "authorId": "2118943843",
                    "name": "Xiang Song"
                },
                {
                    "authorId": "2153619495",
                    "name": "Chenguang Zheng"
                },
                {
                    "authorId": "2116502347",
                    "name": "James Cheng"
                },
                {
                    "authorId": "50877490",
                    "name": "G. Karypis"
                }
            ]
        },
        {
            "paperId": "5e98192e28fd2c5223f83f6ba8fca2e342fca51b",
            "title": "Analyzing and Combating Attribute Bias for Face Restoration",
            "abstract": "Face restoration (FR) recovers high resolution (HR) faces from low resolution (LR) faces and is challenging due to its ill-posed nature. With years of development, existing methods can produce quality HR faces with realistic details. However, we observe that key facial attributes (e.g., age and gender) of the restored faces could be dramatically different from the LR faces and call this phenomenon attribute bias, which is fatal when using FR for applications such as surveillance and security. Thus, we argue that FR should consider not only image quality as in existing works but also attribute bias. To this end, we thoroughly analyze attribute bias with extensive experiments and find that two major causes are the lack of attribute information in LR faces and bias in the training data. Moreover, we propose the DebiasFR framework to produce HR faces with high image quality and accurate facial attributes. The key design is to explicitly model the facial attributes, which also allows to adjust facial attributes for the output HR faces. Experiment results show that DebiasFR has comparable image quality but significantly smaller attribute bias when compared with state-of-the-art FR methods.",
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "authors": [
                {
                    "authorId": "2109967987",
                    "name": "Zelin Li"
                },
                {
                    "authorId": "39422721",
                    "name": "Dan Zeng"
                },
                {
                    "authorId": "145837716",
                    "name": "Xiao Yan"
                },
                {
                    "authorId": "2647686",
                    "name": "Qiaomu Shen"
                },
                {
                    "authorId": "2084612700",
                    "name": "Bo Tang"
                }
            ]
        },
        {
            "paperId": "9a91890329b65d43d91b0d83399d68949bd85ad5",
            "title": "Speeding Up End-to-end Query Execution via Learning-based Progressive Cardinality Estimation",
            "abstract": "Fast query execution requires learning-based cardinality estimators to have short inference time (as model inference time adds to end-to-end query execution time) and high estimation accuracy (which is crucial for finding good execution plan). However, existing estimators cannot meet both requirements due to the inherent tension between model complexity and estimation accuracy. We propose a novel Learning-based Progressive Cardinality Estimator (LPCE), which adopts a query re-optimization methodology. In particular, LPCE consists of an initial model (LPCE-I), which estimates cardinality before query execution, and a refinement model (LPCE-R), which progressively refines the cardinality estimations using the actual cardinalities of the executed operators. During query execution, re-optimization is triggered if the estimations of LPCE-I are found to have large errors, and more efficient execution plans are selected for the remaining operators using the refined estimations provided by LPCE-R. Both LPCE-I and LPCE-R are light-weight query-driven estimators but they achieve both good efficiency and high accuracy when used jointly. Besides designing the models for LPCE-I and LPCE-R, we also integrate re-optimization and LPCE into PostgreSQL, a popular database engine. Extensive experiments show that LPCE yields shorter end-to-end query execution time than state-of-the-art learning-based estimators.",
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "authors": [
                {
                    "authorId": "7572514",
                    "name": "Fang Wang"
                },
                {
                    "authorId": "145837716",
                    "name": "Xiao Yan"
                },
                {
                    "authorId": "1722082",
                    "name": "Man Lung Yiu"
                },
                {
                    "authorId": "2059078144",
                    "name": "LI Shuai"
                },
                {
                    "authorId": "2169798543",
                    "name": "Zunyao Mao"
                },
                {
                    "authorId": "2065093887",
                    "name": "Bo Tang"
                }
            ]
        },
        {
            "paperId": "c47ac61187b974b9b32512d569627c6d70a1ed94",
            "title": "Multi-domain Recommendation with Embedding Disentangling and Domain Alignment",
            "abstract": "Multi-domain recommendation (MDR) aims to provide recommendations for different domains (e.g., types of products) with overlapping users/items and is common for platforms such as Amazon, Facebook, and LinkedIn that host multiple services. Existing MDR models face two challenges: First, it is difficult to disentangle knowledge that generalizes across domains (e.g., a user likes cheap items) and knowledge specific to a single domain (e.g., a user likes blue clothing but not blue cars). Second, they have limited ability to transfer knowledge across domains with small overlaps. We propose a new MDR method named EDDA with two key components, i.e., embedding disentangling recommender and domain alignment, to tackle the two challenges respectively. In particular, the embedding disentangling recommender separates both the model and embedding for the inter-domain part and the intra-domain part, while most existing MDR methods only focus on model-level disentangling. The domain alignment leverages random walks from graph processing to identify similar user/item pairs from different domains and encourages similar user/item pairs to have similar embeddings, enhancing knowledge transfer. We compare EDDA with 12 state-of-the-art baselines on 3 real datasets. The results show that EDDA consistently outperforms the baselines on all datasets and domains. All datasets and codes are available at https://github.com/Stevenn9981/EDDA.",
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "authors": [
                {
                    "authorId": "1942884880",
                    "name": "Wentao Ning"
                },
                {
                    "authorId": "145837716",
                    "name": "Xiao Yan"
                },
                {
                    "authorId": "2130051800",
                    "name": "Weiwen Liu"
                },
                {
                    "authorId": "2073538844",
                    "name": "R. Cheng"
                },
                {
                    "authorId": "144142354",
                    "name": "Rui Zhang"
                },
                {
                    "authorId": "2084612700",
                    "name": "Bo Tang"
                }
            ]
        },
        {
            "paperId": "d0b8c21ab5380265f3a76f01a152be51f36b0f67",
            "title": "Cascaded face super-resolution with shape and identity priors",
            "abstract": "Despite impressive progress in face super-resolution (SR), it is an open challenge to reconstruct a reliable SR face that preserves authentic facial characteristics. Here, the problem of super-resolving low-resolution (LR) faces to high-resolution (HR) ones is addressed. To tackle the ill-posed nature of face SR, the cascaded super-resolution network (CSR-Net) is proposed to utilize shape and identity priors jointly and progressively, the \ufb01rst to explore multiple priors. Speci\ufb01cally, CSRNet adopts a cascaded structure to transform an LR face to HR face progressively via multiple stages. At each stage, CSRNet forces its output face image to match both the shape priors and identity priors extracted from the ground-truth HR face. The shape priors estimated in one stage are merged into the inputs of its subsequent stage to provide rich information for the face SR. To generate realistic yet discriminative faces, the cascaded super-resolution generative adversarial network (CSRGAN) is also proposed to incorporate the adversarial loss and identi\ufb01cation loss into CSRNet. Extensive experiments on popular benchmarks show that the CSRNet and CSRGAN outperform existing face SR state-of-the-art methods, both quantitatively and qualitatively, and detailed ablation studies show the advantage of this method.",
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "authors": [
                {
                    "authorId": "39422721",
                    "name": "Dan Zeng"
                },
                {
                    "authorId": "2109967987",
                    "name": "Zelin Li"
                },
                {
                    "authorId": "145837716",
                    "name": "Xiao Yan"
                },
                {
                    "authorId": "2161236333",
                    "name": "Wen Jiang"
                },
                {
                    "authorId": "145152770",
                    "name": "Xinshao Wang"
                },
                {
                    "authorId": "2155403822",
                    "name": "Jiang Liu"
                },
                {
                    "authorId": "2084612700",
                    "name": "Bo Tang"
                }
            ]
        },
        {
            "paperId": "f5af46e32c516d1158519b7e78f794c16df32494",
            "title": "FEC: Efficient Deep Recommendation Model Training with Flexible Embedding Communication",
            "abstract": "Embedding-based deep recommendation models (EDRMs), which contain small dense models and large embedding tables, are widely used in industry. Embedding communication constitutes the main cost for the distributed training of EDRMs, and thus we propose two strategies to improve its efficiency, i.e.,embedding tiering andpre-fetching. In particular, embedding tiering uses AllReduce to communicate popular embeddings that are accessed frequently. This is counter-intuitive as embeddings belong to the sparse embedding tables, but reasonable because the access pattern of popular embeddings resembles dense models. Pre-fetching starts communication early for embeddings that receive no updates such that they are removed from the critical path of training. We implement embedding tiering and pre-fetching in a system called FEC and compare it with the state-of-the-art systems on real datasets. The results show that FEC consistently outperforms the existing methods on all datasets, and its speed can be up to 6.65x and 2.42x in terms of embedding communication time and training throughput compared with the best performing baseline.",
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "authors": [
                {
                    "authorId": "1381894756",
                    "name": "Kaihao Ma"
                },
                {
                    "authorId": "145837716",
                    "name": "Xiao Yan"
                },
                {
                    "authorId": "35349851",
                    "name": "Zhenkun Cai"
                },
                {
                    "authorId": "2143454301",
                    "name": "Yuzhen Huang"
                },
                {
                    "authorId": "47096554",
                    "name": "Yidi Wu"
                },
                {
                    "authorId": "1717691",
                    "name": "James Cheng"
                }
            ]
        },
        {
            "paperId": "2831b9f7b9ece3c6ae6be8cef5ac57d6cf7e5c0d",
            "title": "CheetahKG: A Demonstration for Core-based Top-$k$ Frequent Pattern Discovery on Knowledge Graphs",
            "abstract": "Knowledge graphs capture the complex relationships among various entities, which can be found in various real world applications, e.g., Amazon product graph, Freebase, and COVID-19. To facilitate the knowledge graph analytical tasks, a system that supports interactive and efficient query processing is always in demand. In this demonstration, we develop a prototype system, CheetahKG, that embeds with our state-of-the-art query processing engine for the top-$k$ frequent pattern discovery. Such discovered patterns can be used for two purposes, (i) identifying related patterns and (ii) guiding knowledge exploration. In the demonstration sessions, the attendees will be invited to test the efficiency and effectiveness of the query engine and use the discovered patterns to analyze knowledge graphs on CheetahKG.",
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "authors": [
                {
                    "authorId": "1410395554",
                    "name": "Bo Tang"
                },
                {
                    "authorId": "2072982165",
                    "name": "Jian Zeng"
                },
                {
                    "authorId": "1931444857",
                    "name": "Qiandong Tang"
                },
                {
                    "authorId": null,
                    "name": "Chuan Yang"
                },
                {
                    "authorId": "2647686",
                    "name": "Qiaomu Shen"
                },
                {
                    "authorId": "1830414684",
                    "name": "Leong Hou U"
                },
                {
                    "authorId": "145837716",
                    "name": "Xiao Yan"
                },
                {
                    "authorId": "39422721",
                    "name": "Dan Zeng"
                }
            ]
        },
        {
            "paperId": "2ca6eb0810e0ab0c60afd9c6b142e4b89aaca8c1",
            "title": "Face2Exp: Combating Data Biases for Facial Expression Recognition",
            "abstract": "Facial expression recognition (FER) is challenging due to the class imbalance caused by data collection. Existing studies tackle the data bias problem using only labeled facial expression dataset. Orthogonal to existing FER methods, we propose to utilize large unlabeled face recognition (FR) datasets to enhance FER. However, this raises another data bias problem\u2014the distribution mismatch between FR and FER data. To combat the mismatch, we propose the Meta-Face2Exp framework, which consists of a base network and an adaptation network. The base network learns prior expression knowledge on class-balanced FER data while the adaptation network is trained to fit the pseudo labels of FR data generated by the base model. To combat the mismatch between FR and FER data, Meta-Face2Exp uses a circuit feedback mechanism, which improves the base network with the feedback from the adaptation network. Experiments show that our MetaFace2Exp achieves comparable accuracy to state-of-the-art FER methods with 10% of the labeled FER data utilized by the baselines. We also demonstrate that the circuit feedback mechanism successfully eliminates data bias11Code is available at link: https://github.com/danzeng1990/Face2Exp..",
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "authors": [
                {
                    "authorId": "39422721",
                    "name": "Dan Zeng"
                },
                {
                    "authorId": "2159108282",
                    "name": "Zhi-Kai Lin"
                },
                {
                    "authorId": "145837716",
                    "name": "Xiao Yan"
                },
                {
                    "authorId": "2108092535",
                    "name": "Yuting Liu"
                },
                {
                    "authorId": "39586294",
                    "name": "Fei Wang"
                },
                {
                    "authorId": "2084612700",
                    "name": "Bo Tang"
                }
            ]
        }
    ]
}