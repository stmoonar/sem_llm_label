{
    "authorId": "2108167911",
    "papers": [
        {
            "paperId": "3097c87cf0536d6af649fc819b4f9f7f2c31940c",
            "title": "Multiview Subspace Tensor Self-Representation for SAR Image Semi-Supervised Classification",
            "abstract": "Synthetic aperture radar (SAR) image classification has proven its significant importance in automatic remote sensing. However, current methods demand a large volume of training data to ensure satisfactory generalization capability. Given the difficulty in obtaining sufficient labeled samples, semi-supervised learning for SAR image classification becomes extremely important. However, existing studies are hindered by sample relationship modeling and single sample descriptions, leading to limited performance. To address this issue, we propose an innovative approach: multiview subspace tensor self-representation learning with label propagation for SAR image classification. Initially, our method extracts global sample relationship matrices of SAR samples using subspace self-representation learning with affine and nonnegative constraints. To enhance the single sample feature description, we construct multiview tensor learning by stacking the subspace representation matrices of different SAR view features. Finally, the SAR image multiview subspace self-representation matrix is treated as the probability indication matrix for classification. The experiments on MSTAR using extreme 10% labeled samples have shown that the proposed method yields performance boosts of 22.3% and 12.2% to the state-of-the-art method under two rigorous evaluation settings, respectively. The remarkably superior experimental results effectively validate the effectiveness of our proposals.",
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "authors": [
                {
                    "authorId": "2298247906",
                    "name": "Yang Yang"
                },
                {
                    "authorId": "2111321753",
                    "name": "Yongqiang Tang"
                },
                {
                    "authorId": "2307246701",
                    "name": "Jiangbo Bai"
                },
                {
                    "authorId": "2307434603",
                    "name": "Lu Zhang"
                },
                {
                    "authorId": "2108167911",
                    "name": "Wensheng Zhang"
                }
            ]
        },
        {
            "paperId": "31c98f9c2e280369413ab7ab803c9aff1ea13421",
            "title": "SASOD: Saliency-Aware Ship Object Detection in High-Resolution Optical Images",
            "abstract": "Ship detection in high-resolution optical remote sensing images (ORSI) is an important yet challenging task with extensive applications, such as maritime security and resource conservation. In recent years, bolstered by deep learning, ship detection has also grown by leaps and bounds. Nevertheless, existing methods still suffer from two challenging issues: 1) imprecise localization for low discriminative ships under the complicated background and 2) missed detections for small ships. To solve the above issues, we propose a novel ship detection method equipped with a saliency-guided feature fusion network (SGFFN) and a dynamic IoU-adaptive strategy (DIAS). SGFFN is designed based on a top-down feature pyramid network to introduce saliency information into the ship detection network and optimize the saliency-aware features. It comprises two components: the resolution-matching saliency supervision (RMS) network and the cross-stage saliency integration network (CSIN). RMS is a bimatching mechanism that adopts diverse prediction structures for the saliency maps with different scales, such that the finer saliency-aware features could be obtained. CSIN is a cross-stage cross-channel integration module that is designed to fuse saliency-aware features with low-level features. Furthermore, a customized training strategy for small ships, i.e., DIAS, is devised to assign appropriate intersection over union (IoU) thresholds for anchors around the small ships during the training phase. Experimental results on two datasets demonstrate that our proposed method achieves state-of-the-art performance.",
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "authors": [
                {
                    "authorId": "1585442738",
                    "name": "Zhida Ren"
                },
                {
                    "authorId": "2111321753",
                    "name": "Yongqiang Tang"
                },
                {
                    "authorId": "2152919172",
                    "name": "Yang Yang"
                },
                {
                    "authorId": "2108167911",
                    "name": "Wensheng Zhang"
                }
            ]
        },
        {
            "paperId": "4a25db8b5ea36935c28e90fbdbfd4fb184fdebea",
            "title": "Super Resolution Graph With Conditional Normalizing Flows for Temporal Link Prediction",
            "abstract": "Temporal link prediction on dynamic graphs has attracted considerable attention. Most methods focus on the graph at each timestamp and extract features for prediction. As graphs are directly compressed into feature matrices, the important latent information at each timestamp has not been well revealed. Eventually, the acquisition of dynamic evolution-related patterns is rendered inadequately. In this paper, inspired by the process of Super-Resolution (SR), a novel deep generative model SRG (Super Resolution Graph) is proposed. We innovatively introduce the concepts of the Low-Resolution (LR) graph, which is a single adjacent matrix at a timestamp, and the High-Resolution (HR) graph, which includes the link status of surrounding snapshots. Specifically, two major aspects are considered regarding the construction of the HR graph. For edges, we endeavor to obtain an extensive information transmission description that affects the current link status. For nodes, similar to the SR process, the neighbor relationship among nodes is maintained. In this form, we could predict the link status from a new perspective: Under the supervision of the graph moving average strategy, the conditional normalizing flow effectively realizes the transformation between LR and HR graphs. Extensive experiments on six real-world datasets from different applications demonstrate the effectiveness of our proposal.",
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "authors": [
                {
                    "authorId": "2223554832",
                    "name": "Yanting Yin"
                },
                {
                    "authorId": "2107922909",
                    "name": "Yajing Wu"
                },
                {
                    "authorId": "1860612",
                    "name": "Xuebing Yang"
                },
                {
                    "authorId": "2108167911",
                    "name": "Wensheng Zhang"
                },
                {
                    "authorId": "1721029",
                    "name": "Xiaojie Yuan"
                }
            ]
        },
        {
            "paperId": "f335f0c40ddbccc71212cce7984903cdb409d876",
            "title": "Graph Structure Aware Contrastive Multi-View Clustering",
            "abstract": "Multi-view clustering has become a research hotspot in recent decades because of its effectiveness in heterogeneous data fusion. Although a large number of related studies have been developed one after another, most of them usually only concern with the characteristics of the data themselves and overlook the inherent connection among samples, hindering them from exploring structural knowledge of graph space. Moreover, many current works tend to highlight the compactness of one cluster without taking the differences between clusters into account. To track these two drawbacks, in this article, we propose a graph structure aware contrastive multi-view clustering (namely, GCMC) approach. Specifically, we incorporate the well-designed graph autoencoder with conventional multi-layer perception autoencoder to extract the structural and high-level representation of multi-view data, so that the underlying correlation of samples can be effectively squeezed for model learning. Then the contrastive learning paradigm is performed on multiple pseudo-label distributions to ensure that the positive pairs of pseudo-label representations share the complementarity across views while the divergence between negative pairs is sufficiently large. This makes each semantic cluster more discriminative, i.e., jointly satisfying intra-cluster compactness and inter-cluster exclusiveness. Through comprehensive experiments on eight widely-known datasets, we prove that the proposed approach can perform better than the state-of-the-art opponents.",
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "authors": [
                {
                    "authorId": "2268058677",
                    "name": "Rui Chen"
                },
                {
                    "authorId": "2111321753",
                    "name": "Yongqiang Tang"
                },
                {
                    "authorId": "3127329",
                    "name": "Xiangrui Cai"
                },
                {
                    "authorId": "2267877841",
                    "name": "Xiaojie Yuan"
                },
                {
                    "authorId": "2166719516",
                    "name": "Wenlong Feng"
                },
                {
                    "authorId": "2108167911",
                    "name": "Wensheng Zhang"
                }
            ]
        },
        {
            "paperId": "1000914d5584e25fe241b9f4edbd9e5faa615e95",
            "title": "PmcaNet: Pyramid multiscale channel attention network for electron microscopy image segmentation",
            "abstract": "Recent advances in high-throughput electron microscopy (EM) have revolutionized the examination of microstructures by enabling fast EM image generation. However, accurately segmenting EM images remains challenging due to inherent characteristics, including low contrast and subtle grayscale variations. Moreover, as manually annotated EM images are limited, it is usually impractical to utilize deep learning techniques for EM image segmentation. To address these challenges, the pyramid multiscale channel attention network (PmcaNet) is specifically designed. PmcaNet employs a convolutional neural network-based architecture and a multiscale feature pyramid to effectively capture global context information, enhancing its ability to comprehend the intricate structures within EM images. To enable the rapid extraction of channel-wise dependencies, a novel attention module is introduced to enhance the representation of intricate nonlinear features within the images. The performance of PmcaNet is evaluated on two general EM image segmentation datasets as well as a homemade dataset of superalloy materials, regarding pixel-wise accuracy and mean intersection over union (mIoU) as evaluation metrics. Extensive experiments demonstrate that PmcaNet outperforms other models on the ISBI 2012 dataset, achieving 87.85% pixel-wise accuracy and 73.11% mean intersection over union (mIoU), while also advancing results on the Kathuri and SEM-material datasets.",
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "authors": [
                {
                    "authorId": "2278093413",
                    "name": "Kaihan Gao"
                },
                {
                    "authorId": "2278049089",
                    "name": "Yiwei Ju"
                },
                {
                    "authorId": "2279021877",
                    "name": "Shuai Li"
                },
                {
                    "authorId": "1860612",
                    "name": "Xuebing Yang"
                },
                {
                    "authorId": "2108167911",
                    "name": "Wensheng Zhang"
                },
                {
                    "authorId": "2278235829",
                    "name": "Guoqing Li"
                }
            ]
        },
        {
            "paperId": "17330c07a59b9dfb6cb01612c4b8be8841735396",
            "title": "Leveraging Summary Guidance on Medical Report Summarization",
            "abstract": "This study presents three deidentified large medical text datasets, named DISCHARGE, ECHO and RADIOLOGY, which contain 50 K, 16 K and 378 K pairs of report and summary that are derived from MIMIC-III, respectively. We implement convincing baselines of automated abstractive summarization on the created datasets with pre-trained encoder-decoder language models, including BERT2BERT, BERTShare, RoBERTaShare, Pegasus, ProphetNet, T5-large, BART and GSUM. Further, based on the BART model, we leverage the sampled summaries from the training set as prior knowledge guidance, for encoding additional contextual representations of the guidance with the encoder and enhancing the decoding representations in the decoder. The experimental results confirm the improvement of ROUGE scores and BERTScore made by the proposed method.",
            "fieldsOfStudy": [
                "Computer Science",
                "Medicine"
            ],
            "authors": [
                {
                    "authorId": "5878432",
                    "name": "Yunqi Zhu"
                },
                {
                    "authorId": "1860612",
                    "name": "Xuebing Yang"
                },
                {
                    "authorId": "2204743673",
                    "name": "Yuanyuan Wu"
                },
                {
                    "authorId": "2108167911",
                    "name": "Wensheng Zhang"
                }
            ]
        },
        {
            "paperId": "6178c99328984452551b0356b64d048d341b9a9e",
            "title": "Parameter-Efficient Fine-Tuning with Layer Pruning on Free-Text Sequence-to-Sequence Modeling",
            "abstract": "The increasing size of language models raises great research interests in parameter-efficient fine-tuning such as LoRA that freezes the pre-trained model, and injects small-scale trainable parameters for multiple downstream tasks (e.g., summarization, question answering and translation). To further enhance the efficiency of fine-tuning, we propose a framework that integrates LoRA and structured layer pruning. The integrated framework is validated on two created deidentified medical report summarization datasets based on MIMIC-IV-Note and two public medical dialogue datasets. By tuning 0.6% parameters of the original model and pruning over 30% Transformer-layers, our framework can reduce 50% of GPU memory usage and speed up 100% of the training phase, while preserving over 92% generation qualities on free-text sequence-to-sequence tasks.",
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "authors": [
                {
                    "authorId": "145350978",
                    "name": "Y. Zhu"
                },
                {
                    "authorId": "1860612",
                    "name": "Xuebing Yang"
                },
                {
                    "authorId": "2204743673",
                    "name": "Yuanyuan Wu"
                },
                {
                    "authorId": "2108167911",
                    "name": "Wensheng Zhang"
                }
            ]
        },
        {
            "paperId": "0ebd08e4922082723816cbf34269367301d1ec08",
            "title": "SE-GRU: Structure Embedded Gated Recurrent Unit Neural Networks for Temporal Link Prediction",
            "abstract": "Temporal link prediction on dynamic graphs is essential to various areas such as recommendation systems, social networks, and citation analysis, and thus attracts great attention in both research and industry fields. For complex graphs in real-world applications, although recent temporal link prediction methods perform well in predicting high-frequency and nearby connections, it becomes more challenging when considering low-frequency and earlier connections. In this work, we introduce a novel and elegant prediction architecture called Structure Embedded Gated Recurrent Unit (SE-GRU) neural networks, to strengthen the prediction robustness against frequency variation and occurrence delay of connections. The established SE-GRU embeds the structure for local topological characteristics to emphasize the different connection frequencies between nodes and captures the temporal dependencies to avoid losing valuable information caused by long-term changes. We realize neural network optimization considering three terms concerning reconstruction, structure, and evolution. The extensive experiments performed on three public datasets demonstrate the significant superiority of SE-GRU compared with 5 representative and state-of-the-art competitors under three evaluation metrics. The results validate the effectiveness and robustness of our proposed method, by showing that the frequencies and timestamps of connections have a little-to-no negative impact on prediction accuracy.",
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "authors": [
                {
                    "authorId": "49545927",
                    "name": "Yanting Yin"
                },
                {
                    "authorId": "2107922909",
                    "name": "Yajing Wu"
                },
                {
                    "authorId": "1860612",
                    "name": "Xuebing Yang"
                },
                {
                    "authorId": "2108167911",
                    "name": "Wensheng Zhang"
                },
                {
                    "authorId": "1721029",
                    "name": "Xiaojie Yuan"
                }
            ]
        },
        {
            "paperId": "4b76cea17ef785f319a453722f202f12e5f47e12",
            "title": "Active Learning with Effective Scoring Functions for Semi-Supervised Temporal Action Localization",
            "abstract": "Temporal Action Localization (TAL) aims to predict both action category and temporal boundary of action instances in untrimmed videos, i.e., start and end time. Fully-supervised solutions are usually adopted in most existing works, and proven to be effective. One of the practical bottlenecks in these solutions is the large amount of labeled training data required. To reduce expensive human label cost, this paper focuses on a rarely investigated yet practical task named semi-supervised TAL and proposes an effective active learning method, named AL-STAL. We leverage four steps for actively selecting video samples with high informativeness and training the localization model, named \\emph{Train, Query, Annotate, Append}. Two scoring functions that consider the uncertainty of localization model are equipped in AL-STAL, thus facilitating the video sample rank and selection. One takes entropy of predicted label distribution as measure of uncertainty, named Temporal Proposal Entropy (TPE). And the other introduces a new metric based on mutual information between adjacent action proposals and evaluates the informativeness of video samples, named Temporal Context Inconsistency (TCI). To validate the effectiveness of proposed method, we conduct extensive experiments on two benchmark datasets THUMOS'14 and ActivityNet 1.3. Experiment results show that AL-STAL outperforms the existing competitors and achieves satisfying performance compared with fully-supervised learning.",
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "authors": [
                {
                    "authorId": "2109153420",
                    "name": "Ding Li"
                },
                {
                    "authorId": "1860612",
                    "name": "Xuebing Yang"
                },
                {
                    "authorId": "2111321753",
                    "name": "Yongqiang Tang"
                },
                {
                    "authorId": "2124944872",
                    "name": "Chenyang Zhang"
                },
                {
                    "authorId": "2108167911",
                    "name": "Wensheng Zhang"
                },
                {
                    "authorId": "2149343311",
                    "name": "Lizhuang Ma"
                }
            ]
        },
        {
            "paperId": "9d0660d76b3fc5a278d2bfa71855b99f13395f19",
            "title": "Inductive Spatiotemporal Graph Convolutional Networks for Short-term Quantitative Precipitation Forecasting",
            "abstract": "Short-term Quantitative Precipitation Forecasting (SQPF) using weather radar is an important but challenging problem as one must cope with inherent nonlinearity and spatiotemporal correlation in the data. In this paper, we propose a novel deep learning model, named Inductive spatiotemporal Graph Convolutional Networks (InstGCN), to overcome these issues in SQPF. The proposed InstGCN can learn a nonlinear mapping from historical radar reflectivity to future rainfall amounts, and extract informative spatiotemporal representations simultaneously. Specifically, we first provide a formal definition for formulating the SQPF problem from a graph perspective. Then, based on radar reflectivity and rain gauge observation, we propose a novel graph construction approach which utilizes a special elliptic structure to model the spatial dependency of precipitation area. Additionally, a new Node level Differential Block (Node-DB) is introduced to tackle the non-stationary temporal dependency. To execute inductive graph learning for unseen nodes, we design to decompose a whole graph into sub-graphs. We conduct extensive experiments on three real-world datasets in East China and a public weather radar dataset in the south-eastern parts of France. The experimental results confirm the advantages of InstGCN compared with several state-of-the-arts.",
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "authors": [
                {
                    "authorId": "2107922909",
                    "name": "Yajing Wu"
                },
                {
                    "authorId": "1860612",
                    "name": "Xuebing Yang"
                },
                {
                    "authorId": "2111321753",
                    "name": "Yongqiang Tang"
                },
                {
                    "authorId": "2124944872",
                    "name": "Chenyang Zhang"
                },
                {
                    "authorId": "2127722396",
                    "name": "Guoping Zhang"
                },
                {
                    "authorId": "2108167911",
                    "name": "Wensheng Zhang"
                }
            ]
        }
    ]
}