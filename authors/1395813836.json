{
    "authorId": "1395813836",
    "papers": [
        {
            "paperId": "21b4777948797377deedf4a9f1f58ad13f6b8b5d",
            "title": "Overview of the Tenth Dialog System Technology Challenge: DSTC10",
            "abstract": "This article introduces the Tenth Dialog System Technology Challenge (DSTC-10). This edition of the DSTC focuses on applying end-to-end dialog technologies for five distinct tasks in dialog systems, namely 1. Incorporation of Meme images into open domain dialogs, 2. Knowledge-grounded Task-oriented Dialogue Modeling on Spoken Conversations, 3. Situated Interactive Multimodal dialogs, 4. Reasoning for Audio Visual Scene-Aware Dialog, and 5. Automatic Evaluation and Moderation of Open-domainDialogue Systems. This article describes the task definition, provided datasets, baselines, and evaluation setup for each track. We also summarize the results of the submitted systems to highlight the general trends of the state-of-the-art technologies for the tasks.",
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "authors": [
                {
                    "authorId": "2237192",
                    "name": "Koichiro Yoshino"
                },
                {
                    "authorId": "1725643",
                    "name": "Yun-Nung (Vivian) Chen"
                },
                {
                    "authorId": "34963487",
                    "name": "Paul A. Crook"
                },
                {
                    "authorId": "2150275",
                    "name": "Satwik Kottur"
                },
                {
                    "authorId": "2887412",
                    "name": "Jinchao Li"
                },
                {
                    "authorId": "2127328167",
                    "name": "Behnam Hedayatnia"
                },
                {
                    "authorId": "29072828",
                    "name": "Seungwhan Moon"
                },
                {
                    "authorId": "2066415714",
                    "name": "Zhengcong Fei"
                },
                {
                    "authorId": "2109965103",
                    "name": "Zekang Li"
                },
                {
                    "authorId": "27672597",
                    "name": "Jinchao Zhang"
                },
                {
                    "authorId": "2257374643",
                    "name": "Yang Feng"
                },
                {
                    "authorId": "2116575668",
                    "name": "Jie Zhou"
                },
                {
                    "authorId": "2127354716",
                    "name": "Seokhwan Kim"
                },
                {
                    "authorId": "2152797401",
                    "name": "Yang Liu"
                },
                {
                    "authorId": "2152284471",
                    "name": "Di Jin"
                },
                {
                    "authorId": "1710287",
                    "name": "A. Papangelis"
                },
                {
                    "authorId": "145916630",
                    "name": "Karthik Gopalakrishnan"
                },
                {
                    "authorId": "1395813836",
                    "name": "Dilek Z. Hakkani-T\u00fcr"
                },
                {
                    "authorId": "3057557",
                    "name": "Babak Damavandi"
                },
                {
                    "authorId": "1979505",
                    "name": "A. Geramifard"
                },
                {
                    "authorId": "1765212",
                    "name": "Chiori Hori"
                },
                {
                    "authorId": "31017418",
                    "name": "Ankit Shah"
                },
                {
                    "authorId": "2111574800",
                    "name": "Chen Zhang"
                },
                {
                    "authorId": "1711271",
                    "name": "Haizhou Li"
                },
                {
                    "authorId": "2319137716",
                    "name": "Jo\u00e3o Sedoc"
                },
                {
                    "authorId": "1405511901",
                    "name": "L. F. D\u2019Haro"
                },
                {
                    "authorId": "1694652",
                    "name": "Rafael E. Banchs"
                },
                {
                    "authorId": "1783635",
                    "name": "Alexander I. Rudnicky"
                }
            ]
        },
        {
            "paperId": "027ec9a2aaa81b01d190e8607b2250779e5834dd",
            "title": "Selective In-Context Data Augmentation for Intent Detection using Pointwise V-Information",
            "abstract": "This work focuses on in-context data augmentation for intent detection. Having found that augmentation via in-context prompting of large pre-trained language models (PLMs) alone does not improve performance, we introduce a novel approach based on PLMs and pointwise V-information (PVI), a metric that can measure the usefulness of a datapoint for training a model. Our method first fine-tunes a PLM on a small seed of training data and then synthesizes new datapoints - utterances that correspond to given intents. It then employs intent-aware filtering, based on PVI, to remove datapoints that are not helpful to the downstream intent classifier. Our method is thus able to leverage the expressive power of large language models to produce diverse training data. Empirical results demonstrate that our method can produce synthetic training data that achieve state-of-the-art performance on three challenging intent detection datasets under few-shot settings (1.28% absolute improvement in 5-shot and 1.18% absolute in 10-shot, on average) and perform on par with the state-of-the-art in full-shot settings (within 0.01% absolute, on average).",
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "authors": [
                {
                    "authorId": "1557269413",
                    "name": "Yen-Ting Lin"
                },
                {
                    "authorId": "1710287",
                    "name": "A. Papangelis"
                },
                {
                    "authorId": "2127354716",
                    "name": "Seokhwan Kim"
                },
                {
                    "authorId": "2108230831",
                    "name": "Sungjin Lee"
                },
                {
                    "authorId": "8223433",
                    "name": "Devamanyu Hazarika"
                },
                {
                    "authorId": "2171886",
                    "name": "Mahdi Namazifar"
                },
                {
                    "authorId": "2152284471",
                    "name": "Di Jin"
                },
                {
                    "authorId": "2152802138",
                    "name": "Yang Liu"
                },
                {
                    "authorId": "1395813836",
                    "name": "Dilek Z. Hakkani-T\u00fcr"
                }
            ]
        },
        {
            "paperId": "09d434d02138ad4049be421bf2351de4aa295412",
            "title": "Alexa, play with robot: Introducing the First Alexa Prize SimBot Challenge on Embodied AI",
            "abstract": "The Alexa Prize program has empowered numerous university students to explore, experiment, and showcase their talents in building conversational agents through challenges like the SocialBot Grand Challenge and the TaskBot Challenge. As conversational agents increasingly appear in multimodal and embodied contexts, it is important to explore the affordances of conversational interaction augmented with computer vision and physical embodiment. This paper describes the SimBot Challenge, a new challenge in which university teams compete to build robot assistants that complete tasks in a simulated physical environment. This paper provides an overview of the SimBot Challenge, which included both online and offline challenge phases. We describe the infrastructure and support provided to the teams including Alexa Arena, the simulated environment, and the ML toolkit provided to teams to accelerate their building of vision and language models. We summarize the approaches the participating teams took to overcome research challenges and extract key lessons learned. Finally, we provide analysis of the performance of the competing SimBots during the competition.",
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "authors": [
                {
                    "authorId": "2167861070",
                    "name": "Hangjie Shi"
                },
                {
                    "authorId": "2167616711",
                    "name": "Leslie Ball"
                },
                {
                    "authorId": "2028300167",
                    "name": "G. Thattai"
                },
                {
                    "authorId": "2187068732",
                    "name": "Desheng Zhang"
                },
                {
                    "authorId": "2144596247",
                    "name": "Lu Hu"
                },
                {
                    "authorId": "3193409",
                    "name": "Qiaozi Gao"
                },
                {
                    "authorId": "1831108414",
                    "name": "Suhaila Shakiah"
                },
                {
                    "authorId": "46757485",
                    "name": "Xiaofeng Gao"
                },
                {
                    "authorId": "2110665",
                    "name": "Aishwarya Padmakumar"
                },
                {
                    "authorId": "2119660672",
                    "name": "Bo Yang"
                },
                {
                    "authorId": "2210738933",
                    "name": "Cadence Chung"
                },
                {
                    "authorId": "2210732208",
                    "name": "Dinakar Guthy"
                },
                {
                    "authorId": "1732493",
                    "name": "G. Sukhatme"
                },
                {
                    "authorId": "2210732281",
                    "name": "Karthika Arumugam"
                },
                {
                    "authorId": "2210732608",
                    "name": "Matthew Wen"
                },
                {
                    "authorId": "2167638287",
                    "name": "Osman Ipek"
                },
                {
                    "authorId": "26882347",
                    "name": "P. Lange"
                },
                {
                    "authorId": "31606876",
                    "name": "Rohan Khanna"
                },
                {
                    "authorId": "31264280",
                    "name": "Shreyas Pansare"
                },
                {
                    "authorId": "144582538",
                    "name": "Vasu Sharma"
                },
                {
                    "authorId": "2256775738",
                    "name": "Chao Zhang"
                },
                {
                    "authorId": "1391844339",
                    "name": "C. Flagg"
                },
                {
                    "authorId": "34931641",
                    "name": "Daniel Pressel"
                },
                {
                    "authorId": "2167643644",
                    "name": "Lavina Vaz"
                },
                {
                    "authorId": "2115177932",
                    "name": "Luke Dai"
                },
                {
                    "authorId": "38774604",
                    "name": "Prasoon Goyal"
                },
                {
                    "authorId": "2167648845",
                    "name": "Sattvik Sahai"
                },
                {
                    "authorId": "2229954252",
                    "name": "Shaohua Liu"
                },
                {
                    "authorId": "2167771392",
                    "name": "Yao Lu"
                },
                {
                    "authorId": "1411423941",
                    "name": "Anna Gottardi"
                },
                {
                    "authorId": "2122825525",
                    "name": "Shui Hu"
                },
                {
                    "authorId": "2152801542",
                    "name": "Yang Liu"
                },
                {
                    "authorId": "1395813836",
                    "name": "Dilek Z. Hakkani-T\u00fcr"
                },
                {
                    "authorId": "35834027",
                    "name": "Kate Bland"
                },
                {
                    "authorId": "151027894",
                    "name": "Heather Rocker"
                },
                {
                    "authorId": "2231135132",
                    "name": "James Jeun"
                },
                {
                    "authorId": "2210728984",
                    "name": "Yadunandana Rao"
                },
                {
                    "authorId": "2078507351",
                    "name": "Michael Johnston"
                },
                {
                    "authorId": "8621381",
                    "name": "Akshaya Iyengar"
                },
                {
                    "authorId": "33638380",
                    "name": "Arindam Mandal"
                },
                {
                    "authorId": "2104644641",
                    "name": "Premkumar Natarajan"
                },
                {
                    "authorId": "3306272",
                    "name": "R. Ghanadan"
                }
            ]
        },
        {
            "paperId": "0bf41988d04253a840fe26a493e4db2e31655adf",
            "title": "Investigating the Representation of Open Domain Dialogue Context for Transformer Models",
            "abstract": "The bulk of work adapting transformer models to open-domain dialogue represents dialogue context as the concatenated set of turns in natural language. However, it is unclear if this is the best approach. In this work, we investigate this question by means of an empirical controlled experiment varying the dialogue context format from text-only formats (all recent utterances, summaries, selected utterances) as well as variants that are more structurally different (triples, AMR). We compare these formats based on fine-tuned model performance on two downstream tasks\u2014knowledge selection and response generation. We find that simply concatenating the utterances works as a strong baseline in most cases, but is outperformed in longer contexts by a hybrid approach of combining a summary of the context with recent utterances. Through empirical analysis, our work highlights the need to examine the format of context representation and offers recommendations on adapting general-purpose language models to dialogue tasks.",
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "authors": [
                {
                    "authorId": "2044959912",
                    "name": "Vishakh Padmakumar"
                },
                {
                    "authorId": "2127328167",
                    "name": "Behnam Hedayatnia"
                },
                {
                    "authorId": "2152284471",
                    "name": "Di Jin"
                },
                {
                    "authorId": "2253404812",
                    "name": "Patrick Lange"
                },
                {
                    "authorId": "2127354716",
                    "name": "Seokhwan Kim"
                },
                {
                    "authorId": "2253599901",
                    "name": "Nanyun Peng"
                },
                {
                    "authorId": "2240100316",
                    "name": "Yang Liu"
                },
                {
                    "authorId": "1395813836",
                    "name": "Dilek Z. Hakkani-T\u00fcr"
                }
            ]
        },
        {
            "paperId": "1658674b715e66ef3a8cf24369a1d1691580f4a9",
            "title": "CESAR: Automatic Induction of Compositional Instructions for Multi-turn Dialogs",
            "abstract": "Instruction-based multitasking has played a critical role in the success of large language models (LLMs) in multi-turn dialog applications. While publicly available LLMs have shown promising performance, when exposed to complex instructions with multiple constraints, they lag against state-of-the-art models like ChatGPT. In this work, we hypothesize that the availability of large-scale complex demonstrations is crucial in bridging this gap. Focusing on dialog applications, we propose a novel framework, CESAR, that unifies a large number of dialog tasks in the same format and allows programmatic induction of complex instructions without any manual effort. We apply CESAR on InstructDial, a benchmark for instruction-based dialog tasks. We further enhance InstructDial with new datasets and tasks and utilize CESAR to induce complex tasks with compositional instructions. This results in a new benchmark called InstructDial++, which includes 63 datasets with 86 basic tasks and 68 composite tasks. Through rigorous experiments, we demonstrate the scalability of CESAR in providing rich instructions. Models trained on InstructDial++ can follow compositional prompts, such as prompts that ask for multiple stylistic constraints.",
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "authors": [
                {
                    "authorId": "2051712707",
                    "name": "Taha \u0130brahim Aksu"
                },
                {
                    "authorId": "8223433",
                    "name": "Devamanyu Hazarika"
                },
                {
                    "authorId": "32251567",
                    "name": "Shikib Mehri"
                },
                {
                    "authorId": "2127354716",
                    "name": "Seokhwan Kim"
                },
                {
                    "authorId": "1395813836",
                    "name": "Dilek Z. Hakkani-T\u00fcr"
                },
                {
                    "authorId": "2268312533",
                    "name": "Yang Liu"
                },
                {
                    "authorId": "2171886",
                    "name": "Mahdi Namazifar"
                }
            ]
        },
        {
            "paperId": "1c013a05bd429467f4a94f7dca18b83769d0b17b",
            "title": "Multimodal Embodied Plan Prediction Augmented with Synthetic Embodied Dialogue",
            "abstract": ",",
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "authors": [
                {
                    "authorId": "2110665",
                    "name": "Aishwarya Padmakumar"
                },
                {
                    "authorId": "2253599252",
                    "name": "Mert Inan"
                },
                {
                    "authorId": "2921001",
                    "name": "Spandana Gella"
                },
                {
                    "authorId": "2253404812",
                    "name": "Patrick Lange"
                },
                {
                    "authorId": "1395813836",
                    "name": "Dilek Z. Hakkani-T\u00fcr"
                }
            ]
        },
        {
            "paperId": "1d75f8de31bf47ec46fa5586056420ec8bc97e86",
            "title": "Using In-Context Learning to Improve Dialogue Safety",
            "abstract": "While large neural-based conversational models have become increasingly proficient dialogue agents, recent work has highlighted safety issues with these systems. For example, these systems can be goaded into generating toxic content, which often perpetuates social biases or stereotypes. We investigate a retrieval-based method for reducing bias and toxicity in responses from chatbots. It uses in-context learning to steer a model towards safer generations. Concretely, to generate a response to an unsafe dialogue context, we retrieve demonstrations of safe responses to similar dialogue contexts. We find our method performs competitively with strong baselines without requiring training. For instance, using automatic evaluation, we find our best fine-tuned baseline only generates safe responses to unsafe dialogue contexts from DiaSafety 4.04% more than our approach. Finally, we also propose a re-ranking procedure which can further improve response safeness.",
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "authors": [
                {
                    "authorId": "150247363",
                    "name": "Nicholas Meade"
                },
                {
                    "authorId": "2921001",
                    "name": "Spandana Gella"
                },
                {
                    "authorId": "8223433",
                    "name": "Devamanyu Hazarika"
                },
                {
                    "authorId": "1491232062",
                    "name": "Prakhar Gupta"
                },
                {
                    "authorId": "2152284471",
                    "name": "Di Jin"
                },
                {
                    "authorId": "145732771",
                    "name": "Siva Reddy"
                },
                {
                    "authorId": "2152797401",
                    "name": "Yang Liu"
                },
                {
                    "authorId": "1395813836",
                    "name": "Dilek Z. Hakkani-T\u00fcr"
                }
            ]
        },
        {
            "paperId": "2ad96c799edcbba5b097c8842461f0d9da4aa1cc",
            "title": "Identifying Entrainment in Task-Oriented Conversations",
            "abstract": "Human interlocutors adapt their behavior to each other in a conversation through entrainment. While entrainment has been found in long chit-chat conversations, much less research has been conducted on task-oriented dialogs. In this paper, we investigate short task-oriented Wizard-of-Oz conversations for acoustic-prosodic and lexical entrainment. We conduct significance tests that reveal changes in speech pitch and frequent words as important indicators of entrainment. Our findings will guide user-entraining dialog systems to improve the quality of conversations.",
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "authors": [
                {
                    "authorId": "2188747624",
                    "name": "Run Chen"
                },
                {
                    "authorId": "2127354716",
                    "name": "Seokhwan Kim"
                },
                {
                    "authorId": "1710287",
                    "name": "A. Papangelis"
                },
                {
                    "authorId": "32057282",
                    "name": "J. Hirschberg"
                },
                {
                    "authorId": "2152797401",
                    "name": "Yang Liu"
                },
                {
                    "authorId": "1395813836",
                    "name": "Dilek Z. Hakkani-T\u00fcr"
                }
            ]
        },
        {
            "paperId": "40881c6184ed58c40c211223ad884da7b24122ee",
            "title": "Twenty-Five Years of Evolution in Speech and Language Processing",
            "abstract": "In this article, we summarize the evolution of speech and language processing (SLP) in the past 25 years. We first provide a snapshot of popular research topics and the associated state of the art (SOTA) in various subfields of SLP 25 years ago, and then highlight the shift in research topics over the years. We describe the major breakthroughs in each of the subfields and the main driving forces that led us to the SOTA today. Societal impacts and potential future directions are also discussed.",
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "authors": [
                {
                    "authorId": "144580027",
                    "name": "Dong Yu"
                },
                {
                    "authorId": "1777280",
                    "name": "Y. Gong"
                },
                {
                    "authorId": "1774515",
                    "name": "M. Picheny"
                },
                {
                    "authorId": "1720857",
                    "name": "B. Ramabhadran"
                },
                {
                    "authorId": "1395813836",
                    "name": "Dilek Z. Hakkani-T\u00fcr"
                },
                {
                    "authorId": "36073757",
                    "name": "R. Prasad"
                },
                {
                    "authorId": "1691713",
                    "name": "H. Zen"
                },
                {
                    "authorId": "1982210",
                    "name": "J. Skoglund"
                },
                {
                    "authorId": "1899242",
                    "name": "J. \u010cernock\u00fd"
                },
                {
                    "authorId": "1816892",
                    "name": "L. Burget"
                },
                {
                    "authorId": "40360972",
                    "name": "Abdel-rahman Mohamed"
                }
            ]
        },
        {
            "paperId": "51879aeb001a8397253755247ccd6507d64d2403",
            "title": "Role of Bias Terms in Dot-Product Attention",
            "abstract": "Dot-product attention is a core module in the present generation of neural network models, particularly transformers, and is being leveraged across numerous areas such as natural language processing and computer vision. This attention module is comprised of three linear transformations, namely query, key, and value linear transformations, each of which has a bias term. In this work, we study the role of these bias terms, and mathematically show that the bias term of the key linear transformation is redundant and could be omitted without any impact on the attention module. Moreover, we argue that the bias term of the value linear transformation has a more prominent role than that of the bias term of the query linear transformation. We empirically verify these findings through multiple experiments on language modeling, natural language understanding, and natural language generation tasks.",
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "authors": [
                {
                    "authorId": "2171886",
                    "name": "Mahdi Namazifar"
                },
                {
                    "authorId": "8223433",
                    "name": "Devamanyu Hazarika"
                },
                {
                    "authorId": "1395813836",
                    "name": "Dilek Z. Hakkani-T\u00fcr"
                }
            ]
        }
    ]
}