{
    "authorId": "2113540586",
    "papers": [
        {
            "paperId": "147ae6a90f69a6fdd4e8877075ea732ff72c6a47",
            "title": "Crafting Training Degradation Distribution for the Accuracy-Generalization Trade-off in Real-World Super-Resolution",
            "abstract": "Super-resolution (SR) techniques designed for real-world applications commonly encounter two primary challenges: generalization performance and restoration accuracy. We demonstrate that when methods are trained using complex, large-range degradations to enhance generalization, a decline in accuracy is inevitable. However, since the degradation in a certain real-world applications typically exhibits a limited variation range, it becomes feasible to strike a trade-off between generalization performance and testing accuracy within this scope. In this work, we introduce a novel approach to craft training degradation distributions using a small set of reference images. Our strategy is founded upon the binned representation of the degradation space and the Fr\\'echet distance between degradation distributions. Our results indicate that the proposed technique significantly improves the performance of test images while preserving generalization capabilities in real-world applications.",
            "fieldsOfStudy": [
                "Computer Science",
                "Engineering"
            ],
            "authors": [
                {
                    "authorId": "2213488418",
                    "name": "Ruofan Zhang"
                },
                {
                    "authorId": "4398255",
                    "name": "Jinjin Gu"
                },
                {
                    "authorId": "2149051548",
                    "name": "Haoyu Chen"
                },
                {
                    "authorId": "2113540586",
                    "name": "Chao Dong"
                },
                {
                    "authorId": "2410227",
                    "name": "Yulun Zhang"
                },
                {
                    "authorId": "2144833647",
                    "name": "Wenming Yang"
                }
            ]
        },
        {
            "paperId": "a317231b6ee33be295e48e43af91172a085ec456",
            "title": "ITstyler: Image-optimized Text-based Style Transfer",
            "abstract": "Text-based style transfer is a newly-emerging research topic that uses text information instead of style image to guide the transfer process, significantly extending the application scenario of style transfer. However, previous methods require extra time for optimization or text-image paired data, leading to limited effectiveness. In this work, we achieve a data-efficient text-based style transfer method that does not require optimization at the inference stage. Specifically, we convert text input to the style space of the pre-trained VGG network to realize a more effective style swap. We also leverage CLIP's multi-modal embedding space to learn the text-to-style mapping with the image dataset only. Our method can transfer arbitrary new styles of text input in real-time and synthesize high-quality artistic images.",
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "authors": [
                {
                    "authorId": "48442720",
                    "name": "Yun-Hao Bai"
                },
                {
                    "authorId": "2108357670",
                    "name": "Jiayue Liu"
                },
                {
                    "authorId": "2113540586",
                    "name": "Chao Dong"
                },
                {
                    "authorId": "2175625059",
                    "name": "Chun Yuan"
                }
            ]
        },
        {
            "paperId": "bf5361001178ab662f153e203c4c9c17315e4e31",
            "title": "Networks are Slacking Off: Understanding Generalization Problem in Image Deraining",
            "abstract": "Deep deraining networks consistently encounter substantial generalization issues when deployed in real-world applications, although they are successful in laboratory benchmarks. A prevailing perspective in deep learning encourages using highly complex data for training, with the expectation that richer image background content will facilitate overcoming the generalization problem. However, through comprehensive and systematic experimentation, we discover that this strategy does not enhance the generalization capability of these networks. On the contrary, it exacerbates the tendency of networks to overfit specific degradations. Our experiments reveal that better generalization in a deraining network can be achieved by simplifying the complexity of the training background images. This is because that the networks are ``slacking off'' during training, that is, learning the least complex elements in the image background and degradation to minimize training loss. When the background images are less complex than the rain streaks, the network will prioritize the background reconstruction, thereby suppressing overfitting the rain patterns and leading to improved generalization performance. Our research offers a valuable perspective and methodology for better understanding the generalization problem in low-level vision tasks and displays promising potential for practical application.",
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "authors": [
                {
                    "authorId": "4398255",
                    "name": "Jinjin Gu"
                },
                {
                    "authorId": "1387903470",
                    "name": "Xianzheng Ma"
                },
                {
                    "authorId": "48111874",
                    "name": "Xiangtao Kong"
                },
                {
                    "authorId": "145858545",
                    "name": "Y. Qiao"
                },
                {
                    "authorId": "2113540586",
                    "name": "Chao Dong"
                }
            ]
        },
        {
            "paperId": "e8422c9883b15da884c9a095fe79be48a41ff4b8",
            "title": "TextIR: A Simple Framework for Text-based Editable Image Restoration",
            "abstract": "Most existing image restoration methods use neural networks to learn strong image-level priors from huge data to estimate the lost information. However, these works still struggle in cases when images have severe information deficits. Introducing external priors or using reference images to provide information also have limitations in the application domain. In contrast, text input is more readily available and provides information with higher flexibility. In this work, we design an effective framework that allows the user to control the restoration process of degraded images with text descriptions. We use the text-image feature compatibility of the CLIP to alleviate the difficulty of fusing text and image features. Our framework can be used for various image restoration tasks, including image inpainting, image super-resolution, and image colorization. Extensive experiments demonstrate the effectiveness of our method.",
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "authors": [
                {
                    "authorId": "48442720",
                    "name": "Yun-Hao Bai"
                },
                {
                    "authorId": "47073960",
                    "name": "Cairong Wang"
                },
                {
                    "authorId": "148165054",
                    "name": "Shuzhao Xie"
                },
                {
                    "authorId": "2113540586",
                    "name": "Chao Dong"
                },
                {
                    "authorId": "2175625059",
                    "name": "Chun Yuan"
                },
                {
                    "authorId": "2108388274",
                    "name": "Zhi Wang"
                }
            ]
        },
        {
            "paperId": "18981e60887244d898f00ef60738eaeae1453f76",
            "title": "Graph-Based Tri-Attention Network for Answer Ranking in CQA",
            "abstract": "In community-based question answering (CQA) platforms, automatic answer ranking for a given question is critical for finding potentially popular answers in early times. The mainstream approaches learn to generate answer ranking scores based on the matching degree between question and answer representations as well as the influence of respondents. However, they encounter two main limitations: (1) Correlations between answers in the same question are often overlooked. (2) Question and respondent representations are built independently of specific answers before affecting answer representations. To address the limitations, we devise a novel graph-based tri-attention network, namely GTAN, which has two innovations. First, GTAN proposes to construct a graph for each question and learn answer correlations from each graph through graph neural networks (GNNs). Second, based on the representations learned from GNNs, an alternating tri-attention method is developed to alternatively build target-aware respondent representations, answer-specific question representations, and context-aware answer representations by attention computation. GTAN finally integrates the above representations to generate answer ranking scores. Experiments on three real-world CQA datasets demonstrate GTAN significantly outperforms state-of-the-art answer ranking methods, validating the rationality of the network architecture.",
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "authors": [
                {
                    "authorId": "2155468861",
                    "name": "Wei Zhang"
                },
                {
                    "authorId": "5478513",
                    "name": "Zeyuan Chen"
                },
                {
                    "authorId": "2113540586",
                    "name": "Chao Dong"
                },
                {
                    "authorId": "2108908267",
                    "name": "Wen Wang"
                },
                {
                    "authorId": "145203884",
                    "name": "H. Zha"
                },
                {
                    "authorId": "2447408",
                    "name": "Jianyong Wang"
                }
            ]
        },
        {
            "paperId": "290a3745559348405ae2e440eaea52bfc466663d",
            "title": "Attentive Representation Learning With Adversarial Training for Short Text Clustering",
            "abstract": "Short text clustering has far-reaching effects on semantic analysis, showing its importance for multiple applications such as corpus summarization and information retrieval. However, it inevitably encounters the severe sparsity of short text representations, making the previous clustering approaches still far from satisfactory. In this paper, we present a novel attentive representation learning model for shot text clustering, wherein cluster-level attention is proposed to capture the correlations between text representations and cluster representations. Relying on this, the representation learning and clustering for short texts are seamlessly integrated into a unified model. To further ensure robust model training for short texts, we apply adversarial training to the unsupervised clustering setting, by injecting perturbations into the cluster representations. The model parameters and perturbations are optimized alternately through a minimax game. Extensive experiments on four real-world short text datasets demonstrate the superiority of the proposed model over several strong competitors, verifying that robust adversarial training yields substantial performance gains.",
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "authors": [
                {
                    "authorId": "47528034",
                    "name": "Wei Zhang"
                },
                {
                    "authorId": "2113540586",
                    "name": "Chao Dong"
                },
                {
                    "authorId": "2051685317",
                    "name": "Jianhua Yin"
                },
                {
                    "authorId": "2447408",
                    "name": "Jianyong Wang"
                }
            ]
        },
        {
            "paperId": "d07110cb6c1d78d642c3069834b6b52ff8ce37b0",
            "title": "Inferring event geolocation based on Twitter",
            "abstract": "With the rapid development of Internet, more and more new events break first in social media. Some studies are now carried out on detecting events in real-time on social media like Twitter. Inferring the geolocation of events is an important problem for better understanding the events. In this work, we develop a multi-level method to infer the event location. We leverage coordinates, text content and geographical knowledge into geolocation inference algorithm to tackle this problem. In addition we construct a World City data set and propose a location prediction model to infer single tweet location as a supplement to the algorithm.",
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "authors": [
                {
                    "authorId": "2056106401",
                    "name": "Yue Ying"
                },
                {
                    "authorId": "2113568231",
                    "name": "Chen Peng"
                },
                {
                    "authorId": "2113540586",
                    "name": "Chao Dong"
                },
                {
                    "authorId": "2153493864",
                    "name": "Yang Li"
                },
                {
                    "authorId": "2115389411",
                    "name": "Yan Feng"
                }
            ]
        },
        {
            "paperId": "d0768ff216ca7906c936ec8a44d3a86b7c1ad6f7",
            "title": "Modeling Rich Contexts for Sentiment Classification with LSTM",
            "abstract": "Sentiment analysis on social media data such as tweets and weibo has become a very important and challenging task. Due to the intrinsic properties of such data, tweets are short, noisy, and of divergent topics, and sentiment classification on these data requires to modeling various contexts such as the retweet/reply history of a tweet, and the social context about authors and relationships. While few prior study has approached the issue of modeling contexts in tweet, this paper proposes to use a hierarchical LSTM to model rich contexts in tweet, particularly long-range context. Experimental results show that contexts can help us to perform sentiment classification remarkably better.",
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "authors": [
                {
                    "authorId": "1730108",
                    "name": "Minlie Huang"
                },
                {
                    "authorId": "2112824029",
                    "name": "Yujie Cao"
                },
                {
                    "authorId": "2113540586",
                    "name": "Chao Dong"
                }
            ]
        }
    ]
}