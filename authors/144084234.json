{
    "authorId": "144084234",
    "papers": [
        {
            "paperId": "06d328e3e0f021be3910b9adf6cd6f5a03ebb982",
            "title": "Community Question Answering Entity Linking via Leveraging Auxiliary Data",
            "abstract": "Community Question Answering (CQA) platforms contain plenty of CQA texts (i.e., questions and answers corresponding to the question) where named entities appear ubiquitously. In this paper, we define a new task of CQA entity linking (CQAEL) as linking the textual entity mentions detected from CQA texts with their corresponding entities in a knowledge base. This task can facilitate many downstream applications including expert finding and knowledge base enrichment. Traditional entity linking methods mainly focus on linking entities in news documents, and are suboptimal over this new task of CQAEL since they cannot effectively leverage various informative auxiliary data involved in the CQA platform to aid entity linking, such as parallel answers and two types of meta-data (i.e., topic tags and users). To remedy this crucial issue, we propose a novel transformer-based framework to effectively harness the knowledge delivered by different kinds of auxiliary data to promote the linking performance. We validate the superiority of our framework through extensive experiments over a newly released CQAEL data set against state-of-the-art entity linking methods.",
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "authors": [
                {
                    "authorId": "2110539208",
                    "name": "Yuhan Li"
                },
                {
                    "authorId": "144084234",
                    "name": "Wei Shen"
                },
                {
                    "authorId": "1810902946",
                    "name": "Jianbo Gao"
                },
                {
                    "authorId": "2107999689",
                    "name": "Yadong Wang"
                }
            ]
        },
        {
            "paperId": "111a2d82fc79ba4679541260594177d1c2117659",
            "title": "Multi-View Clustering for Open Knowledge Base Canonicalization",
            "abstract": "Open information extraction (OIE) methods extract plenty of OIE triples  from unstructured text, which compose large open knowledge bases (OKBs). Noun phrases and relation phrases in such OKBs are not canonicalized, which leads to scattered and redundant facts. It is found that two views of knowledge (i.e., a fact view based on the fact triple and a context view based on the fact triple's source context) provide complementary information that is vital to the task of OKB canonicalization, which clusters synonymous noun phrases and relation phrases into the same group and assigns them unique identifiers. However, these two views of knowledge have so far been leveraged in isolation by existing works. In this paper, we propose CMVC, a novel unsupervised framework that leverages these two views of knowledge jointly for canonicalizing OKBs without the need of manually annotated labels. To achieve this goal, we pro- pose a multi-view CH K-Means clustering algorithm to mutually reinforce the clustering of view-specific embeddings learned from each view by considering their different clustering qualities. In order to further enhance the canonicalization performance, we propose a training data optimization strategy in terms of data quantity and data quality respectively in each particular view to refine the learned view-specific embeddings in an iterative manner. Additionally, we propose a Log-Jump algorithm to predict the optimal number of clusters in a data-driven way without requiring any labels. We demonstrate the superiority of our framework through extensive experiments on multiple real-world OKB data sets against state-of-the-art methods.",
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "authors": [
                {
                    "authorId": "144084234",
                    "name": "Wei Shen"
                },
                {
                    "authorId": "2152920501",
                    "name": "Yang Yang"
                },
                {
                    "authorId": "119924024",
                    "name": "Yinan Liu"
                }
            ]
        },
        {
            "paperId": "4576a20af20e58d461ef5179bb321be00250999c",
            "title": "Personal Attribute Prediction from Conversations",
            "abstract": "Personal knowledge bases (PKBs) are critical to many applications, such as Web-based chatbots and personalized recommendation. Conversations containing rich personal knowledge can be regarded as a main source to populate the PKB. Given a user, a user attribute, and user utterances from a conversational system, we aim to predict the personal attribute value for the user, which is helpful for the enrichment of PKBs. However, there are three issues existing in previous studies: (1) manually labeled utterances are required for model training; (2) personal attribute knowledge embedded in both utterances and external resources is underutilized; (3) the performance on predicting some difficult personal attributes is unsatisfactory. In this paper, we propose a framework DSCGN based on the pre-trained language model with a noise-robust loss function to predict personal attributes from conversations without requiring any labeled utterances. We yield two categories of supervision, i.e., document-level supervision via a distant supervision strategy and contextualized word-level supervision via a label guessing method, by mining the personal attribute knowledge embedded in both unlabeled utterances and external resources to fine-tune the language model. Extensive experiments over two real-world data sets (i.e., a profession data set and a hobby data set) show our framework obtains the best performance compared with all the twelve baselines in terms of nDCG and MRR.",
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "authors": [
                {
                    "authorId": "119924024",
                    "name": "Yinan Liu"
                },
                {
                    "authorId": "2157128693",
                    "name": "Hu Chen"
                },
                {
                    "authorId": "144084234",
                    "name": "Wei Shen"
                }
            ]
        },
        {
            "paperId": "4d5326408cc5b894fd4e2cc36e3aa5ee4bb2f1c2",
            "title": "Learning Entity Linking Features for Emerging Entities",
            "abstract": "Entity linking (EL) is the process of linking entity mentions appearing in text with their corresponding entities in a knowledge base. EL features of entities (e.g., prior probability, relatedness score, and entity embedding) are usually estimated based on Wikipedia. However, for newly emerging entities (EEs) which have just been discovered in news, they may still not be included in Wikipedia yet. As a consequence, it is unable to obtain required EL features for those EEs from Wikipedia and EL models will always fail to link ambiguous mentions with those EEs correctly as the absence of their EL features. To deal with this problem, in this paper we focus on a new task of learning EL features for emerging entities in a general way. We propose a novel approach called STAMO to learn high-quality EL features for EEs automatically, which needs just a small number of labeled documents for each EE collected from the Web, as it could further leverage the knowledge hidden in the unlabeled data. STAMO is mainly based on self-training, which makes it flexibly integrated with any EL feature or EL model, but also makes it easily suffer from the error reinforcement problem caused by the mislabeled data. Instead of some common self-training strategies that try to throw the mislabeled data away explicitly, we regard self-training as a multiple optimization process with respect to the EL features of EEs, and propose both intra-slot and inter-slot optimizations to alleviate the error reinforcement problem implicitly. We construct two EL datasets involving selected EEs to evaluate the quality of obtained EL features for EEs, and the experimental results show that our approach significantly outperforms other baseline methods of learning EL features.",
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "authors": [
                {
                    "authorId": "3011549",
                    "name": "Chenwei Ran"
                },
                {
                    "authorId": "144084234",
                    "name": "Wei Shen"
                },
                {
                    "authorId": "1810902946",
                    "name": "Jianbo Gao"
                },
                {
                    "authorId": "2110539208",
                    "name": "Yuhan Li"
                },
                {
                    "authorId": "2447408",
                    "name": "Jianyong Wang"
                },
                {
                    "authorId": "2861442",
                    "name": "Yantao Jia"
                }
            ]
        },
        {
            "paperId": "f1e588f1fc1e6456c7ec14a984c630ef58f8df9c",
            "title": "Low-resource Personal Attribute Prediction from Conversation",
            "abstract": "Personal knowledge bases (PKBs) are crucial for a broad range of applications such as personalized recommendation and Web-based chatbots. A critical challenge to build PKBs is extracting personal attribute knowledge from users' conversation data. Given some users of a conversational system, a personal attribute and these users' utterances, our goal is to predict the ranking of the given personal attribute values for each user. Previous studies often rely on a relative number of resources such as labeled utterances and external data, yet the attribute knowledge embedded in unlabeled utterances is underutilized and their performance of predicting some difficult personal attributes is still unsatisfactory. In addition, it is found that some text classification methods could be employed to resolve this task directly. However, they also perform not well over those difficult personal attributes. In this paper, we propose a novel framework PEARL to predict personal attributes from conversations by leveraging the abundant personal attribute knowledge from utterances under a low-resource setting in which no labeled utterances or external data are utilized. PEARL combines the biterm semantic information with the word co-occurrence information seamlessly via employing the updated prior attribute knowledge to refine the biterm topic model's Gibbs sampling process in an iterative manner. The extensive experimental results show that PEARL outperforms all the baseline methods not only on the task of personal attribute prediction from conversations over two data sets, but also on the more general weakly supervised text classification task over one data set.",
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "authors": [
                {
                    "authorId": "119924024",
                    "name": "Yinan Liu"
                },
                {
                    "authorId": "2157128751",
                    "name": "H. Chen"
                },
                {
                    "authorId": "144084234",
                    "name": "Wei Shen"
                },
                {
                    "authorId": "1731892",
                    "name": "Jiaoyan Chen"
                }
            ]
        },
        {
            "paperId": "ffeb482b80aa8ed0df595ffc6f17508b2672b808",
            "title": "Toward Tweet Entity Linking With Heterogeneous Information Networks",
            "abstract": "Twitter, a microblogging platform, has developed into an increasingly invaluable information source, where millions of users post a great quantity of tweets with various topics per day. Heterogeneous information networks consisting of multi-type objects and relations are becoming more and more prevalent as an organization form of knowledge and information. The task of linking an entity mention in a tweet with its corresponding entity in a heterogeneous information network is of great importance, for the purpose of enriching heterogeneous information networks with the abundant and fresh knowledge embedded in tweets. However, the entity mention is ambiguous. Additionally, tweets are short and informal, making it difficult to mine enough information from a single tweet for entity linking. In this paper, we propose an unsupervised iterative clustering framework TELHIN to link multiple similar tweets with a heterogeneous information network jointly. Our framework takes three dimensions of tweet similarity into consideration: (1) content similarity, (2) temporal similarity, and (3) user similarity. The appropriate weights of different similarity dimensions for each entity mention are learned iteratively based on the metric learning algorithm by leveraging the pairwise constraints generated automatically. Experiments on real data demonstrate the effectiveness of our framework in comparison with the baselines.",
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "authors": [
                {
                    "authorId": "144084234",
                    "name": "Wei Shen"
                },
                {
                    "authorId": null,
                    "name": "Yuwei Yin"
                },
                {
                    "authorId": "2152920501",
                    "name": "Yang Yang"
                },
                {
                    "authorId": "145325584",
                    "name": "Jiawei Han"
                },
                {
                    "authorId": "2447408",
                    "name": "Jianyong Wang"
                },
                {
                    "authorId": "1721029",
                    "name": "Xiaojie Yuan"
                }
            ]
        },
        {
            "paperId": "c24cbe99bfde5bea6adda58edaf4471794f2852c",
            "title": "Joint Open Knowledge Base Canonicalization and Linking",
            "abstract": "Open Information Extraction (OIE) methods extract a large number of OIE triples (noun phrase, relation phrase, noun phrase) from text, which compose large Open Knowledge Bases (OKBs). However, noun phrases (NPs) and relation phrases (RPs) in OKBs are not canonicalized and often appear in different paraphrased textual variants, which leads to redundant and ambiguous facts. To address this problem, there are two related tasks: OKB canonicalization (i.e., convert NPs and RPs to canonicalized form) and OKB linking (i.e., link NPs and RPs with their corresponding entities and relations in a curated Knowledge Base (e.g., DBPedia). These two tasks are tightly coupled, and one task can benefit significantly from the other. However, they have been studied in isolation so far. In this paper, we explore the task of joint OKB canonicalization and linking for the first time, and propose a novel framework JOCL based on factor graph model to make them reinforce each other. JOCL is flexible enough to combine different signals from both tasks, and able to extend to fit any new signals. A thorough experimental study over two large scale OIE triple data sets shows that our framework outperforms all the baseline methods for the task of OKB canonicalization (OKB linking) in terms of average F1 (accuracy).",
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "authors": [
                {
                    "authorId": "119924024",
                    "name": "Yinan Liu"
                },
                {
                    "authorId": "144084234",
                    "name": "Wei Shen"
                },
                {
                    "authorId": "2146017601",
                    "name": "Yuanfei Wang"
                },
                {
                    "authorId": "2447408",
                    "name": "Jianyong Wang"
                },
                {
                    "authorId": "2149231521",
                    "name": "Zhenglu Yang"
                },
                {
                    "authorId": "1721029",
                    "name": "Xiaojie Yuan"
                }
            ]
        },
        {
            "paperId": "463b036ce4468cd59186c7ce3a3182684acd414c",
            "title": "Predicting Named Entity Location Using Twitter",
            "abstract": "A knowledge base contains a set of concepts, entities, attributes, and relations. Knowledge bases are increasingly critical to a wide variety of applications in both industry and academia. Yet despite all that, knowledge bases are greatly incomplete. As the world evolves, new entities are generated. Enriching existing knowledge bases with new entities and new location attribute values for them becomes more and more important. Twitter is one of the most popular micro-blogging platforms. Named entities are mentioned frequently in the huge collection of tweets which contain abundant geographical location knowledge. Given a named entity and a set of tweets where the entity appears, we are interested in predicting the entity city-level location using the knowledge embedded in tweets. This task is helpful for many applications such as knowledge base enrichment, tweet location prediction, and entity search. In this paper we propose NELPT, the first unsupervised framework for Named Entity city-level Location Prediction by leveraging the geographical location knowledge from Twitter. This framework leverages a Linear Neural Network model as the predictive model combining two categories of information: (1) local count information; (2) global distributional information. A learning algorithm based on the expectation-maximization (EM) method is proposed to automatically learn the parameters of the Linear Neural Network predictive model without requiring any training data. The experimental results on a real world Twitter data set show that our framework significantly outperforms the baselines in terms of accuracy, and scales very well.",
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "authors": [
                {
                    "authorId": "144084234",
                    "name": "Wei Shen"
                },
                {
                    "authorId": "119924024",
                    "name": "Yinan Liu"
                },
                {
                    "authorId": "2447408",
                    "name": "Jianyong Wang"
                }
            ]
        },
        {
            "paperId": "83424547f1b06e33e51487e12e624e15320b4b10",
            "title": "SHINE+: A General Framework for Domain-Specific Entity Linking with Heterogeneous Information Networks",
            "abstract": "Heterogeneous information networks that consist of multi-type, interconnected objects are becoming increasingly popular, such as social media networks and bibliographic networks. The task of linking named entity mentions detected from unstructured Web text with their corresponding entities in a heterogeneous information network is of practical importance for the problem of information network population. This task is challenging due to name ambiguity and limited knowledge existing in the network. Most existing entity linking methods focus on linking entities with Wikipedia and cannot be applied to our task. In this paper, we present SHINE+, a general framework for linking named entitieS in Web free text with a Heterogeneous I nformation NEtwork. We propose a probabilistic linking model, which unifies an entity popularity model with an entity object model. As the entity knowledge contained in the information network is insufficient, we propose a knowledge population algorithm to iteratively enrich the network entity knowledge by leveraging the context information of mentions mapped by the linking model with high confidence, which subsequently boosts the linking performance. Experimental results over two real heterogeneous information networks (i.e., DBLP and IMDb) demonstrate the effectiveness and efficiency of our proposed framework in comparison with the baselines.",
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "authors": [
                {
                    "authorId": "144084234",
                    "name": "Wei Shen"
                },
                {
                    "authorId": "145325584",
                    "name": "Jiawei Han"
                },
                {
                    "authorId": "2447408",
                    "name": "Jianyong Wang"
                },
                {
                    "authorId": "1721029",
                    "name": "Xiaojie Yuan"
                },
                {
                    "authorId": "2881049",
                    "name": "Zhenglu Yang"
                }
            ]
        },
        {
            "paperId": "8862f743fb17fc427934b6e442f3b5b440cbf362",
            "title": "An Attention Factor Graph Model for Tweet Entity Linking",
            "abstract": "The rapid expansion of Twitter has attracted worldwide attention. With more than 500 million tweets posted per day, Twitter becomes an invaluable information and knowledge source. Many Twitter related tasks have been studied, such as event extraction, hashtag recommendation, and topic detection. A critical step in understanding and mining information from Twitter is to disambiguate entities in tweets, i.e., tweet entity linking. It is a challenging task because tweets are short, noisy, and fresh. Many tweet-specific signals have been found to solve the tweet entity linking problem, such as user interest, temporal popularity, location information and so on. However, two common weaknesses exist in previous work. First, most proposed models are not flexible and extendable to fit new signals. Second, their scalability is not good enough to handle the large-scale social network like Twitter. In this work, we formalize the tweet entity linking problem into a factor graph model which has shown its effectiveness and efficiency in many other applications. We also propose selective attention over entities to increase the scalability of our model, which brings linear complexity. To adopt the attention mechanism in the factor graph, we propose a new type of nodes called pseudo-variable nodes to solve the asymmetry attention problem caused by the undirected characteristic of the factor graph. We evaluated our model on two different manually annotated tweet datasets. The experimental results show that our model achieves better performance in terms of both effectiveness and efficiency compared with the state-of-the-art approaches.",
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "authors": [
                {
                    "authorId": "3011549",
                    "name": "Chenwei Ran"
                },
                {
                    "authorId": "144084234",
                    "name": "Wei Shen"
                },
                {
                    "authorId": "2447408",
                    "name": "Jianyong Wang"
                }
            ]
        }
    ]
}