{
    "authorId": "2130595625",
    "papers": [
        {
            "paperId": "3d5f5a51ea8fca91f54b01727f7f6cb9b44b1030",
            "title": "Explainability for Transparent Conversational Information-Seeking",
            "abstract": "The increasing reliance on digital information necessitates advancements in conversational search systems, particularly in terms of information transparency. While prior research in conversational information-seeking has concentrated on improving retrieval techniques, the challenge remains in generating responses useful from a user perspective. This study explores different methods of explaining the responses, hypothesizing that transparency about the source of the information, system confidence, and limitations can enhance users' ability to objectively assess the response. By exploring transparency across explanation type, quality, and presentation mode, this research aims to bridge the gap between system-generated responses and responses verifiable by the user. We design a user study to answer questions concerning the impact of (1) the quality of explanations enhancing the response on its usefulness and (2) ways of presenting explanations to users. The analysis of the collected data reveals lower user ratings for noisy explanations, although these scores seem insensitive to the quality of the response. Inconclusive results on the explanations presentation format suggest that it may not be a critical factor in this setting.",
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "authors": [
                {
                    "authorId": "2130595625",
                    "name": "Weronika Lajewska"
                },
                {
                    "authorId": "1630446247",
                    "name": "Damiano Spina"
                },
                {
                    "authorId": "2528063",
                    "name": "Johanne R. Trippas"
                },
                {
                    "authorId": "1680484",
                    "name": "K. Balog"
                }
            ]
        },
        {
            "paperId": "7cda2b1dc91473f2abad7b044e1960bab059c295",
            "title": "Estimating the Usefulness of Clarifying Questions and Answers for Conversational Search",
            "abstract": "While the body of research directed towards constructing and generating clarifying questions in mixed-initiative conversational search systems is vast, research aimed at processing and comprehending users' answers to such questions is scarce. To this end, we present a simple yet effective method for processing answers to clarifying questions, moving away from previous work that simply appends answers to the original query and thus potentially degrades retrieval performance. Specifically, we propose a classifier for assessing usefulness of the prompted clarifying question and an answer given by the user. Useful questions or answers are further appended to the conversation history and passed to a transformer-based query rewriting module. Results demonstrate significant improvements over strong non-mixed-initiative baselines. Furthermore, the proposed approach mitigates the performance drops when non useful questions and answers are utilized.",
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "authors": [
                {
                    "authorId": "2278794364",
                    "name": "Ivan Sekuli'c"
                },
                {
                    "authorId": "2130595625",
                    "name": "Weronika Lajewska"
                },
                {
                    "authorId": "1680484",
                    "name": "K. Balog"
                },
                {
                    "authorId": "2278789548",
                    "name": "Fabio Crestani"
                }
            ]
        },
        {
            "paperId": "cc1ec702b227353c5f19fcad95338c3800e581e1",
            "title": "Towards Reliable and Factual Response Generation: Detecting Unanswerable Questions in Information-Seeking Conversations",
            "abstract": "Generative AI models face the challenge of hallucinations that can undermine users' trust in such systems. We approach the problem of conversational information seeking as a two-step process, where relevant passages in a corpus are identified first and then summarized into a final system response. This way we can automatically assess if the answer to the user's question is present in the corpus. Specifically, our proposed method employs a sentence-level classifier to detect if the answer is present, then aggregates these predictions on the passage level, and eventually across the top-ranked passages to arrive at a final answerability estimate. For training and evaluation, we develop a dataset based on the TREC CAsT benchmark that includes answerability labels on the sentence, passage, and ranking levels. We demonstrate that our proposed method represents a strong baseline and outperforms a state-of-the-art LLM on the answerability prediction task.",
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "authors": [
                {
                    "authorId": "2130595625",
                    "name": "Weronika Lajewska"
                },
                {
                    "authorId": "1680484",
                    "name": "K. Balog"
                }
            ]
        },
        {
            "paperId": "cb4ac54372b5029e66fd278d550732642fdf1306",
            "title": "From Baseline to Top Performer: A Reproducibility Study of Approaches at the TREC 2021 Conversational Assistance Track",
            "abstract": "This paper reports on an effort of reproducing the organizers' baseline as well as the top performing participant submission at the 2021 edition of the TREC Conversational Assistance track. TREC systems are commonly regarded as reference points for effectiveness comparison. Yet, the papers accompanying them have less strict requirements than peer-reviewed publications, which can make reproducibility challenging. Our results indicate that key practical information is indeed missing. While the results can be reproduced within a 19% relative margin with respect to the main evaluation measure, the relative difference between the baseline and the top performing approach shrinks from the reported 18% to 5%. Additionally, we report on a new set of experiments aimed at understanding the impact of various pipeline components. We show that end-to-end system performance can indeed benefit from advanced retrieval techniques in either stage of a two-stage retrieval pipeline. We also measure the impact of the dataset used for fine-tuning the query rewriter and find that employing different query rewriting methods in different stages of the retrieval pipeline might be beneficial. Moreover, these results are shown to generalize across the 2020 and 2021 editions of the track. We conclude our study with a list of lessons learned and practical suggestions.",
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "authors": [
                {
                    "authorId": "2130595625",
                    "name": "Weronika Lajewska"
                },
                {
                    "authorId": "1680484",
                    "name": "K. Balog"
                }
            ]
        },
        {
            "paperId": "fbbe8f9cdaaa7ef2dc9a15729ad8ac9ab8ee640b",
            "title": "Towards Filling the Gap in Conversational Search: From Passage Retrieval to Conversational Response Generation",
            "abstract": "Research on conversational search has so far mostly focused on query rewriting and multi-stage passage retrieval. However, synthesizing the top retrieved passages into a complete, relevant, and concise response is still an open challenge. Having snippet-level annotations of relevant passages would enable both (1) the training of response generation models that are able to ground answers in actual statements and (2) automatic evaluation of the generated responses in terms of completeness. In this paper, we address the problem of collecting high-quality snippet-level answer annotations for two of the TREC Conversational Assistance track datasets. To ensure quality, we first perform a preliminary annotation study, employing different task designs, crowdsourcing platforms, and workers with different qualifications. Based on the outcomes of this study, we refine our annotation protocol before proceeding with the full-scale data collection to gather annotations for 1.8k question-paragraph pairs. The process of collecting data at this magnitude also led to multiple insights about the problem that can inform the design of future response-generation methods.",
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "authors": [
                {
                    "authorId": "2130595625",
                    "name": "Weronika Lajewska"
                },
                {
                    "authorId": "1680484",
                    "name": "K. Balog"
                }
            ]
        },
        {
            "paperId": "0aa3a19301770579af278117a1a255dea758f9e2",
            "title": "ProtagonistTagger - a Tool for Entity Linkage of Persons in Texts from Various Languages and Domains",
            "abstract": "Named entities recognition (NER) and disambiguation (NED) can add semantic context to the recognized named entities in texts. Named entity linkage in texts, regardless of a domain, provides links between the entities mentioned in unstructured texts and individual instances of real-world objects. In this poster, we present a tool - protagonistTagger - for person NER and NED in texts. The tool was tested on texts extracted from classic English novels and Polish Internet news. The tool's performance (both precision and recall) fluctuates between 78% and even 88%.",
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "authors": [
                {
                    "authorId": "2130595625",
                    "name": "Weronika Lajewska"
                },
                {
                    "authorId": "143897180",
                    "name": "Anna Wr\u00f3blewska"
                }
            ]
        },
        {
            "paperId": "7d97bbecd10d6777b932830946d3c8d81e5c074a",
            "title": "The University of Stavanger (IAI) at the TREC 2022 Conversational Assistance Track",
            "abstract": ". This paper describes the participation of the IAI group at the University of Stavanger in the TREC 2022 Conversational Assistance track. We employ an established two-stage passage ranking architecture, i.e., first-pass passage retrieval (with standard BM25 ranking and pseudo-relevance feedback) followed by re-ranking (with mono and duo T5) using a rewritten query (with a T5 model fine-tuned on the CANARD dataset). In our runs, we experiment with intent classification based on MSDialog-Intent and term expansion using beam search scores for query rewriting as well as with clarifying questions for the mixed-initiative subtask.",
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "authors": [
                {
                    "authorId": "2130595625",
                    "name": "Weronika Lajewska"
                },
                {
                    "authorId": "1885345380",
                    "name": "Nolwenn Bernard"
                },
                {
                    "authorId": "2126525846",
                    "name": "Ivica Kostric"
                },
                {
                    "authorId": "3305422",
                    "name": "Ivan Sekulic"
                },
                {
                    "authorId": "1680484",
                    "name": "K. Balog"
                }
            ]
        },
        {
            "paperId": "95d02f5494d9e59c9d4fc85e644043784b1c5003",
            "title": "DAGFiNN: A Conversational Conference Assistant",
            "abstract": "DAGFiNN is a conversational conference assistant that can be made available for a given conference both as a chatbot on the website and as a Furhat robot physically exhibited at the conference venue. Conference participants can interact with the assistant to get advice on various questions, ranging from where to eat in the city or how to get to the airport to which sessions we recommend them to attend based on the information we have about them. The overall objective is to provide a personalized and engaging experience and allow users to ask a broad range of questions that naturally arise before and during the conference.",
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "authors": [
                {
                    "authorId": "2126525846",
                    "name": "Ivica Kostric"
                },
                {
                    "authorId": "1680484",
                    "name": "K. Balog"
                },
                {
                    "authorId": "2184741497",
                    "name": "T\u00f8ll\u00f8v Alexander Aresvik"
                },
                {
                    "authorId": "1885345380",
                    "name": "Nolwenn Bernard"
                },
                {
                    "authorId": "2184741495",
                    "name": "Eyvinn Thu D\u00f8rheim"
                },
                {
                    "authorId": "2184740750",
                    "name": "Pholit Hantula"
                },
                {
                    "authorId": "2184740852",
                    "name": "Sander Havn-S\u00f8rensen"
                },
                {
                    "authorId": "2184741218",
                    "name": "Rune Henriksen"
                },
                {
                    "authorId": "2184740931",
                    "name": "Hengameh Hosseini"
                },
                {
                    "authorId": "2184741492",
                    "name": "Ekaterina Khlybova"
                },
                {
                    "authorId": "2130595625",
                    "name": "Weronika Lajewska"
                },
                {
                    "authorId": "2184741549",
                    "name": "Sindre Ekrheim Mosand"
                },
                {
                    "authorId": "2094473560",
                    "name": "Narmin Orujova"
                }
            ]
        },
        {
            "paperId": "9ce53df67dd4e7110321cefdab9a36f0291a602a",
            "title": "Protagonists' Tagger in Literary Domain - New Datasets and a Method for Person Entity Linkage",
            "abstract": "Semantic annotation of long texts, such as novels, remains an open challenge in Natural Language Processing (NLP). This research investigates the problem of detecting person entities and assigning them unique identities, i.e., recognizing people (especially main characters) in novels. We prepared a method for person entity linkage (named entity recognition and disambiguation) and new testing datasets. The datasets comprise 1,300 sentences from 13 classic novels of different genres that a novel reader had manually annotated. Our process of identifying literary characters in a text, implemented in protagonistTagger, comprises two stages: (1) named entity recognition (NER) of persons, (2) named entity disambiguation (NED) - matching each recognized person with the literary character's full name, based on approximate text matching. The protagonistTagger achieves both precision and recall of above 83% on the prepared testing sets. Finally, we gathered a corpus of 13 full-text novels tagged with protagonistTagger that comprises more than 35,000 mentions of literary characters.",
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "authors": [
                {
                    "authorId": "2130595625",
                    "name": "Weronika Lajewska"
                },
                {
                    "authorId": "2065175441",
                    "name": "Anna Wr'oblewska"
                }
            ]
        }
    ]
}