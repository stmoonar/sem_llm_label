{
    "authorId": "2152939552",
    "papers": [
        {
            "paperId": "54ed1873f88feea868e6182d44b3c6ff8d69f71e",
            "title": "Backdoor Graph Condensation",
            "abstract": "Recently, graph condensation has emerged as a prevalent technique to improve the training efficiency for graph neural networks (GNNs). It condenses a large graph into a small one such that a GNN trained on this small synthetic graph can achieve comparable performance to a GNN trained on a large graph. However, while existing graph condensation studies mainly focus on the best trade-off between graph size and the GNNs' performance (model utility), the security issues of graph condensation have not been studied. To bridge this research gap, we propose the task of backdoor graph condensation. While graph backdoor attacks have been extensively explored, applying existing graph backdoor methods for graph condensation is not practical since they can undermine the model utility and yield low attack success rate. To alleviate these issues, we introduce two primary objectives for backdoor attacks against graph condensation: 1) the injection of triggers cannot affect the quality of condensed graphs, maintaining the utility of GNNs trained on them; and 2) the effectiveness of triggers should be preserved throughout the condensation process, achieving high attack success rate. To pursue the objectives, we devise the first backdoor attack against graph condensation, denoted as BGC. Specifically, we inject triggers during condensation and iteratively update the triggers to ensure effective attacks. Further, we propose a poisoned node selection module to minimize the influence of triggers on condensed graphs' quality. The extensive experiments demonstrate the effectiveness of our attack. BGC achieves a high attack success rate (close to 1.0) and good model utility in all cases. Furthermore, the results demonstrate our method's resilience against multiple defense methods. Finally, we conduct comprehensive studies to analyze the factors that influence the attack performance.",
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "authors": [
                {
                    "authorId": "2109164978",
                    "name": "Jiahao Wu"
                },
                {
                    "authorId": "2147128045",
                    "name": "Ning Lu"
                },
                {
                    "authorId": "2311579404",
                    "name": "Zeiyu Dai"
                },
                {
                    "authorId": "2291324376",
                    "name": "Wenqi Fan"
                },
                {
                    "authorId": "2152939552",
                    "name": "Shengcai Liu"
                },
                {
                    "authorId": "2254366521",
                    "name": "Qing Li"
                },
                {
                    "authorId": "2253405825",
                    "name": "Ke Tang"
                }
            ]
        },
        {
            "paperId": "7ab1d8101c500c4ae2d265e26c7bf1fb4d4eeb77",
            "title": "Learning Mixture-of-Experts for General-Purpose Black-Box Discrete Optimization",
            "abstract": "Real-world applications involve various discrete optimization problems. Designing a specialized optimizer for each of these problems is challenging, typically requiring significant domain knowledge and human efforts. Hence, developing general-purpose optimizers as an off-the-shelf tool for a wide range of problems has been a long-standing research target. This article introduces MEGO, a novel general-purpose neural optimizer trained through a fully data-driven learning-to-optimize (L2O) approach. MEGO consists of a mixture-of-experts trained on experiences from solving training problems and can be viewed as a foundation model for optimization problems with binary decision variables. When presented with a problem to solve, MEGO actively selects relevant expert models to generate high-quality solutions. MEGO can be used as a standalone sample-efficient optimizer or in conjunction with existing search methods as an initial solution generator. The generality of MEGO is validated across six problem classes, including three classic problem classes and three problem classes arising from real-world applications in compilers, network analysis, and 3D reconstruction. Trained solely on classic problem classes, MEGO performs very well on all six problem classes, significantly surpassing widely used general-purpose optimizers in both solution quality and efficiency. In some cases, MEGO even surpasses specialized state-of-the-art optimizers. Additionally, MEGO provides a similarity measure between problems, yielding a new perspective for problem classification. In the pursuit of general-purpose optimizers through L2O, MEGO represents an initial yet significant step forward.",
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "authors": [
                {
                    "authorId": "2152939552",
                    "name": "Shengcai Liu"
                },
                {
                    "authorId": "2303678294",
                    "name": "Zhiyuan Wang"
                },
                {
                    "authorId": "101252726",
                    "name": "Y. Ong"
                },
                {
                    "authorId": "2258303878",
                    "name": "Xin Yao"
                },
                {
                    "authorId": "2241100351",
                    "name": "Ke Tang"
                }
            ]
        },
        {
            "paperId": "9827ada804719c60f59e439049303ba591dd9166",
            "title": "Towards Geometry-Aware Pareto Set Learning for Neural Multi-Objective Combinatorial Optimization",
            "abstract": "Multi-objective combinatorial optimization (MOCO) problems are prevalent in various real-world applications. Most existing neural MOCO methods rely on problem decomposition to transform an MOCO problem into a series of singe-objective combinatorial optimization (SOCO) problems. However, these methods often approximate partial regions of the Pareto front and spend excessive time on diversity enhancement because of ambiguous decomposition and time-consuming precise hypervolume calculation. To address these limitations, we design a Geometry-Aware Pareto set Learning algorithm named GAPL, which provides a novel geometric perspective for neural MOCO via a Pareto attention model based on hypervolume expectation maximization. In addition, we propose a hypervolume residual update strategy to enable the Pareto attention model to capture both local and non-local information of the Pareto set/front. We also design a novel inference approach to further improve quality of the solution set and speed up hypervolume calculation. Experimental results on three classic MOCO problems demonstrate that our GAPL outperforms several state-of-the-art baselines via superior decomposition and efficient diversity enhancement.",
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "authors": [
                {
                    "authorId": "2222973943",
                    "name": "Yongfan Lu"
                },
                {
                    "authorId": "2301202811",
                    "name": "Zixiang Di"
                },
                {
                    "authorId": "2185835781",
                    "name": "Bingdong Li"
                },
                {
                    "authorId": "2152939552",
                    "name": "Shengcai Liu"
                },
                {
                    "authorId": "2259965088",
                    "name": "Hong Qian"
                },
                {
                    "authorId": "2289681804",
                    "name": "Peng Yang"
                },
                {
                    "authorId": "2301205560",
                    "name": "Ke Tang"
                },
                {
                    "authorId": "2258140188",
                    "name": "Aimin Zhou"
                }
            ]
        },
        {
            "paperId": "06889990c6e4f324a5921bb29119495b3fa0e9df",
            "title": "Multi-Domain Learning From Insufficient Annotations",
            "abstract": "Multi-domain learning (MDL) refers to simultaneously constructing a model or a set of models on datasets collected from different domains. Conventional approaches emphasize domain-shared information extraction and domain-private information preservation, following the shared-private framework (SP models), which offers significant advantages over single-domain learning. However, the limited availability of annotated data in each domain considerably hinders the effectiveness of conventional supervised MDL approaches in real-world applications. In this paper, we introduce a novel method called multi-domain contrastive learning (MDCL) to alleviate the impact of insufficient annotations by capturing both semantic and structural information from both labeled and unlabeled data.Specifically, MDCL comprises two modules: inter-domain semantic alignment and intra-domain contrast. The former aims to align annotated instances of the same semantic category from distinct domains within a shared hidden space, while the latter focuses on learning a cluster structure of unlabeled instances in a private hidden space for each domain. MDCL is readily compatible with many SP models, requiring no additional model parameters and allowing for end-to-end training. Experimental results across five textual and image multi-domain datasets demonstrate that MDCL brings noticeable improvement over various SP models.Furthermore, MDCL can further be employed in multi-domain active learning (MDAL) to achieve a superior initialization, eventually leading to better overall performance.",
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "authors": [
                {
                    "authorId": "22272507",
                    "name": "Ruidan He"
                },
                {
                    "authorId": "2152939552",
                    "name": "Shengcai Liu"
                },
                {
                    "authorId": "2109164978",
                    "name": "Jiahao Wu"
                },
                {
                    "authorId": "2115300867",
                    "name": "Shan He"
                },
                {
                    "authorId": "2055742585",
                    "name": "Ke Tang"
                }
            ]
        },
        {
            "paperId": "077d0d96198252c1b8c9f256ed10edbe8e6ae7ad",
            "title": "Dataset Condensation for Recommendation",
            "abstract": "Training recommendation models on large datasets often requires significant time and computational resources. Consequently, an emergent imperative has arisen to construct informative, smaller-scale datasets for efficiently training. Dataset compression techniques explored in other domains show potential possibility to address this problem, via sampling a subset or synthesizing a small dataset. However, applying existing approaches to condense recommendation datasets is impractical due to following challenges: (i) sampling-based methods are inadequate in addressing the long-tailed distribution problem; (ii) synthesizing-based methods are not applicable due to discreteness of interactions and large size of recommendation datasets; (iii) neither of them fail to address the specific issue in recommendation of false negative items, where items with potential user interest are incorrectly sampled as negatives owing to insufficient exposure. To bridge this gap, we investigate dataset condensation for recommendation, where discrete interactions are continualized with probabilistic re-parameterization. To avoid catastrophically expensive computations, we adopt a one-step update strategy for inner model training and introducing policy gradient estimation for outer dataset synthesis. To mitigate amplification of long-tailed problem, we compensate long-tailed users in the condensed dataset. Furthermore, we propose to utilize a proxy model to identify false negative items. Theoretical analysis regarding the convergence property is provided. Extensive experiments on multiple datasets demonstrate the efficacy of our method. In particular, we reduce the dataset size by 75% while approximating over 98% of the original performance on Dianping and over 90% on other datasets.",
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "authors": [
                {
                    "authorId": "2109164978",
                    "name": "Jiahao Wu"
                },
                {
                    "authorId": "41031455",
                    "name": "Wenqi Fan"
                },
                {
                    "authorId": "2152939552",
                    "name": "Shengcai Liu"
                },
                {
                    "authorId": "2244776472",
                    "name": "Qijiong Liu"
                },
                {
                    "authorId": "2253403022",
                    "name": "Rui He"
                },
                {
                    "authorId": "2254366521",
                    "name": "Qing Li"
                },
                {
                    "authorId": "2253405825",
                    "name": "Ke Tang"
                }
            ]
        },
        {
            "paperId": "0790ffc8118c9ebba6a1d2b0e7f805f39faeae82",
            "title": "Leveraging Large Language Models (LLMs) to Empower Training-Free Dataset Condensation for Content-Based Recommendation",
            "abstract": "Modern techniques in Content-based Recommendation (CBR) leverage item content information to provide personalized services to users, but suffer from resource-intensive training on large datasets. To address this issue, we explore the dataset condensation for textual CBR in this paper. The goal of dataset condensation is to synthesize a small yet informative dataset, upon which models can achieve performance comparable to those trained on large datasets. While existing condensation approaches are tailored to classification tasks for continuous data like images or embeddings, direct application of them to CBR has limitations. To bridge this gap, we investigate efficient dataset condensation for content-based recommendation. Inspired by the remarkable abilities of large language models (LLMs) in text comprehension and generation, we leverage LLMs to empower the generation of textual content during condensation. To handle the interaction data involving both users and items, we devise a dual-level condensation method: content-level and user-level. At content-level, we utilize LLMs to condense all contents of an item into a new informative title. At user-level, we design a clustering-based synthesis module, where we first utilize LLMs to extract user interests. Then, the user interests and user embeddings are incorporated to condense users and generate interactions for condensed users. Notably, the condensation paradigm of this method is forward and free from iterative optimization on the synthesized dataset. Extensive empirical findings from our study, conducted on three authentic datasets, substantiate the efficacy of the proposed method. Particularly, we are able to approximate up to 97% of the original performance while reducing the dataset size by 95% (i.e., on dataset MIND).",
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "authors": [
                {
                    "authorId": "2109164978",
                    "name": "Jiahao Wu"
                },
                {
                    "authorId": "2244776472",
                    "name": "Qijiong Liu"
                },
                {
                    "authorId": "2258801777",
                    "name": "Hengchang Hu"
                },
                {
                    "authorId": "41031455",
                    "name": "Wenqi Fan"
                },
                {
                    "authorId": "2152939552",
                    "name": "Shengcai Liu"
                },
                {
                    "authorId": "2254366521",
                    "name": "Qing Li"
                },
                {
                    "authorId": "2187512110",
                    "name": "Xiao-Ming Wu"
                },
                {
                    "authorId": "2253405825",
                    "name": "Ke Tang"
                }
            ]
        },
        {
            "paperId": "0cf42b7b982c80ee36408b084705651573966b3d",
            "title": "Neural Influence Estimator: Towards Real-time Solutions to Influence Blocking Maximization",
            "abstract": "Real-time solutions to the influence blocking maximization (IBM) problems are crucial for promptly containing the spread of misinformation. However, achieving this goal is non-trivial, mainly because assessing the blocked influence of an IBM problem solution typically requires plenty of expensive Monte Carlo simulations (MCSs). Although several approaches have been proposed to enhance efficiency, they still fail to achieve real-time solutions to IBM problems of practical scales. This work presents a novel approach that enables solving IBM problems with hundreds of thousands of nodes and edges in seconds. The key idea is to construct a fast-to-evaluate surrogate model, called neural influence estimator (NIE), as a substitute for the time-intensive MCSs. To this end, a learning problem is formulated to build the NIE that takes the false-and-true information instance as input, extracts features describing the topology and inter-relationship between two seed sets, and predicts the blocked influence. A well-trained NIE can generalize across different IBM problems defined on a social network, and can be readily combined with existing IBM optimization algorithms such as the greedy algorithm. The experiments on 25 IBM problems with up to millions of edges show that the NIE-based optimization method can be up to four orders of magnitude faster than MCSs-based optimization method to achieve the same solution quality. Moreover, given a real-time constraint of one minute, the NIE-based method can solve IBM problems with up to hundreds of thousands of nodes, which is at least one order of magnitude larger than what can be solved by existing methods.",
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "authors": [
                {
                    "authorId": "2109098710",
                    "name": "Wen-Jing Chen"
                },
                {
                    "authorId": "2152939552",
                    "name": "Shengcai Liu"
                },
                {
                    "authorId": "144848119",
                    "name": "Y. Ong"
                },
                {
                    "authorId": "2078692567",
                    "name": "Ke Tang"
                }
            ]
        },
        {
            "paperId": "1c259361caa85c2d95a7d04e5e42fa98693da85b",
            "title": "Large Language Models as Evolutionary Optimizers",
            "abstract": "Evolutionary algorithms (EAs) have achieved remarkable success in tackling complex combinatorial optimization problems. However, EAs often demand carefully-designed operators with the aid of domain expertise to achieve satisfactory performance. In this work, we present the first study on large language models (LLMs) as evolutionary combinatorial optimizers. The main advantage is that it requires minimal domain knowledge and human efforts, as well as no additional training of the model. This approach is referred to as LLM-driven EA (LMEA). Specifically, in each generation of the evolutionary search, LMEA instructs the LLM to select parent solutions from current population, and perform crossover and mutation to generate offspring solutions. Then, LMEA evaluates these new solutions and include them into the population for the next generation. LMEA is equipped with a self-adaptation mechanism that controls the temperature of the LLM. This enables it to balance between exploration and exploitation and prevents the search from getting stuck in local optima. We investigate the power of LMEA on the classical traveling salesman problems (TSPs) widely used in combinatorial optimization research. Notably, the results show that LMEA performs competitively to traditional heuristics in finding high-quality solutions on TSP instances with up to 20 nodes. Additionally, we also study the effectiveness of LLM-driven crossover/mutation and the self- adaptation mechanism in evolutionary search. In summary, our results reveal the great potentials of LLMs as evolutionary optimizers for solving combinatorial problems. We hope our research shall inspire future explorations on LLM-driven EAs for complex optimization challenges.",
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "authors": [
                {
                    "authorId": "2152939552",
                    "name": "Shengcai Liu"
                },
                {
                    "authorId": "3486051",
                    "name": "Caishun Chen"
                },
                {
                    "authorId": "40507824",
                    "name": "Xinghua Qu"
                },
                {
                    "authorId": "2253405825",
                    "name": "Ke Tang"
                },
                {
                    "authorId": "8748397",
                    "name": "Y. Ong"
                }
            ]
        },
        {
            "paperId": "4dbfc7f8bfe4933b7bfbd29e4eb761573e4ba123",
            "title": "Pointer Networks Trained Better via Evolutionary Algorithms",
            "abstract": "Pointer Network (PtrNet) is a specific neural network for solving Combinatorial Optimization Problems (COPs). While PtrNets offer real-time feed-forward inference for complex COPs instances, its quality of the results tends to be less satisfactory. One possible reason is that such issue suffers from the lack of global search ability of the gradient descent, which is frequently employed in traditional PtrNet training methods including both supervised learning and reinforcement learning. To improve the performance of PtrNet, this paper delves deeply into the advantages of training PtrNet with Evolutionary Algorithms (EAs), which have been widely acknowledged for not easily getting trapped by local optima. Extensive empirical studies based on the Travelling Salesman Problem (TSP) have been conducted. Results demonstrate that PtrNet trained with EA can consistently perform much better inference results than eight state-of-the-art methods on various problem scales. Compared with gradient descent based PtrNet training methods, EA achieves up to 30.21\\% improvement in quality of the solution with the same computational time. With this advantage, this paper is able to at the first time report the results of solving 1000-dimensional TSPs by training a PtrNet on the same dimensionality, which strongly suggests that scaling up the training instances is in need to improve the performance of PtrNet on solving higher-dimensional COPs.",
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "authors": [
                {
                    "authorId": "2269556672",
                    "name": "Muyao Zhong"
                },
                {
                    "authorId": "2152939552",
                    "name": "Shengcai Liu"
                },
                {
                    "authorId": "2185835781",
                    "name": "Bingdong Li"
                },
                {
                    "authorId": "2269849464",
                    "name": "Haobo Fu"
                },
                {
                    "authorId": "2143159234",
                    "name": "Ke Tang"
                },
                {
                    "authorId": "2257509588",
                    "name": "Peng Yang"
                }
            ]
        },
        {
            "paperId": "6e6d5ab8a8f5893b4ffc7cd7f64e2d655a669f93",
            "title": "A Sample Reuse Strategy for Dynamic Influence Maximization Problem",
            "abstract": "Dynamic influence maximization problem (DIMP) aims to maintain a group of influential users within an evolving social network, so that the influence scope can be maximized at any given moment. A primary category of DIMP algorithms focuses on the renewal of reverse reachable (RR) sets, which is designed for static social network scenarios, to accelerate the estimation of influence spread. And the generation time of RR sets plays a crucial role in algorithm efficiency. However, their update approaches require sequential updates for each edge change, leading to considerable computational cost. In this paper, we propose a strategy for batch updating the changes in network edge weights to efficiently maintain RR sets. By calculating the probability that previous RR sets can be regenerated at the current moment, we retain those with a high probability. This method can effectively avoid the computational cost associated with updating and sampling these RR sets. Besides, we propose an resampling strategy that generates high-probability RR sets to make the final distribution of RR sets approximate to the sampling probability distribution under the current social network. The experimental results indicate that our strategy is both scalable and efficient. On the one hand, compared to the previous update strategies, the running time of our strategy is insensitive to the number of changes in network weight; on the other hand, for various RR set-based algorithms, our strategy can reduce the running time while maintaining the solution quality that is essentially consistent with the static algorithms.",
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "authors": [
                {
                    "authorId": "2268400295",
                    "name": "Shaofeng Zhang"
                },
                {
                    "authorId": "2152939552",
                    "name": "Shengcai Liu"
                },
                {
                    "authorId": "2253405825",
                    "name": "Ke Tang"
                }
            ]
        }
    ]
}