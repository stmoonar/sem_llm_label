{
    "authorId": "2054043979",
    "papers": [
        {
            "paperId": "524026b02f7149660d5c29918d329c208868245e",
            "title": "OpenDP Platform for Differential Privacy",
            "abstract": "Differential privacy is a formal, mathematical conception of privacy preservation. An algorithm is differentially private when it injects a precisely calculated quantity of noise to any statistical query, masking the possible contribution of any one individual to the result. This provides a gold standard definition of privacy protection for data scientists who want to analyze data that contains personal information that must remain private. The open source project provides several basic building blocks that can be used by people involved with sensitive data, with implementations based on vetted and mature differential privacy research. It aims to connect theoretical solutions from the academic community with practical lessons learned from real-world deployments and to make differential privacy broadly accessible to future deployments. The core library is a native runtime that is built in Rust to be memory safe and fast. It can be used to safely build differentially private releases from native code running on various devices. It has a SQL data access layer that allows users to compose analysis graphs using the SQL language. The data access layer supports a wide variety of SQL database engines. To ease deployment, it includes a sample hosted service that shows users how to compose heterogeneous queries over the same dataset, fronted by a REST-based endpoint.",
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "authors": [
                {
                    "authorId": "2037593166",
                    "name": "joshua-allen"
                },
                {
                    "authorId": "145583374",
                    "name": "Sarah Bird"
                },
                {
                    "authorId": "2054043979",
                    "name": "Kathleen Walker"
                }
            ]
        },
        {
            "paperId": "5894d57ea49bd5c136ebefb1e6c3986555908ea0",
            "title": "Fairlearn: A toolkit for assessing and improving fairness in AI",
            "abstract": "We introduce Fairlearn, an open source toolkit that empowers data scientists and developers to assess and improve the fairness of their AI systems. Fairlearn has two components: an interactive visualization dashboard and unfairness mitigation algorithms. These components are designed to help with navigating trade-offs between fairness and model performance. We emphasize that prioritizing fairness in AI systems is a sociotechnical challenge. Because there are many complex sources of unfairness\u2014some societal and some technical\u2014it is not possible to fully \u201cdebias\u201d a system or to guarantee fairness; the goal is to mitigate fairness-related harms as much as possible. As Fairlearn grows to include additional fairness metrics, unfairness mitigation algorithms, and visualization capabilities, we hope that it will be shaped by a diverse community of stakeholders, ranging from data scientists, developers, and business decision makers to the people whose lives may be affected by the predictions of AI systems.",
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "authors": [
                {
                    "authorId": "145583374",
                    "name": "Sarah Bird"
                },
                {
                    "authorId": "144652072",
                    "name": "Miroslav Dud\u00edk"
                },
                {
                    "authorId": "113003571",
                    "name": "R. Edgar"
                },
                {
                    "authorId": "2064040799",
                    "name": "Brandon Horn"
                },
                {
                    "authorId": "40451032",
                    "name": "Roman Lutz"
                },
                {
                    "authorId": "1390070911",
                    "name": "Vanessa Milan"
                },
                {
                    "authorId": "2128305",
                    "name": "M. Sameki"
                },
                {
                    "authorId": "1831395",
                    "name": "Hanna M. Wallach"
                },
                {
                    "authorId": "2054043979",
                    "name": "Kathleen Walker"
                }
            ]
        },
        {
            "paperId": "662ed4b6b162ca33195a6817a59366a48d3b1478",
            "title": "WhiteNoise: A Platform for Differential Privacy",
            "abstract": ",",
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "authors": [
                {
                    "authorId": "2115224286",
                    "name": "Joshua Allen"
                },
                {
                    "authorId": "145583374",
                    "name": "Sarah Bird"
                },
                {
                    "authorId": "2054043979",
                    "name": "Kathleen Walker"
                }
            ]
        }
    ]
}