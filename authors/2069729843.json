{
    "authorId": "2069729843",
    "papers": [
        {
            "paperId": "1d5a3c90e9a1d6309ef6b59296fb650826542219",
            "title": "Robust Text Classification: Analyzing Prototype-Based Networks",
            "abstract": "Downstream applications often require text classification models to be accurate and robust. While the accuracy of the state-of-the-art Language Models (LMs) approximates human performance, they often exhibit a drop in performance on noisy data found in the real world. This lack of robustness can be concerning, as even small perturbations in the text, irrelevant to the target task, can cause classifiers to incorrectly change their predictions. A potential solution can be the family of Prototype-Based Networks (PBNs) that classifies examples based on their similarity to prototypical examples of a class (prototypes) and has been shown to be robust to noise for computer vision tasks. In this paper, we study whether the robustness properties of PBNs transfer to text classification tasks under both targeted and static adversarial attack settings. Our results show that PBNs, as a mere architectural variation of vanilla LMs, offer more robustness compared to vanilla LMs under both targeted and static settings. We showcase how PBNs' interpretability can help us to understand PBNs' robustness properties. Finally, our ablation studies reveal the sensitivity of PBNs' robustness to how strictly clustering is done in the training phase, as tighter clustering results in less robust PBNs.",
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "authors": [
                {
                    "authorId": "2196148017",
                    "name": "Zhivar Sourati"
                },
                {
                    "authorId": "2069729843",
                    "name": "D. Deshpande"
                },
                {
                    "authorId": "2125822063",
                    "name": "Filip Ilievski"
                },
                {
                    "authorId": "24868638",
                    "name": "Kiril Gashteovski"
                },
                {
                    "authorId": "3467930",
                    "name": "S. Saralajew"
                }
            ]
        },
        {
            "paperId": "8b118ad3f9247a188d95d01500e652519cd3ec21",
            "title": "Contextualizing Argument Quality Assessment with Relevant Knowledge",
            "abstract": "Automatic assessment of the quality of arguments has been recognized as a challenging task with significant implications for misinformation and targeted speech. While real-world arguments are tightly anchored in context, existing computational methods analyze their quality in isolation, which affects their accuracy and generalizability. We propose SPARK: a novel method for scoring argument quality based on contextualization via relevant knowledge. We devise four augmentations that leverage large language models to provide feedback, infer hidden assumptions, supply a similar-quality argument, or give a counter-argument. SPARK uses a dual-encoder Transformer architecture to enable the original argument and its augmentation to be considered jointly. Our experiments in both in-domain and zero-shot setups show that SPARK consistently outperforms existing techniques across multiple metrics",
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "authors": [
                {
                    "authorId": "2069729843",
                    "name": "D. Deshpande"
                },
                {
                    "authorId": "2196148017",
                    "name": "Zhivar Sourati"
                },
                {
                    "authorId": "2125822063",
                    "name": "Filip Ilievski"
                },
                {
                    "authorId": "2775559",
                    "name": "Fred Morstatter"
                }
            ]
        },
        {
            "paperId": "db7a69f36a792b2d642da7f0b3260e3c155b248e",
            "title": "Robust and Explainable Identification of Logical Fallacies in Natural Language Arguments",
            "abstract": "The spread of misinformation, propaganda, and flawed argumentation has been amplified in the Internet era. Given the volume of data and the subtlety of identifying violations of argumentation norms, supporting information analytics tasks, like content moderation, with trustworthy methods that can identify logical fallacies is essential. In this paper, we formalize prior theoretical work on logical fallacies into a comprehensive three-stage evaluation framework of detection, coarse-grained, and fine-grained classification. We adapt existing evaluation datasets for each stage of the evaluation. We employ three families of robust and explainable methods based on prototype reasoning, instance-based reasoning, and knowledge injection. The methods combine language models with background knowledge and explainable mechanisms. Moreover, we address data sparsity with strategies for data augmentation and curriculum learning. Our three-stage framework natively consolidates prior datasets and methods from existing tasks, like propaganda detection, serving as an overarching evaluation testbed. We extensively evaluate these methods on our datasets, focusing on their robustness and explainability. Our results provide insight into the strengths and weaknesses of the methods on different components and fallacy classes, indicating that fallacy identification is a challenging task that may require specialized forms of reasoning to capture various classes. We share our open-source code and data on GitHub to support further work on logical fallacy identification.",
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "authors": [
                {
                    "authorId": "2196148017",
                    "name": "Zhivar Sourati"
                },
                {
                    "authorId": "1931556395",
                    "name": "Vishnu Priya Prasanna Venkatesh"
                },
                {
                    "authorId": "2069729843",
                    "name": "D. Deshpande"
                },
                {
                    "authorId": "2197068504",
                    "name": "Himanshu Rawlani"
                },
                {
                    "authorId": "2125822063",
                    "name": "Filip Ilievski"
                },
                {
                    "authorId": "2196129589",
                    "name": "H\u00f4ng-\u00c2n Sandlin"
                },
                {
                    "authorId": "122986258",
                    "name": "Alain Mermoud"
                }
            ]
        }
    ]
}