{
    "authorId": "2116518438",
    "papers": [
        {
            "paperId": "2c5f6080a69efe76cf56d225808324fb5b692c1b",
            "title": "Asynchronous Distributed Bilevel Optimization",
            "abstract": "Bilevel optimization plays an essential role in many machine learning tasks, ranging from hyperparameter optimization to meta-learning. Existing studies on bilevel optimization, however, focus on either centralized or synchronous distributed setting. The centralized bilevel optimization approaches require collecting massive amount of data to a single server, which inevitably incur significant communication expenses and may give rise to data privacy risks. Synchronous distributed bilevel optimization algorithms, on the other hand, often face the straggler problem and will immediately stop working if a few workers fail to respond. As a remedy, we propose Asynchronous Distributed Bilevel Optimization (ADBO) algorithm. The proposed ADBO can tackle bilevel optimization problems with both nonconvex upper-level and lower-level objective functions, and its convergence is theoretically guaranteed. Furthermore, it is revealed through theoretic analysis that the iteration complexity of ADBO to obtain the $\\epsilon$-stationary point is upper bounded by $\\mathcal{O}(\\frac{1}{{{\\epsilon ^2}}})$. Thorough empirical studies on public datasets have been conducted to elucidate the effectiveness and efficiency of the proposed ADBO.",
            "fieldsOfStudy": [
                "Computer Science",
                "Mathematics"
            ],
            "authors": [
                {
                    "authorId": "2055181125",
                    "name": "Yang Jiao"
                },
                {
                    "authorId": "2163436495",
                    "name": "Kai Yang"
                },
                {
                    "authorId": "2116518438",
                    "name": "Tiancheng Wu"
                },
                {
                    "authorId": "2451800",
                    "name": "Dongjin Song"
                },
                {
                    "authorId": "2142035704",
                    "name": "Chen Jian"
                }
            ]
        },
        {
            "paperId": "33e88fa73710ffbe027b93ea942abfc60f634f76",
            "title": "Felicitas: Federated Learning in Distributed Cross Device Collaborative Frameworks",
            "abstract": "Felicitas is a distributed cross-device Federated Learning (FL) framework to solve the industrial difficulties of FL in large-scale device deployment scenarios. In Felicitas, FL-Clients are deployed on mobile or embedded devices, while FL-Server is deployed on the cloud platform. We also summarize the challenges of FL deployment in industrial cross-device scenarios (massively parallel, stateless clients, non-use of client identifiers, highly unreliable, unsteady and complex deployment), and provide reliable solutions. We provide the source code and documents at https://www.mindspore.cn/. In addition, the Felicitas has been deployed on mobile phones in real world. At the end of the paper, we demonstrate the validity of the framework through experiments.",
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "authors": [
                {
                    "authorId": "2145907210",
                    "name": "Qi Zhang"
                },
                {
                    "authorId": "2116518438",
                    "name": "Tiancheng Wu"
                },
                {
                    "authorId": "2181282341",
                    "name": "Peichen Zhou"
                },
                {
                    "authorId": "144596278",
                    "name": "Shan Zhou"
                },
                {
                    "authorId": "2181287638",
                    "name": "Yuan Yang"
                },
                {
                    "authorId": "2148654861",
                    "name": "Xiulang Jin"
                }
            ]
        },
        {
            "paperId": "5680e298cd933d7a644d2e96df31bbb7bda46d07",
            "title": "Collaborative Self-Perception Network Architecture for Hyperspectral Image Change Detection",
            "abstract": "Despite the great advantages in deep feature representation when dealing with change detection (CD) problem, the designs of neural networks were time-consuming processes of trial and error. In addition, the traditional CD methods based on deep neural networks (DNN) only deal with one dataset at a time, which has limited learning knowledge and undoubtedly fails to take advantage of the common characteristics among similar datasets. For hyperspectral images (HSIs) obtained by the same sensor, the spectral information has a similar physical meaning (radiance or reflectivity). To utilize the inherent similarity within hyperspectra for learning a robust difference signature, a collaborative analysis framework with self-perception network architecture (SPNA-CA) is proposed to efficiently learn from multiple datasets and leverage their synergy. Different network architecture searching tasks are established for each dataset pertinently, in which the evolutionary multitasking self-perception network architecture (SPNA) method is designed for exploring effective and reasonable network architectures. Besides, a cross-task knowledge transfer mechanism (CKTM) is proposed to transfer excellent network architecture information, which improves the efficiency of the collaborative analysis framework. Experimental results confirm the effectiveness of collaborative analysis for solving HSI-CD problems among multiple datasets.",
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "authors": [
                {
                    "authorId": "145894051",
                    "name": "Jiao Shi"
                },
                {
                    "authorId": "2118690771",
                    "name": "Zeping Zhang"
                },
                {
                    "authorId": "2116518438",
                    "name": "Tiancheng Wu"
                },
                {
                    "authorId": "2108285915",
                    "name": "Xi Zhang"
                },
                {
                    "authorId": "2113650274",
                    "name": "Yu Lei"
                }
            ]
        },
        {
            "paperId": "2a0ae7182b13789056e13dc1887904c923a92675",
            "title": "KDLSQ-BERT: A Quantized Bert Combining Knowledge Distillation with Learned Step Size Quantization",
            "abstract": "Recently, transformer-based language models such as BERT have shown tremendous performance improvement for a range of natural language processing tasks. However, these language models usually are computation expensive and memory intensive during inference. As a result, it is difficult to deploy them on resource-restricted devices. To improve the inference performance, as well as reduce the model size while maintaining the model accuracy, we propose a novel quantization method named KDLSQ-BERT that combines knowledge distillation (KD) with learned step size quantization (LSQ) for language model quantization. The main idea of our method is that the KD technique is leveraged to transfer the knowledge from a\"teacher\"model to a\"student\"model when exploiting LSQ to quantize that\"student\"model during the quantization training process. Extensive experiment results on GLUE benchmark and SQuAD demonstrate that our proposed KDLSQ-BERT not only performs effectively when doing different bit (e.g. 2-bit $\\sim$ 8-bit) quantization, but also outperforms the existing BERT quantization methods, and even achieves comparable performance as the full-precision base-line model while obtaining 14.9x compression ratio. Our code will be public available.",
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "authors": [
                {
                    "authorId": "2115757711",
                    "name": "Jing Jin"
                },
                {
                    "authorId": "2113438641",
                    "name": "Cai Liang"
                },
                {
                    "authorId": "2116518438",
                    "name": "Tiancheng Wu"
                },
                {
                    "authorId": "2172149331",
                    "name": "Li Zou"
                },
                {
                    "authorId": "2066402010",
                    "name": "Zhiliang Gan"
                }
            ]
        },
        {
            "paperId": "975adbac83149eb6f42e5ae76261abb0d5dd4e67",
            "title": "A Performance Evaluation Method of Load Balancing Capability in SaaS Layer of Cloud Platform",
            "abstract": "Cloud platform load balancing has become one of the essential elements in modern cloud platform operations. However, there are still some problems in the evaluation methods of cloud platform load balance, such as unreasonable evaluation indexes and lack of comprehensive evaluation methods. This paper first proposes a performance evaluation method of cloud platform load balancing capabilities. This method analyzes the characteristics of the cloud platform and the actual needs of users, designs and proposes a cloud platform load balancing capability evaluation system, quantitatively analyzes and quantifies specific indexes, and uses the Analytic Hierarchy Process to determine the weight of each index. Finally, we deploy and test our method on the OpenStack cloud platform. Experiments show that the evaluation results of the method proposed in this paper are consistent with the actual results, which verifies the feasibility and rationality of the method proposed in this paper.",
            "fieldsOfStudy": [
                "Physics",
                "Computer Science"
            ],
            "authors": [
                {
                    "authorId": "2146672523",
                    "name": "Hui Liu"
                },
                {
                    "authorId": "2120069504",
                    "name": "Zhaocheng Niu"
                },
                {
                    "authorId": "2116518438",
                    "name": "Tiancheng Wu"
                },
                {
                    "authorId": "1683723",
                    "name": "Junzhao Du"
                },
                {
                    "authorId": "1884418505",
                    "name": "Feng Zhang"
                },
                {
                    "authorId": "2100447448",
                    "name": "Haoyu Bi"
                }
            ]
        },
        {
            "paperId": "5e8799ecf6055e7bf5f27341b2af36cf57048908",
            "title": "A Wide-Band High-Resolution Transmitter for Optical Isolation Amplifier",
            "abstract": "A wide-band and high-resolution transmitter of optical isolation amplifier is proposed for switching power supply isolation and servo motor drive applications. The transmitter is based on the chopper-stabilized technique and sigma delta modulator. A built-in common-mode voltage circuit of switched capacitor is proposed to ensure the stability of input DC common mode. Meanwhile, the feedback capacitor is used to improve the driving ability, which helps to avoid a buffer with large input swing. The circuit is tapeout with GF CMOS 0.18\u2009\u03bcm 1P6M process with 5\u2009V power supply. The test results show that in 5\u2009V supply voltage, the input swing of transmitter is 2\u2009V and the effective signal bandwidth is 110\u2009kHz. And the output resolution achieves 11\u2009bit.",
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "authors": [
                {
                    "authorId": "7863425",
                    "name": "Chengying Chen"
                },
                {
                    "authorId": "2075398777",
                    "name": "Lixia Bai"
                },
                {
                    "authorId": "2117077432",
                    "name": "Yunrong Zhu"
                },
                {
                    "authorId": "2116518438",
                    "name": "Tiancheng Wu"
                }
            ]
        }
    ]
}