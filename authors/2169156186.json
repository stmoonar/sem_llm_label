{
    "authorId": "2169156186",
    "papers": [
        {
            "paperId": "8a7dc1630911808ff2469f3b53038ddf62a661bc",
            "title": "Evading Provenance-Based ML Detectors with Adversarial System Actions",
            "abstract": "The artifact evaluation process is designed to validate the repeatability and usability of the results presented in the research paper \"Evading Provenance-Based ML Detectors with Adversarial System Actions.\" The paper introduces P ROV N-INJA , a novel framework designed to discover adversarial samples, also known as gadgets, specifically tailored for path-based Intrusion Detection Systems (IDS) and Graph Neural Network-based IDS. The primary objective of P ROV N INJA is to identify actions that can successfully evade state-of-the-art IDSs. The evaluation process comprises two main components: training and testing the IDS and generating adversarial examples to evade the IDSs. As a valuable resource, the authors provide a GitHub link that grants access to the source code, data, and scripts necessary for reproducing the results described in the paper. By offering these artifacts, the researchers enable fellow researchers and practitioners to replicate and build upon their work in provenance-based ML detectors. The artifacts include comprehensive software, data, and scripts employed to generate the findings presented in the paper. The accessibility of the GitHub repository ensures transparency. It fosters collaboration among researchers, facilitating advancements in the domain of provenance-based ML detectors and contributing to the overall improvement of security systems.",
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "authors": [
                {
                    "authorId": "2218792397",
                    "name": "Kunal Mukherjee"
                },
                {
                    "authorId": "2219236005",
                    "name": "Joshua Wiedemeier"
                },
                {
                    "authorId": "49980880",
                    "name": "Tianhao Wang"
                },
                {
                    "authorId": "2111343761",
                    "name": "James Wei"
                },
                {
                    "authorId": "2156361901",
                    "name": "Feng Chen"
                },
                {
                    "authorId": "2169156186",
                    "name": "Muhyun Kim"
                },
                {
                    "authorId": "1741044",
                    "name": "Murat Kantarcioglu"
                },
                {
                    "authorId": "3344254",
                    "name": "Kangkook Jee"
                }
            ]
        },
        {
            "paperId": "f6861ce39bad377f05337653eae78102f2c0a510",
            "title": "Interpreting GNN-based IDS Detections Using Provenance Graph Structural Features",
            "abstract": "The black-box nature of complex Neural Network (NN)-based models has hindered their widespread adoption in security domains due to the lack of logical explanations and actionable follow-ups for their predictions. To enhance the transparency and accountability of Graph Neural Network (GNN) security models used in system provenance analysis, we propose PROVEXPLAINER, a framework for projecting abstract GNN decision boundaries onto interpretable feature spaces. We first replicate the decision-making process of GNNbased security models using simpler and explainable models such as Decision Trees (DTs). To maximize the accuracy and fidelity of the surrogate models, we propose novel graph structural features founded on classical graph theory and enhanced by extensive data study with security domain knowledge. Our graph structural features are closely tied to problem-space actions in the system provenance domain, which allows the detection results to be explained in descriptive, human language. PROVEXPLAINER allowed simple DT models to achieve 95% fidelity to the GNN on program classification tasks with general graph structural features, and 99% fidelity on malware detection tasks with a task-specific feature package tailored for direct interpretation. The explanations for malware classification are demonstrated with case studies of five real-world malware samples across three malware families.",
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "authors": [
                {
                    "authorId": "2218792397",
                    "name": "Kunal Mukherjee"
                },
                {
                    "authorId": "2219236005",
                    "name": "Joshua Wiedemeier"
                },
                {
                    "authorId": "49980880",
                    "name": "Tianhao Wang"
                },
                {
                    "authorId": "2169156186",
                    "name": "Muhyun Kim"
                },
                {
                    "authorId": "2156361901",
                    "name": "Feng Chen"
                },
                {
                    "authorId": "1741044",
                    "name": "Murat Kantarcioglu"
                },
                {
                    "authorId": "3344254",
                    "name": "Kangkook Jee"
                }
            ]
        },
        {
            "paperId": "7b75e579544a2f4c07577dbf28db28e555cc2a88",
            "title": "Profiling Deep Learning Workloads at Scale using Amazon SageMaker",
            "abstract": "With the rise of deep learning (DL), machine learning (ML) has become compute and data intensive, typically requiring multi-node multi-GPU clusters. As state-of-the-art models grow in size in the order of trillions of parameters, their computational complexity and cost also increase rapidly. Since 2012, the cost of deep learning doubled roughly every quarter, and this trend is likely to continue. ML practitioners have to cope with common challenges of efficient resource utilization when training such large models. In this paper, we propose a new profiling tool that cross-correlates relevant system utilization metrics and framework operations. The tool supports profiling DL models at scale, identifies performance bottlenecks, and provides insights with recommendations. We deployed the profiling functionality as an add-on to Amazon SageMaker Debugger, a fully-managed service that leverages an on-the-fly analysis system (called rules) to automatically identify complex issues in DL training jobs. By presenting deployment results and customer case studies, we show that it enables users to identify and fix issues caused by inefficient hardware resource usage, thereby reducing training time and cost.",
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "authors": [
                {
                    "authorId": "120529492",
                    "name": "N. Rauschmayr"
                },
                {
                    "authorId": "121079944",
                    "name": "S. Kama"
                },
                {
                    "authorId": "2169156186",
                    "name": "Muhyun Kim"
                },
                {
                    "authorId": "2111882036",
                    "name": "Mi-Sun Choi"
                },
                {
                    "authorId": "1769861",
                    "name": "K. Kenthapadi"
                }
            ]
        },
        {
            "paperId": "abc3f04cf373a03178be1b81e11eec14a40c83e9",
            "title": "PropInit: Scalable Inductive Initialization for Heterogeneous Graph Neural Networks",
            "abstract": "Graph Neural Networks (GNNs) require that all nodes have initial representations which are usually derived from the node features. When the node features are absent, GNNs can learn node embeddings with an embedding layer or use pre-trained network embeddings for the initial node representations. However, these approaches are limited because i) they cannot be easily extended to initialize new nodes that are added to the graph for inference after training and ii) they are memory intensive and store a fixed representation for every node in the graph. In this work, we present PropInit a scalable node representation initialization method for training GNNs and other Graph Machine Learning (ML) models on heterogeneous graphs where some or all node types have no natural features. Unlike existing methods that learn a fixed embedding vector for each node, PropInit learns an inductive function that leverages the metagraph to initialize node representations. As a result, PropInit is fully inductive and can be applied, without retraining, to new nodes without features that are added to the graph. PropInit also scales to large graphs as it requires only a small fraction of the memory requirements of existing methods. On public benchmark heterogeneous graph datasets, using various GNN models, PropInit achieves comparable or better performance to other competing approaches while needing only 0.01% to 2% of their memory consumption for representing node embeddings. We also demonstrate PropInit's effectiveness on an industry heterogeneous graph dataset for fraud detection and achieve better classification accuracy than learning full embeddings while reducing the embedding memory footprint during training and inference by 99.99%",
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "authors": [
                {
                    "authorId": "2121390172",
                    "name": "Soji Adeshina"
                },
                {
                    "authorId": "2151810148",
                    "name": "Jian Zhang"
                },
                {
                    "authorId": "2169156186",
                    "name": "Muhyun Kim"
                },
                {
                    "authorId": "2139389377",
                    "name": "Min Chen"
                },
                {
                    "authorId": "7320311",
                    "name": "Rizal Fathony"
                },
                {
                    "authorId": "2204840154",
                    "name": "Advitiya Vashisht"
                },
                {
                    "authorId": "2117930025",
                    "name": "Jia Chen"
                },
                {
                    "authorId": "50877490",
                    "name": "G. Karypis"
                }
            ]
        }
    ]
}