{
    "authorId": "2065333595",
    "papers": [
        {
            "paperId": "0140b38d66f5ce3910a7cce691240fa8fee83184",
            "title": "FbMultiLingMisinfo: Challenging Large-Scale Multilingual Benchmark for Misinformation Detection",
            "abstract": "According to recent research, geometric deep learning allows to reach unprecedented accuracy for online misinformation detection. By fully leveraging the news social context, URL propagation paths in social networks are first represented as graphs and then classified using Graph Neural Network (GNN) models. Despite these remarkable efforts, researchers are still hampered by the scarcity of high-quality benchmark datasets, and as a result, the efficacy of state-of-the-art approaches could be overestimated. So far, in order to obtain a decent number of third-party fact-checked URLs, researchers have either sampled news from notoriously reliable and unreliable sources using distant supervision, or they have gathered pre-labeled URLs from third-party fact-checking websites. In the former case, resulting datasets can be quite large, but also noisy and biased since pieces of news are labeled as true or false according to their source label, and not individually fact-checked. In the latter case, assigned labels are more reliable, but the included news articles are usually in a single language and they may reflect unknown editorial decisions. As a result, datasets of the latter type are typically small, homogeneous, and thus unrealistically easy for automatic fake news detection models. In this work, we present FbMultiLingMisinfo, a new multilingual benchmark dataset, aimed at a more realistic evaluation of state-of-the-art misinformation detection models. URLs in our dataset come from the Facebook Privacy-Protected Full URLs Data Set, which we augmented with their propagation paths on Twitter. Our experimental results show that, when GNN-based models are tested on FbMultiLingMisinfo, recent misinformation detection results are only partially confirmed. We further show that a sharp reduction in the training size significantly reduces the model accuracy on FbMultiLingMisinfo, but not on two other widely used benchmark datasets for fake news detection.",
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "authors": [
                {
                    "authorId": "122381506",
                    "name": "Giorgio Barnab\u00f2"
                },
                {
                    "authorId": "1752951302",
                    "name": "F. Siciliano"
                },
                {
                    "authorId": "2065333595",
                    "name": "C. Castillo"
                },
                {
                    "authorId": "144954554",
                    "name": "S. Leonardi"
                },
                {
                    "authorId": "2026545715",
                    "name": "Preslav Nakov"
                },
                {
                    "authorId": "134000266",
                    "name": "Giovanni Da San Martino"
                },
                {
                    "authorId": "144925193",
                    "name": "F. Silvestri"
                }
            ]
        },
        {
            "paperId": "6223114eb0a64680e43f7ed41503980cd5f922a4",
            "title": "Rewiring What-to-Watch-Next Recommendations to Reduce Radicalization Pathways",
            "abstract": "Recommender systems typically suggest to users content similar to what they consumed in the past. If a user happens to be exposed to strongly polarized content, she might subsequently receive recommendations which may steer her towards more and more radicalized content, eventually being trapped in what we call a \u201cradicalization pathway\u201d. In this paper, we study the problem of mitigating radicalization pathways using a graph-based approach. Specifically, we model the set of recommendations of a \u201cwhat-to-watch-next\u201d recommender as a d-regular directed graph where nodes correspond to content items, links to recommendations, and paths to possible user sessions. We measure the \u201csegregation\u201d score of a node representing radicalized content as the expected length of a random walk from that node to any node representing non-radicalized content. High segregation scores are associated to larger chances to get users trapped in radicalization pathways. Hence, we define the problem of reducing the prevalence of radicalization pathways by selecting a small number of edges to \u201crewire\u201d, so to minimize the maximum of segregation scores among all radicalized nodes, while maintaining the relevance of the recommendations. We prove that the problem of finding the optimal set of recommendations to rewire is NP-hard and NP-hard to approximate within any factor. Therefore, we turn our attention to heuristics, and propose an efficient yet effective greedy algorithm based on the absorbing random walk theory. Our experiments on real-world datasets in the context of video and news recommendations confirm the effectiveness of our proposal.",
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "authors": [
                {
                    "authorId": "120088794",
                    "name": "Francesco Fabbri"
                },
                {
                    "authorId": "2220456",
                    "name": "Yanhao Wang"
                },
                {
                    "authorId": "1705764",
                    "name": "F. Bonchi"
                },
                {
                    "authorId": "2065333595",
                    "name": "C. Castillo"
                },
                {
                    "authorId": "49105984",
                    "name": "M. Mathioudakis"
                }
            ]
        },
        {
            "paperId": "01bd2ae31f36ad05e94aaf7aa87b836c0982f622",
            "title": "SciClops: Detecting and Contextualizing Scientific Claims for Assisting Manual Fact-Checking",
            "abstract": "This paper describes SciClops, a method to help combat online scientific misinformation. Although automated fact-checking methods have gained significant attention recently, they require pre-existing ground-truth evidence, which, in the scientific context, is sparse and scattered across a constantly-evolving scientific literature. Existing methods do not exploit this literature, which can effectively contextualize and combat science-related fallacies. Furthermore, these methods rarely require human intervention, which is essential for the convoluted and critical domain of scientific misinformation. SciClops involves three main steps to process scientific claims found in online news articles and social media postings: extraction, clustering, and contextualization. First, the extraction of scientific claims takes place using a domain-specific, fine-tuned transformer model. Second, similar claims extracted from heterogeneous sources are clustered together with related scientific literature using a method that exploits their content and the connections among them. Third, check-worthy claims, broadcasted by popular yet unreliable sources, are highlighted together with an enhanced fact-checking context that includes related verified claims, news articles, and scientific papers. Extensive experiments show that SciClops tackles sufficiently these three steps, and effectively assists non-expert fact-checkers in the verification of complex scientific claims, outperforming commercial fact-checking systems.",
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "authors": [
                {
                    "authorId": "3314639",
                    "name": "Panayiotis Smeros"
                },
                {
                    "authorId": "2065333595",
                    "name": "C. Castillo"
                },
                {
                    "authorId": "1751802",
                    "name": "K. Aberer"
                }
            ]
        },
        {
            "paperId": "3f80df9898d949d22ac8703e17dbeb327540aef0",
            "title": "Efficiency and fairness in recurring data-driven risk assessments of violent recidivism",
            "abstract": "In this paper, we consider the prediction of violent recidivism in criminal justice as currently done through machine learning methods. Specifically, we consider sequential evaluations performed on jail inmates with a state-of-the-art risk assessment instrument, RisCanvi. In this protocol, evaluations are done periodically every six months to all inmates. We study a scenario in which the inter-evaluation period depends on the characteristics of each inmate. In this scenario, only a fraction of the inmates, those with the highest probability of having changed risk, are selected for the next evaluation. Our work is based on a cost-benefit analysis which leads to fewer evaluations in exchange for some missed/undetected changes. When modeling risk change, we obtain prediction models with AUC in the order of 0.74-0.78, which can be used to schedule evaluations leading to a small number of missed changes (about 14%) by performing half of the evaluations (50%). This allows freeing resources and staff for other tasks. Importantly, we analyze if this method leads to discriminatory outcomes across some characteristics, including disparate impact in the evaluation rates along nationality and age. By adjusting decision boundaries we are able to mitigate the disparate impact and ensure equality in the rate of evaluation. Even after mitigation, missed changes remain small (about 15%) while still halving the number of evaluations needed.",
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "authors": [
                {
                    "authorId": "2054107784",
                    "name": "Marzieh Karimi-Haghighi"
                },
                {
                    "authorId": "2065333595",
                    "name": "C. Castillo"
                }
            ]
        },
        {
            "paperId": "752550edce9e667004a959b562dac856d184f902",
            "title": "Predicting Early Dropout: Calibration and Algorithmic Fairness Considerations",
            "abstract": "In this work, the problem of predicting dropout risk in undergraduate studies is addressed from a perspective of algorithmic fairness. We develop a machine learning method to predict the risks of university dropout and underperformance. The objective is to understand if such a system can identify students at risk while avoiding potential discriminatory biases. When modeling both risks, we obtain prediction models with an Area Under the ROC Curve (AUC) of 0.77-0.78 based on the data available at the enrollment time, before the first year of studies starts. This data includes the students\u2019 demographics, the high school they attended, and their admission (average) grade. Our models are calibrated: they produce estimated probabilities for each risk, not mere scores. We analyze if this method leads to discriminatory outcomes for some sensitive groups in terms of prediction accuracy (AUC) and error rates (Generalized False Positive Rate, GFPR, or Generalized False Negative Rate, GFNR). The models exhibit some equity in terms of AUC and GFNR along groups. The similar GFNR means a similar probability of failing to detect risk for students who drop out. The disparities in GFPR are addressed through a mitigation process that does not affect the calibration of the model.",
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "authors": [
                {
                    "authorId": "2054107784",
                    "name": "Marzieh Karimi-Haghighi"
                },
                {
                    "authorId": "2065333595",
                    "name": "C. Castillo"
                },
                {
                    "authorId": "7383461",
                    "name": "Davinia Hern\u00e1ndez Leo"
                },
                {
                    "authorId": "47464039",
                    "name": "Ver\u00f3nica Moreno Oliver"
                }
            ]
        },
        {
            "paperId": "cbb0d8ccae7629940131cf036193b534b3abd24c",
            "title": "Perceptions of Diversity in Electronic Music: the Impact of Listener, Artist, and Track Characteristics",
            "abstract": "Shared practices to assess the diversity of retrieval system results are still debated in the Information Retrieval community, partly because of the challenges of determining what diversity means in specific scenarios, and of understanding how diversity is perceived by end-users. The field of Music Information Retrieval is not exempt from this issue. Even if fields such as Musicology or Sociology of Music have a long tradition in questioning the representation and the impact of diversity in cultural environments, such knowledge has not been yet embedded into the design and development of music technologies. In this paper, focusing on electronic music, we investigate the characteristics of listeners, artists, and tracks that are influential in the perception of diversity. Specifically, we center our attention on 1) understanding the relationship between perceived diversity and computational methods to measure diversity, and 2) analyzing how listeners' domain knowledge and familiarity influence such perceived diversity. To accomplish this, we design a user-study in which listeners are asked to compare pairs of lists of tracks and artists, and to select the most diverse list from each pair. We compare participants' ratings with results obtained through computational models built using audio tracks' features and artist attributes. We find that such models are generally aligned with participants' choices when most of them agree that one list is more diverse than the other, while they present a mixed behaviour in cases where participants have little agreement. Moreover, we observe how differences in domain knowledge, familiarity, and demographics can influence the level of agreement among listeners, and between listeners and diversity metrics computed automatically.",
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "authors": [
                {
                    "authorId": "74248595",
                    "name": "Lorenzo Porcaro"
                },
                {
                    "authorId": "2065565656",
                    "name": "Emilia G'omez"
                },
                {
                    "authorId": "2065333595",
                    "name": "C. Castillo"
                }
            ]
        },
        {
            "paperId": "f53e1a275139760bfb273506200ffcf4587cf25d",
            "title": "Exposure Inequality in People Recommender Systems: The Long-Term Effects",
            "abstract": "People recommender systems may affect the exposure that users receive in social networking platforms, influencing attention dynamics and potentially strengthening pre-existing inequalities that disproportionately affect certain groups.\nIn this paper we introduce a model to simulate the feedback loop created by multiple rounds of interactions between users and a link recommender in a social network. This allows us to study the long-term consequences of those particular recommendation algorithms. Our model is equipped with several parameters to control: (i) the level of homophily in the network, (ii) the relative size of the groups, (iii) the choice among several state-of-the-art link recommenders, and (iv) the choice among three different stochastic user behavior models, that decide which recommendations are accepted or rejected.\nOur extensive experimentation with the proposed model shows that a minority group, if homophilic enough, can get a disproportionate advantage in exposure from all link recommenders. Instead, when it is heterophilic, it gets underexposed. Moreover, while the homophily level of the minority affects the speed of the growth of the disparate exposure, the relative size of the minority affects the magnitude of the effect. Finally, link recommenders strengthen exposure inequalities at the individual level, exacerbating the\u201crich-get-richer\u201d effect: this happens for both the minority and the majority class and independently of their level of homophily.",
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "authors": [
                {
                    "authorId": "120088794",
                    "name": "Francesco Fabbri"
                },
                {
                    "authorId": "2145478330",
                    "name": "Maria Luisa Croci"
                },
                {
                    "authorId": "1705764",
                    "name": "F. Bonchi"
                },
                {
                    "authorId": "2065333595",
                    "name": "C. Castillo"
                }
            ]
        },
        {
            "paperId": "2c03652190f4f1dd8f23b52e693c170d29934937",
            "title": "A Note on the Significance Adjustment for FA*IR with Two Protected Groups",
            "abstract": "In this report we provide an improvement of the significance adjustment from the FA*IR algorithm in Zehlike et al. [2], which did not work for very short rankings in combination with a low minimum proportion p for the protected group. We show how the minimum number of protected candidates per ranking position can be calculated exactly and provide a mapping from the continuous space of significance levels (\u03b1) to a discrete space of tables, which allows us to find \u03b1corr using a binary search heuristic. In this report we describe a correction of the significance adjustment procedure from [2], which did not work for very small k and \u03b1 . For binomial distributions, i.e. where only one protected and one non-protected group is present, the inverse CDF can be stored as a simple table, which we compute using Algorithm 1. We will call such a table mTable. Algorithm 1: Algorithm ConstructMTable computes the data structure to efficiently verify or construct a ranking that satisfies binomial ranked group fairness. input :k , the size of the ranking to produce; p , the expected proportion of protected elements; \u03b1corr, the significance for each individual test. output :mTable: A list that contains the minimum number of protected candidates required at each position of a ranking of size k . 1 mTable\u2190 [k] // list of size k 2 for i \u2190 1 to k do 3 mTable[i] \u2190 F\u22121 (i, p, \u03b1corr) // the inverse binomial cdf 4 end 5 return mTable Table 1 shows an example of mTables for different k and p , using \u03b1 = 0.1. For instance, for p = 0.5 we see that at least 1 candidate from the protected group is needed in the top 4 positions, and 2 protected candidates in the top 7 positions. Figure 1 shows that we need a correction for \u03b1 as we are testing multiple hypothesis in the ranked group fairness test, namely k of them (note that the scale is logarithmic). In the following, we show that the special case of having only one protected group offers possibilities for verifying ranked group fairness efficiently. A key advantage of considering just one protected group, rather than multiple, is that we can calculate the exact failure probability Pfail (i.e. a fair ranking gets rejected by the ranked group fairness test), which results in an efficient binary search for \u03b1corr. First we introduce the necessary notation for the binomial case and describe how we calculate the exact Pfail. Then we show that we can divide the continuum of possible \u03b1 values in discrete . This paper is published under the Creative Commons Attribution 4.0 International (CC-BY 4.0) license. Authors reserve their rights to disseminate the work on their personal and corporate Web sites with the appropriate attribution. \u00a9 2020 IW3C2 (International World Wide Web Conference Committee), published under Creative Commons CC-BY 4.0 License. XXXX-XXXX/2020/12-ART https://doi.org/10.1145/nnnnnnn.nnnnnnn ar X iv :2 01 2. 12 79 5v 1 [ cs .I R ] 2 3 D ec 2 02 0",
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "authors": [
                {
                    "authorId": "41154657",
                    "name": "Meike Zehlike"
                },
                {
                    "authorId": "134810739",
                    "name": "Tom S\u00fchr"
                },
                {
                    "authorId": "2065333595",
                    "name": "C. Castillo"
                }
            ]
        },
        {
            "paperId": "6e3e13500f97cf2da66d30ebf5aabf8f370a64fa",
            "title": "Exploring Artist Gender Bias in Music Recommendation",
            "abstract": "Music Recommender Systems (mRS) are designed to give personalised and meaningful recommendations of items (i.e. songs, playlists or artists) to a user base, thereby reflecting and further complementing individual users' specific music preferences. Whilst accuracy metrics have been widely applied to evaluate recommendations in mRS literature, evaluating a user's item utility from other impact-oriented perspectives, including their potential for discrimination, is still a novel evaluation practice in the music domain. In this work, we center our attention on a specific phenomenon for which we want to estimate if mRS may exacerbate its impact: gender bias. Our work presents an exploratory study, analyzing the extent to which commonly deployed state of the art Collaborative Filtering(CF) algorithms may act to further increase or decrease artist gender bias. To assess group biases introduced by CF, we deploy a recently proposed metric of bias disparity on two listening event datasets: the LFM-1b dataset, and the earlier constructed Celma's dataset. Our work traces the causes of disparity to variations in input gender distributions and user-item preferences, highlighting the effect such configurations can have on user's gender bias after recommendation generation.",
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "authors": [
                {
                    "authorId": "1922945781",
                    "name": "Dougal Shakespeare"
                },
                {
                    "authorId": "74248595",
                    "name": "Lorenzo Porcaro"
                },
                {
                    "authorId": "2065565656",
                    "name": "Emilia G'omez"
                },
                {
                    "authorId": "2065333595",
                    "name": "C. Castillo"
                }
            ]
        },
        {
            "paperId": "92d5cb8e499748f97da93b5b377e4b92ee209bed",
            "title": "Intersectional Affirmative Action Policies for Top-k Candidates Selection",
            "abstract": "We study the problem of selecting the top-k candidates from a pool of applicants, where each candidate is associated with a score indicating his/her aptitude. Depending on the specific scenario, such as job search or college admissions, these scores may be the results of standardized tests or other predictors of future performance and utility. We consider a situation in which some groups of candidates experience historical and present disadvantage that makes their chances of being accepted much lower than other groups. In these circumstances, we wish to apply an affirmative action policy to reduce acceptance rate disparities, while avoiding any large decrease in the aptitude of the candidates that are eventually selected. Our algorithmic design is motivated by the frequently observed phenomenon that discrimination disproportionately affects individuals who simultaneously belong to multiple disadvantaged groups, defined along intersecting dimensions such as gender, race, sexual orientation, socio-economic status, and disability. In short, our algorithm's objective is to simultaneously: select candidates with high utility, and level up the representation of disadvantaged intersectional classes. This naturally involves trade-offs and is computationally challenging due to the the combinatorial explosion of potential subgroups as more attributes are considered. We propose two algorithms to solve this problem, analyze them, and evaluate them experimentally using a dataset of university application scores and admissions to bachelor degrees in an OECD country. Our conclusion is that it is possible to significantly reduce disparities in admission rates affecting intersectional classes with a small loss in terms of selected candidate aptitude. To the best of our knowledge, we are the first to study fairness constraints with regards to intersectional classes in the context of top-k selection.",
            "fieldsOfStudy": [
                "Computer Science",
                "Psychology"
            ],
            "authors": [
                {
                    "authorId": "122381506",
                    "name": "Giorgio Barnab\u00f2"
                },
                {
                    "authorId": "2065333595",
                    "name": "C. Castillo"
                },
                {
                    "authorId": "49105984",
                    "name": "M. Mathioudakis"
                },
                {
                    "authorId": "49712831",
                    "name": "S. Celis"
                }
            ]
        }
    ]
}