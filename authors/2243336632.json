{
    "authorId": "2243336632",
    "papers": [
        {
            "paperId": "bd44f96232df6f59a0720973b8498d039d66287f",
            "title": "Entity Disambiguation via Fusion Entity Decoding",
            "abstract": "Entity disambiguation (ED), which links the mentions of ambiguous entities to their referent entities in a knowledge base, serves as a core component in entity linking (EL). Existing generative approaches demonstrate improved accuracy compared to classification approaches under the standardized ZELDA benchmark. Nevertheless, generative approaches suffer from the need for large-scale pre-training and inefficient generation. Most importantly, entity descriptions, which could contain crucial information to distinguish similar entities from each other, are often overlooked.We propose an encoder-decoder model to disambiguate entities with more detailed entity descriptions. Given text and candidate entities, the encoder learns interactions between the text and each candidate entity, producing representations for each entity candidate. The decoder then fuses the representations of entity candidates together and selects the correct entity.Our experiments, conducted on various entity disambiguation benchmarks, demonstrate the strong and robust performance of this model, particularly +1.5% in the ZELDA benchmark compared with GENRE. Furthermore, we integrate this approach into the retrieval/reader framework and observe +1.5% improvements in end-to-end entity linking in the GERBIL benchmark compared with EntQA.",
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "authors": [
                {
                    "authorId": "2280932302",
                    "name": "Junxiong Wang"
                },
                {
                    "authorId": "2243336632",
                    "name": "Ali Mousavi"
                },
                {
                    "authorId": "2294568479",
                    "name": "Omar Attia"
                },
                {
                    "authorId": "2294572235",
                    "name": "Saloni Potdar"
                },
                {
                    "authorId": "2261743768",
                    "name": "Alexander M. Rush"
                },
                {
                    "authorId": "1856878",
                    "name": "U. F. Minhas"
                },
                {
                    "authorId": "2268606252",
                    "name": "Yunyao Li"
                }
            ]
        },
        {
            "paperId": "d51c61372656471bce6b92eb576e537056779b13",
            "title": "ConvKGYarn: Spinning Configurable and Scalable Conversational Knowledge Graph QA datasets with Large Language Models",
            "abstract": "The rapid advancement of Large Language Models (LLMs) and conversational assistants necessitates dynamic, scalable, and configurable conversational datasets for training and evaluation. These datasets must accommodate diverse user interaction modes, including text and voice, each presenting unique modeling challenges. Knowledge Graphs (KGs), with their structured and evolving nature, offer an ideal foundation for current and precise knowledge. Although human-curated KG-based conversational datasets exist, they struggle to keep pace with the rapidly changing user information needs. We present ConvKGYarn, a scalable method for generating up-to-date and configurable conversational KGQA datasets. Qualitative psychometric analyses confirm our method can generate high-quality datasets rivaling a popular conversational KGQA dataset while offering it at scale and covering a wide range of human-interaction configurations. We showcase its utility by testing LLMs on diverse conversations - exploring model behavior on conversational KGQA sets with different configurations grounded in the same KG fact set. Our results highlight the ability of ConvKGYarn to improve KGQA foundations and evaluate parametric knowledge of LLMs, thus offering a robust solution to the constantly evolving landscape of conversational assistants.",
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "authors": [
                {
                    "authorId": "1816753042",
                    "name": "Ronak Pradeep"
                },
                {
                    "authorId": "2268434271",
                    "name": "Daniel Lee"
                },
                {
                    "authorId": "2243336632",
                    "name": "Ali Mousavi"
                },
                {
                    "authorId": "2243336030",
                    "name": "Jeff Pound"
                },
                {
                    "authorId": "2261737773",
                    "name": "Yisi Sang"
                },
                {
                    "authorId": "2315949053",
                    "name": "Jimmy Lin"
                },
                {
                    "authorId": "2243335549",
                    "name": "Ihab Ilyas"
                },
                {
                    "authorId": "2294572235",
                    "name": "Saloni Potdar"
                },
                {
                    "authorId": "2305481986",
                    "name": "Mostafa Arefiyan"
                },
                {
                    "authorId": "2268606252",
                    "name": "Yunyao Li"
                }
            ]
        },
        {
            "paperId": "d9dc17570ae4e52f930e29d446819e3771ab94d1",
            "title": "Time Sensitive Knowledge Editing through Efficient Finetuning",
            "abstract": "Large Language Models (LLMs) have demonstrated impressive capability in different tasks and are bringing transformative changes to many domains. However, keeping the knowledge in LLMs up-to-date remains a challenge once pretraining is complete. It is thus essential to design effective methods to both update obsolete knowledge and induce new knowledge into LLMs. Existing locate-and-edit knowledge editing (KE) method suffers from two limitations. First, the post-edit LLMs by such methods generally have poor capability in answering complex queries that require multi-hop reasoning. Second, the long run-time of such locate-and-edit methods to perform knowledge edits make it infeasible for large scale KE in practice. In this paper, we explore Parameter-Efficient Fine-Tuning (PEFT) techniques as an alternative for KE. We curate a more comprehensive temporal KE dataset with both knowledge update and knowledge injection examples for KE performance benchmarking. We further probe the effect of fine-tuning on a range of layers in an LLM for the multi-hop QA task. We find that PEFT performs better than locate-and-edit techniques for time-sensitive knowledge edits.",
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "authors": [
                {
                    "authorId": "2305484183",
                    "name": "Xiou Ge"
                },
                {
                    "authorId": "2243336632",
                    "name": "Ali Mousavi"
                },
                {
                    "authorId": "3024698",
                    "name": "Edouard Grave"
                },
                {
                    "authorId": "2319608",
                    "name": "Armand Joulin"
                },
                {
                    "authorId": "2261737666",
                    "name": "Kun Qian"
                },
                {
                    "authorId": "2243377351",
                    "name": "Benjamin Han"
                },
                {
                    "authorId": "2305481986",
                    "name": "Mostafa Arefiyan"
                },
                {
                    "authorId": "2268606252",
                    "name": "Yunyao Li"
                }
            ]
        },
        {
            "paperId": "bb86a2592e9efa196aefd6bbc39bf62a3202e9db",
            "title": "Construction of Paired Knowledge Graph - Text Datasets Informed by Cyclic Evaluation",
            "abstract": "Datasets that pair Knowledge Graphs (KG) and text together (KG-T) can be used to train forward and reverse neural models that generate text from KG and vice versa. However models trained on datasets where KG and text pairs are not equivalent can suffer from more hallucination and poorer recall. In this paper, we verify this empirically by generating datasets with different levels of noise and find that noisier datasets do indeed lead to more hallucination. We argue that the ability of forward and reverse models trained on a dataset to cyclically regenerate source KG or text is a proxy for the equivalence between the KG and the text in the dataset. Using cyclic evaluation we find that manually created WebNLG is much better than automatically created TeKGen and T-REx. Informed by these observations, we construct a new, improved dataset called LAGRANGE using heuristics meant to improve equivalence between KG and text and show the impact of each of the heuristics on cyclic evaluation. We also construct two synthetic datasets using large language models (LLMs), and observe that these are conducive to models that perform significantly well on cyclic generation of text, but less so on cyclic generation of KGs, probably because of a lack of a consistent underlying ontology.",
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "authors": [
                {
                    "authorId": "2243336632",
                    "name": "Ali Mousavi"
                },
                {
                    "authorId": "2243337763",
                    "name": "Xin Zhan"
                },
                {
                    "authorId": "37374479",
                    "name": "Richard He Bai"
                },
                {
                    "authorId": "2243340600",
                    "name": "Peng Shi"
                },
                {
                    "authorId": "2243336634",
                    "name": "Theo Rekatsinas"
                },
                {
                    "authorId": "2243377351",
                    "name": "Benjamin Han"
                },
                {
                    "authorId": "1718694",
                    "name": "Yunyao Li"
                },
                {
                    "authorId": "2243336030",
                    "name": "Jeff Pound"
                },
                {
                    "authorId": "2243336902",
                    "name": "Josh Susskind"
                },
                {
                    "authorId": "2243335295",
                    "name": "Natalie Schluter"
                },
                {
                    "authorId": "2243335549",
                    "name": "Ihab Ilyas"
                },
                {
                    "authorId": "3111912",
                    "name": "N. Jaitly"
                }
            ]
        }
    ]
}