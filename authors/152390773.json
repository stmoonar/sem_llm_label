{
    "authorId": "152390773",
    "papers": [
        {
            "paperId": "383bd69f7cc915a4d01d48a30be1658a78123434",
            "title": "Unifying Graph Contrastive Learning via Graph Message Augmentation",
            "abstract": "Graph contrastive learning is usually performed by first conducting Graph Data Augmentation (GDA) and then employing a contrastive learning pipeline to train GNNs. As we know that GDA is an important issue for graph contrastive learning. Various GDAs have been developed recently which mainly involve dropping or perturbing edges, nodes, node attributes and edge attributes. However, to our knowledge, it still lacks a universal and effective augmentor that is suitable for different types of graph data. To address this issue, in this paper, we first introduce the graph message representation of graph data. Based on it, we then propose a novel Graph Message Augmentation (GMA), a universal scheme for reformulating many existing GDAs. The proposed unified GMA not only gives a new perspective to understand many existing GDAs but also provides a universal and more effective graph data augmentation for graph self-supervised learning tasks. Moreover, GMA introduces an easy way to implement the mixup augmentor which is natural for images but usually challengeable for graphs. Based on the proposed GMA, we then propose a unified graph contrastive learning, termed Graph Message Contrastive Learning (GMCL), that employs attribution-guided universal GMA for graph contrastive learning. Experiments on many graph learning tasks demonstrate the effectiveness and benefits of the proposed GMA and GMCL approaches.",
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "authors": [
                {
                    "authorId": "152780956",
                    "name": "Ziyan Zhang"
                },
                {
                    "authorId": "152390773",
                    "name": "Bo Jiang"
                },
                {
                    "authorId": "2260595835",
                    "name": "Jin Tang"
                },
                {
                    "authorId": "2213563581",
                    "name": "Bin Luo"
                }
            ]
        },
        {
            "paperId": "3b3369db0e5602cdc0f3038540cc8d50f51ae58a",
            "title": "A Unified Graph Selective Prompt Learning for Graph Neural Networks",
            "abstract": "In recent years, graph prompt learning/tuning has garnered increasing attention in adapting pre-trained models for graph representation learning. As a kind of universal graph prompt learning method, Graph Prompt Feature (GPF) has achieved remarkable success in adapting pre-trained models for Graph Neural Networks (GNNs). By fixing the parameters of a pre-trained GNN model, the aim of GPF is to modify the input graph data by adding some (learnable) prompt vectors into graph node features to better align with the downstream tasks on the smaller dataset. However, existing GPFs generally suffer from two main limitations. First, GPFs generally focus on node prompt learning which ignore the prompting for graph edges. Second, existing GPFs generally conduct the prompt learning on all nodes equally which fails to capture the importances of different nodes and may perform sensitively w.r.t noisy nodes in aligning with the downstream tasks. To address these issues, in this paper, we propose a new unified Graph Selective Prompt Feature learning (GSPF) for GNN fine-tuning. The proposed GSPF integrates the prompt learning on both graph node and edge together, which thus provides a unified prompt model for the graph data. Moreover, it conducts prompt learning selectively on nodes and edges by concentrating on the important nodes and edges for prompting which thus make our model be more reliable and compact. Experimental results on many benchmark datasets demonstrate the effectiveness and advantages of the proposed GSPF method.",
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "authors": [
                {
                    "authorId": "152390773",
                    "name": "Bo Jiang"
                },
                {
                    "authorId": "2307344836",
                    "name": "Hao Wu"
                },
                {
                    "authorId": "2116462794",
                    "name": "Ziyan Zhang"
                },
                {
                    "authorId": "49292271",
                    "name": "Beibei Wang"
                },
                {
                    "authorId": "2291996193",
                    "name": "Jinhui Tang"
                }
            ]
        },
        {
            "paperId": "6cb0df899ff217ce76170c20bad896595c699270",
            "title": "Graph Edge Representation via Tensor Product Graph Convolutional Representation",
            "abstract": "Graph Convolutional Networks (GCNs) have been widely studied. The core of GCNs is the definition of convolution operators on graphs. However, existing Graph Convolution (GC) operators are mainly defined on adjacency matrix and node features and generally focus on obtaining effective node embeddings which cannot be utilized to address the graphs with (high-dimensional) edge features. To address this problem, by leveraging tensor contraction representation and tensor product graph diffusion theories, this paper analogously defines an effective convolution operator on graphs with edge features which is named as Tensor Product Graph Convolution (TPGC). The proposed TPGC aims to obtain effective edge embeddings. It provides a complementary model to traditional graph convolutions (GCs) to address the more general graph data analysis with both node and edge features. Experimental results on several graph learning tasks demonstrate the effectiveness of the proposed TPGC.",
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "authors": [
                {
                    "authorId": "152390773",
                    "name": "Bo Jiang"
                },
                {
                    "authorId": "2298252767",
                    "name": "Sheng Ge"
                },
                {
                    "authorId": "152780956",
                    "name": "Ziyan Zhang"
                },
                {
                    "authorId": "49292271",
                    "name": "Beibei Wang"
                },
                {
                    "authorId": "2291996193",
                    "name": "Jinhui Tang"
                },
                {
                    "authorId": "2288473027",
                    "name": "Bin Luo"
                }
            ]
        },
        {
            "paperId": "1371b5dc3a2f1434b89d41a0bdc97f100d19a4c7",
            "title": "Graph Neural Network Meets Sparse Representation: Graph Sparse Neural Networks via Exclusive Group Lasso",
            "abstract": "Existing GNNs usually conduct the layer-wise message propagation via the \u2018full\u2019 aggregation of all neighborhood information which are usually sensitive to the structural noises existed in the graphs, such as incorrect or undesired redundant edge connections. To overcome this issue, we propose to exploit Sparse Representation (SR) theory into GNNs and propose Graph Sparse Neural Networks (GSNNs) which conduct sparse aggregation to select reliable neighbors for message aggregation. GSNNs problem contains discrete/sparse constraint which is difficult to be optimized. Thus, we then develop a tight continuous relaxation model Exclusive Group Lasso GNNs (EGLassoGNNs) for GSNNs. An effective algorithm is derived to optimize the proposed EGLassoGNNs model. Experimental results on several benchmark datasets demonstrate the better performance and robustness of the proposed EGLassoGNNs model.",
            "fieldsOfStudy": [
                "Medicine",
                "Computer Science"
            ],
            "authors": [
                {
                    "authorId": "152390773",
                    "name": "Bo Jiang"
                },
                {
                    "authorId": "49292271",
                    "name": "Beibei Wang"
                },
                {
                    "authorId": "50358605",
                    "name": "Sibao Chen"
                },
                {
                    "authorId": "37864689",
                    "name": "Jin Tang"
                },
                {
                    "authorId": "2151264175",
                    "name": "B. Luo"
                }
            ]
        },
        {
            "paperId": "1e7e2eeac837dcc7f1109215cda9064efb3b1a3b",
            "title": "AMatFormer: Efficient Feature Matching via Anchor Matching Transformer",
            "abstract": "Learning based feature matching methods have been commonly studied in recent years. The core issue for learning feature matching is to how to learn (1) discriminative representations for feature points (or regions) within each intra-image and (2) consensus representations for feature points across inter-images. Recently, self- and cross-attention models have been exploited to address this issue. However, in many scenes, features are coming with large-scale, redundant and outliers contaminated. Previous self-/cross-attention models generally conduct message passing on all primal features which thus lead to redundant learning and high computational cost. To mitigate limitations, inspired by recent seed matching methods, in this article, we propose a novel efficient Anchor Matching Transformer (AMatFormer) for the feature matching problem. AMatFormer has two main aspects: First, it mainly conducts self-/cross-attention on some anchor features and leverages these anchor features as message bottleneck to learn the representations for all primal features. Thus, it can be implemented efficiently and compactly. Second, AMatFormer adopts a shared FFN module to further embed the features of two images into the common domain and thus learn the consensus feature representations for the matching problem. Experiments on several benchmarks demonstrate the effectiveness and efficiency of the proposed AMatFormer matching approach.",
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "authors": [
                {
                    "authorId": "152390773",
                    "name": "Bo Jiang"
                },
                {
                    "authorId": "1646713373",
                    "name": "S. Luo"
                },
                {
                    "authorId": "144129720",
                    "name": "Xiao Wang"
                },
                {
                    "authorId": "2218482422",
                    "name": "Chuanfu Li"
                },
                {
                    "authorId": "37864689",
                    "name": "Jin Tang"
                }
            ]
        },
        {
            "paperId": "234e75c55a315ea527112fe77fe0db5de17759ba",
            "title": "AGFormer: Efficient Graph Representation with Anchor-Graph Transformer",
            "abstract": "To alleviate the local receptive issue of GCN, Transformers have been exploited to capture the long range dependences of nodes for graph data representation and learning. However, existing graph Transformers generally employ regular self-attention module for all node-to-node message passing which needs to learn the affinities/relationships between all node's pairs, leading to high computational cost issue. Also, they are usually sensitive to graph noises. To overcome this issue, we propose a novel graph Transformer architecture, termed Anchor Graph Transformer (AGFormer), by leveraging an anchor graph model. To be specific, AGFormer first obtains some representative anchors and then converts node-to-node message passing into anchor-to-anchor and anchor-to-node message passing process. Thus, AGFormer performs much more efficiently and also robustly than regular node-to-node Transformers. Extensive experiments on several benchmark datasets demonstrate the effectiveness and benefits of proposed AGFormer.",
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "authors": [
                {
                    "authorId": "152390773",
                    "name": "Bo Jiang"
                },
                {
                    "authorId": "2217950073",
                    "name": "Fei Xu"
                },
                {
                    "authorId": "4927354",
                    "name": "Ziyan Zhang"
                },
                {
                    "authorId": "2118350993",
                    "name": "Jin Tang"
                },
                {
                    "authorId": "144962210",
                    "name": "F. Nie"
                }
            ]
        },
        {
            "paperId": "595adb75ddeb90760c79e89b76d99e55079e0708",
            "title": "Fine-Grained Visual Classification via Internal Ensemble Learning Transformer",
            "abstract": "Recently, vision transformers (ViTs) have been investigated in fine-grained visual recognition (FGVC) and are now considered state of the art. However, most ViT-based works ignore the different learning performances of the heads in the multi-head self-attention (MHSA) mechanism and its layers. To address these issues, in this paper, we propose a novel internal ensemble learning transformer (IELT) for FGVC. The proposed IELT involves three main modules: multi-head voting (MHV) module, cross-layer refinement (CLR) module, and dynamic selection (DS) module. To solve the problem of the inconsistent performances of multiple heads, we propose the MHV module, which considers all of the heads in each layer as weak learners and votes for tokens of discriminative regions as cross-layer feature based on the attention maps and spatial relationships. To effectively mine the cross-layer feature and suppress the noise, the CLR module is proposed, where the refined feature is extracted and the assist logits operation is developed for the final prediction. In addition, a newly designed DS module adjusts the token selection number at each layer by weighting their contributions of the refined feature. In this way, the idea of ensemble learning is combined with the ViT to improve fine-grained feature representation. The experiments demonstrate that our method achieves competitive results compared with the state of the art on five popular FGVC datasets.",
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "authors": [
                {
                    "authorId": "1498047222",
                    "name": "Qin Xu"
                },
                {
                    "authorId": "2175012664",
                    "name": "Jiahui Wang"
                },
                {
                    "authorId": "152390773",
                    "name": "Bo Jiang"
                },
                {
                    "authorId": "2175688252",
                    "name": "Bin Luo"
                }
            ]
        },
        {
            "paperId": "c38d8daa2a0f98cdc2a45a52665bb90797968f62",
            "title": "Generalizing Aggregation Functions in GNNs: Building High Capacity and Robust GNNs via Nonlinear Aggregation",
            "abstract": "The main aspect powering GNNs is the multi-layer network architecture to learn the nonlinear representation for graph learning task. The core operation in GNNs is the message propagation in which each node updates its information by aggregating the information from its neighbors. Existing GNNs usually adopt either linear neighborhood aggregation (e.g. mean, sum) or max aggregator in their message propagation. 1) For linear aggregators, the whole nonlinearity and network's capacity of GNNs are generally limited because deeper GNNs usually suffer from the over-smoothing issue due to their inherent information propagation mechanism. Also, linear aggregators are usually vulnerable to the spatial perturbations. 2) For max aggregator, it usually fails to be aware of the detailed information of node representations within neighborhood. To overcome these issues, we re-think the message propagation mechanism in GNNs and develop the new general nonlinear aggregators for neighborhood information aggregation in GNNs. One main aspect of our nonlinear aggregators is that they all provide the optimally balanced aggregator between max and mean/sum aggregators. Thus, they can inherit both i) high nonlinearity that enhances network's capacity, robustness and ii) detail-sensitivity that is aware of the detailed information of node representations in GNNs\u2019 message propagation. Promising experiments show the effectiveness, high capacity and robustness of the proposed methods.",
            "fieldsOfStudy": [
                "Medicine",
                "Computer Science"
            ],
            "authors": [
                {
                    "authorId": "49292271",
                    "name": "Beibei Wang"
                },
                {
                    "authorId": "152390773",
                    "name": "Bo Jiang"
                },
                {
                    "authorId": "37864689",
                    "name": "Jin Tang"
                },
                {
                    "authorId": "2151264175",
                    "name": "B. Luo"
                }
            ]
        },
        {
            "paperId": "8a41f6de0f2921ff5fd8a3296ff496c584d758ef",
            "title": "RGTransformer: Region-Graph Transformer for Image Representation and Few-Shot Classification",
            "abstract": "The goal of few-shot image classification is to learn a classifier that can be well generalized to the unseen classes with a few available labeled samples. One major challenge for few-shot learning is how to conduct effective image representation for support and query images. Recently, local region-based image representation and metric learning approaches have been demonstrated effectively for few-shot classification problem. However, existing approaches generally conduct representations of image regions individually which thus lack of considering the rich spatial/structural relationships among image regions. In this paper, we propose to bridge the individual regions and exploit the structural contexts among regions via a novel Region-Graph Transformer (RGTransformer). In RGTransformer, each region aggregates the information from its neighboring regions and thus can obtain context-aware feature representations for regions. Using the proposed RGTransformer, we propose an effective metric learning model for few-shot image classification. We evaluate the proposed method on four benchmark datasets and experimental results demonstrate the effectiveness and advantages of the proposed RGTransformer.",
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "authors": [
                {
                    "authorId": "152390773",
                    "name": "Bo Jiang"
                },
                {
                    "authorId": "2074108729",
                    "name": "Kangkang Zhao"
                },
                {
                    "authorId": "37864689",
                    "name": "Jin Tang"
                }
            ]
        },
        {
            "paperId": "98a35fdd82dea014260aaf0ec9b414ecc6b5bce8",
            "title": "Semi-supervised Learning via Multiple Layer Graph Regularized Perception",
            "abstract": "Recently, Graph Neural Networks (GNNs) have made remarkable achievements in semi-supervised classification tasks. Nevertheless, GNNs usually rely on a specific graph convolution which has high computational complexity. To overcome this issue, recent works attempt to implicitly use adjacency matrix to guide message propagation in multi-layer perception (MLP) via neighboring contrastive loss. However, existing works accomplish implicit message passing only, without considering multi-order graph topology information. In this paper, we propose a novel method called Multiple Layer Graph Regularized Perception (MLGP). The main advantage of MLGP is to incorporate multi-order neighboring information into MLP. Further, inspired by gated mechanism, we design a linear gating to capture important features of nodes. More discriminant features can be obtained to alleviate over-smoothing. MLGP is more effective and more robust than existing works when dealing with large-scale graph data and noisy adjacency information. The comparative experiment results show that our model achieves better performance and strong robustness.",
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "authors": [
                {
                    "authorId": "7271358",
                    "name": "Hai-Wei Xu"
                },
                {
                    "authorId": "2164820498",
                    "name": "Lili Huang"
                },
                {
                    "authorId": "152390773",
                    "name": "Bo Jiang"
                },
                {
                    "authorId": "37864689",
                    "name": "Jin Tang"
                },
                {
                    "authorId": "72655446",
                    "name": "S. Zhang"
                }
            ]
        }
    ]
}