{
    "authorId": "2144340010",
    "papers": [
        {
            "paperId": "a955eeda762dce23d254fb76e1071ebaf7d78fce",
            "title": "STAS: Spatial-Temporal Return Decomposition for Multi-agent Reinforcement Learning",
            "abstract": "Centralized Training with Decentralized Execution (CTDE) has been proven to be an effective paradigm in cooperative multi-agent reinforcement learning (MARL). One of the major challenges is credit assignment, which aims to credit agents by their contributions. While prior studies have shown great success, their methods typically fail to work in episodic reinforcement learning scenarios where global rewards are revealed only at the end of the episode. They lack the functionality to model complicated relations of the delayed global reward in the temporal dimension and suffer from inefficiencies. To tackle this, we introduce Spatial-Temporal Attention with Shapley (STAS), a novel method that learns credit assignment in both temporal and spatial dimensions. It first decomposes the global return back to each time step, then utilizes the Shapley Value to redistribute the individual payoff from the decomposed global reward. To mitigate the computational complexity of the Shapley Value, we introduce an approximation of marginal contribution and utilize Monte Carlo sampling to estimate it. We evaluate our method on an Alice&Bob example and MPE environments across different scenarios. Our results demonstrate that our method effectively assigns spatial-temporal credit, outperforming all state-of-the-art baselines.",
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "authors": [
                {
                    "authorId": "2144340010",
                    "name": "Sirui Chen"
                },
                {
                    "authorId": "2174174943",
                    "name": "Zhaowei Zhang"
                },
                {
                    "authorId": "1390662136",
                    "name": "Yali Du"
                },
                {
                    "authorId": "47796324",
                    "name": "Yaodong Yang"
                }
            ]
        },
        {
            "paperId": "b08b495b2a74ade64960e64f4ec485fffcb71407",
            "title": "Controllable Multi-Objective Re-ranking with Policy Hypernetworks",
            "abstract": "Multi-stage ranking pipelines have become widely used strategies in modern recommender systems, where the final stage aims to return a ranked list of items that balances a number of requirements such as user preference, diversity, novelty etc. Linear scalarization is arguably the most widely used technique to merge multiple requirements into one optimization objective, by summing up the requirements with certain preference weights. Existing final-stage ranking methods often adopt a static model where the preference weights are determined during offline training and kept unchanged during online serving. Whenever a modification of the preference weights is needed, the model has to be re-trained, which is time and resources inefficient. Meanwhile, the most appropriate weights may vary greatly for different groups of targeting users or at different time periods (e.g., during holiday promotions). In this paper, we propose a framework called controllable multi-objective re-ranking (CMR) which incorporates a hypernetwork to generate parameters for a re-ranking model according to different preference weights. In this way, CMR is enabled to adapt the preference weights according to the environment changes in an online manner, without retraining the models. Moreover, we classify practical business-oriented tasks into four main categories and seamlessly incorporate them in a new proposed re-ranking model based on an Actor-Evaluator framework, which serves as a reliable real-world testbed for CMR. Offline experiments based on the dataset collected from Taobao App showed that CMR improved several popular re-ranking models by using them as underlying models. Online A/B tests also demonstrated the effectiveness and trustworthiness of CMR.",
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "authors": [
                {
                    "authorId": "2144340010",
                    "name": "Sirui Chen"
                },
                {
                    "authorId": "2156167158",
                    "name": "Yuan Wang"
                },
                {
                    "authorId": "90431185",
                    "name": "Zijing Wen"
                },
                {
                    "authorId": "2109823035",
                    "name": "Zhiyu Li"
                },
                {
                    "authorId": "2219692939",
                    "name": "Changshuo Zhang"
                },
                {
                    "authorId": "2128029592",
                    "name": "Xiao Zhang"
                },
                {
                    "authorId": "1830450502",
                    "name": "Quan Lin"
                },
                {
                    "authorId": "2219689040",
                    "name": "Cheng Zhu"
                },
                {
                    "authorId": "2150636233",
                    "name": "Jun Xu"
                }
            ]
        },
        {
            "paperId": "ed9d3a882c425083bf989aca495511f7dc0cc908",
            "title": "Synthesizing Dexterous Nonprehensile Pregrasp for Ungraspable Objects",
            "abstract": "Daily objects embedded in a contextual environment are often ungraspable initially. Whether it is a book sandwiched by other books on a fully packed bookshelf or a piece of paper lying flat on the desk, a series of nonprehensile pregrasp maneuvers is required to manipulate the object into a graspable state. Humans are proficient at utilizing environmental contacts to achieve manipulation tasks that are otherwise impossible, but synthesizing such nonprehensile pregrasp behaviors is challenging to existing methods. We present a novel method that combines graph search, optimal control, and a learning-based objective function to synthesize physically realistic and diverse nonprehensile pre-grasp motions that leverage the external contacts. Since the \u201cgraspability\u201d of an object in context with its surrounding is difficult to define, we utilize a dataset of dexterous grasps to learn a metric which implicitly takes into account the exposed surface of the object and the finger tip locations. Our method can efficiently discover hand and object trajectories that are certified to be physically feasible by the simulation and kinematically achievable by the dexterous hand. We evaluate our method on eight challenging scenarios where nonprehensile pre-grasps are required to succeed. We also show that our method can be applied to unseen objects different from those in the training dataset. Finally, we report quantitative analyses on generalization and robustness of our method, as well as an ablation study.",
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "authors": [
                {
                    "authorId": "2144340010",
                    "name": "Sirui Chen"
                },
                {
                    "authorId": "46840821",
                    "name": "A. Wu"
                },
                {
                    "authorId": "2216562668",
                    "name": "C.Karen Liu"
                }
            ]
        },
        {
            "paperId": "1211ba752bfc4f35ab93f47cefed37f4accf5360",
            "title": "CEP3: Community Event Prediction with Neural Point Process on Graph",
            "abstract": "Many real world applications can be formulated as event forecasting on Continuous Time Dynamic Graphs (CTDGs) where the occurrence of a timed event between two entities is represented as an edge along with its occurrence timestamp in the graphs.However, most previous works approach the problem in compromised settings, either formulating it as a link prediction task on the graph given the event time or a time prediction problem given which event will happen next. In this paper, we propose a novel model combining Graph Neural Networks and Marked Temporal Point Process (MTPP) that jointly forecasts multiple link events and their timestamps on communities over a CTDG. Moreover, to scale our model to large graphs, we factorize the jointly event prediction problem into three easier conditional probability modeling problems.To evaluate the effectiveness of our model and the rationale behind such a decomposition, we establish a set of benchmarks and evaluation metrics for this event forecasting task. Our experiments demonstrate the superior performance of our model in terms of both model accuracy and training efficiency.",
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "authors": [
                {
                    "authorId": "47119335",
                    "name": "Xuhong Wang"
                },
                {
                    "authorId": "2144340010",
                    "name": "Sirui Chen"
                },
                {
                    "authorId": "2118917694",
                    "name": "Yixuan He"
                },
                {
                    "authorId": "1508337194",
                    "name": "Minjie Wang"
                },
                {
                    "authorId": "47594426",
                    "name": "Quan Gan"
                },
                {
                    "authorId": "153690188",
                    "name": "Yupu Yang"
                },
                {
                    "authorId": "3063894",
                    "name": "Junchi Yan"
                }
            ]
        },
        {
            "paperId": "68c4cf5e8e80499bb361ca88e83bf5214a799940",
            "title": "Real-Time Model Predictive Control and System Identification Using Differentiable Simulation",
            "abstract": "Transferring a controller from a simulated environment to a physical system is regarded as a challenging problem in robotics. We present a method for continuous improvement of modeling and control after deploying the robot to a dynamically-changing target environment. We develop a differentiable physics simulation framework that simultaneously performs online system identification and optimal control using the incoming observations from the target environment in real time. To ensure robust system identification against noisy observations, we devise an algorithm to assess the confidence of our estimated parameters using numerical analysis of the dynamic equations. To ensure real-time optimal control, we adapt start time of the optimization window so that the optimized actions can be replenished ahead of consumption, while staying as up-to-date with new information as possible. The constantly re-planning based on a constantly improving model allows the robot to swiftly adapt to the changing environment using real-world data in a sample-efficient way. Thanks to a fast differentiable physics simulator, both system identification and control can be solved efficiently in real time. We demonstrate our method on a set of examples in simulation and on a real robot. Our method can outperform all baseline methods in different experiments.",
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "authors": [
                {
                    "authorId": "2144340010",
                    "name": "Sirui Chen"
                },
                {
                    "authorId": "2795219",
                    "name": "Keenon Werling"
                },
                {
                    "authorId": "46840821",
                    "name": "A. Wu"
                },
                {
                    "authorId": "2282970129",
                    "name": "C. Liu"
                }
            ]
        },
        {
            "paperId": "1b6279fe633cd30d5338262b0a277f7ca700f690",
            "title": "DiffSRL: Learning Dynamic-aware State Representation for Deformable Object Control with Differentiable Simulator",
            "abstract": "\u2014Dynamic state representation learning is an important task in robot learning. Latent space that can capture dynamics related information has wide application in areas such as accelerating model free reinforcement learning, closing the simulation to reality gap, as well as reducing the motion planning complexity. However, current dynamic state representation learning methods scale poorly on complex dynamic systems such as deformable objects, and cannot directly embed well de-\ufb01ned simulation function into the training pipeline. We propose DiffSRL, a dynamic state representation learning pipeline utilizing differentiable simulation that can embed complex dynamics models as part of the end-to-end training. We also integrate differentiable dynamic constraints as part of the pipeline which provide incentives for the latent state to be aware of dynamical constraints. We further establish a state representation learning benchmark on a soft-body simulation system, PlasticineLab, and our model demonstrates superior performance in terms of capturing long-term dynamics as well as reward prediction. The source code and more experiments results is available at https://ericcsr.github.io/DiffSRL/ .",
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "authors": [
                {
                    "authorId": "2144340010",
                    "name": "Sirui Chen"
                },
                {
                    "authorId": "2136355882",
                    "name": "Yunhao Liu"
                },
                {
                    "authorId": "2108961682",
                    "name": "Jialong Li"
                },
                {
                    "authorId": "2147300811",
                    "name": "Shang Wen Yao"
                },
                {
                    "authorId": "26336089",
                    "name": "Tingxiang Fan"
                },
                {
                    "authorId": "143938045",
                    "name": "Jia Pan"
                }
            ]
        },
        {
            "paperId": "8270f6b9fc8999d1958985b83552ff795f2cf5f2",
            "title": "DiffSRL: Learning Dynamical State Representation for Deformable Object Manipulation With Differentiable Simulation",
            "abstract": "Dynamic state representation learning is essential for robot learning. Good latent space that can accurately describe dynamic transition and constraints can significantly accelerate reinforcement learning training as well as reduce motion planning complexity. However, deformable object have very complicated dynamics and is hard to be represented directly by a neural network without any prior physics information. We propose DiffSRL, an end-to-end dynamic state representation learning pipeline that uses differentiable physics engine to teach neural network how to represent high dimensional pointcloud data collected from deformable objects. Our specially designed loss function can guide neural network aware physics constraints and feasibility. We benchmark the performance of our methods as well as other state representation algorithms with multiple downstream tasks on PlasticineLab. Our model demonstrates superior performance most of the time on all tasks. We also demonstrate our model's performance in real hardware setting with two manipulation tasks on a UR-5 robot arm.",
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "authors": [
                {
                    "authorId": "2144340010",
                    "name": "Sirui Chen"
                },
                {
                    "authorId": "2136355882",
                    "name": "Yunhao Liu"
                },
                {
                    "authorId": "2147300811",
                    "name": "Shang Wen Yao"
                },
                {
                    "authorId": "2108961756",
                    "name": "Jialong Li"
                },
                {
                    "authorId": "26336089",
                    "name": "Tingxiang Fan"
                },
                {
                    "authorId": "143938045",
                    "name": "Jia Pan"
                }
            ]
        }
    ]
}