{
    "authorId": "2116951322",
    "papers": [
        {
            "paperId": "07f187699a444dc8e2bebe212bf83f0181f823ef",
            "title": "A Counterfactual Collaborative Session-based Recommender System",
            "abstract": "Most session-based recommender systems (SBRSs) focus on extracting information from the observed items in the current session of a user to predict a next item, ignoring the causes outside the session (called outer-session causes, OSCs) that influence the user\u2019s selection of items. However, these causes widely exist in the real world, and few studies have investigated their role in SBRSs. In this work, we analyze the causalities and correlations of the OSCs in SBRSs from the perspective of causal inference. We find that the OSCs are essentially the confounders in SBRSs, which leads to spurious correlations in the data used to train SBRS models. To address this problem, we propose a novel SBRS framework named COCO-SBRS (COunterfactual COllaborative Session-Based Recommender Systems) to learn the causality between OSCs and user-item interactions in SBRSs. COCO-SBRS first adopts a self-supervised approach to pre-train a recommendation model by designing pseudo-labels of causes for each user\u2019s selection of the item in data to guide the training process. Next, COCO-SBRS adopts counterfactual inference to recommend items based on the outputs of the pre-trained recommendation model considering the causalities to alleviate the data sparsity problem. As a result, COCO-SBRS can learn the causalities in data, preventing the model from learning spurious correlations. The experimental results of our extensive experiments conducted on three real-world datasets demonstrate the superiority of our proposed framework over ten representative SBRSs.",
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "authors": [
                {
                    "authorId": "51122248",
                    "name": "Wenzhuo Song"
                },
                {
                    "authorId": "2116951322",
                    "name": "Shoujin Wang"
                },
                {
                    "authorId": "2152541925",
                    "name": "Yan Wang"
                },
                {
                    "authorId": "2029695204",
                    "name": "Kunpeng Liu"
                },
                {
                    "authorId": "120280976",
                    "name": "Xue Liu"
                },
                {
                    "authorId": "2105567718",
                    "name": "Minghao Yin"
                }
            ]
        },
        {
            "paperId": "377bb27f5069dcd526f1c4bb1cab70fa471e3452",
            "title": "Modeling User Demand Evolution for Next-Basket Prediction",
            "abstract": "Users\u2019 purchase behaviors are complex and dynamic, which are usually driven by various personal demands evolving with time. According to psychology and economic theories, user demands can be satisfied with a sequence of purchase behaviors, resulting in a basket of items. However, most of the existing works simply predict the next basket from a shallow perspective of (purchase) sequence data modeling without deep insight into the underlying factors which drive user purchase behaviors. In fact, filling a basket with multiple items is a process to incrementally satisfy a user's demand. Therefore, the key challenges to predict a user's next basket lie in (1) how to track the changes of the user's demand, and (2) how to satisfy her demand at a given moment. To this end, we propose an Evolving DEmand SAtisfaction (EvoDESA) model to model a user's demand evolution for next-basket prediction. In EvoDESA, a demand evolution module learns the dynamics of user demand over a sequence of basket-purchase behaviors. Then, a next-basket planning module effectively packs an optimal combination of items to best satisfy the user's current demand. Extensive experiments on three real-world transaction datasets demonstrate the considerable superiority of EvoDESA over the state-of-the-art approaches.",
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "authors": [
                {
                    "authorId": "2116951322",
                    "name": "Shoujin Wang"
                },
                {
                    "authorId": "2152541925",
                    "name": "Yan Wang"
                },
                {
                    "authorId": "2118850040",
                    "name": "Liang Hu"
                },
                {
                    "authorId": "1485105824",
                    "name": "Xiuzhen Zhang"
                },
                {
                    "authorId": "2145908596",
                    "name": "Qi Zhang"
                },
                {
                    "authorId": "1713128",
                    "name": "Quan Z. Sheng"
                },
                {
                    "authorId": "145572420",
                    "name": "M. Orgun"
                },
                {
                    "authorId": "2184095458",
                    "name": "Longbin Cao"
                },
                {
                    "authorId": "1862782",
                    "name": "Defu Lian"
                }
            ]
        },
        {
            "paperId": "3a10c683a7dac0d30d4cecf0a2cf52fe7170d911",
            "title": "Dual Contrastive Transformer for Hierarchical Preference Modeling in Sequential Recommendation",
            "abstract": "Sequential recommender systems (SRSs) aim to predict the subsequent items which may interest users via comprehensively modeling users' complex preference embedded in the sequence of user-item interactions. However, most of existing SRSs often model users' single low-level preference based on item ID information while ignoring the high-level preference revealed by item attribute information, such as item category. Furthermore, they often utilize limited sequence context information to predict the next item while overlooking richer inter-item semantic relations. To this end, in this paper, we proposed a novel hierarchical preference modeling framework to substantially model the complex low- and high-level preference dynamics for accurate sequential recommendation. Specifically, in the framework, a novel dual-transformer module and a novel dual contrastive learning scheme have been designed to discriminatively learn users' low- and high-level preference and to effectively enhance both low- and high-level preference learning respectively. In addition, a novel semantics-enhanced context embedding module has been devised to generate more informative context embedding for further improving the recommendation performance. Extensive experiments on six real-world datasets have demonstrated both the superiority of our proposed method over the state-of-the-art ones and the rationality of our design.",
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "authors": [
                {
                    "authorId": "2150607873",
                    "name": "Chengkai Huang"
                },
                {
                    "authorId": "2116951322",
                    "name": "Shoujin Wang"
                },
                {
                    "authorId": "2107924437",
                    "name": "Xianzhi Wang"
                },
                {
                    "authorId": "145095579",
                    "name": "L. Yao"
                }
            ]
        },
        {
            "paperId": "5becc0d68692f36b7d87aab3f1c172a1df370670",
            "title": "A Survey on Deep Learning based Time Series Analysis with Frequency Transformation",
            "abstract": "Recently, frequency transformation (FT) has been increasingly incorporated into deep learning models to significantly enhance state-of-the-art accuracy and efficiency in time series analysis. The advantages of FT, such as high efficiency and a global view, have been rapidly explored and exploited in various time series tasks and applications, demonstrating the promising potential of FT as a new deep learning paradigm for time series analysis. Despite the growing attention and the proliferation of research in this emerging field, there is currently a lack of a systematic review and in-depth analysis of deep learning-based time series models with FT. It is also unclear why FT can enhance time series analysis and what its limitations in the field are. To address these gaps, we present a comprehensive review that systematically investigates and summarizes the recent research advancements in deep learning-based time series analysis with FT. Specifically, we explore the primary approaches used in current models that incorporate FT, the types of neural networks that leverage FT, and the representative FT-equipped models in deep time series analysis. We propose a novel taxonomy to categorize the existing methods in this field, providing a structured overview of the diverse approaches employed in incorporating FT into deep learning models for time series analysis. Finally, we highlight the advantages and limitations of FT for time series modeling and identify potential future research directions that can further contribute to the community of time series analysis.",
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "authors": [
                {
                    "authorId": "2060200167",
                    "name": "Kun Yi"
                },
                {
                    "authorId": "47835189",
                    "name": "Qi Zhang"
                },
                {
                    "authorId": "2116951322",
                    "name": "Shoujin Wang"
                },
                {
                    "authorId": "2107477853",
                    "name": "Hui He"
                },
                {
                    "authorId": "2062835",
                    "name": "Guodong Long"
                },
                {
                    "authorId": "8253080",
                    "name": "Zhendong Niu"
                }
            ]
        },
        {
            "paperId": "6d18dcd4b562ea15f3270551b71596b2a1980b07",
            "title": "Tutorials at The Web Conference 2023",
            "abstract": "This paper summarizes the content of the 28 tutorials that have been given at The Web Conference 2023.",
            "fieldsOfStudy": [
                "Computer Science",
                "Physics"
            ],
            "authors": [
                {
                    "authorId": "1705291",
                    "name": "Valeria Fionda"
                },
                {
                    "authorId": "2215622430",
                    "name": "Olaf Hartig"
                },
                {
                    "authorId": "1805958417",
                    "name": "Reyhaneh Abdolazimi"
                },
                {
                    "authorId": "1403657578",
                    "name": "S. Amer-Yahia"
                },
                {
                    "authorId": "2215690996",
                    "name": "Hongzhi Chen"
                },
                {
                    "authorId": "2117027107",
                    "name": "Xiao Chen"
                },
                {
                    "authorId": "2052469774",
                    "name": "P. Cui"
                },
                {
                    "authorId": "145269114",
                    "name": "Jeffrey Dalton"
                },
                {
                    "authorId": "2215596266",
                    "name": "Xin Luna Dong"
                },
                {
                    "authorId": "2957808",
                    "name": "Lisette Espin Noboa"
                },
                {
                    "authorId": "41031455",
                    "name": "Wenqi Fan"
                },
                {
                    "authorId": "2132398392",
                    "name": "Manuela Fritz"
                },
                {
                    "authorId": "47594426",
                    "name": "Quan Gan"
                },
                {
                    "authorId": "2161309826",
                    "name": "Jingtong Gao"
                },
                {
                    "authorId": "46909769",
                    "name": "Xiaojie Guo"
                },
                {
                    "authorId": "2215622544",
                    "name": "Torsten Hahmann"
                },
                {
                    "authorId": "145325584",
                    "name": "Jiawei Han"
                },
                {
                    "authorId": "2046142",
                    "name": "S. Han"
                },
                {
                    "authorId": "1842532",
                    "name": "Estevam Hruschka"
                },
                {
                    "authorId": "2118850040",
                    "name": "Liang Hu"
                },
                {
                    "authorId": "2139299903",
                    "name": "Jiaxin Huang"
                },
                {
                    "authorId": "47247243",
                    "name": "Utkarshani Jaimini"
                },
                {
                    "authorId": "2299944027",
                    "name": "Olivier Jeunen"
                },
                {
                    "authorId": "2214140574",
                    "name": "Yushan Jiang"
                },
                {
                    "authorId": "51118506",
                    "name": "F. Karimi"
                },
                {
                    "authorId": "50877490",
                    "name": "G. Karypis"
                },
                {
                    "authorId": "1769861",
                    "name": "K. Kenthapadi"
                },
                {
                    "authorId": "1892673",
                    "name": "Himabindu Lakkaraju"
                },
                {
                    "authorId": "3309003",
                    "name": "Hady W. Lauw"
                },
                {
                    "authorId": "145535348",
                    "name": "Thai Le"
                },
                {
                    "authorId": "1808423005",
                    "name": "Trung-Hoang Le"
                },
                {
                    "authorId": "2158951945",
                    "name": "Dongwon Lee"
                },
                {
                    "authorId": "2110855835",
                    "name": "Geon Lee"
                },
                {
                    "authorId": "19326298",
                    "name": "Liat Levontin"
                },
                {
                    "authorId": "2144231489",
                    "name": "Cheng-Te Li"
                },
                {
                    "authorId": "144911687",
                    "name": "Haoyang Li"
                },
                {
                    "authorId": "2110471246",
                    "name": "Ying Li"
                },
                {
                    "authorId": "2030126978",
                    "name": "Jay Chiehen Liao"
                },
                {
                    "authorId": "2157067900",
                    "name": "Qidong Liu"
                },
                {
                    "authorId": "46189109",
                    "name": "Usha Lokala"
                },
                {
                    "authorId": "2085850",
                    "name": "Ben London"
                },
                {
                    "authorId": "32545338",
                    "name": "Siqu Long"
                },
                {
                    "authorId": "153612944",
                    "name": "H. Mcginty"
                },
                {
                    "authorId": "145391513",
                    "name": "Yu Meng"
                },
                {
                    "authorId": "29072828",
                    "name": "Seungwhan Moon"
                },
                {
                    "authorId": "1394609613",
                    "name": "Usman Naseem"
                },
                {
                    "authorId": "49824581",
                    "name": "P. Natarajan"
                },
                {
                    "authorId": "1403851743",
                    "name": "Behrooz Omidvar-Tehrani"
                },
                {
                    "authorId": "2069543964",
                    "name": "Zijie Pan"
                },
                {
                    "authorId": "48331451",
                    "name": "Devesh Parekh"
                },
                {
                    "authorId": "2188744953",
                    "name": "Jian Pei"
                },
                {
                    "authorId": "2101664",
                    "name": "Tiago P. Peixoto"
                },
                {
                    "authorId": "144615425",
                    "name": "S. Pemberton"
                },
                {
                    "authorId": "144179461",
                    "name": "Josiah Poon"
                },
                {
                    "authorId": "2065812052",
                    "name": "Filip Radlinski"
                },
                {
                    "authorId": "48890086",
                    "name": "Federico Rossetto"
                },
                {
                    "authorId": "2091913080",
                    "name": "Kaushik Roy"
                },
                {
                    "authorId": "2911888",
                    "name": "Aghiles Salah"
                },
                {
                    "authorId": "2128305",
                    "name": "M. Sameki"
                },
                {
                    "authorId": "2064342729",
                    "name": "Amit P. Sheth"
                },
                {
                    "authorId": "28908689",
                    "name": "C. Shimizu"
                },
                {
                    "authorId": "40553270",
                    "name": "Kijung Shin"
                },
                {
                    "authorId": "2451800",
                    "name": "Dongjin Song"
                },
                {
                    "authorId": "1682824",
                    "name": "Julia Stoyanovich"
                },
                {
                    "authorId": "2064266862",
                    "name": "Dacheng Tao"
                },
                {
                    "authorId": "2528063",
                    "name": "Johanne R. Trippas"
                },
                {
                    "authorId": "39603708",
                    "name": "Quoc-Tuan Truong"
                },
                {
                    "authorId": "1896151979",
                    "name": "Yu-Che Tsai"
                },
                {
                    "authorId": "150035131",
                    "name": "Adaku Uchendu"
                },
                {
                    "authorId": "2215624802",
                    "name": "Bram Van Den Akker"
                },
                {
                    "authorId": "3265905",
                    "name": "Linshan Wang"
                },
                {
                    "authorId": "2144295736",
                    "name": "Minjie Wang"
                },
                {
                    "authorId": "2116951322",
                    "name": "Shoujin Wang"
                },
                {
                    "authorId": "2153691630",
                    "name": "Xin Wang"
                },
                {
                    "authorId": "1684687",
                    "name": "Ingmar Weber"
                },
                {
                    "authorId": "69047048",
                    "name": "H. Weld"
                },
                {
                    "authorId": "2116666963",
                    "name": "Lingfei Wu"
                },
                {
                    "authorId": "2181385841",
                    "name": "D. Xu"
                },
                {
                    "authorId": "2138609128",
                    "name": "E. Xu"
                },
                {
                    "authorId": "2111044480",
                    "name": "Shuyuan Xu"
                },
                {
                    "authorId": "2156653838",
                    "name": "Bo Yang"
                },
                {
                    "authorId": "2125559318",
                    "name": "Keyue Yang"
                },
                {
                    "authorId": "1388775854",
                    "name": "E. Yom-Tov"
                },
                {
                    "authorId": "31888223",
                    "name": "Jaemin Yoo"
                },
                {
                    "authorId": "144007938",
                    "name": "Zhou Yu"
                },
                {
                    "authorId": "2281410",
                    "name": "R. Zafarani"
                },
                {
                    "authorId": "2499986",
                    "name": "Hamed Zamani"
                },
                {
                    "authorId": "41154657",
                    "name": "Meike Zehlike"
                },
                {
                    "authorId": "2145906426",
                    "name": "Qi Zhang"
                },
                {
                    "authorId": "3358065",
                    "name": "Xikun Zhang"
                },
                {
                    "authorId": "1739818",
                    "name": "Yongfeng Zhang"
                },
                {
                    "authorId": "49891156",
                    "name": "Yu Zhang"
                },
                {
                    "authorId": "2148904413",
                    "name": "Zhengqi Zhang"
                },
                {
                    "authorId": "144010790",
                    "name": "Liang Zhao"
                },
                {
                    "authorId": "2116710405",
                    "name": "Xiangyu Zhao"
                },
                {
                    "authorId": "2156154955",
                    "name": "Wenwu Zhu"
                }
            ]
        },
        {
            "paperId": "807a1e587fec61f50970c05055243cf959fb09e5",
            "title": "Modeling Temporal Positive and Negative Excitation for Sequential Recommendation",
            "abstract": "Sequential recommendation aims to predict the next item which interests users via modeling their interest in items over time. Most of the existing works on sequential recommendation model users\u2019 dynamic interest in specific items while overlooking users\u2019 static interest revealed by some static attribute information of items, e.g., category, brand. Moreover, existing works often only consider the positive excitation of a user\u2019s historical interactions on his/her next choice on candidate items while ignoring the commonly existing negative excitation, resulting in insufficiently modeling dynamic interest. The overlook of static interest and negative excitation will lead to incomplete interest modeling and thus impedes the recommendation performance. To this end, in this paper, we propose modeling both static interest and negative excitation for dynamic interest to further improve the recommendation performance. Accordingly, we design a novel Static-Dynamic Interest Learning (SDIL) framework featured with a novel Temporal Positive and Negative Excitation Modeling (TPNE) module for accurate sequential recommendation. TPNE is specially designed for comprehensively modeling dynamic interest based on temporal positive and negative excitation learning. Extensive experiments on three real-world datasets show that SDIL can effectively capture both static and dynamic interest and outperforms state-of-the-art baselines.",
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "authors": [
                {
                    "authorId": "2150607873",
                    "name": "Chengkai Huang"
                },
                {
                    "authorId": "2116951322",
                    "name": "Shoujin Wang"
                },
                {
                    "authorId": "2107924437",
                    "name": "Xianzhi Wang"
                },
                {
                    "authorId": "145095579",
                    "name": "L. Yao"
                }
            ]
        },
        {
            "paperId": "85722b13631d9846866d45ff2bfc2a2fe1026ac8",
            "title": "LLMRec: Benchmarking Large Language Models on Recommendation Task",
            "abstract": "Recently, the fast development of Large Language Models (LLMs) such as ChatGPT has significantly advanced NLP tasks by enhancing the capabilities of conversational models. However, the application of LLMs in the recommendation domain has not been thoroughly investigated. To bridge this gap, we propose LLMRec, a LLM-based recommender system designed for benchmarking LLMs on various recommendation tasks. Specifically, we benchmark several popular off-the-shelf LLMs, such as ChatGPT, LLaMA, ChatGLM, on five recommendation tasks, including rating prediction, sequential recommendation, direct recommendation, explanation generation, and review summarization. Furthermore, we investigate the effectiveness of supervised finetuning to improve LLMs' instruction compliance ability. The benchmark results indicate that LLMs displayed only moderate proficiency in accuracy-based tasks such as sequential and direct recommendation. However, they demonstrated comparable performance to state-of-the-art methods in explainability-based tasks. We also conduct qualitative evaluations to further evaluate the quality of contents generated by different models, and the results show that LLMs can truly understand the provided information and generate clearer and more reasonable results. We aspire that this benchmark will serve as an inspiration for researchers to delve deeper into the potential of LLMs in enhancing recommendation performance. Our codes, processed data and benchmark results are available at https://github.com/williamliujl/LLMRec.",
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "authors": [
                {
                    "authorId": "2218869839",
                    "name": "Junling Liu"
                },
                {
                    "authorId": "3741691",
                    "name": "Chao-Hong Liu"
                },
                {
                    "authorId": "1800462890",
                    "name": "Peilin Zhou"
                },
                {
                    "authorId": "2190432576",
                    "name": "Qichen Ye"
                },
                {
                    "authorId": "52290752",
                    "name": "Dading Chong"
                },
                {
                    "authorId": "2165702320",
                    "name": "Kangan Zhou"
                },
                {
                    "authorId": "2154871075",
                    "name": "Yueqi Xie"
                },
                {
                    "authorId": "150346771",
                    "name": "Yuwei Cao"
                },
                {
                    "authorId": "2116951322",
                    "name": "Shoujin Wang"
                },
                {
                    "authorId": "2061592207",
                    "name": "Chenyu You"
                },
                {
                    "authorId": "2233087809",
                    "name": "Philip S.Yu"
                }
            ]
        },
        {
            "paperId": "86d6a2ada003dde3a7019a22e3e9bb2d4e750152",
            "title": "WSDM 2023 Workshop on Interactive Recommender Systems",
            "abstract": "Interactive recommender systems have attracted increasingly research attentions from both academia and industry. This workshop is a half-day event, which provides a forum for researchers and practitioners to discuss recent research progress and novel research directions about interactive recommender systems. The program will include two keynotes and 6 to 8 research paper presentations. The objective of this workshop is to consolidate the recent technical progresses about interactive recommendation, which will be a promising research and development direction for future recommendation technologies. This workshop will attract the attention of researchers from both academia and industry. It aligns with WSDM's spirit of promoting the collaborations between academia and industry.",
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "authors": [
                {
                    "authorId": "2209633655",
                    "name": "Yong Liu"
                },
                {
                    "authorId": "153504695",
                    "name": "Hao Zhang"
                },
                {
                    "authorId": "35040403",
                    "name": "Zhu Sun"
                },
                {
                    "authorId": "2116951322",
                    "name": "Shoujin Wang"
                },
                {
                    "authorId": "51250527",
                    "name": "J Zhang"
                }
            ]
        },
        {
            "paperId": "a44d904432cdda9d188bfff8e31619e02f2a4d89",
            "title": "Attention Calibration for Transformer-based Sequential Recommendation",
            "abstract": "Transformer-based sequential recommendation (SR) has been booming in recent years, with the self-attention mechanism as its key component. Self-attention has been widely believed to be able to effectively select those informative and relevant items from a sequence of interacted items for next-item prediction via learning larger attention weights for these items. However, this may not always be true in reality. Our empirical analysis of some representative Transformer-based SR models reveals that it is not uncommon for large attention weights to be assigned to less relevant items, which can result in inaccurate recommendations. Through further in-depth analysis, we find two factors that may contribute to such inaccurate assignment of attention weights:sub-optimal position encoding andnoisy input. To this end, in this paper, we aim to address this significant yet challenging gap in existing works. To be specific, we propose a simple yet effective framework called Attention Calibration for Transformer-based Sequential Recommendation (AC-TSR). In AC-TSR, a novel spatial calibrator and adversarial calibrator are designed respectively to directly calibrates those incorrectly assigned attention weights. The former is devised to explicitly capture the spatial relationships (i.e., order and distance) among items for more precise calculation of attention weights. The latter aims to redistribute the attention weights based on each item's contribution to the next-item prediction. AC-TSR is readily adaptable and can be seamlessly integrated into various existing transformer-based SR models. Extensive experimental results on four benchmark real-world datasets demonstrate the superiority of our proposed AC-TSR via significant recommendation performance enhancements. The source code is available at https://github.com/AIM-SE/AC-TSR.",
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "authors": [
                {
                    "authorId": "1800462890",
                    "name": "Peilin Zhou"
                },
                {
                    "authorId": "2190432576",
                    "name": "Qichen Ye"
                },
                {
                    "authorId": "2154871075",
                    "name": "Yueqi Xie"
                },
                {
                    "authorId": "2118389668",
                    "name": "Jingqi Gao"
                },
                {
                    "authorId": "2116951322",
                    "name": "Shoujin Wang"
                },
                {
                    "authorId": "2156009696",
                    "name": "Jae Boum Kim"
                },
                {
                    "authorId": "2061592207",
                    "name": "Chenyu You"
                },
                {
                    "authorId": "2118021616",
                    "name": "Sunghun Kim"
                }
            ]
        },
        {
            "paperId": "d17771d1e83304b0072ebc7536b638c89efe0f95",
            "title": "Learning Informative Representation for Fairness-Aware Multivariate Time-Series Forecasting: A Group-Based Perspective",
            "abstract": "Multivariate time series (MTS) forecasting penetrates various aspects of our economy and society, whose roles become increasingly recognized. However, often MTS forecasting is unfair, not only degrading their practical benefits but even incurring potential risk. Unfair MTS forecasting may be attributed to disparities relating to advantaged and disadvantaged variables, which has rarely been studied in the MTS forecasting. In this work, we formulate the MTS fairness modeling problem as learning informative representations attending to both advantaged and disadvantaged variables. Accordingly, we propose a novel framework, named <italic>FairFor</italic>, for fairness-aware MTS forecasting, i.e., <italic>fair MTS forecasting</italic>. <italic>FairFor</italic> uses adversarial learning to generate both group-irrelevant and -relevant representations for downstream forecasting. <italic>FairFor</italic> first adopts recurrent graph convolution to capture spatio-temporal variable correlations and to group variables by leveraging a spectral relaxation of the K-means objective. Then, it utilizes a novel filtering <inline-formula><tex-math notation=\"LaTeX\">$ \\& $</tex-math><alternatives><mml:math><mml:mo>&</mml:mo></mml:math><inline-graphic xlink:href=\"zhang-ieq1-3323956.gif\"/></alternatives></inline-formula> fusion module to filter group-relevant information and generate group-irrelevant representations by orthogonality regularization. The group-irrelevant and -relevant representations form highly informative representations, facilitating to share the knowledge from advantaged variables to disadvantaged variables and guarantee the fairness of forecasting. Extensive experiments on four public datasets demonstrate the <italic>FairFor</italic> effectiveness for fair forecasting and significant performance improvement.",
            "fieldsOfStudy": [
                "Computer Science",
                "Engineering"
            ],
            "authors": [
                {
                    "authorId": "2107477853",
                    "name": "Hui He"
                },
                {
                    "authorId": "2145908596",
                    "name": "Qi Zhang"
                },
                {
                    "authorId": "2116951322",
                    "name": "Shoujin Wang"
                },
                {
                    "authorId": "2060200167",
                    "name": "Kun Yi"
                },
                {
                    "authorId": "8253080",
                    "name": "Zhendong Niu"
                },
                {
                    "authorId": "2184095458",
                    "name": "Longbin Cao"
                }
            ]
        }
    ]
}