{
    "authorId": "2293818809",
    "papers": [
        {
            "paperId": "125ab16dd7de95aa897230e222ef354d6637e7ef",
            "title": "Bridging Text Data and Graph Data: Towards Semantics and Structure-aware Knowledge Discovery",
            "abstract": "Graphs and texts are two key modalities in data mining. In many cases, the data presents a mixture of the two modalities and the information is often complementary: in e-commerce data, the product-user graph and product descriptions capture different aspects of product features; in scientific literature, the citation graph, author metadata, and the paper content all contribute to modeling the paper impact.",
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "authors": [
                {
                    "authorId": "2057050247",
                    "name": "Bowen Jin"
                },
                {
                    "authorId": "2293820617",
                    "name": "Yu Zhang"
                },
                {
                    "authorId": "2293818809",
                    "name": "Sha Li"
                },
                {
                    "authorId": "2257136881",
                    "name": "Jiawei Han"
                }
            ]
        },
        {
            "paperId": "1da54405069963eaa1bba7a221b483a04ab5cdd6",
            "title": "Text2DB: Integration-Aware Information Extraction with Large Language Model Agents",
            "abstract": "The task of information extraction (IE) is to extract structured knowledge from text. However, it is often not straightforward to utilize IE output due to the mismatch between the IE ontology and the downstream application needs. We propose a new formulation of IE T EXT 2DB that emphasizes the integration of IE output and the target database (or knowledge base). Given a user instruction, a document set, and a database, our task requires the model to update the database with values from the document set to satisfy the user instruction. This task requires understanding user instructions for what to extract and adapting to the given DB/KB schema for how to extract on the fly. To evaluate this new task, we introduce a new benchmark featuring common demands such as data infilling, row population, and column addition. In addition, we propose an LLM agent framework OPAL (Observe-Plan-Analyze LLM) which includes an Observer component that interacts with the database, the Planner component that generates a code-based plan with calls to IE models, and the Analyzer component that provides feedback regarding code quality before execution. Experiments show that OPAL can successfully adapt to diverse database schemas by generating different code plans and calling the required IE models. We also highlight difficult cases such as dealing with large databases with complex dependencies and extraction hallucination, which we believe deserve further investigation.",
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "authors": [
                {
                    "authorId": "1381900594",
                    "name": "Yizhu Jiao"
                },
                {
                    "authorId": "2293818809",
                    "name": "Sha Li"
                },
                {
                    "authorId": "2187778761",
                    "name": "Sizhe Zhou"
                },
                {
                    "authorId": "2181650518",
                    "name": "Heng Ji"
                },
                {
                    "authorId": "2259869648",
                    "name": "Jiawei Han"
                }
            ]
        },
        {
            "paperId": "6c2f36544226a34ede9aaae4a9655595ab543611",
            "title": "Establishing Knowledge Preference in Language Models",
            "abstract": "Language models are known to encode a great amount of factual knowledge through pretraining. However, such knowledge might be insufficient to cater to user requests, requiring the model to integrate external knowledge sources and adhere to user-provided specifications. When answering questions about ongoing events, the model should use recent news articles to update its response; when asked to provide recommendations, the model should prioritize user specifications over retrieved product reviews; when some facts are edited in the model, the updated facts should override all prior knowledge learned by the model even if they are conflicting. In all of the cases above, the model faces a decision between its own parametric knowledge, (retrieved) contextual knowledge, and user instruction knowledge. In this paper, we (1) unify such settings into the problem of knowledge preference and define a three-level preference hierarchy over these knowledge sources; (2) compile a collection of existing datasets IfQA, MQuAKE, and MRQA covering a combination of settings (with/without user specifications, with/without context documents) to systematically evaluate how well models obey the intended knowledge preference; and (3) propose a dataset synthesis method that composes diverse question-answer pairs with user assumptions and related context to directly fine-tune LMs for instilling the hierarchy of knowledge. We demonstrate that a 7B model, fine-tuned on only a few thousand examples automatically generated by our proposed method, effectively achieves superior performance (more than 18% improvement across all evaluation benchmarks) in adhering to the desired knowledge preference hierarchy.",
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "authors": [
                {
                    "authorId": "2187778761",
                    "name": "Sizhe Zhou"
                },
                {
                    "authorId": "2293818809",
                    "name": "Sha Li"
                },
                {
                    "authorId": "145391513",
                    "name": "Yu Meng"
                },
                {
                    "authorId": "1381900594",
                    "name": "Yizhu Jiao"
                },
                {
                    "authorId": "2181650518",
                    "name": "Heng Ji"
                },
                {
                    "authorId": "2259869648",
                    "name": "Jiawei Han"
                }
            ]
        }
    ]
}