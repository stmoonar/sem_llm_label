{
    "authorId": "2066621592",
    "papers": [
        {
            "paperId": "00209e4a681118b5e56b4cd029183166af5114dd",
            "title": "OneSparse: A Unified System for Multi-index Vector Search",
            "abstract": "Multi-index vector search has become the cornerstone for many applications, such as recommendation systems. Efficient search in such a multi-modal hybrid vector space is challenging since no single index design performs well for all kinds of vector data. Existing approaches to processing multi-index hybrid queries either suffer from algorithmic limitations or processing inefficiency. In this paper, we propose OneSparse, a unified multi-vector index query system that incorporates multiple posting-based vector indices, which enables highly efficient retrieval of multi-modal data-sets. OneSparse introduces a novel multi-index query engine design of inter-index intersection push-down. It also optimizes the vector posting format to expedite multi-index queries. Our experiments show OneSparse achieves more than 6x search performance improvement while maintaining comparable accuracy. OneSparse has already been integrated into Microsoft online web search and advertising systems with 5x+ latency gain for Bing web search and 2.0% Revenue Per Mille (RPM) gain for Bing sponsored search.",
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "authors": [
                {
                    "authorId": "2301264351",
                    "name": "Yaoqi Chen"
                },
                {
                    "authorId": "2301150232",
                    "name": "Ruicheng Zheng"
                },
                {
                    "authorId": "2254026795",
                    "name": "Qi Chen"
                },
                {
                    "authorId": "2253867834",
                    "name": "Shuotao Xu"
                },
                {
                    "authorId": "2108076499",
                    "name": "Qianxi Zhang"
                },
                {
                    "authorId": "2301231880",
                    "name": "Xue Wu"
                },
                {
                    "authorId": "2114924471",
                    "name": "Weihao Han"
                },
                {
                    "authorId": "2302523164",
                    "name": "Hua Yuan"
                },
                {
                    "authorId": "2301166281",
                    "name": "Mingqin Li"
                },
                {
                    "authorId": "2279761133",
                    "name": "Yujing Wang"
                },
                {
                    "authorId": "2301168769",
                    "name": "Jason Li"
                },
                {
                    "authorId": "145338263",
                    "name": "Fan Yang"
                },
                {
                    "authorId": "2298630412",
                    "name": "Haochen Sun"
                },
                {
                    "authorId": "2066621592",
                    "name": "Weiwei Deng"
                },
                {
                    "authorId": "2075375820",
                    "name": "Feng Sun"
                },
                {
                    "authorId": "2181348993",
                    "name": "Qi Zhang"
                },
                {
                    "authorId": "2226686275",
                    "name": "Mao Yang"
                }
            ]
        },
        {
            "paperId": "146cf9e9eeb1807034a8622504529c5ef93e956f",
            "title": "Text Diffusion with Reinforced Conditioning",
            "abstract": "Diffusion models have demonstrated exceptional capability in generating high-quality images, videos, and audio. Due to their adaptiveness in iterative refinement, they provide a strong potential for achieving better non-autoregressive sequence generation. However, existing text diffusion models still fall short in their performance due to a challenge in handling the discreteness of language. This paper thoroughly analyzes text diffusion models and uncovers two significant limitations: degradation of self-conditioning during training and misalignment between training and sampling. Motivated by our findings, we propose a novel Text Diffusion model called TReC, which mitigates the degradation with Reinforced Conditioning and the misalignment by Time-Aware Variance Scaling. Our extensive experiments demonstrate the competitiveness of TReC against autoregressive, non-autoregressive, and diffusion baselines. Moreover, qualitative analysis shows its advanced ability to fully utilize the diffusion process in refining samples.",
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "authors": [
                {
                    "authorId": "2261155019",
                    "name": "Yuxuan Liu"
                },
                {
                    "authorId": "2260740143",
                    "name": "Tianchi Yang"
                },
                {
                    "authorId": "3110003",
                    "name": "Shaohan Huang"
                },
                {
                    "authorId": "2260851231",
                    "name": "Zihan Zhang"
                },
                {
                    "authorId": "2146285313",
                    "name": "Haizhen Huang"
                },
                {
                    "authorId": "2253471545",
                    "name": "Furu Wei"
                },
                {
                    "authorId": "2066621592",
                    "name": "Weiwei Deng"
                },
                {
                    "authorId": "2247156451",
                    "name": "Feng Sun"
                },
                {
                    "authorId": "2256972722",
                    "name": "Qi Zhang"
                }
            ]
        },
        {
            "paperId": "392305c7cf8922af0a919d05a26852e5d4150e9c",
            "title": "ResLoRA: Identity Residual Mapping in Low-Rank Adaption",
            "abstract": "As one of the most popular parameter-efficient fine-tuning (PEFT) methods, low-rank adaptation (LoRA) is commonly applied to fine-tune large language models (LLMs). However, updating the weights of LoRA blocks effectively and expeditiously is challenging due to the long calculation path in the original model. To address this, we propose ResLoRA, an improved framework of LoRA. By adding residual paths during training and using merging approaches to eliminate these extra paths during inference, our method can achieve better results in fewer training steps without any extra trainable parameters or inference cost compared to LoRA. The experiments on NLG, NLU, and text-to-image tasks demonstrate the effectiveness of our method. To the best of our knowledge, ResLoRA is the first work that combines the residual path with LoRA. The code of our method is available at https://github.com/microsoft/LMOps/tree/main/reslora .",
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "authors": [
                {
                    "authorId": "2288389647",
                    "name": "Shuhua Shi"
                },
                {
                    "authorId": "3110003",
                    "name": "Shaohan Huang"
                },
                {
                    "authorId": "2260342581",
                    "name": "Minghui Song"
                },
                {
                    "authorId": "2288144026",
                    "name": "Zhoujun Li"
                },
                {
                    "authorId": "2260851231",
                    "name": "Zihan Zhang"
                },
                {
                    "authorId": "2146285313",
                    "name": "Haizhen Huang"
                },
                {
                    "authorId": "2253471545",
                    "name": "Furu Wei"
                },
                {
                    "authorId": "2066621592",
                    "name": "Weiwei Deng"
                },
                {
                    "authorId": "2247156451",
                    "name": "Feng Sun"
                },
                {
                    "authorId": "2256972722",
                    "name": "Qi Zhang"
                }
            ]
        },
        {
            "paperId": "79a0648bb7e22ae183932707718b73b67e10b735",
            "title": "MoRA: High-Rank Updating for Parameter-Efficient Fine-Tuning",
            "abstract": "Low-rank adaptation is a popular parameter-efficient fine-tuning method for large language models. In this paper, we analyze the impact of low-rank updating, as implemented in LoRA. Our findings suggest that the low-rank updating mechanism may limit the ability of LLMs to effectively learn and memorize new knowledge. Inspired by this observation, we propose a new method called MoRA, which employs a square matrix to achieve high-rank updating while maintaining the same number of trainable parameters. To achieve it, we introduce the corresponding non-parameter operators to reduce the input dimension and increase the output dimension for the square matrix. Furthermore, these operators ensure that the weight can be merged back into LLMs, which makes our method can be deployed like LoRA. We perform a comprehensive evaluation of our method across five tasks: instruction tuning, mathematical reasoning, continual pretraining, memory and pretraining. Our method outperforms LoRA on memory-intensive tasks and achieves comparable performance on other tasks.",
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "authors": [
                {
                    "authorId": "2259012212",
                    "name": "Ting Jiang"
                },
                {
                    "authorId": "3110003",
                    "name": "Shaohan Huang"
                },
                {
                    "authorId": "2279762497",
                    "name": "Shengyue Luo"
                },
                {
                    "authorId": "2260851231",
                    "name": "Zihan Zhang"
                },
                {
                    "authorId": "2146285313",
                    "name": "Haizhen Huang"
                },
                {
                    "authorId": "2253471545",
                    "name": "Furu Wei"
                },
                {
                    "authorId": "2066621592",
                    "name": "Weiwei Deng"
                },
                {
                    "authorId": "2247156451",
                    "name": "Feng Sun"
                },
                {
                    "authorId": "2256972722",
                    "name": "Qi Zhang"
                },
                {
                    "authorId": "2145351849",
                    "name": "Deqing Wang"
                },
                {
                    "authorId": "2162961864",
                    "name": "Fuzhen Zhuang"
                }
            ]
        },
        {
            "paperId": "868c06e552be0c9a53d41d18eaa233402a2bb7ee",
            "title": "HD-Eval: Aligning Large Language Model Evaluators Through Hierarchical Criteria Decomposition",
            "abstract": "Large language models (LLMs) have emerged as a promising alternative to expensive human evaluations. However, the alignment and coverage of LLM-based evaluations are often limited by the scope and potential bias of the evaluation prompts and criteria. To address this challenge, we propose HD-Eval, a novel framework that iteratively aligns LLM-based evaluators with human preference via Hierarchical Criteria Decomposition. HD-Eval inherits the essence from the evaluation mindset of human experts and enhances the alignment of LLM-based evaluators by decomposing a given evaluation task into finer-grained criteria, aggregating them according to estimated human preferences, pruning insignificant criteria with attribution, and further decomposing significant criteria. By integrating these steps within an iterative alignment training process, we obtain a hierarchical decomposition of criteria that comprehensively captures aspects of natural language at multiple levels of granularity. Implemented as a white box, the human preference-guided aggregator is efficient to train and more explainable than relying solely on prompting, and its independence from model parameters makes it applicable to closed-source LLMs. Extensive experiments on three evaluation domains demonstrate the superiority of HD-Eval in further aligning state-of-the-art evaluators and providing deeper insights into the explanation of evaluation results and the task itself.",
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "authors": [
                {
                    "authorId": "2261155019",
                    "name": "Yuxuan Liu"
                },
                {
                    "authorId": "2260740143",
                    "name": "Tianchi Yang"
                },
                {
                    "authorId": "3110003",
                    "name": "Shaohan Huang"
                },
                {
                    "authorId": "2260851231",
                    "name": "Zihan Zhang"
                },
                {
                    "authorId": "2146285313",
                    "name": "Haizhen Huang"
                },
                {
                    "authorId": "2253471545",
                    "name": "Furu Wei"
                },
                {
                    "authorId": "2066621592",
                    "name": "Weiwei Deng"
                },
                {
                    "authorId": "2247156451",
                    "name": "Feng Sun"
                },
                {
                    "authorId": "2256972722",
                    "name": "Qi Zhang"
                }
            ]
        },
        {
            "paperId": "a2e1039157257a8fae038259d1642536e1641b3e",
            "title": "Se2: Sequential Example Selection for In-Context Learning",
            "abstract": "The remarkable capability of large language models (LLMs) for in-context learning (ICL) needs to be activated by demonstration examples. Prior work has extensively explored the selection of examples for ICL, predominantly following the\"select then organize\"paradigm, such approaches often neglect the internal relationships between examples and exist an inconsistency between the training and inference. In this paper, we formulate the problem as a $Se$quential $Se$lection problem and introduce $Se^2$, a sequential-aware method that leverages the LLM's feedback on varying context, aiding in capturing inter-relationships and sequential information among examples, significantly enriching the contextuality and relevance of ICL prompts. Meanwhile, we utilize beam search to seek and construct example sequences, enhancing both quality and diversity. Extensive experiments across 23 NLP tasks from 8 distinct categories illustrate that $Se^2$ markedly surpasses competitive baselines and achieves 42\\% relative improvement over random selection. Further in-depth analysis shows the effectiveness of proposed strategies, highlighting $Se^2$'s exceptional stability and adaptability across various scenarios. Code available at https://github.com/microsoft/LMOps.",
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "authors": [
                {
                    "authorId": "2285342063",
                    "name": "Haoyu Liu"
                },
                {
                    "authorId": "2284937854",
                    "name": "Jianfeng Liu"
                },
                {
                    "authorId": "3110003",
                    "name": "Shaohan Huang"
                },
                {
                    "authorId": "2279698244",
                    "name": "Yuefeng Zhan"
                },
                {
                    "authorId": "2279736148",
                    "name": "Hao Sun"
                },
                {
                    "authorId": "2066621592",
                    "name": "Weiwei Deng"
                },
                {
                    "authorId": "2253471545",
                    "name": "Furu Wei"
                },
                {
                    "authorId": "2256972722",
                    "name": "Qi Zhang"
                }
            ]
        },
        {
            "paperId": "c1474dc03848cb26d118bc37c26636d7082c3854",
            "title": "Improving Domain Adaptation through Extended-Text Reading Comprehension",
            "abstract": "To enhance the domain-specific capabilities of large language models, continued pre-training on a domain-specific corpus is a prevalent method. Recent work demonstrates that adapting models using reading comprehension data formatted by regex-based patterns can significantly improve performance on domain-specific tasks. However, regex-based patterns are incapable of parsing raw corpora using domain-specific knowledge. Furthermore, the question and answer pairs are extracted directly from the corpus in predefined formats offers limited context. To address this limitation, we improve reading comprehension via LLM and clustering. LLM focuses on leveraging domain knowledge within the corpus to refine comprehension stage, while clustering supplies relevant knowledge by extending the context to enrich reading stage. Additionally, our method incorporates parameter-efficient fine-tuning to improve the efficiency of domain adaptation. In comparison to AdaptLLM, our method achieves an improvement exceeding 5% in domain-specific tasks. Our code will available at https://github.com/microsoft/LMOps.",
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "authors": [
                {
                    "authorId": "2259012212",
                    "name": "Ting Jiang"
                },
                {
                    "authorId": "3110003",
                    "name": "Shaohan Huang"
                },
                {
                    "authorId": "2279762497",
                    "name": "Shengyue Luo"
                },
                {
                    "authorId": "2260851231",
                    "name": "Zihan Zhang"
                },
                {
                    "authorId": "2146285313",
                    "name": "Haizhen Huang"
                },
                {
                    "authorId": "2253471545",
                    "name": "Furu Wei"
                },
                {
                    "authorId": "2066621592",
                    "name": "Weiwei Deng"
                },
                {
                    "authorId": "2247156451",
                    "name": "Feng Sun"
                },
                {
                    "authorId": "2256972722",
                    "name": "Qi Zhang"
                },
                {
                    "authorId": "2145351849",
                    "name": "Deqing Wang"
                },
                {
                    "authorId": "2162961864",
                    "name": "Fuzhen Zhuang"
                }
            ]
        },
        {
            "paperId": "cd5d736218589e0d9a8db4808f31eddcc038a3cb",
            "title": "E5-V: Universal Embeddings with Multimodal Large Language Models",
            "abstract": "Multimodal large language models (MLLMs) have shown promising advancements in general visual and language understanding. However, the representation of multimodal information using MLLMs remains largely unexplored. In this work, we introduce a new framework, E5-V, designed to adapt MLLMs for achieving universal multimodal embeddings. Our findings highlight the significant potential of MLLMs in representing multimodal inputs compared to previous approaches. By leveraging MLLMs with prompts, E5-V effectively bridges the modality gap between different types of inputs, demonstrating strong performance in multimodal embeddings even without fine-tuning. We propose a single modality training approach for E5-V, where the model is trained exclusively on text pairs. This method demonstrates significant improvements over traditional multimodal training on image-text pairs, while reducing training costs by approximately 95%. Additionally, this approach eliminates the need for costly multimodal training data collection. Extensive experiments across four types of tasks demonstrate the effectiveness of E5-V. As a universal multimodal model, E5-V not only achieves but often surpasses state-of-the-art performance in each task, despite being trained on a single modality.",
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "authors": [
                {
                    "authorId": "2259012212",
                    "name": "Ting Jiang"
                },
                {
                    "authorId": "2260342581",
                    "name": "Minghui Song"
                },
                {
                    "authorId": "2260851231",
                    "name": "Zihan Zhang"
                },
                {
                    "authorId": "2146285313",
                    "name": "Haizhen Huang"
                },
                {
                    "authorId": "2066621592",
                    "name": "Weiwei Deng"
                },
                {
                    "authorId": "2247156451",
                    "name": "Feng Sun"
                },
                {
                    "authorId": "2256972722",
                    "name": "Qi Zhang"
                },
                {
                    "authorId": "2145351849",
                    "name": "Deqing Wang"
                },
                {
                    "authorId": "2162961864",
                    "name": "Fuzhen Zhuang"
                }
            ]
        },
        {
            "paperId": "ea48207a5aff36e8606ad128f7cd1aa45a9024ff",
            "title": "ASI++: Towards Distributionally Balanced End-to-End Generative Retrieval",
            "abstract": "Generative retrieval, a promising new paradigm in information retrieval, employs a seq2seq model to encode document features into parameters and decode relevant document identifiers (IDs) based on search queries. Existing generative retrieval solutions typically rely on a preprocessing stage to pre-define document IDs, which can suffer from a semantic gap between these IDs and the retrieval task. However, end-to-end training for both ID assignments and retrieval tasks is challenging due to the long-tailed distribution characteristics of real-world data, resulting in inefficient and unbalanced ID space utilization. To address these issues, we propose ASI++, a novel fully end-to-end generative retrieval method that aims to simultaneously learn balanced ID assignments and improve retrieval performance. ASI++ builds on the fully end-to-end training framework of vanilla ASI and introduces several key innovations. First, a distributionally balanced criterion addresses the imbalance in ID assignments, promoting more efficient utilization of the ID space. Next, a representation bottleneck criterion enhances dense representations to alleviate bottlenecks in learning ID assignments. Finally, an information consistency criterion integrates these processes into a joint optimization framework grounded in information theory. We further explore various module structures for learning ID assignments, including neural quantization, differentiable product quantization, and residual quantization. Extensive experiments on both public and industrial datasets demonstrate the effectiveness of ASI++ in improving retrieval performance and achieving balanced ID assignments.",
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "authors": [
                {
                    "authorId": "2261155019",
                    "name": "Yuxuan Liu"
                },
                {
                    "authorId": "2260740143",
                    "name": "Tianchi Yang"
                },
                {
                    "authorId": "2260851231",
                    "name": "Zihan Zhang"
                },
                {
                    "authorId": "2260342581",
                    "name": "Minghui Song"
                },
                {
                    "authorId": "2146285313",
                    "name": "Haizhen Huang"
                },
                {
                    "authorId": "2066621592",
                    "name": "Weiwei Deng"
                },
                {
                    "authorId": "2247156451",
                    "name": "Feng Sun"
                },
                {
                    "authorId": "2256972722",
                    "name": "Qi Zhang"
                }
            ]
        },
        {
            "paperId": "08ec444e77c43b318aa3999b32553f68f8a402fc",
            "title": "Pre-training Language Model as a Multi-perspective Course Learner",
            "abstract": "ELECTRA, the generator-discriminator pre-training framework, has achieved impressive semantic construction capability among various downstream tasks. Despite the convincing performance, ELECTRA still faces the challenges of monotonous training and deficient interaction. Generator with only masked language modeling (MLM) leads to biased learning and label imbalance for discriminator, decreasing learning efficiency; no explicit feedback loop from discriminator to generator results in the chasm between these two components, underutilizing the course learning. In this study, a multi-perspective course learning (MCL) method is proposed to fetch a many degrees and visual angles for sample-efficient pre-training, and to fully leverage the relationship between generator and discriminator. Concretely, three self-supervision courses are designed to alleviate inherent flaws of MLM and balance the label in a multi-perspective way. Besides, two self-correction courses are proposed to bridge the chasm between the two encoders by creating a\"correction notebook\"for secondary-supervision. Moreover, a course soups trial is conducted to solve the\"tug-of-war\"dynamics problem of MCL, evolving a stronger pre-trained model. Experimental results show that our method significantly improves ELECTRA's average performance by 2.8% and 3.2% absolute points respectively on GLUE and SQuAD 2.0 benchmarks, and overshadows recent advanced ELECTRA-style models under the same settings. The pre-trained MCL model is available at https://huggingface.co/McmanusChen/MCL-base.",
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "authors": [
                {
                    "authorId": "2108382686",
                    "name": "Beiduo Chen"
                },
                {
                    "authorId": "3110003",
                    "name": "Shaohan Huang"
                },
                {
                    "authorId": "2116461859",
                    "name": "Zi-qiang Zhang"
                },
                {
                    "authorId": "2149286028",
                    "name": "Wu Guo"
                },
                {
                    "authorId": "2072392338",
                    "name": "Zhen-Hua Ling"
                },
                {
                    "authorId": "2146285313",
                    "name": "Haizhen Huang"
                },
                {
                    "authorId": "49807919",
                    "name": "Furu Wei"
                },
                {
                    "authorId": "2066621592",
                    "name": "Weiwei Deng"
                },
                {
                    "authorId": "2145907063",
                    "name": "Qi Zhang"
                }
            ]
        }
    ]
}