{
    "authorId": "40626717",
    "papers": [
        {
            "paperId": "20ec685d59370acdc81a5b8eb3fd566d2b709a32",
            "title": "MC-GTA: Metric-Constrained Model-Based Clustering using Goodness-of-fit Tests with Autocorrelations",
            "abstract": "A wide range of (multivariate) temporal (1D) and spatial (2D) data analysis tasks, such as grouping vehicle sensor trajectories, can be formulated as clustering with given metric constraints. Existing metric-constrained clustering algorithms overlook the rich correlation between feature similarity and metric distance, i.e., metric autocorrelation. The model-based variations of these clustering algorithms (e.g. TICC and STICC) achieve SOTA performance, yet suffer from computational instability and complexity by using a metric-constrained Expectation-Maximization procedure. In order to address these two problems, we propose a novel clustering algorithm, MC-GTA (Model-based Clustering via Goodness-of-fit Tests with Autocorrelations). Its objective is only composed of pairwise weighted sums of feature similarity terms (square Wasserstein-2 distance) and metric autocorrelation terms (a novel multivariate generalization of classic semivariogram). We show that MC-GTA is effectively minimizing the total hinge loss for intra-cluster observation pairs not passing goodness-of-fit tests, i.e., statistically not originating from the same distribution. Experiments on 1D/2D synthetic and real-world datasets demonstrate that MC-GTA successfully incorporates metric autocorrelation. It outperforms strong baselines by large margins (up to 14.3% in ARI and 32.1% in NMI) with faster and stabler optimization (>10x speedup).",
            "fieldsOfStudy": [
                "Computer Science",
                "Mathematics"
            ],
            "authors": [
                {
                    "authorId": "2284563915",
                    "name": "Zhangyu Wang"
                },
                {
                    "authorId": "40626717",
                    "name": "Gengchen Mai"
                },
                {
                    "authorId": "2173297773",
                    "name": "Krzysztof Janowicz"
                },
                {
                    "authorId": "2135307417",
                    "name": "Ni Lao"
                }
            ]
        },
        {
            "paperId": "bed07856bd5dcfd57c1e56ec2411db45aed22683",
            "title": "Probing the Information Theoretical Roots of Spatial Dependence Measures",
            "abstract": "Intuitively, there is a relation between measures of spatial dependence and information theoretical measures of entropy. For instance, we can provide an intuition of why spatial data is special by stating that, on average, spatial data samples contain less than expected information. Similarly, spatial data, e.g., remotely sensed imagery, that is easy to compress is also likely to show significant spatial autocorrelation. Formulating our (highly specific) core concepts of spatial information theory in the widely used language of information theory opens new perspectives on their differences and similarities and also fosters cross-disciplinary collaboration, e.g., with the broader AI/ML communities. Interestingly, however, this intuitive relation is challenging to formalize and generalize, leading prior work to rely mostly on experimental results, e.g., for describing landscape patterns. In this work, we will explore the information theoretical roots of spatial autocorrelation, more specifically Moran's I, through the lens of self-information (also known as surprisal) and provide both formal proofs and experiments.",
            "fieldsOfStudy": [
                "Computer Science",
                "Mathematics"
            ],
            "authors": [
                {
                    "authorId": "2284563915",
                    "name": "Zhangyu Wang"
                },
                {
                    "authorId": "2173297773",
                    "name": "Krzysztof Janowicz"
                },
                {
                    "authorId": "40626717",
                    "name": "Gengchen Mai"
                },
                {
                    "authorId": "2303653181",
                    "name": "Ivan Majic"
                }
            ]
        },
        {
            "paperId": "00e3fb53bbd56a51db8adb875ecedc86ab0ddc43",
            "title": "EVKG: An interlinked and interoperable electric vehicle knowledge graph for smart transportation system",
            "abstract": "Over the past decade, the electric vehicle (EV) industry has experienced unprecedented growth and diversification, resulting in a complex ecosystem. To effectively manage this multifaceted field, we present an EV\u2010centric knowledge graph (EVKG) as a comprehensive, cross\u2010domain, extensible, and open geospatial knowledge management system. The EVKG encapsulates essential EV\u2010related knowledge, including EV adoption, EV supply equipment, and electricity transmission network, to support decision\u2010making related to EV technology development, infrastructure planning, and policy\u2010making by providing timely and accurate information and analysis. To enrich and contextualize the EVKG, we integrate the developed EV\u2010relevant ontology modules from existing well\u2010known knowledge graphs and ontologies. This integration enables interoperability with other knowledge graphs in the Linked Data Open Cloud, enhancing the EVKG's value as a knowledge hub for EV decision\u2010making. Using six competency questions, we demonstrate how the EVKG can be used to answer various types of EV\u2010related questions, providing critical insights into the EV ecosystem. Our EVKG provides an efficient and effective approach for managing the complex and diverse EV industry. By consolidating critical EV\u2010related knowledge into a single, easily accessible resource, the EVKG supports decision\u2010makers in making informed choices about EV technology development, infrastructure planning, and policy\u2010making. As a flexible and extensible platform, the EVKG is capable of accommodating a wide range of data sources, enabling it to evolve alongside the rapidly changing EV landscape.",
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "authors": [
                {
                    "authorId": "145270896",
                    "name": "Ye Qi"
                },
                {
                    "authorId": "40626717",
                    "name": "Gengchen Mai"
                },
                {
                    "authorId": "2070268166",
                    "name": "Rui Zhu"
                },
                {
                    "authorId": "2214004083",
                    "name": "Michael Zhang"
                }
            ]
        },
        {
            "paperId": "20c9d24790ee490f3899c7964a8d718461292d29",
            "title": "SSIF: Learning Continuous Image Representation for Spatial-Spectral Super-Resolution",
            "abstract": "Existing digital sensors capture images at fixed spatial and spectral resolutions (e.g., RGB, multispectral, and hyperspectral images), and each combination requires bespoke machine learning models. Neural Implicit Functions partially overcome the spatial resolution challenge by representing an image in a resolution-independent way. However, they still operate at fixed, pre-defined spectral resolutions. To address this challenge, we propose Spatial-Spectral Implicit Function (SSIF), a neural implicit model that represents an image as a function of both continuous pixel coordinates in the spatial domain and continuous wavelengths in the spectral domain. We empirically demonstrate the effectiveness of SSIF on two challenging spatio-spectral super-resolution benchmarks. We observe that SSIF consistently outperforms state-of-the-art baselines even when the baselines are allowed to train separate models at each spectral resolution. We show that SSIF generalizes well to both unseen spatial resolutions and spectral resolutions. Moreover, SSIF can generate high-resolution images that improve the performance of downstream tasks (e.g., land use classification) by 1.7%-7%.",
            "fieldsOfStudy": [
                "Computer Science",
                "Engineering"
            ],
            "authors": [
                {
                    "authorId": "40626717",
                    "name": "Gengchen Mai"
                },
                {
                    "authorId": "2135307417",
                    "name": "Ni Lao"
                },
                {
                    "authorId": "2250016600",
                    "name": "Weiwei Sun"
                },
                {
                    "authorId": "2249853600",
                    "name": "Yuchi Ma"
                },
                {
                    "authorId": "2250159648",
                    "name": "Jiaming Song"
                },
                {
                    "authorId": "83262128",
                    "name": "Chenlin Meng"
                },
                {
                    "authorId": "2249891390",
                    "name": "Hongxu Ma"
                },
                {
                    "authorId": "2249762455",
                    "name": "Jinmeng Rao"
                },
                {
                    "authorId": "2214579492",
                    "name": "Ziyuan Li"
                },
                {
                    "authorId": "2490652",
                    "name": "Stefano Ermon"
                }
            ]
        },
        {
            "paperId": "303ac31085a35500194416ec089e0dc2771b722f",
            "title": "Text2Seg: Remote Sensing Image Semantic Segmentation via Text-Guided Visual Foundation Models",
            "abstract": "Remote sensing imagery has attracted significant attention in recent years due to its instrumental role in global environmental monitoring, land usage monitoring, and more. As image databases grow each year, performing automatic segmentation with deep learning models has gradually become the standard approach for processing the data. Despite the improved performance of current models, certain limitations remain unresolved. Firstly, training deep learning models for segmentation requires per-pixel annotations. Given the large size of datasets, only a small portion is fully annotated and ready for training. Additionally, the high intra-dataset variance in remote sensing data limits the transfer learning ability of such models. Although recently proposed generic segmentation models like SAM have shown promising results in zero-shot instance-level segmentation, adapting them to semantic segmentation is a non-trivial task. To tackle these challenges, we propose a novel method named Text2Seg for remote sensing semantic segmentation. Text2Seg overcomes the dependency on extensive annotations by employing an automatic prompt generation process using different visual foundation models (VFMs), which are trained to understand semantic information in various ways. This approach not only reduces the need for fully annotated datasets but also enhances the model's ability to generalize across diverse datasets. Evaluations on four widely adopted remote sensing datasets demonstrate that Text2Seg significantly improves zero-shot prediction performance compared to the vanilla SAM model, with relative improvements ranging from 31% to 225%. Our code is available at https://github.com/Douglas2Code/Text2Seg.",
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "authors": [
                {
                    "authorId": "150167509",
                    "name": "Jielu Zhang"
                },
                {
                    "authorId": "2116589565",
                    "name": "Zhongliang Zhou"
                },
                {
                    "authorId": "40626717",
                    "name": "Gengchen Mai"
                },
                {
                    "authorId": "2215168738",
                    "name": "Lan Mu"
                },
                {
                    "authorId": "2215174877",
                    "name": "Mengxuan Hu"
                },
                {
                    "authorId": "39541577",
                    "name": "Sheng Li"
                }
            ]
        },
        {
            "paperId": "4d08d652a80050d3682a626ca0fa388534a160b4",
            "title": "Building Privacy-Preserving and Secure Geospatial Artificial Intelligence Foundation Models (Vision Paper)",
            "abstract": "In recent years we have seen substantial advances in foundation models for artificial intelligence, including language, vision, and multimodal models. Recent studies have highlighted the potential of using foundation models in geospatial artificial intelligence, known as GeoAI Foundation Models, for geographic question answering, remote sensing image understanding, map generation, and location-based services, among others. However, the development and application of GeoAI foundation models can pose serious privacy and security risks, which have not been fully discussed or addressed to date. This paper introduces the potential privacy and security risks throughout the lifecycle of GeoAI foundation models and proposes a comprehensive blueprint for research directions and preventative and control strategies. Through this vision paper, we hope to draw the attention of researchers and policymakers in geospatial domains to these privacy and security risks inherent in GeoAI foundation models and advocate for the development of privacy-preserving and secure GeoAI foundation models.",
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "authors": [
                {
                    "authorId": "29952206",
                    "name": "Jinmeng Rao"
                },
                {
                    "authorId": "2261100216",
                    "name": "Song Gao"
                },
                {
                    "authorId": "40626717",
                    "name": "Gengchen Mai"
                },
                {
                    "authorId": "2173297773",
                    "name": "Krzysztof Janowicz"
                }
            ]
        },
        {
            "paperId": "76f85712c5ad90ed3b7b3e52ff8343cb0c5fbf07",
            "title": "CSP: Self-Supervised Contrastive Spatial Pre-Training for Geospatial-Visual Representations",
            "abstract": "Geo-tagged images are publicly available in large quantities, whereas labels such as object classes are rather scarce and expensive to collect. Meanwhile, contrastive learning has achieved tremendous success in various natural image and language tasks with limited labeled data. However, existing methods fail to fully leverage geospatial information, which can be paramount to distinguishing objects that are visually similar. To directly leverage the abundant geospatial information associated with images in pre-training, fine-tuning, and inference stages, we present Contrastive Spatial Pre-Training (CSP), a self-supervised learning framework for geo-tagged images. We use a dual-encoder to separately encode the images and their corresponding geo-locations, and use contrastive objectives to learn effective location representations from images, which can be transferred to downstream supervised tasks such as image classification. Experiments show that CSP can improve model performance on both iNat2018 and fMoW datasets. Especially, on iNat2018, CSP significantly boosts the model performance with 10-34% relative improvement with various labeled training data sampling ratios.",
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "authors": [
                {
                    "authorId": "40626717",
                    "name": "Gengchen Mai"
                },
                {
                    "authorId": "2135307417",
                    "name": "Ni Lao"
                },
                {
                    "authorId": "1490933536",
                    "name": "Yutong He"
                },
                {
                    "authorId": "51453887",
                    "name": "Jiaming Song"
                },
                {
                    "authorId": "2490652",
                    "name": "Stefano Ermon"
                }
            ]
        },
        {
            "paperId": "7c9d39c6cfff82e08ab556a8297822507ca44981",
            "title": "The Expertise Ontology: Modeling Expertise in the Context of Emergency Management",
            "abstract": "It is crucial for emergency management organizations to have rapid access to relevant experts who can advise and assist following a disaster. To improve expert-mining and recommendation capabilities, creating a knowledge graph that links experts to their corresponding topics of expertise and other sources of relevant information is a natural choice to capture an integrated network of people and a rich taxonomy of expertise. In this paper, we present an ontology for modeling experts, their expertise topics and relations between them, and their spatiotemporal scoping. We go on to discuss the primary conceptual components and how they can be instantiated, then present overarching examples related to emergency management operations. The ontology synthesizes three different ways to characterize an expert, based on a) identifiable academic expertise; b) voluntary engagements, work-related responsibilities or experience; and c) organization specializations or affiliations.",
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "authors": [
                {
                    "authorId": "39610072",
                    "name": "Shirly Stephen"
                },
                {
                    "authorId": "1962202",
                    "name": "M. Schildhauer"
                },
                {
                    "authorId": "2112830444",
                    "name": "Ling Cai"
                },
                {
                    "authorId": "2284617310",
                    "name": "Yuanyuan Tian"
                },
                {
                    "authorId": "2256211984",
                    "name": "Kitty Currier"
                },
                {
                    "authorId": "28908689",
                    "name": "C. Shimizu"
                },
                {
                    "authorId": "2173297773",
                    "name": "Krzysztof Janowicz"
                },
                {
                    "authorId": "2265653053",
                    "name": "Pascal Hitzler"
                },
                {
                    "authorId": "1406553068",
                    "name": "Anna Lopez-Carr"
                },
                {
                    "authorId": "2256213767",
                    "name": "Andrew Schroeder"
                },
                {
                    "authorId": "2145253061",
                    "name": "Zilong Liu"
                },
                {
                    "authorId": "2256211667",
                    "name": "Rui Zhu"
                },
                {
                    "authorId": "2256210338",
                    "name": "Colby K. Fisher"
                },
                {
                    "authorId": "40626717",
                    "name": "Gengchen Mai"
                },
                {
                    "authorId": "2284306135",
                    "name": "Tony Huang"
                }
            ]
        },
        {
            "paperId": "7d5657c78f3fee9756061c6a82db44db9d413e0b",
            "title": "AD-AutoGPT: An Autonomous GPT for Alzheimer's Disease Infodemiology",
            "abstract": "In this pioneering study, inspired by AutoGPT, the state-of-the-art open-source application based on the GPT-4 large language model, we develop a novel tool called AD-AutoGPT which can conduct data collection, processing, and analysis about complex health narratives of Alzheimer's Disease in an autonomous manner via users' textual prompts. We collated comprehensive data from a variety of news sources, including the Alzheimer's Association, BBC, Mayo Clinic, and the National Institute on Aging since June 2022, leading to the autonomous execution of robust trend analyses, intertopic distance maps visualization, and identification of salient terms pertinent to Alzheimer's Disease. This approach has yielded not only a quantifiable metric of relevant discourse but also valuable insights into public focus on Alzheimer's Disease. This application of AD-AutoGPT in public health signifies the transformative potential of AI in facilitating a data-rich understanding of complex health narratives like Alzheimer's Disease in an autonomous manner, setting the groundwork for future AI-driven investigations in global health landscapes.",
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "authors": [
                {
                    "authorId": "29944950",
                    "name": "Haixing Dai"
                },
                {
                    "authorId": "2111161355",
                    "name": "Yiwei Li"
                },
                {
                    "authorId": "2145977326",
                    "name": "Zheng Liu"
                },
                {
                    "authorId": "2111641126",
                    "name": "Lin Zhao"
                },
                {
                    "authorId": "47039788",
                    "name": "Zihao Wu"
                },
                {
                    "authorId": "15168164",
                    "name": "Suhang Song"
                },
                {
                    "authorId": "2136131892",
                    "name": "Ye Shen"
                },
                {
                    "authorId": "2181182",
                    "name": "Dajiang Zhu"
                },
                {
                    "authorId": "113075935",
                    "name": "Xiang Li"
                },
                {
                    "authorId": "2153702893",
                    "name": "Sheng Li"
                },
                {
                    "authorId": "2220689432",
                    "name": "Xiaobai Yao"
                },
                {
                    "authorId": "5931921",
                    "name": "Lu Shi"
                },
                {
                    "authorId": "1762919",
                    "name": "Quanzheng Li"
                },
                {
                    "authorId": "48354755",
                    "name": "Zhuo Chen"
                },
                {
                    "authorId": "49357039",
                    "name": "D. Zhang"
                },
                {
                    "authorId": "40626717",
                    "name": "Gengchen Mai"
                },
                {
                    "authorId": "2115345993",
                    "name": "Tianming Liu"
                }
            ]
        },
        {
            "paperId": "7dd463b2fef845f3cbd39db36a8fbeec7109956d",
            "title": "AGI: Artificial General Intelligence for Education",
            "abstract": "Artificial general intelligence (AGI) has gained global recognition as a future technology due to the emergence of breakthrough large language models and chatbots such as GPT-4 and ChatGPT, respectively. Compared to conventional AI models, typically designed for a limited range of tasks, demand significant amounts of domain-specific data for training and may not always consider intricate interpersonal dynamics in education. AGI, driven by the recent large pre-trained models, represents a significant leap in the capability of machines to perform tasks that require human-level intelligence, such as reasoning, problem-solving, decision-making, and even understanding human emotions and social interactions. This position paper reviews AGI's key concepts, capabilities, scope, and potential within future education, including achieving future educational goals, designing pedagogy and curriculum, and performing assessments. It highlights that AGI can significantly improve intelligent tutoring systems, educational assessment, and evaluation procedures. AGI systems can adapt to individual student needs, offering tailored learning experiences. They can also provide comprehensive feedback on student performance and dynamically adjust teaching methods based on student progress. The paper emphasizes that AGI's capabilities extend to understanding human emotions and social interactions, which are critical in educational settings. The paper discusses that ethical issues in education with AGI include data bias, fairness, and privacy and emphasizes the need for codes of conduct to ensure responsible AGI use in academic settings like homework, teaching, and recruitment. We also conclude that the development of AGI necessitates interdisciplinary collaborations between educators and AI engineers to advance research and application efforts.",
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "authors": [
                {
                    "authorId": "50355525",
                    "name": "E. Latif"
                },
                {
                    "authorId": "40626717",
                    "name": "Gengchen Mai"
                },
                {
                    "authorId": "2120697686",
                    "name": "Matthew Nyaaba"
                },
                {
                    "authorId": "2145346360",
                    "name": "Xuansheng Wu"
                },
                {
                    "authorId": "47717322",
                    "name": "Ninghao Liu"
                },
                {
                    "authorId": "2114183110",
                    "name": "Guoyu Lu"
                },
                {
                    "authorId": "2153702893",
                    "name": "Sheng Li"
                },
                {
                    "authorId": "2115345993",
                    "name": "Tianming Liu"
                },
                {
                    "authorId": "2202162761",
                    "name": "Xiaoming Zhai"
                }
            ]
        }
    ]
}