{
    "authorId": "144444438",
    "papers": [
        {
            "paperId": "24e277f6484083e0e18ab99ada96955b98bb8b9b",
            "title": "Exploring Contrastive Learning for Long-Tailed Multi-Label Text Classification",
            "abstract": "Learning an effective representation in multi-label text classification (MLTC) is a significant challenge in NLP. This challenge arises from the inherent complexity of the task, which is shaped by two key factors: the intricate connections between labels and the widespread long-tailed distribution of the data. To overcome this issue, one potential approach involves integrating supervised contrastive learning with classical supervised loss functions. Although contrastive learning has shown remarkable performance in multi-class classification, its impact in the multi-label framework has not been thoroughly investigated. In this paper, we conduct an in-depth study of supervised contrastive learning and its influence on representation in MLTC context. We emphasize the importance of considering long-tailed data distributions to build a robust representation space, which effectively addresses two critical challenges associated with contrastive learning that we identify: the\"lack of positives\"and the\"attraction-repulsion imbalance\". Building on this insight, we introduce a novel contrastive loss function for MLTC. It attains Micro-F1 scores that either match or surpass those obtained with other frequently employed loss functions, and demonstrates a significant improvement in Macro-F1 scores across three multi-label datasets.",
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "authors": [
                {
                    "authorId": "2223158865",
                    "name": "Alexandre Audibert"
                },
                {
                    "authorId": "2296711693",
                    "name": "Aur\u00e9lien Gauffre"
                },
                {
                    "authorId": "144444438",
                    "name": "Massih-Reza Amini"
                }
            ]
        },
        {
            "paperId": "3069478b8ef4218451a91df966df31ad5afab97e",
            "title": "Classification Tree-based Active Learning: A Wrapper Approach",
            "abstract": "Supervised machine learning often requires large training sets to train accurate models, yet obtaining large amounts of labeled data is not always feasible. Hence, it becomes crucial to explore active learning methods for reducing the size of training sets while maintaining high accuracy. The aim is to select the optimal subset of data for labeling from an initial unlabeled set, ensuring precise prediction of outcomes. However, conventional active learning approaches are comparable to classical random sampling. This paper proposes a wrapper active learning method for classification, organizing the sampling process into a tree structure, that improves state-of-the-art algorithms. A classification tree constructed on an initial set of labeled samples is considered to decompose the space into low-entropy regions. Input-space based criteria are used thereafter to sub-sample from these regions, the total number of points to be labeled being decomposed into each region. This adaptation proves to be a significant enhancement over existing active learning methods. Through experiments conducted on various benchmark data sets, the paper demonstrates the efficacy of the proposed framework by being effective in constructing accurate classification models, even when provided with a severely restricted labeled data set.",
            "fieldsOfStudy": [
                "Computer Science",
                "Mathematics"
            ],
            "authors": [
                {
                    "authorId": "2296716031",
                    "name": "Ashna Jose"
                },
                {
                    "authorId": "2258693793",
                    "name": "Emilie Devijver"
                },
                {
                    "authorId": "144444438",
                    "name": "Massih-Reza Amini"
                },
                {
                    "authorId": "2254667435",
                    "name": "No\u00ebl Jakse"
                },
                {
                    "authorId": "2232343322",
                    "name": "R. Poloni"
                }
            ]
        },
        {
            "paperId": "4f9eefd9a34ea8ceb4b76ffe28983268c765d419",
            "title": "Multi-class Probabilistic Bounds for Majority Vote Classifiers with Partially Labeled Data",
            "abstract": "In this paper, we propose a probabilistic framework for analyzing a multi-class majority vote classi\ufb01er in the case where training data is partially labeled. First, we derive a multi-class transductive bound over the risk of the majority vote classi\ufb01er, which is based on the classi\ufb01er\u2019s vote distribution over each class. Then, we introduce a mislabeling error model to analyze the error of the majority vote classi\ufb01er in the case of the pseudo-labeled training data. We derive a generalization bound over the majority vote error when imperfect labels are given, taking into account the mean and the variance of the prediction margin. Finally, we demonstrate an application of the derived transductive bound for self-training to \ufb01nd automatically the con\ufb01dence threshold used to determine unlabeled examples for pseudo-labeling. Empirical results on di\ufb00erent data sets show the e\ufb00ectiveness of our framework compared to several state-of-the-art semi-supervised approaches.",
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "authors": [
                {
                    "authorId": "66383219",
                    "name": "Vasilii Feofanov"
                },
                {
                    "authorId": "2876902",
                    "name": "Emilie Devijver"
                },
                {
                    "authorId": "144444438",
                    "name": "Massih-Reza Amini"
                }
            ]
        },
        {
            "paperId": "51c8692d371fbe48a6270a5f8daf25e4a82ed820",
            "title": "Neural architecture search for radio map reconstruction with partially labeled data",
            "abstract": "In this paper, we tackle the challenging task of reconstructing Received Signal Strength (RSS) maps by harnessing location-dependent radio measurements and augmenting them with supplementary data related to the local environment. This side information includes city plans, terrain elevations, and the locations of gateways. The quantity of available supplementary data varies, necessitating the utilization of Neural Architecture Search (NAS) to tailor the neural network architecture to the specific characteristics of each setting. Our approach takes advantage of NAS\u2019s adaptability, allowing it to automatically explore and pinpoint the optimal neural network architecture for each unique scenario. This adaptability ensures that the model is finely tuned to extract the most relevant features from the input data, thereby maximizing its ability to accurately reconstruct RSS maps. We demonstrate the effectiveness of our approach using three distinct datasets, each corresponding to a major city. Notably, we observe significant enhancements in areas near the gateways, where fluctuations in the mean received signal power are typically more pronounced. This underscores the importance of NAS-driven architectures in capturing subtle spatial variations. We also illustrate how NAS efficiently identifies the architecture of a Neural Network using both labeled and unlabeled data for Radio Map reconstruction. Our findings emphasize the potential of NAS as a potent tool for improving the precision and applicability of RSS map reconstruction techniques in urban environments.",
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "authors": [
                {
                    "authorId": "2093472485",
                    "name": "A. Malkova"
                },
                {
                    "authorId": "144444438",
                    "name": "Massih-Reza Amini"
                },
                {
                    "authorId": "2282678591",
                    "name": "Beno\u00eet Denis"
                },
                {
                    "authorId": "1924694",
                    "name": "C. Villien"
                }
            ]
        },
        {
            "paperId": "56e45ced6cea0cbe8b7217b249e6d5e5cc42f1af",
            "title": "Unified Framework for Neural Network Compression via Decomposition and Optimal Rank Selection",
            "abstract": "Despite their high accuracy, complex neural networks demand significant computational resources, posing challenges for deployment on resource-constrained devices such as mobile phones and embedded systems. Compression algorithms have been developed to address these challenges by reducing model size and computational demands while maintaining accuracy. Among these approaches, factorization methods based on tensor decomposition are theoretically sound and effective. However, they face difficulties in selecting the appropriate rank for decomposition. This paper tackles this issue by presenting a unified framework that simultaneously applies decomposition and optimal rank selection, employing a composite compression loss within defined rank constraints. Our approach includes an automatic rank search in a continuous space, efficiently identifying optimal rank configurations without the use of training data, making it computationally efficient. Combined with a subsequent fine-tuning step, our approach maintains the performance of highly compressed models on par with their original counterparts. Using various benchmark datasets, we demonstrate the efficacy of our method through a comprehensive analysis.",
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "authors": [
                {
                    "authorId": "2319830253",
                    "name": "Ali Aghababaei-Harandi"
                },
                {
                    "authorId": "144444438",
                    "name": "Massih-Reza Amini"
                }
            ]
        },
        {
            "paperId": "75acd6194b368c1c780ba3188c297e3e3f23ff40",
            "title": "Jargon: A Suite of Language Models and Evaluation Tasks for French Specialized Domains",
            "abstract": "Pretrained Language Models (PLMs) are the de facto backbone of most state-of-the-art NLP systems. In this paper, we introduce a family of domain-specific pretrained PLMs for French, focusing on three important domains: transcribed speech, medicine, and law. We use a transformer architecture based on efficient methods (LinFormer) to maximise their utility, since these domains often involve processing long documents. We evaluate and compare our models to state-of-the-art models on a diverse set of tasks and datasets, some of which are introduced in this paper. We gather the datasets into a new French-language evaluation benchmark for these three domains. We also compare various training configurations: continued pretraining, pretraining from scratch, as well as single- and multi-domain pretraining. Extensive domain-specific experiments show that it is possible to attain competitive downstream performance even when pre-training with the approximative LinFormer attention mechanism. For full reproducibility, we release the models and pretraining data, as well as contributed datasets.",
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "authors": [
                {
                    "authorId": "139097094",
                    "name": "Vincent Segonne"
                },
                {
                    "authorId": "2003619686",
                    "name": "Aidan Mannion"
                },
                {
                    "authorId": "2302562177",
                    "name": "Laura Cristina Alonzo Canul"
                },
                {
                    "authorId": "2223158865",
                    "name": "Alexandre Audibert"
                },
                {
                    "authorId": "2302320764",
                    "name": "Xingyu Liu"
                },
                {
                    "authorId": "2261848410",
                    "name": "C\u00e9cile Macaire"
                },
                {
                    "authorId": "2185314126",
                    "name": "Adrien Pupier"
                },
                {
                    "authorId": "2302122191",
                    "name": "Yongxin Zhou"
                },
                {
                    "authorId": "2301581563",
                    "name": "Mathilde Aguiar"
                },
                {
                    "authorId": "2302563348",
                    "name": "Felix E. Herron"
                },
                {
                    "authorId": "2033742895",
                    "name": "Magali Norr\u00e9"
                },
                {
                    "authorId": "144444438",
                    "name": "Massih-Reza Amini"
                },
                {
                    "authorId": "2217830773",
                    "name": "Pierrette Bouillon"
                },
                {
                    "authorId": "2301581032",
                    "name": "Iris Eshkol-Taravella"
                },
                {
                    "authorId": "2237431477",
                    "name": "Emmanuelle Esperan\u00e7a-Rodier"
                },
                {
                    "authorId": "2301579198",
                    "name": "Thomas Fran\u00e7ois"
                },
                {
                    "authorId": "2301580714",
                    "name": "Lorraine Goeuriot"
                },
                {
                    "authorId": "3266126",
                    "name": "J\u00e9r\u00f4me Goulian"
                },
                {
                    "authorId": "2301581108",
                    "name": "Mathieu Lafourcade"
                },
                {
                    "authorId": "2281748259",
                    "name": "Benjamin Lecouteux"
                },
                {
                    "authorId": "2301579319",
                    "name": "Fran\u00e7ois Portet"
                },
                {
                    "authorId": "2124680",
                    "name": "F. Ringeval"
                },
                {
                    "authorId": "2288614297",
                    "name": "Vincent Vandeghinste"
                },
                {
                    "authorId": "3443469",
                    "name": "Maximin Coavoux"
                },
                {
                    "authorId": "3003979",
                    "name": "Marco Dinarelli"
                },
                {
                    "authorId": "2237429172",
                    "name": "Didier Schwab"
                }
            ]
        },
        {
            "paperId": "12862cc5cbe2a010ce5f05523857b18d83fab57b",
            "title": "Generalization Guarantees of Self-Training of Halfspaces under Label Noise Corruption",
            "abstract": "We investigate the generalization properties of a self-training algorithm with halfspaces. The approach learns a list of halfspaces iteratively from labeled and unlabeled training data, in which each iteration consists of two steps: exploration and pruning. In the exploration phase, the halfspace is found sequentially by maximizing the unsigned-margin among unlabeled examples and then assigning pseudo-labels to those that have a distance higher than the current threshold. These pseudo-labels are allegedly corrupted by noise. The training set is then augmented with noisy pseudo-labeled examples, and a new classifier is trained. This process is repeated until no more unlabeled examples remain for pseudo-labeling. In the pruning phase, pseudo-labeled samples that have a distance to the last halfspace greater than the associated unsigned-margin are then discarded. We prove that the misclassification error of the resulting sequence of classifiers is bounded and show that the resulting semi-supervised approach never degrades performance compared to the classifier learned using only the initial labeled training set. Experiments carried out on a variety of benchmarks demonstrate the efficiency of the proposed approach compared to state-of-the-art methods.",
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "authors": [
                {
                    "authorId": "2142471704",
                    "name": "Lies Hadjadj"
                },
                {
                    "authorId": "144444438",
                    "name": "Massih-Reza Amini"
                },
                {
                    "authorId": "1905833",
                    "name": "S. Louhichi"
                }
            ]
        },
        {
            "paperId": "bd1cca193c034953af164102c8956a0ad0cb8d24",
            "title": "Pool-Based Active Learning with Proper Topological Regions",
            "abstract": "Machine learning methods usually rely on large sample size to have good performance, while it is difficult to provide labeled set in many applications. Pool-based active learning methods are there to detect, among a set of unlabeled data, the ones that are the most relevant for the training. We propose in this paper a meta-approach for pool-based active learning strategies in the context of multi-class classification tasks based on Proper Topological Regions. PTR, based on topological data analysis (TDA), are relevant regions used to sample cold-start points or within the active learning scheme. The proposed method is illustrated empirically on various benchmark datasets, being competitive to the classical methods from the literature.",
            "fieldsOfStudy": [
                "Computer Science",
                "Mathematics"
            ],
            "authors": [
                {
                    "authorId": "2142471704",
                    "name": "Lies Hadjadj"
                },
                {
                    "authorId": "2876902",
                    "name": "Emilie Devijver"
                },
                {
                    "authorId": "2253463126",
                    "name": "R'emi Molinier"
                },
                {
                    "authorId": "144444438",
                    "name": "Massih-Reza Amini"
                }
            ]
        },
        {
            "paperId": "c692a6e606d076bfae9fa93aacb3cbabd9127b65",
            "title": "Deep Learning with Partially Labeled Data for Radio Map Reconstruction",
            "abstract": "In this paper, we address the problem of Received Signal Strength map reconstruction based on location-dependent radio measurements and utilizing side knowledge about the local region; for example, city plan, terrain height, gateway position. Depending on the quantity of such prior side information, we employ Neural Architecture Search to find an optimized Neural Network model with the best architecture for each of the supposed settings. We demonstrate that using additional side information enhances the final accuracy of the Received Signal Strength map reconstruction on three datasets that correspond to three major cities, particularly in sub-areas near the gateways where larger variations of the average received signal power are typically observed.",
            "fieldsOfStudy": [
                "Computer Science",
                "Engineering",
                "Mathematics"
            ],
            "authors": [
                {
                    "authorId": "2219692353",
                    "name": "Alkesandra Malkova"
                },
                {
                    "authorId": "144444438",
                    "name": "Massih-Reza Amini"
                },
                {
                    "authorId": "6356417",
                    "name": "B. Denis"
                },
                {
                    "authorId": "1924694",
                    "name": "C. Villien"
                }
            ]
        },
        {
            "paperId": "c9c3ae012b682d97cba62dca0f579c368fe6aa94",
            "title": "Low-Rank Updates of pre-trained Weights for Multi-Task Learning",
            "abstract": "Multi-Task Learning used with pre-trained models has been quite popular in the field of Natural Language Processing in recent years. This framework remains still challenging due to the complexity of the tasks and the challenges associated with fine-tuning large pre-trained models. In this paper, we propose a new approach for Multi-task learning which is based on stacking the weights of Neural Networks as a tensor. We show that low-rank updates in the canonical polyadic tensor decomposition of this tensor of weights lead to a simple, yet efficient algorithm, which without loss of performance allows to reduce considerably the model parameters. We investigate the interactions between tasks inside the model as well as the inclusion of sparsity to find the best tensor rank and to increase the compression rate. Our strategy is consistent with recent efforts that attempt to use constraints to fine-tune some model components. More precisely, we achieve equivalent performance as the state-of-the-art on the General Language Understanding Evaluation benchmark by training only 0.3% of the parameters per task while not modifying the baseline weights.",
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "authors": [
                {
                    "authorId": "2223158865",
                    "name": "Alexandre Audibert"
                },
                {
                    "authorId": "144444438",
                    "name": "Massih-Reza Amini"
                },
                {
                    "authorId": "2616556",
                    "name": "K. Usevich"
                },
                {
                    "authorId": "2889171",
                    "name": "M. Clausel"
                }
            ]
        },
        {
            "paperId": "10170aac8e942d74da0cd669c3e8eb8cb649d408",
            "title": "Ranking-Based Physics-Informed Line Failure Detection in Power Grids",
            "abstract": "Climate change increases the number of extreme weather events (wind and snowstorms, heavy rains, wildfires) that compromise power system reliability and lead to multiple equipment failures. Real-time and accurate detecting of potential line failures is the first step to mitigating the extreme weather impact and activating emergency controls. Power balance equations nonlinearity, increased uncertainty in generation during extreme events, and lack of grid observability compromise the efficiency of traditional data-driven failure detection methods. At the same time, modern problem-oblivious machine learning methods based on neural networks require a large amount of data to detect an accident, especially in a time-changing environment. This paper proposes a Physics-InformEd Line failure Detector (FIELD) that leverages grid topology information to reduce sample and time complexities and improve localization accuracy. Finally, we illustrate the superior empirical performance of our approach compared to state-of-the-art methods over various test cases.",
            "fieldsOfStudy": [
                "Computer Science",
                "Engineering"
            ],
            "authors": [
                {
                    "authorId": "2037379701",
                    "name": "Aleksandra Burashnikova"
                },
                {
                    "authorId": "2108743200",
                    "name": "Wenting Li"
                },
                {
                    "authorId": "144444438",
                    "name": "Massih-Reza Amini"
                },
                {
                    "authorId": "2178341247",
                    "name": "Deepjoyti Deka"
                },
                {
                    "authorId": "3147078",
                    "name": "Yury Maximov"
                }
            ]
        },
        {
            "paperId": "4833a3266e774083938785963a5c9815e0f21257",
            "title": "Learning over No-Preferred and Preferred Sequence of Items for Robust Recommendation (Extended Abstract)",
            "abstract": "This paper is an extended version of [Burashnikova et al., 2021, arXiv: 2012.06910], where we proposed a theoretically supported sequential strategy for training a large-scale Recommender System (RS) over implicit feedback, mainly in the form of clicks. The proposed approach consists in minimizing pairwise ranking loss over blocks of consecutive items constituted by a sequence of non-clicked items followed by a clicked one for each user. We present two variants of this strategy where model parameters are updated using either the momentum method or a gradient-based approach. To prevent updating the parameters for an abnormally high number of clicks over some targeted items (mainly due to bots), we introduce an upper and a lower threshold on the number of updates for each user. These thresholds are estimated over the distribution of the number of blocks in the training set. They affect the decision of RS by shifting the distribution of items that are shown to the users. Furthermore, we provide a convergence analysis of both algorithms and demonstrate their practical efficiency over six large-scale collections with respect to various ranking measures.",
            "fieldsOfStudy": [
                "Computer Science",
                "Mathematics"
            ],
            "authors": [
                {
                    "authorId": "2037379701",
                    "name": "Aleksandra Burashnikova"
                },
                {
                    "authorId": "3147078",
                    "name": "Yury Maximov"
                },
                {
                    "authorId": "2889171",
                    "name": "M. Clausel"
                },
                {
                    "authorId": "1947597",
                    "name": "Charlotte Laclau"
                },
                {
                    "authorId": "3060709",
                    "name": "F. Iutzeler"
                },
                {
                    "authorId": "144444438",
                    "name": "Massih-Reza Amini"
                }
            ]
        },
        {
            "paperId": "8c22c1e4bff645127168d8e83f22b1c393210db5",
            "title": "Self Semi Supervised Neural Architecture Search for Semantic Segmentation",
            "abstract": "In this paper, we propose a Neural Architecture Search strategy based on self supervision and semi-supervised learning for the task of semantic segmentation. Our approach builds an optimized neural network (NN) model for this task by jointly solving a jigsaw pretext task discovered with self-supervised learning over unlabeled training data, and, exploiting the structure of the unlabeled data with semi-supervised learning. The search of the architecture of the NN model is performed by dynamic routing using a gradient descent algorithm. Experiments on the Cityscapes and PASCAL VOC 2012 datasets demonstrate that the discovered neural network is more efficient than a state-of-the-art hand-crafted NN model with four times less floating operations.",
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "authors": [
                {
                    "authorId": "2005691911",
                    "name": "Lo\u00efc Pauletto"
                },
                {
                    "authorId": "144444438",
                    "name": "Massih-Reza Amini"
                },
                {
                    "authorId": "2151790544",
                    "name": "Nicolas Winckler"
                }
            ]
        },
        {
            "paperId": "8e729c666166a4a75cf47667b9a110b6a3d2be2e",
            "title": "Telemetry-Based Software Failure Prediction by Concept-Space Model Creation",
            "abstract": "Telemetry data (e.g.: CPU and memory usage) is an essential source of information for a software system that projects the system\u2019s health. Anomalies in telemetry data warn system administrators about an imminent failure or deterioration of service quality. However, input events to the system (such as service requests) are the cause of abnormal system behaviour and, thus, anomalous telemetry data. By observing input events, one might predict anomalies even before they appear in telemetry data, thus giving the system administrator even earlier warning before the failure. Finding a correlation between input events and anomalies in telemetry data is challenging in many cases. This paper proposes a machine learning approach to learn the causality correlation between input event sequences and telemetry data. To this aim, a Natural Language Processing(NLP) approach is employed to create a concept space model to distinguish between normal and abnormal test sequences. Based on a vectorized representation of each input sequence, the concept space indicates whether the sequence will cause a system failure. Since the meaning of fault is not established in system status Telemetry-based fault detection, the suggested technique first detects periods of time when a software system status encounters aberrant situations (Bug-Zones). An extensive study on a real-world database acquired by a telecommunication operator and an open-source microservice software demonstrates that our approach achieves 71% and 90% accuracy as a Bug-Zones predictor.",
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "authors": [
                {
                    "authorId": "2047694473",
                    "name": "Bahareh Afshinpour"
                },
                {
                    "authorId": "2334996",
                    "name": "Roland Groz"
                },
                {
                    "authorId": "144444438",
                    "name": "Massih-Reza Amini"
                }
            ]
        },
        {
            "paperId": "ad07587eb94ee488709f30e86e8ba8c80b91fe48",
            "title": "Se2NAS: Self-Semi-Supervised architecture optimization for Semantic Segmentation",
            "abstract": "In this paper, we propose a Neural Architecture Search strategy based on self supervision and semi-supervised learning for the task of semantic segmentation. Our approach builds an optimized neural network (NN) model for this task by solving a jigsaw pretext problem identified by self-supervised learning over unlabeled training data, and, leveraging the structure of the unlabeled data with semi-supervised learning. Dynamic routing with a gradient descent approach is used to find the architecture of the NN model. Experiments on the Cityscapes and PASCAL VOC 2012 datasets show that the found neural network is four times more efficient than a state-of-the-art hand designed NN model in terms of floating-point operations.",
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "authors": [
                {
                    "authorId": "2005691911",
                    "name": "Lo\u00efc Pauletto"
                },
                {
                    "authorId": "144444438",
                    "name": "Massih-Reza Amini"
                },
                {
                    "authorId": "2151790544",
                    "name": "Nicolas Winckler"
                }
            ]
        },
        {
            "paperId": "ca3bcb13d6d9566d1825ce1c60690ba6eb092574",
            "title": "Correlating Test Events With Monitoring Logs For Test Log Reduction And Anomaly Prediction",
            "abstract": "Automated fault identification in long test logs is a tough problem, mainly because of their sequential character and the impossibility of constructing training sets for zero-day faults. To reduce software testers' workload, rule-based approaches have been extensively investigated as solutions for efficiently finding and predicting the fault. Based on software system status monitoring log analysis, we propose a new learning-based technique to automate anomaly detection, correlate test events to anomalies and predict system failures. Since the meaning of fault is not established in system status monitoring-based fault detection, the suggested technique first detects periods of time when a software system status encounters aberrant situations (Bug-Zones). The suggested technique is then tested in a real-time system for anomaly prediction of new tests. The model may be used in two ways. It can assist testers to focus on faulty-like time intervals by reducing the number of test logs. It may also be used to forecast a Bug-Zone in an online system, allowing system administrators to anticipate or even prevent a system failure. An extensive study on a real-world database acquired by a telecommunication operator demonstrates that our approach achieves 71 % accuracy as a Bug-Zones predictor.",
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "authors": [
                {
                    "authorId": "2047694473",
                    "name": "Bahareh Afshinpour"
                },
                {
                    "authorId": "2334996",
                    "name": "Roland Groz"
                },
                {
                    "authorId": "144444438",
                    "name": "Massih-Reza Amini"
                }
            ]
        },
        {
            "paperId": "fb985e51608b7fa464ffa38eb3657b6c9f3d21bf",
            "title": "Self-Training: A Survey",
            "abstract": "Semi-supervised algorithms aim to learn prediction functions from a small set of labeled observations and a large set of unlabeled observations. Because this framework is relevant in many applications, they have received a lot of interest in both academia and industry. Among the existing techniques, self-training methods have undoubtedly attracted greater attention in recent years. These models are designed to find the decision boundary on low density regions without making additional assumptions about the data distribution, and use the unsigned output score of a learned classifier, or its margin, as an indicator of confidence. The working principle of self-training algorithms is to learn a classifier iteratively by assigning pseudo-labels to the set of unlabeled training samples with a margin greater than a certain threshold. The pseudo-labeled examples are then used to enrich the labeled training data and to train a new classifier in conjunction with the labeled training set. In this paper, we present self-training methods for binary and multi-class classification; as well as their variants and two related approaches, namely consistency-based approaches and transductive learning. We examine the impact of significant self-training features on various methods, using different general and image classification benchmarks, and we discuss our ideas for future research in self-training. To the best of our knowledge, this is the first thorough and complete survey on this subject.",
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "authors": [
                {
                    "authorId": "144444438",
                    "name": "Massih-Reza Amini"
                },
                {
                    "authorId": "66383219",
                    "name": "Vasilii Feofanov"
                },
                {
                    "authorId": "2005691911",
                    "name": "Lo\u00efc Pauletto"
                },
                {
                    "authorId": "2876902",
                    "name": "Emilie Devijver"
                },
                {
                    "authorId": "3147078",
                    "name": "Yury Maximov"
                }
            ]
        },
        {
            "paperId": "2086eae064b44d5cd526be36c021f9bc203b2d97",
            "title": "A Semi-Supervised Multi-Task Learning Approach for Predicting Short-Term Kidney Disease Evolution",
            "abstract": "Kidney Disease (KD) may hide complex causes and is associated with a tremendous socio-economic impact. Timely identification and management from the first level of medical care represent the most effective strategy to address the growing global burden sustainably. Clinical practice guidelines suggest utilizing estimated Glomerular Filtration Rate (eGFR) for routine evaluation within a screening purpose. Accordingly, the analysis of Electronic Health Records (EHRs) using Machine Learning techniques offers great opportunities to monitor and predict the eGFR trend over time. This paper aims to propose a novel Semi-Supervised Multi-Task Learning (SS-MTL) approach for predicting short-term KD evolution on multiple General Practitioners\u2019 EHR data. We demonstrated that the SS-MTL approach can (i) capture the eGFR temporal evolution by imposing a temporal relatedness between consecutive time windows and (ii) exploit useful information from unlabeled patients when labeled patients are less numerous with a gain of up to 4.1% in terms of Recall. This situation reflects the real-case scenario, where available labeled samples are limited, but those unlabeled much more abundant. The SS-MTL approach, also given the high level of interpretability, might be the ideal candidate in general practice to get integrated within a decision support system for KD screening purposes.",
            "fieldsOfStudy": [
                "Computer Science",
                "Medicine"
            ],
            "authors": [
                {
                    "authorId": "143782471",
                    "name": "Michele Bernardini"
                },
                {
                    "authorId": "2065802367",
                    "name": "L. Romeo"
                },
                {
                    "authorId": "1721130",
                    "name": "E. Frontoni"
                },
                {
                    "authorId": "144444438",
                    "name": "Massih-Reza Amini"
                }
            ]
        },
        {
            "paperId": "2695f4736209b3e235fb2ce69a7a7a36eb389db2",
            "title": "Uplift Modeling with Generalization Guarantees",
            "abstract": "In this paper, we consider the task of ranking individuals based on the potential benefit of being \"treated\" (e.g. by a drug or exposure to recommendations or ads), referred to as Uplift Modeling in the literature. This application has gained a surge of interest in recent years and it is found in many applications such as personalized medicine, recommender systems or targeted advertising. In real life scenarios the capacity of models to rank individuals by potential benefit is measured by the Area Under the Uplift Curve (AUUC), a ranking metric related to the well known Area Under ROC Curve. In the case where the objective function, for learning model parameters, is different from AUUC, the capacity of the resulting system to generalize on AUUC is limited. To tackle this issue, we propose to learn a model that directly optimizes an upper bound on AUUC. To find such a model we first develop a generalization bound on AUUC and then derive from it a learning objective called AUUC-max, usable with linear and deep models. We empirically study the tightness of this generalization bound, its effectiveness for hyperparameters tuning and show the efficiency of the proposed learning objective compared to a wide range of competitive baselines on two classical uplift modeling benchmarks using real-world datasets.",
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "authors": [
                {
                    "authorId": "52163968",
                    "name": "Artem Betlei"
                },
                {
                    "authorId": "3008835",
                    "name": "E. Diemert"
                },
                {
                    "authorId": "144444438",
                    "name": "Massih-Reza Amini"
                }
            ]
        },
        {
            "paperId": "2804a137bbfb7267fc290e05d6a4a1a38f6cc1fd",
            "title": "Bilingual Topic Models for Comparable Corpora",
            "abstract": "Probabilistic topic models like Latent Dirichlet Allocation (LDA) have been previously extended to the bilingual setting. A fundamental modeling assumption in several of these extensions is that the input corpora are in the form of document pairs whose constituent documents share a single topic distribution. However, this assumption is strong for comparable corpora that consist of documents thematically similar to an extent only, which are, in turn, the most commonly available or easy to obtain. In this paper we relax this assumption by proposing for the paired documents to have separate, yet bound topic distributions. % a binding mechanism between the distributions of the paired documents. We suggest that the strength of the bound should depend on each pair's semantic similarity. To estimate the similarity of documents that are written in different languages we use cross-lingual word embeddings that are learned with shallow neural networks. We evaluate the proposed binding mechanism by extending two topic models: a bilingual adaptation of LDA that assumes bag-of-words inputs and a model that incorporates part of the text structure in the form of boundaries of semantically coherent segments. To assess the performance of the novel topic models we conduct intrinsic and extrinsic experiments on five bilingual, comparable corpora of English documents with French, German, Italian, Spanish and Portuguese documents. The results demonstrate the efficiency of our approach in terms of both topic coherence measured by the normalized point-wise mutual information, and generalization performance measured by perplexity and in terms of Mean Reciprocal Rank in a cross-lingual document retrieval task for each of the language pairs.",
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "authors": [
                {
                    "authorId": "1951080",
                    "name": "Georgios Balikas"
                },
                {
                    "authorId": "144444438",
                    "name": "Massih-Reza Amini"
                },
                {
                    "authorId": "2889171",
                    "name": "M. Clausel"
                }
            ]
        },
        {
            "paperId": "49df6bc381216d31e84519edd562c465900b527a",
            "title": "Multi-class Probabilistic Bounds for Self-learning",
            "abstract": "Self-learning is a classical approach for learning with both labeled and unlabeled observations which consists in giving pseudo-labels to unlabeled training instances with a confidence score over a predetermined threshold. At the same time, the pseudo-labeling technique is prone to error and runs the risk of adding noisy labels into unlabeled training data. In this paper, we present a probabilistic framework for analyzing self-learning in the multi-class classification scenario with partially labeled data. First, we derive a transductive bound over the risk of the multi-class majority vote classifier. Based on this result, we propose to automatically choose the threshold for pseudo-labeling that minimizes the transductive bound. Then, we introduce a mislabeling error model to analyze the error of the majority vote classifier in the case of the pseudo-labeled data. We derive a probabilistic C-bound over the majority vote error when an imperfect label is given. Empirical results on different data sets show the effectiveness of our framework compared to several state-of-the-art semi-supervised approaches.",
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "authors": [
                {
                    "authorId": "66383219",
                    "name": "Vasilii Feofanov"
                },
                {
                    "authorId": "2876902",
                    "name": "Emilie Devijver"
                },
                {
                    "authorId": "144444438",
                    "name": "Massih-Reza Amini"
                }
            ]
        },
        {
            "paperId": "5d5dd99f208c2f861eeb6329acac7c8f945f363a",
            "title": "A Large Scale Benchmark for Individual Treatment Effect Prediction and Uplift Modeling",
            "abstract": "Individual Treatment Effect (ITE) prediction is an important area of research in machine learning which aims at explaining and estimating the causal impact of an action at the granular level. It represents a problem of growing interest in multiple sectors of application such as healthcare, online advertising or socioeconomics. To foster research on this topic we release a publicly available collection of 13.9 million samples collected from several randomized control trials, scaling up previously available datasets by a healthy 210x factor. We provide details on the data collection and perform sanity checks to validate the use of this data for causal inference tasks. First, we formalize the task of uplift modeling (UM) that can be performed with this data, along with the relevant evaluation metrics. Then, we propose synthetic response surfaces and heterogeneous treatment assignment providing a general set-up for ITE prediction. Finally, we report experiments to validate key characteristics of the dataset leveraging its size to evaluate and compare - with high statistical significance - a selection of baseline UM and ITE prediction methods.",
            "fieldsOfStudy": [
                "Mathematics",
                "Computer Science"
            ],
            "authors": [
                {
                    "authorId": "2123693923",
                    "name": "Eustache Diemert"
                },
                {
                    "authorId": "52163968",
                    "name": "Artem Betlei"
                },
                {
                    "authorId": "1863870853",
                    "name": "Christophe Renaudin"
                },
                {
                    "authorId": "144444438",
                    "name": "Massih-Reza Amini"
                },
                {
                    "authorId": "2046878429",
                    "name": "T. Gregoir"
                },
                {
                    "authorId": "89447801",
                    "name": "Thibaud Rahier"
                }
            ]
        },
        {
            "paperId": "865c41f14b00c46149f0a5d55a04b97f01ed3ce9",
            "title": "Self-Training of Halfspaces with Generalization Guarantees under Massart Mislabeling Noise Model",
            "abstract": "We investigate the generalization properties of a self-training algorithm with halfspaces. The approach learns a list of halfspaces iteratively from labeled and unlabeled training data, in which each iteration consists of two steps: exploration and pruning. In the exploration phase, the halfspace is found sequentially by maximizing the unsigned-margin among unlabeled examples and then assigning pseudo-labels to those that have a distance higher than the current threshold. The pseudo-labeled examples are then added to the training set, and a new classifier is learned. This process is repeated until no more unlabeled examples remain for pseudo-labeling. In the pruning phase, pseudo-labeled samples that have a distance to the last halfspace greater than the associated unsigned-margin are then discarded. We prove that the misclassification error of the resulting sequence of classifiers is bounded and show that the resulting semi-supervised approach never degrades performance compared to the classifier learned using only the initial labeled training set. Experiments carried out on a variety of benchmarks demonstrate the efficiency of the proposed approach compared to state-of-the-art methods.",
            "fieldsOfStudy": [
                "Computer Science",
                "Mathematics"
            ],
            "authors": [
                {
                    "authorId": "2142471704",
                    "name": "Lies Hadjadj"
                },
                {
                    "authorId": "144444438",
                    "name": "Massih-Reza Amini"
                },
                {
                    "authorId": "1905833",
                    "name": "S. Louhichi"
                },
                {
                    "authorId": "98848768",
                    "name": "A. Deschamps"
                }
            ]
        },
        {
            "paperId": "5c4b1e9a7c3f6bd768738898afea49e1ab996d04",
            "title": "Reducing Regression Test Suites using the Word2Vec Natural Language Processing Tool",
            "abstract": "Continuous integration in software development requires to run the tests on a regular basis to ensure that the code does not regress. So that the execution time of the regression test suite remains reasonable its size must be reduced while preserving its fault detection capability. From test execution logs, we extract from each test a trace, which is a sequence of events. We then consider each event as a word, and apply natural language processing methods, here the Word2Vec tool, to detect similarities in sentences, and partition them into clusters. We thus can reduce the regression test suite by removing redundant tests. We present the approach on a small case study, and we use mutation based testing to assess the effectiveness of the reduction.",
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "authors": [
                {
                    "authorId": "2047694473",
                    "name": "Bahareh Afshinpour"
                },
                {
                    "authorId": "2334996",
                    "name": "Roland Groz"
                },
                {
                    "authorId": "144444438",
                    "name": "Massih-Reza Amini"
                },
                {
                    "authorId": "1764966",
                    "name": "Y. Ledru"
                },
                {
                    "authorId": "2481895",
                    "name": "Catherine Oriat"
                }
            ]
        },
        {
            "paperId": "627a636b59d13934b9e2e4e50d5cd017675aa45c",
            "title": "Learning over no-Preferred and Preferred Sequence of items for Robust Recommendation",
            "abstract": "In this paper, we propose a theoretically supported sequential strategy for training a large-scale Recommender System (RS) over implicit feedback, mainly in the form of clicks. The proposed approach consists in minimizing pairwise ranking loss over blocks of consecutive items constituted by a sequence of non-clicked items followed by a clicked one for each user. We present two variants of this strategy where model parameters are updated using either the momentum method or a gradient-based approach. To prevent updating the parameters for an abnormally high number of clicks over some targeted items (mainly due to bots), we introduce an upper and a lower threshold on the number of updates for each user. These thresholds are estimated over the distribution of the number of blocks in the training set. They affect the decision of RS by shifting the distribution of items that are shown to the users. Furthermore, we provide a convergence analysis of both algorithms and demonstrate their practical efficiency over six large-scale collections with respect to various ranking measures and computational time.",
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "authors": [
                {
                    "authorId": "2037379701",
                    "name": "Aleksandra Burashnikova"
                },
                {
                    "authorId": "2889171",
                    "name": "M. Clausel"
                },
                {
                    "authorId": "1947597",
                    "name": "Charlotte Laclau"
                },
                {
                    "authorId": "2037379373",
                    "name": "Frack Iutzeller"
                },
                {
                    "authorId": "3147078",
                    "name": "Yury Maximov"
                },
                {
                    "authorId": "144444438",
                    "name": "Massih-Reza Amini"
                }
            ]
        },
        {
            "paperId": "76c58ea4d69bcf77ff1961cd9b3588a300ef24d7",
            "title": "Treatment Targeting by AUUC Maximization with Generalization Guarantees",
            "abstract": "We consider the task of optimizing treatment assignment based on individual treatment effect prediction. This task is found in many applications such as personalized medicine or targeted advertising and has gained a surge of interest in recent years under the name of Uplift Modeling. It consists in targeting treatment to the individuals for whom it would be the most beneficial. In real life scenarios, when we do not have access to ground-truth individual treatment effect, the capacity of models to do so is generally measured by the Area Under the Uplift Curve (AUUC), a metric that differs from the learning objectives of most of the Individual Treatment Effect (ITE) models. We argue that the learning of these models could inadvertently degrade AUUC and lead to suboptimal treatment assignment. To tackle this issue, we propose a generalization bound on the AUUC and present a novel learning algorithm that optimizes a derivable surrogate of this bound, called AUUC-max. Finally, we empirically demonstrate the tightness of this generalization bound, its effectiveness for hyper-parameter tuning and show the efficiency of the proposed algorithm compared to a wide range of competitive baselines on two classical benchmarks.",
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "authors": [
                {
                    "authorId": "52163968",
                    "name": "Artem Betlei"
                },
                {
                    "authorId": "3008835",
                    "name": "E. Diemert"
                },
                {
                    "authorId": "144444438",
                    "name": "Massih-Reza Amini"
                }
            ]
        },
        {
            "paperId": "871440830403fd4921ca1c68a9da1a6ab4c25fc8",
            "title": "Neural Architecture Search for extreme multi-label classification: an evolutionary approach",
            "abstract": "Extreme multi-label classification (XMC) and Neural Architecture Search (NAS) are research topics, which have gain a lot of interest recently. While the former deals in supervised learning problems with extremely large number of labels in text and NLP domain, the latter has been mainly applied to much smaller tasks, mainly in image processing. In this study, we extend the scope of NAS to (XMC) tasks. We propose a neuro-evolution approach, that has been found most suitable for a variety of tasks. The proposed NAS method automatically finds architectures that give competitive results to the state of the art (and superior to other methods) with faster convergence. Furthermore, the weights of the architecture blocks have been analyzed to give insight on the importance of the various operations that have been selected by the method.",
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "authors": [
                {
                    "authorId": "2005691911",
                    "name": "Lo\u00efc Pauletto"
                },
                {
                    "authorId": "144444438",
                    "name": "Massih-Reza Amini"
                },
                {
                    "authorId": "1986256",
                    "name": "Rohit Babbar"
                },
                {
                    "authorId": "7662326",
                    "name": "N. Winckler"
                }
            ]
        },
        {
            "paperId": "1214a1d193f5ab6188f43503f6260cd7afa437bb",
            "title": "Semi-supervised Wrapper Feature Selection by Modeling Imperfect Labels.",
            "abstract": "In this paper, we propose a new wrapper feature selection approach with partially labeled training examples where unlabeled observations are pseudo-labeled using the predictions of an initial classifier trained on the labeled training set. The wrapper is composed of a genetic algorithm for proposing new feature subsets, and an evaluation measure for scoring the different feature subsets. The selection of feature subsets is done by assigning weights to characteristics and recursively eliminating those that are irrelevant. The selection criterion is based on a new multi-class $\\mathcal{C}$-bound that explicitly takes into account the mislabeling errors induced by the pseudo-labeling mechanism, using a probabilistic error model. Empirical results on different data sets show the effectiveness of our framework compared to several state-of-the-art semi-supervised feature selection approaches.",
            "fieldsOfStudy": [
                "Mathematics",
                "Computer Science"
            ],
            "authors": [
                {
                    "authorId": "66383219",
                    "name": "Vasilii Feofanov"
                },
                {
                    "authorId": "2876902",
                    "name": "Emilie Devijver"
                },
                {
                    "authorId": "144444438",
                    "name": "Massih-Reza Amini"
                }
            ]
        },
        {
            "paperId": "5d9f6908676f59e8cd9bfc6ca019c36840c78b0f",
            "title": "Semi-supervised Wrapper Feature Selection with Imperfect Labels",
            "abstract": "In this paper, we propose a new wrapper approach for semi-supervised feature selection. A common strategy in semi-supervised learning is to augment the training set by pseudo-labeled unlabeled examples. However, the pseudo-labeling procedure is prone to error and has a high risk of disrupting the learning algorithm with additional noisy labeled training data. To overcome this, we propose to model explicitly the mislabeling error during the learning phase with the overall aim of selecting the most relevant feature characteristics. We derive a $\\mathcal{C}$-bound for Bayes classifiers trained over partially labeled training sets by taking into account the mislabeling errors. The risk bound is then considered as an objective function that is minimized over the space of possible feature subsets using a genetic algorithm. In order to produce both sparse and accurate solution, we propose a modification of a genetic algorithm with the crossover based on feature weights and recursive elimination of irrelevant features. Empirical results on different data sets show the effectiveness of our framework compared to several state-of-the-art semi-supervised feature selection approaches.",
            "fieldsOfStudy": [
                "Mathematics",
                "Computer Science"
            ],
            "authors": [
                {
                    "authorId": "66383219",
                    "name": "Vasilii Feofanov"
                },
                {
                    "authorId": "144444438",
                    "name": "Massih-Reza Amini"
                },
                {
                    "authorId": "2876902",
                    "name": "Emilie Devijver"
                }
            ]
        },
        {
            "paperId": "f32259c4e79a313be3768aae9a2216f8370582d1",
            "title": "Transductive Bounds for the Multi-Class Majority Vote Classifier",
            "abstract": "In this paper, we propose a transductive bound over the risk of the majority vote classifier learned with partially labeled data for the multi-class classification. The bound is obtained by considering the class confusion matrix as an error indicator and it involves the margin distribution of the classifier over each class and a bound over the risk of the associated Gibbs classifier. When this latter bound is tight and, the errors of the majority vote classifier per class are concentrated on a low margin zone; we prove that the bound over the Bayes classifier\u2019 risk is tight. As an application, we extend the self-learning algorithm to the multi-class case. The algorithm iteratively assigns pseudo-labels to a subset of unlabeled training examples that have their associated class margin above a threshold obtained from the proposed transductive bound. Empirical results on different data sets show the effectiveness of our approach compared to the same algorithm where the threshold is fixed manually, to the extension of TSVM to multi-class classification and to a graph-based semi-supervised algorithm.",
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "authors": [
                {
                    "authorId": "66383219",
                    "name": "Vasilii Feofanov"
                },
                {
                    "authorId": "2876902",
                    "name": "Emilie Devijver"
                },
                {
                    "authorId": "144444438",
                    "name": "Massih-Reza Amini"
                }
            ]
        },
        {
            "paperId": "40031d8784e27328e13af056123c34d3721f76c5",
            "title": "A Delay-tolerant Proximal-Gradient Algorithm for Distributed Learning",
            "abstract": "Distributed learning aims at computing high-quality models by training over scattered data. This covers a diversity of scenarios, including computer clusters or mobile agents. One of the main challenges is then to deal with heterogeneous machines and unreliable communications. In this setting, we propose and analyze a flexible asynchronous optimization algorithm for solving nonsmooth learning problems. Unlike most existing methods, our algorithm is adjustable to various levels of communication costs, machines computational powers, and data distribution evenness. We prove that the algorithm converges linearly with a fixed learning rate that does not depend on communication delays nor on the number of machines. Although long delays in communication may slow down performance, no delay can break convergence.",
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "authors": [
                {
                    "authorId": "144950781",
                    "name": "Konstantin Mishchenko"
                },
                {
                    "authorId": "3060709",
                    "name": "F. Iutzeler"
                },
                {
                    "authorId": "35080700",
                    "name": "J. Malick"
                },
                {
                    "authorId": "144444438",
                    "name": "Massih-Reza Amini"
                }
            ]
        },
        {
            "paperId": "5b7ff651b9e84f585a12dfe9b806d9218d0b4475",
            "title": "Distributed Learning with Sparse Communications by Identification",
            "abstract": "In distributed optimization for large-scale learning, a major performance limitation comes from the communications between the different entities. When computations are performed by workers on local data while a coordinator machine coordinates their updates to minimize a global loss, we present an asynchronous optimization algorithm that efficiently reduces the communications between the coordinator and workers. This reduction comes from a random sparsification of the local updates. We show that this algorithm converges linearly in the strongly convex case and also identifies optimal strongly sparse solutions. We further exploit this identification to propose an automatic dimension reduction, aptly sparsifying all exchanges between coordinator and workers.",
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "authors": [
                {
                    "authorId": "2081837493",
                    "name": "Dmitry Grishchenko"
                },
                {
                    "authorId": "3060709",
                    "name": "F. Iutzeler"
                },
                {
                    "authorId": "35080700",
                    "name": "J. Malick"
                },
                {
                    "authorId": "144444438",
                    "name": "Massih-Reza Amini"
                }
            ]
        },
        {
            "paperId": "63aa18efccd9fadefc8a75d604b62c8a9a944ee3",
            "title": "Concurrent Learning of Semantic Relations",
            "abstract": "Discovering whether words are semantically related and identifying the specific semantic relation that holds between them is of crucial importance for NLP as it is essential for tasks like query expansion in IR. Within this context, different methodologies have been proposed that either exclusively focus on a single lexical relation (e.g. hypernymy vs. random) or learn specific classifiers capable of identifying multiple semantic relations (e.g. hypernymy vs. synonymy vs. random). In this paper, we propose another way to look at the problem that relies on the multi-task learning paradigm. In particular, we want to study whether the learning process of a given semantic relation (e.g. hypernymy) can be improved by the concurrent learning of another semantic relation (e.g. co-hyponymy). Within this context, we particularly examine the benefits of semi-supervised learning where the training of a prediction function is performed over few labeled data jointly with many unlabeled ones. Preliminary results based on simple learning strategies and state-of-the-art distributional feature representations show that concurrent learning can lead to improvements in a vast majority of tested situations.",
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "authors": [
                {
                    "authorId": "1951080",
                    "name": "Georgios Balikas"
                },
                {
                    "authorId": "143673279",
                    "name": "G. Dias"
                },
                {
                    "authorId": "2221585",
                    "name": "Rumen Moraliyski"
                },
                {
                    "authorId": "144444438",
                    "name": "Massih-Reza Amini"
                }
            ]
        },
        {
            "paperId": "acab1564d98f5d850bdae58ad6c7b2083a5bfe7a",
            "title": "Multi-task Learning for Semantic Relations Discovery",
            "abstract": "Identifying the semantic relations that hold between words is of crucial importance for reasoning purposes. Within this context, different methodolo-gies have been proposed that either exclusively focus on a single lexical relation (two-class problem) or learn specific classifiers capable of identifying multiple semantic relations (multi-class problem). In this paper, we propose another way to look at the problem that relies on the multi-task learning paradigm. Preliminary results based on simple learning strategies and state-of-the-art distributional feature representations show that concurrent learning can lead to improvements.",
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "authors": [
                {
                    "authorId": "1951080",
                    "name": "Georgios Balikas"
                },
                {
                    "authorId": "143673279",
                    "name": "G. Dias"
                },
                {
                    "authorId": "144444438",
                    "name": "Massih-Reza Amini"
                }
            ]
        },
        {
            "paperId": "c992f7876383379c8a92291a36370958c6419b9c",
            "title": "Asynchronous Distributed Learning with Sparse Communications and Identification",
            "abstract": "In this paper, we present an asynchronous optimization algorithm for distributed learning, that efficiently reduces the communications between a master and working machines by randomly sparsifying the local updates. This sparsification allows to lift the communication bottleneck often present in distributed learning setups where computations are performed by workers on local data while a master machine coordinates their updates to optimize a global loss. We prove that despite its sparse asynchronous communications, our algorithm allows for a fixed stepsize and benefits from a linear convergence rate in the strongly convex case. Moreover, for $\\ell_1$-regularized problems, this algorithm identifies near-optimal sparsity patterns, so that all communications eventually become sparse. We furthermore leverage on this identification to improve our sparsification technique. We illustrate on real and synthetic data that this algorithm converges faster in terms of data exchanges.",
            "fieldsOfStudy": [
                "Computer Science",
                "Mathematics"
            ],
            "authors": [
                {
                    "authorId": "2081837493",
                    "name": "Dmitry Grishchenko"
                },
                {
                    "authorId": "3060709",
                    "name": "F. Iutzeler"
                },
                {
                    "authorId": "35080700",
                    "name": "J. Malick"
                },
                {
                    "authorId": "144444438",
                    "name": "Massih-Reza Amini"
                }
            ]
        },
        {
            "paperId": "eb0b5a365f2277fcc4ede9c9cae9600534fe6320",
            "title": "Learning to recommend diverse items over implicit feedback on PANDOR",
            "abstract": "In this paper, we present a novel and publicly available dataset for online recommendation provided by Purch1. The dataset records the clicks generated by users of one of Purch's high-tech website over the ads they have been shown for one month. In addition, the dataset contains contextual information about offers such as offer titles and keywords, as well as the anonymized content of the page on which offers were displayed. Then, besides a detailed description of the dataset, we evaluate the performance of six popular baselines and propose a simple yet effective strategy on how to overcome the existing challenges inherent to implicit feedback and popularity bias introduced while designing an efficient and scalable recommendation algorithm. More specifically, we propose to demonstrate the importance of introducing diversity based on an appropriate representation of items in Recommender Systems, when the available feedback is strongly biased.",
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "authors": [
                {
                    "authorId": "3430051",
                    "name": "Sumit Sidana"
                },
                {
                    "authorId": "1947597",
                    "name": "Charlotte Laclau"
                },
                {
                    "authorId": "144444438",
                    "name": "Massih-Reza Amini"
                }
            ]
        },
        {
            "paperId": "1012cab0c954d5fc41cb033f7388a1bfee4c643b",
            "title": "Topical Coherence in LDA-based Models through Induced Segmentation",
            "abstract": "This paper presents an LDA-based model that generates topically coherent segments within documents by jointly segmenting documents and assigning topics to their words. The coherence between topics is ensured through a copula, binding the topics associated to the words of a segment. In addition, this model relies on both document and segment specific topic distributions so as to capture fine grained differences in topic assignments. We show that the proposed model naturally encompasses other state-of-the-art LDA-based models designed for similar tasks. Furthermore, our experiments, conducted on six different publicly available datasets, show the effectiveness of our model in terms of perplexity, Normalized Pointwise Mutual Information, which captures the coherence between the generated topics, and the Micro F1 measure for text classification.",
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "authors": [
                {
                    "authorId": "3440447",
                    "name": "Hesam Amoualian"
                },
                {
                    "authorId": "143844110",
                    "name": "Wei Lu"
                },
                {
                    "authorId": "1732180",
                    "name": "\u00c9ric Gaussier"
                },
                {
                    "authorId": "1951080",
                    "name": "Georgios Balikas"
                },
                {
                    "authorId": "144444438",
                    "name": "Massih-Reza Amini"
                },
                {
                    "authorId": "2889171",
                    "name": "M. Clausel"
                }
            ]
        },
        {
            "paperId": "371abb12dfd53850daf6c02221574ff3212e6e9d",
            "title": "On the Effectiveness of Feature Set Augmentation Using Clusters of Word Embeddings",
            "abstract": "Word clusters have been empirically shown to offer important performance improvements on various tasks. Despite their importance, their incorporation in the standard pipeline of feature engineering relies more on a trial-and-error procedure where one evaluates several hyper-parameters, like the number of clusters to be used. In order to better understand the role of such features we systematically evaluate their effect on four tasks, those of named entity segmentation and classification as well as, those of five-point sentiment classification and quantification. Our results strongly suggest that cluster membership features improve the performance.",
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "authors": [
                {
                    "authorId": "1951080",
                    "name": "Georgios Balikas"
                },
                {
                    "authorId": "3071383",
                    "name": "Ioannis Partalas"
                },
                {
                    "authorId": "144444438",
                    "name": "Massih-Reza Amini"
                }
            ]
        },
        {
            "paperId": "410c981eae8e67916aedd9450e3f687bf10d4b2c",
            "title": "CAp 2017 challenge: Twitter Named Entity Recognition",
            "abstract": "The paper describes the CAp 2017 challenge. The challenge concerns the problem of Named Entity Recognition (NER) for tweets written in French. We first present the data preparation steps we followed for constructing the dataset released in the framework of the challenge. We begin by demonstrating why NER for tweets is a challenging problem especially when the number of entities increases. We detail the annotation process and the necessary decisions we made. We provide statistics on the inter-annotator agreement, and we conclude the data description part with examples and statistics for the data. We, then, describe the participation in the challenge, where 8 teams participated, with a focus on the methods employed by the challenge participants and the scores achieved in terms of F$_1$ measure. Importantly, the constructed dataset comprising $\\sim$6,000 tweets annotated for 13 types of entities, which to the best of our knowledge is the first such dataset in French, is publicly available at \\url{this http URL} .",
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "authors": [
                {
                    "authorId": "75180201",
                    "name": "C. Lopez"
                },
                {
                    "authorId": "3071383",
                    "name": "Ioannis Partalas"
                },
                {
                    "authorId": "1951080",
                    "name": "Georgios Balikas"
                },
                {
                    "authorId": "3224603",
                    "name": "N. Derbas"
                },
                {
                    "authorId": "2110950320",
                    "name": "Am\u00e9lie Martin"
                },
                {
                    "authorId": "2082433709",
                    "name": "Coralie Reutenauer"
                },
                {
                    "authorId": "3189921",
                    "name": "F. Segond"
                },
                {
                    "authorId": "144444438",
                    "name": "Massih-Reza Amini"
                }
            ]
        },
        {
            "paperId": "4b95dd7ee0804e6ddbd5cde8537b8288732da1b9",
            "title": "Representation Learning and Pairwise Ranking for Implicit and Explicit Feedback in Recommendation Systems",
            "abstract": "In this paper, we propose a novel ranking approach for collaborative filtering based on Neural-Networks that jointly learns a new representation of users and items in an embedded space as well as the preference relation of users over pairs of items. The learning objective is based on two ranking losses that control the ability of the model to respect the ordering over the items induced from the users preferences, as well as, the capacity of the dot-product defined in the learned embedded space to produce the ordering. The proposed model is by nature suitable for both implicit and explicit feedback and involves the estimation of only very few parameters. Through extensive experiments on several real-world benchmarks, both explicit and implicit, we show the interest of learning the preference and the embedding simultaneously when compared to learning those separately. We also demonstrate that our approach is very competitive with the best state-of-the-art collaborative filtering techniques proposed independently for explicit and implicit feedback.",
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "authors": [
                {
                    "authorId": "103810919",
                    "name": "Mikhail Trofimov"
                },
                {
                    "authorId": "3430051",
                    "name": "Sumit Sidana"
                },
                {
                    "authorId": "12562607",
                    "name": "Oleh Horodnitskii"
                },
                {
                    "authorId": "1947597",
                    "name": "Charlotte Laclau"
                },
                {
                    "authorId": "3147078",
                    "name": "Yury Maximov"
                },
                {
                    "authorId": "144444438",
                    "name": "Massih-Reza Amini"
                }
            ]
        },
        {
            "paperId": "9f9750f94e1e3fb92d6c9ab3ec4b518279596b87",
            "title": "Aggressive Sampling for Multi-class to Binary Reduction with Applications to Text Classification",
            "abstract": "We address the problem of multi-class classification in the case where the number of classes is very large. We propose a double sampling strategy on top of a multi-class to binary reduction strategy, which transforms the original multi-class problem into a binary classification problem over pairs of examples. The aim of the sampling strategy is to overcome the curse of long-tailed class distributions exhibited in majority of large-scale multi-class classification problems and to reduce the number of pairs of examples in the expanded data. We show that this strategy does not alter the consistency of the empirical risk minimization principle defined over the double sample reduction. Experiments are carried out on DMOZ and Wikipedia collections with 10,000 to 100,000 classes where we show the efficiency of the proposed approach in terms of training and prediction time, memory consumption, and predictive performance with respect to state-of-the-art approaches.",
            "fieldsOfStudy": [
                "Computer Science",
                "Mathematics"
            ],
            "authors": [
                {
                    "authorId": "39277610",
                    "name": "Bikash Joshi"
                },
                {
                    "authorId": "144444438",
                    "name": "Massih-Reza Amini"
                },
                {
                    "authorId": "3071383",
                    "name": "Ioannis Partalas"
                },
                {
                    "authorId": "3060709",
                    "name": "F. Iutzeler"
                },
                {
                    "authorId": "3147078",
                    "name": "Yury Maximov"
                }
            ]
        },
        {
            "paperId": "a643a37e5aa949d40422b87d207984a2633f8bcd",
            "title": "KASANDR: A Large-Scale Dataset with Implicit Feedback for Recommendation",
            "abstract": "In this paper, we describe a novel, publicly available collection for recommendation systems that records the behavior of customers of the European leader in eCommerce advertising, Kelkoo\\footnote{\\url{https://www.kelkoo.com/}}, during one month. This dataset gathers implicit feedback, in form of clicks, of users that have interacted with over 56 million offers displayed by Kelkoo, along with a rich set of contextual features regarding both customers and offers. In conjunction with a detailed description of the dataset, we show the performance of six state-of-the-art recommender models and raise some questions on how to encompass the existing contextual information in the system.",
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "authors": [
                {
                    "authorId": "3430051",
                    "name": "Sumit Sidana"
                },
                {
                    "authorId": "1947597",
                    "name": "Charlotte Laclau"
                },
                {
                    "authorId": "144444438",
                    "name": "Massih-Reza Amini"
                },
                {
                    "authorId": "2155997",
                    "name": "Gilles Vandelle"
                },
                {
                    "authorId": "1411248486",
                    "name": "Andr\u00e9 Bois-Crettez"
                }
            ]
        },
        {
            "paperId": "a83fd705cffdfdc178a248bd9825661f34ab806d",
            "title": "Multitask Learning for Fine-Grained Twitter Sentiment Analysis",
            "abstract": "Traditional sentiment analysis approaches tackle problems like ternary (3-category) and fine-grained (5-category) classification by learning the tasks separately. We argue that such classification tasks are correlated and we propose a multitask approach based on a recurrent neural network that benefits by jointly learning them. Our study demonstrates the potential of multitask models on this type of problems and improves the state-of-the-art results in the fine-grained sentiment classification problem.",
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "authors": [
                {
                    "authorId": "1951080",
                    "name": "Georgios Balikas"
                },
                {
                    "authorId": "40185286",
                    "name": "Simon Moura"
                },
                {
                    "authorId": "144444438",
                    "name": "Massih-Reza Amini"
                }
            ]
        },
        {
            "paperId": "29bfcea71f732eae2814d98f6744ebff3a3ae5c9",
            "title": "An empirical study on large scale text classification with skip-gram embeddings",
            "abstract": "We investigate the integration of word embeddings as classification features in the setting of large scale text classification. Such representations have been used in a plethora of tasks, however their application in classification scenarios with thousands of classes has not been extensively researched, partially due to hardware limitations. In this work, we examine efficient composition functions to obtain document-level from word-level embeddings and we subsequently investigate their combination with the traditional one-hot-encoding representations. By presenting empirical evidence on large, multi-class, multi-label classification problems, we demonstrate the efficiency and the performance benefits of this combination.",
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "authors": [
                {
                    "authorId": "1951080",
                    "name": "Georgios Balikas"
                },
                {
                    "authorId": "144444438",
                    "name": "Massih-Reza Amini"
                }
            ]
        },
        {
            "paperId": "2d5321cf92547cd4db15b9b6995e09621777802b",
            "title": "TwiSE at SemEval-2016 Task 4: Twitter Sentiment Classification",
            "abstract": "This paper describes the participation of the team \"TwiSE\" in the SemEval 2016 challenge. Specifically, we participated in Task 4, namely \"Sentiment Analysis in Twitter\" for which we implemented sentiment classification systems for subtasks A, B, C and D. Our approach consists of two steps. In the first step, we generate and validate diverse feature sets for twitter sentiment evaluation, inspired by the work of participants of previous editions of such challenges. In the second step, we focus on the optimization of the evaluation measures of the different subtasks. To this end, we examine different learning strategies by validating them on the data provided by the task organisers. For our final submissions we used an ensemble learning approach (stacked generalization) for Subtask A and single linear models for the rest of the subtasks. In the official leaderboard we were ranked 9/35, 8/19, 1/11 and 2/14 for subtasks A, B, C and D respectively.\\footnote{We make the code available for research purposes at \\url{this https URL\\_Sentiment\\_Evaluation}.}",
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "authors": [
                {
                    "authorId": "1951080",
                    "name": "Georgios Balikas"
                },
                {
                    "authorId": "144444438",
                    "name": "Massih-Reza Amini"
                }
            ]
        },
        {
            "paperId": "35692e7f8e409a1952e0ec174a866d8f310b2a8a",
            "title": "Rademacher Complexity Bounds for a Penalized Multiclass Semi-Supervised Algorithm",
            "abstract": "We propose Rademacher complexity bounds for multi-class classifiers trained with a two-step semi-supervised model. In the first step, the algorithm partitions the partially labeled data and then identifies dense clusters containing k predominant classes using the labeled training examples such that the proportion of their non-predominant classes is below a fixed threshold stands for clustering consistency. In the second step, a classifier is trained by minimizing a margin empirical loss over the labeled training set and a penalization term measuring the disability of the learner to predict the k predominant classes of the identified clusters. The resulting data-dependent generalization error bound involves the margin distribution of the classifier, the stability of the clustering technique used in the first step and Rademacher complexity terms corresponding to partially labeled training data. Our theoretical result exhibit convergence rates extending those proposed in the literature for the binary case, and experimental results on different multi-class classification problems show empirical evidence that supports the theory.",
            "fieldsOfStudy": [
                "Computer Science",
                "Mathematics"
            ],
            "authors": [
                {
                    "authorId": "3147078",
                    "name": "Yury Maximov"
                },
                {
                    "authorId": "144444438",
                    "name": "Massih-Reza Amini"
                },
                {
                    "authorId": "1753355",
                    "name": "Za\u00efd Harchaoui"
                }
            ]
        },
        {
            "paperId": "400828710f967a264e9b196574f0f848b352e591",
            "title": "Streaming-LDA: A Copula-based Approach to Modeling Topic Dependencies in Document Streams",
            "abstract": "We propose in this paper two new models for modeling topic and word-topic dependencies between consecutive documents in document streams. The first model is a direct extension of Latent Dirichlet Allocation model (LDA) and makes use of a Dirichlet distribution to balance the influence of the LDA prior parameters wrt to topic and word-topic distribution of the previous document. The second extension makes use of copulas, which constitute a generic tools to model dependencies between random variables. We rely here on Archimedean copulas, and more precisely on Franck copulas, as they are symmetric and associative and are thus appropriate for exchangeable random variables. Our experiments, conducted on three standard collections that have been used in several studies on topic modeling, show that our proposals outperform previous ones (as dynamic topic models and temporal \\LDA), both in terms of perplexity and for tracking similar topics in a document stream.",
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "authors": [
                {
                    "authorId": "3440447",
                    "name": "Hesam Amoualian"
                },
                {
                    "authorId": "2889171",
                    "name": "M. Clausel"
                },
                {
                    "authorId": "1732180",
                    "name": "\u00c9ric Gaussier"
                },
                {
                    "authorId": "144444438",
                    "name": "Massih-Reza Amini"
                }
            ]
        },
        {
            "paperId": "5262d8abc192446e9fe302e28425c02a447244b2",
            "title": "On a Topic Model for Sentences",
            "abstract": "Probabilistic topic models are generative models that describe the content of documents by discovering the latent topics underlying them. However, the structure of the textual input, and for instance the grouping of words in coherent text spans such as sentences, contains much information which is generally lost with these models. In this paper, we propose sentenceLDA, an extension of LDA whose goal is to overcome this limitation by incorporating the structure of the text in the generative and inference processes. We illustrate the advantages of sentenceLDA by comparing it with LDA using both intrinsic (perplexity) and extrinsic (text classification) evaluation tasks on different text collections.",
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "authors": [
                {
                    "authorId": "1951080",
                    "name": "Georgios Balikas"
                },
                {
                    "authorId": "144444438",
                    "name": "Massih-Reza Amini"
                },
                {
                    "authorId": "2889171",
                    "name": "M. Clausel"
                }
            ]
        },
        {
            "paperId": "542a3e2b97f6df5eedc2509f915ea12508118aec",
            "title": "Asynchronous Distributed Matrix Factorization with Similar User and Item Based Regularization",
            "abstract": "We introduce an asynchronous distributed stochastic gradient algorithm for matrix factorization based collaborative filtering. The main idea of this approach is to distribute the user-rating matrix across different machines, each having access only to a part of the information, and to asynchronously propagate the updates of the stochastic gradient optimization across the network. Each time a machine receives a parameter vector, it averages its current parameter vector with the received one, and continues its iterations from this new point. Additionally, we introduce a similarity based regularization that constrains the user and item factors to be close to the average factors of their similar users and items found on subparts of the distributed user-rating matrix. We analyze the impact of the regularization terms on MovieLens (100K, 1M, 10M) and NetFlix datasets and show that it leads to a more efficient matrix factorization in terms of Root Mean Square Error (RMSE) and Mean Absolute Error (MAE), and that the asynchronous distributed approach significantly improves in convergence time as compared to an equivalent synchronous distributed approach.",
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "authors": [
                {
                    "authorId": "39277610",
                    "name": "Bikash Joshi"
                },
                {
                    "authorId": "3060709",
                    "name": "F. Iutzeler"
                },
                {
                    "authorId": "144444438",
                    "name": "Massih-Reza Amini"
                }
            ]
        },
        {
            "paperId": "726b5705c2c826b07fbd246adf3c90ccbcafcff6",
            "title": "Modeling topic dependencies in semantically coherent text spans with copulas",
            "abstract": "The exchangeability assumption in topic models like Latent Dirichlet Allocation (LDA) often results in inferring inconsistent topics for the words of text spans like noun-phrases, which are usually expected to be topically coherent. We propose copulaLDA, that extends LDA by integrating part of the text structure to the model and relaxes the conditional independence assumption between the word-specific latent topics given the per-document topic distributions. To this end, we assume that the words of text spans like noun-phrases are topically bound and we model this dependence with copulas. We demonstrate empirically the effectiveness of copulaLDA on both intrinsic and extrinsic evaluation tasks on several publicly available corpora.",
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "authors": [
                {
                    "authorId": "1951080",
                    "name": "Georgios Balikas"
                },
                {
                    "authorId": "3440447",
                    "name": "Hesam Amoualian"
                },
                {
                    "authorId": "2889171",
                    "name": "M. Clausel"
                },
                {
                    "authorId": "1732180",
                    "name": "\u00c9ric Gaussier"
                },
                {
                    "authorId": "144444438",
                    "name": "Massih-Reza Amini"
                }
            ]
        },
        {
            "paperId": "94f4804f784d20e03adaba8f743f9e736167cfc4",
            "title": "Learning Taxonomy Adaptation in Large-scale Classification",
            "abstract": "In this paper, we study flat and hierarchical classification strategies in the context of large-scale taxonomies. Addressing the problem from a learning-theoretic point of view, we first propose a multi-class, hierarchical data dependent bound on the generalization error of classifiers deployed in large-scale taxonomies. This bound provides an explanation to several empirical results reported in the literature, related to the performance of flat and hierarchical classifiers. Based on this bound, we also propose a technique for modifying a given taxonomy through pruning, that leads to a lower value of the upper bound as compared to the original taxonomy. We then present another method for hierarchy pruning by studying approximation error of a family of classifiers, and derive from it features used in a meta-classifier to decide which nodes to prune. We finally illustrate the theoretical developments through several experiments conducted on two widely used taxonomies.",
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "authors": [
                {
                    "authorId": "1986256",
                    "name": "Rohit Babbar"
                },
                {
                    "authorId": "3071383",
                    "name": "Ioannis Partalas"
                },
                {
                    "authorId": "1732180",
                    "name": "\u00c9ric Gaussier"
                },
                {
                    "authorId": "144444438",
                    "name": "Massih-Reza Amini"
                },
                {
                    "authorId": "2621453",
                    "name": "C\u00e9cile Amblard"
                }
            ]
        },
        {
            "paperId": "c5c92d217b6f0bcdc537e891c8cd9f7d7ef0db5b",
            "title": "Health Monitoring on Social Media over Time",
            "abstract": "Social media has become a major source for analyzing all aspects of daily life. Thanks to dedicated latent topic analysis methods such as the Ailment Topic Aspect Model (ATAM), public health can now be observed on Twitter. In this work, we are interested in using social media to monitor people\u2019s health over time. The use of tweets has several benefits including instantaneous data availability at virtually no cost. Early monitoring of health data is complementary to post-factum studies and enables a range of applications such as measuring behavioral risk factors and triggering health campaigns. We formulate two problems: health transition detection and  health transition prediction. We first propose the Temporal Ailment Topic Aspect Model (TM\u2013ATAM), a new latent model dedicated to solving the first problem by capturing transitions that involve health-related topics. TM\u2013ATAM is a non-obvious extension to ATAM that was designed to extract health-related topics. It learns health-related topic transitions by minimizing the prediction error on topic distributions between consecutive posts at different time and geographic granularities. To solve the second problem, we develop T\u2013ATAM, a Temporal Ailment Topic Aspect Model where time is treated as a random variable natively inside ATAM. Our experiments on an 8-month corpus of tweets show that TM\u2013ATAM outperforms TM\u2013LDA in estimating health-related transitions from tweets for different geographic populations. We examine the ability of TM\u2013ATAM to detect transitions due to climate conditions in different geographic regions. We then show how T\u2013ATAM can be used to predict the most important transition and additionally compare T\u2013ATAM with CDC (Center for Disease Control) data and Google Flu Trends.",
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "authors": [
                {
                    "authorId": "3430051",
                    "name": "Sumit Sidana"
                },
                {
                    "authorId": "1403657578",
                    "name": "S. Amer-Yahia"
                },
                {
                    "authorId": "2889171",
                    "name": "M. Clausel"
                },
                {
                    "authorId": "1412139901",
                    "name": "Majdeddine Rebai"
                },
                {
                    "authorId": "2925880",
                    "name": "S. T. Mai"
                },
                {
                    "authorId": "144444438",
                    "name": "Massih-Reza Amini"
                }
            ]
        },
        {
            "paperId": "094fc6d4bca6c3657739a9165c2d31de67a8569e",
            "title": "Entropy-Based Concentration Inequalities for Dependent Variables",
            "abstract": "We provide new concentration inequalities for functions of dependent variables. The work extends that of Janson (2004), which proposes concentration inequalities using a combination of the Laplace transform and the idea of fractional graph coloring, as well as many works that derive concentration inequalities using the entropy method (see, e.g., (Boucheron et al., 2003)). We give inequalities for fractionally sub-additive and fractionally self-bounding functions. In the way, we prove a new Talagrand concentration inequality for fractionally sub-additive functions of dependent variables. The results allow us to envision the derivation of generalization bounds for various applications where dependent variables naturally appear, such as in bipartite ranking.",
            "fieldsOfStudy": [
                "Mathematics",
                "Computer Science"
            ],
            "authors": [
                {
                    "authorId": "1741364",
                    "name": "L. Ralaivola"
                },
                {
                    "authorId": "144444438",
                    "name": "Massih-Reza Amini"
                }
            ]
        },
        {
            "paperId": "0af53061d998011b3a6a584f498307f95bfe85b2",
            "title": "Multi-class to Binary reduction of Large-scale classification Problems",
            "abstract": "Large-scale multi-class classification problems have gained increased popularity in recent time mainly because of the overwhelming growth of textual and visual data in the web. However, this is a challenging task for many reasons. The main challenges in Large-scale classification problems are: scalability, complexity of model and class imbalance problem. In this work, we present an algorithm for binary reduction of multi-class classification problems, which aims at addressing the above-mentioned challenges.",
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "authors": [
                {
                    "authorId": "39277610",
                    "name": "Bikash Joshi"
                },
                {
                    "authorId": "144444438",
                    "name": "Massih-Reza Amini"
                },
                {
                    "authorId": "3071383",
                    "name": "Ioannis Partalas"
                },
                {
                    "authorId": "1741364",
                    "name": "L. Ralaivola"
                },
                {
                    "authorId": "1746841",
                    "name": "Nicolas Usunier"
                },
                {
                    "authorId": "2084160496",
                    "name": "Gaussier Eric"
                }
            ]
        },
        {
            "paperId": "0e9f1d63530b673b30fe74c00003c5014cadaf22",
            "title": "Language-independent Query Representation for IR Model Parameter Estimation on Unlabeled Collections",
            "abstract": "We study here the problem of estimating the parameters of standard IR models (as BM25 or language models) on new collections without any relevance judgments, by using collections with already available relevance judgements. We propose different query representations that allow mapping queries (with and without relevance judgments, from different collections, potentially in different languages) into a common space. We then introduce a kernel regression approach to learn the parameters of standard IR models individually for each query in the new, unlabeled collection. Our experiments, conducted on standard English and Indian IR collections, show that our approach can be used to efficiently tune, query by query, standard IR models to new collections, potentially written in different languages. In particular, the versions of the standard IR models we obtain not only outperform the versions with default parameters, but can also outperform the versions in which the parameter values have been optimized globally over a set of queries with target relevance judgements.",
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "authors": [
                {
                    "authorId": "1868168",
                    "name": "Parantapa Goswami"
                },
                {
                    "authorId": "144444438",
                    "name": "Massih-Reza Amini"
                },
                {
                    "authorId": "1732180",
                    "name": "\u00c9ric Gaussier"
                }
            ]
        },
        {
            "paperId": "9869538ca59734f753cb111015b22ae5e9688dc7",
            "title": "Learning language-independent sentence representations for multi-lingual, multi-document summarization",
            "abstract": "This paper presents an extension of a denoising auto-encoder to learn language-independent representations of parallel multilingual sentences. Each sentence from one language is represented using language dependent distributed representations. The input of the auto-encoder is then constituted of a concatenation of the distributed representations corresponding to the vector representations of translations of the same sentence in different languages. We show the effectiveness of the learnt representation for extractive multidocument summarization, using a simple cosine measure that estimates the similarity between vectors of sentences found by the auto-encoder and the vector representation of a generic query represented in the same learnt space. The top ranked sentences are then selected to generate the summary. Compared to other classical sentence representations, we demonstrate the effectiveness of our approach on the TAC 2011 MultiLing collection and show that learning language-independent representations of sentences that are translations one from another helps to significantly improve performance with respect to Rouge-SU4 measure.",
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "authors": [
                {
                    "authorId": "1951080",
                    "name": "Georgios Balikas"
                },
                {
                    "authorId": "144444438",
                    "name": "Massih-Reza Amini"
                }
            ]
        },
        {
            "paperId": "989e2f0518b4eb7beb73c41de7cdccd6188af310",
            "title": "Sparsification of Linear Models for Large-Scale Text Classification",
            "abstract": "In this paper we propose a simple yet effective method for sparsifying a posteriori linear models for large-scale text classification. The objective is to maintain high performance while reducing the prediction time by producing very sparse models. This is especially important in real-case scenarios where one deploys predictive models in several machines across the network and constraints apply on the prediction time. We empirically evaluate the proposed approach in a large collection of documents from the Large-Scale Hierarchical Text Classification Challenge. The comparison with a feature selection method and LASSO regularization shows that we achieve to obtain a sparse representation improving in the same time the classification performance.",
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "authors": [
                {
                    "authorId": "40185286",
                    "name": "Simon Moura"
                },
                {
                    "authorId": "3071383",
                    "name": "Ioannis Partalas"
                },
                {
                    "authorId": "144444438",
                    "name": "Massih-Reza Amini"
                }
            ]
        },
        {
            "paperId": "9bc2a536e2cbfa60e8526b8f2e0122dab86a834a",
            "title": "Study of Heuristic IR Constraints Under Function Discovery Framework",
            "abstract": "In this paper we investigate the effect of the heuristic IR constraints on IR term-document scoring functions within the recently proposed function discovery framework. In the earlier study the constraints were empirically validated as a whole. Moreover, only the group of form constraints was utilized and the other prominent group, the adjustment constraints, was not considered. In this work we will investigate all the constraints individually and study them with two different term frequency normalization, namely normalization scheme used in DFR models and relative term count normalization used in language models.",
            "fieldsOfStudy": [
                "Mathematics",
                "Computer Science"
            ],
            "authors": [
                {
                    "authorId": "1868168",
                    "name": "Parantapa Goswami"
                },
                {
                    "authorId": "144444438",
                    "name": "Massih-Reza Amini"
                },
                {
                    "authorId": "1732180",
                    "name": "\u00c9ric Gaussier"
                }
            ]
        },
        {
            "paperId": "9f40ec54a840c77b7c4dcaa830c77e737adf57da",
            "title": "LSHTC: A Benchmark for Large-Scale Text Classification",
            "abstract": "LSHTC is a series of challenges which aims to assess the performance of classification systems in large-scale classification in a a large number of classes (up to hundreds of thousands). This paper describes the dataset that have been released along the LSHTC series. The paper details the construction of the datsets and the design of the tracks as well as the evaluation measures that we implemented and a quick overview of the results. All of these datasets are available online and runs may still be submitted on the online server of the challenges.",
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "authors": [
                {
                    "authorId": "3071383",
                    "name": "Ioannis Partalas"
                },
                {
                    "authorId": "2195041",
                    "name": "Aris Kosmopoulos"
                },
                {
                    "authorId": "1800361",
                    "name": "Nicolas Baskiotis"
                },
                {
                    "authorId": "7364123",
                    "name": "T. Arti\u00e8res"
                },
                {
                    "authorId": "4738873",
                    "name": "G. Paliouras"
                },
                {
                    "authorId": "1732180",
                    "name": "\u00c9ric Gaussier"
                },
                {
                    "authorId": "1752430",
                    "name": "Ion Androutsopoulos"
                },
                {
                    "authorId": "144444438",
                    "name": "Massih-Reza Amini"
                },
                {
                    "authorId": "1741426",
                    "name": "P. Gallinari"
                }
            ]
        },
        {
            "paperId": "da07375e88a6e3a2610e5ab62ccf3cc547d2530e",
            "title": "Transfer Learning for IR Model Parameter Tuning",
            "abstract": "In this paper we study the problem of tuning the free parameters of standard IR models on collections without any relevance judgements, called target collections, utilizing collections with available relevance judgements, called source collections. The queries from source and target collections are mapped into a common vectorial space using a mapping kernel. The kernel mapping takes into account the representation of query words in their respective collections along with their semantic meaning. Then, standard regression techniques are deployed to learn the parameter values on a source collection which are later applied to obtain the values on the target collections. Our experiments on standard IR collections show that the proposed approach can efficiently tune the parameters of IR models query by query for new (unseen) target collections. Results also prove that the versions of the standard IR models we obtain outperform the versions with the default parameters and are on par with the versions where the parameter values are optimized over a set of queries using the target relevance judgements.",
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "authors": [
                {
                    "authorId": "46479704",
                    "name": "Anil Goyal"
                },
                {
                    "authorId": "1951080",
                    "name": "Georgios Balikas"
                },
                {
                    "authorId": "1868168",
                    "name": "Parantapa Goswami"
                },
                {
                    "authorId": "144444438",
                    "name": "Massih-Reza Amini"
                },
                {
                    "authorId": "48819635",
                    "name": "\u00c9ric Gaussier"
                }
            ]
        },
        {
            "paperId": "1c6bc73fead1e4984cbfa8e6f1681b6044593666",
            "title": "On power law distributions in large-scale taxonomies",
            "abstract": "In many of the large-scale physical and social complex systems phenomena fat-tailed distributions occur, for which different generating mechanisms have been proposed. In this paper, we study models of generating power law distributions in the evolution of large-scale taxonomies such as Open Directory Project, which consist of websites assigned to one of tens of thousands of categories. The categories in such taxonomies are arranged in tree or DAG structured configurations having parent-child relations among them. We first quantitatively analyse the formation process of such taxonomies, which leads to power law distribution as the stationary distributions. In the context of designing classifiers for large-scale taxonomies, which automatically assign unseen documents to leaf-level categories, we highlight how the fat-tailed nature of these distributions can be leveraged to analytically study the space complexity of such classifiers. Empirical evaluation of the space complexity on publicly available datasets demonstrates the applicability of our approach.",
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "authors": [
                {
                    "authorId": "1986256",
                    "name": "Rohit Babbar"
                },
                {
                    "authorId": "2472214",
                    "name": "Cornelia Metzig"
                },
                {
                    "authorId": "3071383",
                    "name": "Ioannis Partalas"
                },
                {
                    "authorId": "1732180",
                    "name": "\u00c9ric Gaussier"
                },
                {
                    "authorId": "144444438",
                    "name": "Massih-Reza Amini"
                }
            ]
        },
        {
            "paperId": "44989c71e7995334bdb0545451cbd4e09d354325",
            "title": "Re-ranking approach to classification in large-scale power-law distributed category systems",
            "abstract": "For large-scale category systems, such as Directory Mozilla, which consist of tens of thousand categories, it has been empirically verified in earlier studies that the distribution of documents among categories can be modeled as a power-law distribution. It implies that a significant fraction of categories, referred to as rare categories, have very few documents assigned to them. This characteristic of the data makes it harder for learning algorithms to learn effective decision boundaries which can correctly detect such categories in the test set. In this work, we exploit the distribution of documents among categories to (i) derive an upper bound on the accuracy of any classifier, and (ii) propose a ranking-based algorithm which aims to maximize this upper bound. The empirical evaluation on publicly available large-scale datasets demonstrate that the proposed method not only achieves higher accuracy but also much higher coverage of rare categories as compared to state-of-the-art methods.",
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "authors": [
                {
                    "authorId": "1986256",
                    "name": "Rohit Babbar"
                },
                {
                    "authorId": "3071383",
                    "name": "Ioannis Partalas"
                },
                {
                    "authorId": "1732180",
                    "name": "\u00c9ric Gaussier"
                },
                {
                    "authorId": "144444438",
                    "name": "Massih-Reza Amini"
                }
            ]
        },
        {
            "paperId": "63eb81a29d2354e9c6af2d834573e5f9b48fb18b",
            "title": "Web-scale classification: web classification in the big data era",
            "abstract": "This paper provides an overview of the workshop Web-Scale Classification: Web Classification in the Big Data Era which was held in New York City, on February 28th as a workshop of the seventh International Conference on Web Search and Data Mining. The goal of the workshop was to discuss and assess recent research focusing on classification and mining in Web-scale category systems. The workshop brought together members of several communities such web mining, machine learning, text classification and social media mining.",
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "authors": [
                {
                    "authorId": "3071383",
                    "name": "Ioannis Partalas"
                },
                {
                    "authorId": "144444438",
                    "name": "Massih-Reza Amini"
                },
                {
                    "authorId": "1752430",
                    "name": "Ion Androutsopoulos"
                },
                {
                    "authorId": "7364123",
                    "name": "T. Arti\u00e8res"
                },
                {
                    "authorId": "1741426",
                    "name": "P. Gallinari"
                },
                {
                    "authorId": "1732180",
                    "name": "\u00c9ric Gaussier"
                },
                {
                    "authorId": "4738873",
                    "name": "G. Paliouras"
                }
            ]
        },
        {
            "paperId": "c27a0c0cc4e1b4768227def888cf95ea72e094d3",
            "title": "Algorithmic Robustness for Learning via $(\\epsilon, \\gamma, \\tau)$-Good Similarity Functions",
            "abstract": "The notion of metric plays a key role in machine learning problems such as classification, clustering or ranking. However, it is worth noting that there is a severe lack of theoretical guarantees that can be expected on the generalization capacity of the classifier associated to a given metric. The theoretical framework of $(\\epsilon, \\gamma, \\tau)$-good similarity functions (Balcan et al., 2008) has been one of the first attempts to draw a link between the properties of a similarity function and those of a linear classifier making use of it. In this paper, we extend and complete this theory by providing a new generalization bound for the associated classifier based on the algorithmic robustness framework.",
            "fieldsOfStudy": [
                "Mathematics",
                "Computer Science"
            ],
            "authors": [
                {
                    "authorId": "2378427",
                    "name": "Maria-Irina Nicolae"
                },
                {
                    "authorId": "1738336",
                    "name": "M. Sebban"
                },
                {
                    "authorId": "1749327",
                    "name": "Amaury Habrard"
                },
                {
                    "authorId": "1403564170",
                    "name": "'Eric Gaussier"
                },
                {
                    "authorId": "144444438",
                    "name": "Massih-Reza Amini"
                }
            ]
        },
        {
            "paperId": "1c477a32a53024c6976025e914b57006d1fa2f78",
            "title": "Multiview semi-supervised ranking for automatic image annotation",
            "abstract": "Most photo sharing sites give their users the opportunity to manually label images. The labels collected that way are usually very incomplete due to the size of the image collections: most images are not labeled according to all the categories they belong to, and, conversely, many class have relatively few representative examples. Automated image systems that can deal with small amounts of labeled examples and unbalanced classes are thus necessary to better organize and annotate images. In this work, we propose a multiview semi-supervised bipartite ranking model which allows to leverage the information contained in unlabeled sets of images in order to improve the prediction performance, using multiple descriptions, or views of images. For each topic class, our approach first learns as many view-specific rankers as available views using the labeled data only. These rankers are then improved iteratively by adding pseudo-labeled pairs of examples on which all view-specific rankers agree over the ranking of examples within these pairs. We report on experiments carried out on the NUS-WIDE dataset, which show that the multiview ranking process improves predictive performances when a small number of labeled examples is available specially for unbalanced classes. We show also that our approach achieves significant improvements over a state-of-the art semi-supervised multiview classification model.",
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "authors": [
                {
                    "authorId": "1403816960",
                    "name": "Ali Fakeri-Tabrizi"
                },
                {
                    "authorId": "144444438",
                    "name": "Massih-Reza Amini"
                },
                {
                    "authorId": "1741426",
                    "name": "P. Gallinari"
                }
            ]
        },
        {
            "paperId": "95a1b8737f0bad5ee6b55f99b12089a40bb6d989",
            "title": "Transferring knowledge with source selection to learn IR functions on unlabeled collections",
            "abstract": "We investigate the problem of learning an IR function on a collection without relevance judgements (called target collection) by transferring knowledge from a selected source collection with relevance judgements. To do so, we first construct, for each query in the target collection, relative relevance judgment pairs using information from the source collection closest to the query (selection and transfer steps), and then learn an IR function from the obtained pairs in the target collection (self-learning step). For the transfer step, the relevance information in the source collection is summarized as a grid that provides, for each term frequency and document frequency values of a word in a document, an empirical estimate of the relevance of the document. The self-learning step iteratively assigns pairwise preferences to documents in the target collection using the scores of the former learned function. We show the effectiveness of our approach through a series of extensive experiments on CLEF and several collections from TREC used either as target or source datasets. Our experiments show the importance of selecting the source collection prior to transfer information to the target collection, and demonstrate that the proposed approach yields results consistently and significantly above state-of-the-art IR functions.",
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "authors": [
                {
                    "authorId": "1868168",
                    "name": "Parantapa Goswami"
                },
                {
                    "authorId": "144444438",
                    "name": "Massih-Reza Amini"
                },
                {
                    "authorId": "1732180",
                    "name": "\u00c9ric Gaussier"
                }
            ]
        },
        {
            "paperId": "e85cb9c607635e8137b762e1d44ebee5dfa3f272",
            "title": "On Flat versus Hierarchical Classification in Large-Scale Taxonomies",
            "abstract": "We study in this paper flat and hierarchical classification strategies in the context of large-scale taxonomies. To this end, we first propose a multiclass, hierarchical data dependent bound on the generalization error of classifiers deployed in large-scale taxonomies. This bound provides an explanation to several empirical results reported in the literature, related to the performance of flat and hierarchical classifiers. We then introduce another type of bound targeting the approximation error of a family of classifiers, and derive from it features used in a meta-classifier to decide which nodes to prune (or flatten) in a large-scale taxonomy. We finally illustrate the theoretical developments through several experiments conducted on two widely used taxonomies.",
            "fieldsOfStudy": [
                "Mathematics",
                "Computer Science"
            ],
            "authors": [
                {
                    "authorId": "1986256",
                    "name": "Rohit Babbar"
                },
                {
                    "authorId": "3071383",
                    "name": "Ioannis Partalas"
                },
                {
                    "authorId": "1732180",
                    "name": "\u00c9ric Gaussier"
                },
                {
                    "authorId": "144444438",
                    "name": "Massih-Reza Amini"
                }
            ]
        },
        {
            "paperId": "17b926e4a190da8da3a52fe36c44f81b9aed4a1d",
            "title": "Fast on-line learning for multilingual categorization",
            "abstract": "Multiview learning has been shown to be a natural and efficient framework for supervised or semi-supervised learning of multilingual document categorizers. The state-of-the-art co-regularization approach relies on alternate minimizations of a combination of language-specific categorization errors and a disagreement between the outputs of the monolingual text categorizers. This is typically solved by repeatedly training categorizers on each language with the appropriate regularizer. We extend and improve this approach by introducing an on-line learning scheme, where language-specific updates are interleaved in order to iteratively optimize the global cost in one pass. Our experimental results show that this produces similar performance as the batch approach, at a fraction of the computational cost.",
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "authors": [
                {
                    "authorId": "152474360",
                    "name": "M. Kovesi"
                },
                {
                    "authorId": "2788842",
                    "name": "Cyril Goutte"
                },
                {
                    "authorId": "144444438",
                    "name": "Massih-Reza Amini"
                }
            ]
        },
        {
            "paperId": "f158c69a1948e7d13bcaa5f5ebca31e4ca391f86",
            "title": "On using a quantum physics formalism for multidocument summarization",
            "abstract": "Multidocument summarization (MDS) aims for each given query to extract compressed and relevant information with respect to the different query-related themes present in a set of documents. Many approaches operate in two steps. Themes are first identified from the set, and then a summary is formed by extracting salient sentences within the different documents of each of the identified themes. Among these approaches, latent semantic analysis (LSA) based approaches rely on spectral decomposition techniques to identify the themes. In this article, we propose a major extension of these techniques that relies on the quantum information access (QIA) framework. The latter is a framework developed for modeling information access based on the probabilistic formalism of quantum physics. The QIA framework not only points out the limitations of the current LSA-based approaches, but motivates a new principled criterium to tackle multidocument summarization that addresses these limitations. As a byproduct, it also provides a way to enhance the LSA-based approaches. Extensive experiments on the DUC 2005, 2006 and 2007 datasets show that the proposed approach consistently improves over both the LSA-based approaches and the systems that competed in the yearly DUC competitions. This demonstrates the potential impact of quantum-inspired approaches to information access in general, and of the QIA framework in particular. \u00a9 2012 Wiley Periodicals, Inc.",
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "authors": [
                {
                    "authorId": "1703777",
                    "name": "Benjamin Piwowarski"
                },
                {
                    "authorId": "144444438",
                    "name": "Massih-Reza Amini"
                },
                {
                    "authorId": "1684032",
                    "name": "M. Lalmas"
                }
            ]
        },
        {
            "paperId": "98db0352534f9298f1157c1aa970c07d4df0cb45",
            "title": "Transductive learning over automatically detected themes for multi-document summarization",
            "abstract": "We propose a new method for query-biased multi-document summarization, based on sentence extraction. The summary of multiple documents is created in two steps. Sentences are first clustered; where each cluster corresponds to one of the main themes present in the collection. Inside each theme, sentences are then ranked using a transductive learning-to-rank algorithm based on RankNet, in order to better identify those which are relevant to the query. The final summary contains the top-ranked sentences of each theme. Our approach is validated on DUC 2006 and DUC 2007 datasets.",
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "authors": [
                {
                    "authorId": "144444438",
                    "name": "Massih-Reza Amini"
                },
                {
                    "authorId": "1746841",
                    "name": "Nicolas Usunier"
                }
            ]
        },
        {
            "paperId": "03d89441c89329f154c663f3a1f94be20ec8084b",
            "title": "UPMC/LIP6 at ImageCLEFannotation 2010",
            "abstract": "In this paper, we present the LIP6 annotation models for the ImageCLEFannotation 2010 task. We study two methods to train and merge the results of different classifiers in order to improve annota- tion. In particular, we propose a multiview learning model based on a RankingSVM. We also consider the use of the tags matching the visual concept names to improve the scores predicted by the models. The ex- periments show the difficulty of merging several classifiers and also the interest to have a robust model able to merge relevant information. Our method using tags always improves the results.",
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "authors": [
                {
                    "authorId": "1403816960",
                    "name": "Ali Fakeri-Tabrizi"
                },
                {
                    "authorId": "2793292",
                    "name": "Sabrina Tollari"
                },
                {
                    "authorId": "1746841",
                    "name": "Nicolas Usunier"
                },
                {
                    "authorId": "144444438",
                    "name": "Massih-Reza Amini"
                },
                {
                    "authorId": "1741426",
                    "name": "P. Gallinari"
                }
            ]
        },
        {
            "paperId": "0d9e7461abd46c47db770b2156d25acfa9a913bf",
            "title": "Multi-view clustering of multilingual documents",
            "abstract": "We propose a new multi-view clustering method which uses clustering results obtained on each view as a voting pattern in order to construct a new set of multi-view clusters. Our experiments on a multilingual corpus of documents show that performance increases significantly over simple concatenation and another multi-view clustering technique.",
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "authors": [
                {
                    "authorId": "38688631",
                    "name": "Young-Min Kim"
                },
                {
                    "authorId": "144444438",
                    "name": "Massih-Reza Amini"
                },
                {
                    "authorId": "2788842",
                    "name": "Cyril Goutte"
                },
                {
                    "authorId": "1741426",
                    "name": "P. Gallinari"
                }
            ]
        },
        {
            "paperId": "48c428d42f28b02526b8bab08f4f0b620efb590a",
            "title": "Combining coregularization and consensus-based self-training for multilingual text categorization",
            "abstract": "We investigate the problem of learning document classifiers in a multilingual setting, from collections where labels are only partially available. We address this problem in the framework of multiview learning, where different languages correspond to different views of the same document, combined with semi-supervised learning in order to benefit from unlabeled documents. We rely on two techniques, coregularization and consensus-based self-training, that combine multiview and semi-supervised learning in different ways. Our approach trains different monolingual classifiers on each of the views, such that the classifiers' decisions over a set of unlabeled examples are in agreement as much as possible, and iteratively labels new examples from another unlabeled training set based on a consensus across language-specific classifiers. We derive a boosting-based training algorithm for this task, and analyze the impact of the number of views on the semi-supervised learning results on a multilingual extension of the Reuters RCV1/RCV2 corpus using five different languages. Our experiments show that coregularization and consensus-based self-training are complementary and that their combination is especially effective in the interesting and very common situation where there are few views (languages) and few labeled documents available.",
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "authors": [
                {
                    "authorId": "144444438",
                    "name": "Massih-Reza Amini"
                },
                {
                    "authorId": "2788842",
                    "name": "Cyril Goutte"
                },
                {
                    "authorId": "1746841",
                    "name": "Nicolas Usunier"
                }
            ]
        },
        {
            "paperId": "656937bf547f7bb299fe00c104b2643c2ad192bc",
            "title": "Incorporating prior knowledge into a transductive ranking algorithm for multi-document summarization",
            "abstract": "This paper presents a transductive approach to learn ranking functions for extractive multi-document summarization. At the first stage, the proposed approach identifies topic themes within a document collection, which help to identify two sets of relevant and irrelevant sentences to a question. It then iteratively trains a ranking function over these two sets of sentences by optimizing a ranking loss and fitting a prior model built on keywords. The output of the function is used to find further relevant and irrelevant sentences. This process is repeated until a desired stopping criterion is met.",
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "authors": [
                {
                    "authorId": "144444438",
                    "name": "Massih-Reza Amini"
                },
                {
                    "authorId": "1746841",
                    "name": "Nicolas Usunier"
                }
            ]
        },
        {
            "paperId": "82402bf63b039073e2027246d1d4332781b15002",
            "title": "Learning from Multiple Partially Observed Views - an Application to Multilingual Text Categorization",
            "abstract": "We address the problem of learning classifiers when observations have multiple views, some of which may not be observed for all examples. We assume the existence of view generating functions which may complete the missing views in an approximate way. This situation corresponds for example to learning text classifiers from multilingual collections where documents are not available in all languages. In that case, Machine Translation (MT) systems may be used to translate each document in the missing languages. We derive a generalization error bound for classifiers learned on examples with multiple artificially created views. Our result uncovers a trade-off between the size of the training set, the number of views, and the quality of the view generating functions. As a consequence, we identify situations where it is more interesting to use multiple views for learning instead of classical single view learning. An extension of this framework is a natural way to leverage unlabeled multi-view data in semi-supervised learning. Experimental results on a subset of the Reuters RCV1/RCV2 collections support our findings by showing that additional views obtained from MT may significantly improve the classification performance in the cases identified by our trade-off.",
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "authors": [
                {
                    "authorId": "144444438",
                    "name": "Massih-Reza Amini"
                },
                {
                    "authorId": "1746841",
                    "name": "Nicolas Usunier"
                },
                {
                    "authorId": "2788842",
                    "name": "Cyril Goutte"
                }
            ]
        },
        {
            "paperId": "b7f597805bafc9d7f6e8b3991392818352f196e0",
            "title": "A self-training method for learning to rank with unlabeled data",
            "abstract": "This paper presents a new algorithm for bipartite ranking functions trained with partially labeled data. The algorithm is an extension of the self-training paradigm developed under the classification framework. We further propose an efficient and scalable optimization method for training linear models though the approach is general in the sense that it can be applied to any classes of scoring functions. Empirical results on several common image and text corpora over the Area Under the ROC Curve (AUC) and the Average Precision measure show that the use of unlabeled data in the training process leads to improve the performance of baseline supervised ranking functions.",
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "authors": [
                {
                    "authorId": "2612533",
                    "name": "Tuong-Vinh Truong"
                },
                {
                    "authorId": "144444438",
                    "name": "Massih-Reza Amini"
                },
                {
                    "authorId": "1741426",
                    "name": "P. Gallinari"
                }
            ]
        },
        {
            "paperId": "15706f0a81daae563b59072d64336a19b76b835f",
            "title": "Consortium AVEIR at ImageCLEFphoto 2008: on the Fusion of Runs",
            "abstract": "In this working note, we present the submission of the AVEIR consortium, composed of 4 French laboratories, to ImageCLEFphoto 2008. The submitted runs correspond to different fusion strategies applied to four individual ranks, each proposed by an AVEIR consortium partner. In particular, we study the complete, and partial, average of the ranking values, the minimum of these values, and a random based diversification. We first briefly describe the individual run of each partner, then we describe the fusion runs. The official results classed one of the runs, the MEAN fusion, as the third best in the automatic text-image run category. This run gives better results than the best partner run.",
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "authors": [
                {
                    "authorId": "2793292",
                    "name": "Sabrina Tollari"
                },
                {
                    "authorId": "1762116",
                    "name": "Marcin Detyniecki"
                },
                {
                    "authorId": "145567641",
                    "name": "Marin Ferecatu"
                },
                {
                    "authorId": "1742496",
                    "name": "H. Glotin"
                },
                {
                    "authorId": "1714010",
                    "name": "P. Mulhem"
                },
                {
                    "authorId": "144444438",
                    "name": "Massih-Reza Amini"
                },
                {
                    "authorId": "1403816960",
                    "name": "Ali Fakeri-Tabrizi"
                },
                {
                    "authorId": "1741426",
                    "name": "P. Gallinari"
                },
                {
                    "authorId": "1692389",
                    "name": "H. Sahbi"
                },
                {
                    "authorId": "33698309",
                    "name": "Zhong-Qiu Zhao"
                }
            ]
        },
        {
            "paperId": "197a8b0d27106f84752bf9f449875ccdba60d186",
            "title": "A boosting algorithm for learning bipartite ranking functions with partially labeled data",
            "abstract": "This paper presents a boosting based algorithm for learning a bipartite ranking function (BRF) with partially labeled data. Until now different attempts had been made to build a BRF in a transductive setting, in which the test points are given to the methods in advance as unlabeled data. The proposed approach is a semi-supervised inductive ranking algorithm which, as opposed to transductive algorithms, is able to infer an ordering on new examples that were not used for its training. We evaluate our approach using the TREC-9 Ohsumed and the Reuters-21578 data collections, comparing against two semi-supervised classification algorithms for ROCArea (AUC), uninterpolated average precision (AUP), mean precision@50 (TP) and Precision-Recall (PR) curves. In the most interesting cases where there are an unbalanced number of irrelevant examples over relevant ones, we show our method to produce statistically significant improvements with respect to these ranking measures.",
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "authors": [
                {
                    "authorId": "144444438",
                    "name": "Massih-Reza Amini"
                },
                {
                    "authorId": "2612533",
                    "name": "Tuong-Vinh Truong"
                },
                {
                    "authorId": "2788842",
                    "name": "Cyril Goutte"
                }
            ]
        },
        {
            "paperId": "7ef59a08352f37e6dd4817458016dc763eccc334",
            "title": "A Transductive Bound for the Voted Classifier with an Application to Semi-supervised Learning",
            "abstract": "We propose two transductive bounds on the risk of majority votes that are estimated over partially labeled training sets. The first one involves the margin distribution of the classifier and a risk bound on its associate Gibbs classifier. The bound is tight when so is the Gibbs's bound and when the errors of the majority vote classifier is concentrated on a zone of low margin. In semi-supervised learning, considering the margin as an indicator of confidence constitutes the working hypothesis of algorithms which search the decision boundary on low density regions. Following this assumption, we propose to bound the error probability of the voted classifier on the examples for whose margins are above a fixed threshold. As an application, we propose a self-learning algorithm which iteratively assigns pseudo-labels to the set of unlabeled training examples that have their margin above a threshold obtained from this bound. Empirical results on different datasets show the effectiveness of our approach compared to the same algorithm and the TSVM in which the threshold is fixed manually.",
            "fieldsOfStudy": [
                "Computer Science",
                "Mathematics"
            ],
            "authors": [
                {
                    "authorId": "144444438",
                    "name": "Massih-Reza Amini"
                },
                {
                    "authorId": "2482151",
                    "name": "Fran\u00e7ois Laviolette"
                },
                {
                    "authorId": "1746841",
                    "name": "Nicolas Usunier"
                }
            ]
        },
        {
            "paperId": "c125969cf9df7b5ccf7a2f547f5c97a6bdb3de55",
            "title": "UPMC/LIP6 at ImageCLEF's WikipediaMM: An Image-Annotation Model for an Image Search-Engine",
            "abstract": "In this paper, we present the LIP6 retrieval system which automatically ranks the most similar images to a given query constituted of both textual and/or visual information through a given textual-visual collection. The system first preprocesses the data set in order to remove stop-words as well as non-informative terms. For each given query, it then finds a ranked list of its most similar images using only their textual informations. Visual features are then used to obtain a second ranking list from a manifold and a linear combination of these two ranking lists gives the final ranking of images.",
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "authors": [
                {
                    "authorId": "1403816960",
                    "name": "Ali Fakeri-Tabrizi"
                },
                {
                    "authorId": "144444438",
                    "name": "Massih-Reza Amini"
                },
                {
                    "authorId": "2793292",
                    "name": "Sabrina Tollari"
                },
                {
                    "authorId": "1741426",
                    "name": "P. Gallinari"
                }
            ]
        },
        {
            "paperId": "d725fd859a15b2d367015bae8ec786c96c700435",
            "title": "An extension of PLSA for document clustering",
            "abstract": "In this paper we propose an extension of the PLSA model in which an extra latent variable allows the model to co-cluster documents and terms simultaneously. We show on three datasets that our extended model produces statistically significant improvements with respect to two clustering measures over the original PLSA and the multinomial mixture MM models.",
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "authors": [
                {
                    "authorId": "38688631",
                    "name": "Young-Min Kim"
                },
                {
                    "authorId": "2099242119",
                    "name": "Jean-Fran\u00e7ois Pessiot"
                },
                {
                    "authorId": "144444438",
                    "name": "Massih-Reza Amini"
                },
                {
                    "authorId": "1741426",
                    "name": "P. Gallinari"
                }
            ]
        },
        {
            "paperId": "e786107783eef3132687e4b816bacb3ed5af9233",
            "title": "UPMC/LIP6 at ImageCLEFphoto 2008: on the Exploitation of Visual Concepts (VCDT)",
            "abstract": "In this working note, we focus our efforts on the study of how to automatically extract and exploit visual concepts. First, in the Visual Concept Detection Task (VCDT), we look at the mutual exclusion and implication relations between VCDT concepts in order to improve the automatic image annotation by Forest of Fuzzy Decision Trees (FFDTs). In our experiments, the use of the relations do not improve nor worsen the quality of the annotation. Our best VCDT run is the 4th ones under 53 submitted runs (3rd team under 11 teams). Second, in the Photo Retrieval Task (ImageCLEFphoto), we use the FFDTs learn in VCDT task and WordNet to improve image retrieval. We analyse the influence of extracted visual concept models to the diversity and precision. This study shows that there is a clear improvement, in terms of precision or cluster recall at 20, when using the visual concepts explicitly appearing in the query.",
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "authors": [
                {
                    "authorId": "2793292",
                    "name": "Sabrina Tollari"
                },
                {
                    "authorId": "1762116",
                    "name": "Marcin Detyniecki"
                },
                {
                    "authorId": "1403816960",
                    "name": "Ali Fakeri-Tabrizi"
                },
                {
                    "authorId": "144444438",
                    "name": "Massih-Reza Amini"
                },
                {
                    "authorId": "1741426",
                    "name": "P. Gallinari"
                }
            ]
        },
        {
            "paperId": "3fd9291b9e90c2721448e5620a33f36b60674202",
            "title": "UHigh-Level Feature Detection with Forests of Fuzzy Decision Trees combined with the RankBoost Algorithm",
            "abstract": "In this paper, we present the methodology we applied in our submission to the NIST TRECVID\u20192007 evaluation. We participated in the High-level Feature Extraction task. Our approach is based on the use of a Forest of Fuzzy Decision Trees combined with the RankBoost algorithm",
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "authors": [
                {
                    "authorId": "1991253",
                    "name": "C. Marsala"
                },
                {
                    "authorId": "1762116",
                    "name": "Marcin Detyniecki"
                },
                {
                    "authorId": "1746841",
                    "name": "Nicolas Usunier"
                },
                {
                    "authorId": "144444438",
                    "name": "Massih-Reza Amini"
                }
            ]
        },
        {
            "paperId": "4465c35cbec7a05aa1926b8330989d7665aebbd0",
            "title": "Learning to Rank for Collaborative Filtering",
            "abstract": "Up to now, most contributions to collaborative filtering rely on rating prediction to generate the recommendations. We, instead, try to correctly rank the items according to the users\u2019 tastes. First, we define a ranking error function which takes available pairwise preferences between items into account. Then we design an effective algorithm that optimizes this error. Finally we illustrate the proposal on a standard collaborative filtering dataset. We adapted the evaluation protocol proposed by (Marlin, 2004) for rating prediction based systems to our case, where pairwise preferences are predicted instead. The preliminary results are between those of two reference rating prediction based methods. We suggest different directions to further explore our ranking based approach for collaborative filtering.",
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "authors": [
                {
                    "authorId": "2099242119",
                    "name": "Jean-Fran\u00e7ois Pessiot"
                },
                {
                    "authorId": "2612533",
                    "name": "Tuong-Vinh Truong"
                },
                {
                    "authorId": "1746841",
                    "name": "Nicolas Usunier"
                },
                {
                    "authorId": "144444438",
                    "name": "Massih-Reza Amini"
                },
                {
                    "authorId": "1741426",
                    "name": "P. Gallinari"
                }
            ]
        },
        {
            "paperId": "6f0f05de9c380ac83e9d9f6eac6278d2d8e02fde",
            "title": "A Contextual Query Expansion Approach by Term Clustering for Robust Text Summarization",
            "abstract": "This paper describes the different steps which lead to the construction of the LIP6 extractive summarizer. The basic idea behind this system is to expand question and title keywords of each topic with their respective cluster terms. Term clusters are found by unsupervised learning using a classification variant of the well-known EM algorithm. Each sentence is then characterized by 4 features, each of which uses bag-of-words similarities between expanded topic title or questions and the current sentence. A final score of the sentences is found by manually tuning the weights of a linear combination of these features ; these weights are chosen in order to maximize the Rouge-2 AvF measure on the Duc 2006 corpus.",
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "authors": [
                {
                    "authorId": "144444438",
                    "name": "Massih-Reza Amini"
                },
                {
                    "authorId": "1746841",
                    "name": "Nicolas Usunier"
                }
            ]
        },
        {
            "paperId": "bc8752f296529c1e30708f1e135c17f882ba7cec",
            "title": "High-Level Feature Detection with Forests of Fuzzy Decision Trees combined with the RankBoost",
            "abstract": "In this paper, we present the methodology we applied in our submission to the NIST TRECVID\u20192007 evaluation. We participated in the High-level Feature Extraction task. Our approach is based on the use of a Forest of Fuzzy Decision Trees combined with the RankBoost algorithm.",
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "authors": [
                {
                    "authorId": "1991253",
                    "name": "C. Marsala"
                },
                {
                    "authorId": "1762116",
                    "name": "Marcin Detyniecki"
                },
                {
                    "authorId": "1746841",
                    "name": "Nicolas Usunier"
                },
                {
                    "authorId": "144444438",
                    "name": "Massih-Reza Amini"
                }
            ]
        },
        {
            "paperId": "dad1a55fdbc84987aba47da0f2eb120e93f7b5ae",
            "title": "Learning to Rank with Partially Labeled Training Data",
            "abstract": "Many real life applications involve the ranking of objects instead of their classification. For example, in Document Retrieval the goal is to rank documents from a collection based on their relevancy to a user\u2019s query. Recently the supervised learning of ranking functions has attracted considerable attention from the Machine Learning community and most computational models proposed for ranking rely on this paradigm. Labeling large amounts of data may require expensive human resources, especially for ranking problems, and they are unrealistic in most applications. In the other hand, the semi-supervised learning paradigm which considers the possibility of learning from both the labeled and unlabeled examples has attracted the interest of the ML community in the field of classification since 1998.\n\nIn this paper, we propose a semi-supervised learning algorithm for ranking. Existing semi supervised ranking algorithms are graph-based transductive techniques which from an observed training dataset, order a specific unlabeled data pool. Our motivation here is to develop a novel inductive approach which from a specific observed training data (labeled and unlabeled) produces a general ranking rule, which ranks unseen examples with high accurancy. Our algorithm is an iterative approach which combines a supervised and a graph-based method. Empirical results on a real-life dataset from the CACM collection have shown the potential of this approach in the context of Document Retrieval.",
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "authors": [
                {
                    "authorId": "2612533",
                    "name": "Tuong-Vinh Truong"
                },
                {
                    "authorId": "144444438",
                    "name": "Massih-Reza Amini"
                },
                {
                    "authorId": "1741426",
                    "name": "P. Gallinari"
                }
            ]
        },
        {
            "paperId": "dfe032595dacc85741d7d4c3990c275a41309a67",
            "title": "Reducing the Annotation Burden in Text Classification",
            "abstract": "In this paper we describe a method which combines semi-supervised and active learning for the classification task. In particular, we propose a semi-supervised PLSA (Probabilistic Latent Semantic Analysis) algorithm [4] combined with a certainty-based active learning method, in order to classify text documents.",
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "authors": [
                {
                    "authorId": "1927081",
                    "name": "Anastasia Krithara"
                },
                {
                    "authorId": "2788842",
                    "name": "Cyril Goutte"
                },
                {
                    "authorId": "144444438",
                    "name": "Massih-Reza Amini"
                },
                {
                    "authorId": "2822140",
                    "name": "J. Renders"
                }
            ]
        },
        {
            "paperId": "628160ae1e43bf750668d2bf0f947da53586525a",
            "title": "Generalization error bounds for classifiers trained with interdependent data",
            "abstract": "In this paper we propose a general framework to study the generalization properties of binary classifiers trained with data which may be dependent, but are deterministically generated upon a sample of independent examples. It provides generalization bounds for binary classification and some cases of ranking problems, and clarifies the relationship between these learning tasks.",
            "fieldsOfStudy": [
                "Computer Science",
                "Mathematics"
            ],
            "authors": [
                {
                    "authorId": "1746841",
                    "name": "Nicolas Usunier"
                },
                {
                    "authorId": "144444438",
                    "name": "Massih-Reza Amini"
                },
                {
                    "authorId": "1741426",
                    "name": "P. Gallinari"
                }
            ]
        },
        {
            "paperId": "9b18ef230541fbbe5241dda1e9645fed13be956a",
            "title": "Learning to summarise XML documents using content and structure",
            "abstract": "Documents formatted in eXtensible Markup Language (XML) are becoming increasingly available in collections of various document types. In this paper, we present an approach for the summarisation of XML documents. The novelty of this approach lies in that it is based on features not only from the content of documents, but also from their logical structure. We follow a machine learning like, sentence extraction-based summarisation technique. To find which features are more effective for producing summaries this approach views sentence extraction as an ordering task. We evaluated our summarisation model using the INEX dataset. The results demonstrate that the inclusion of features from the logical structure of documents increases the effectiveness of the summariser, and that the learnable system is also effective and well-suited to the task of summarisation in the context of XML documents.",
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "authors": [
                {
                    "authorId": "144444438",
                    "name": "Massih-Reza Amini"
                },
                {
                    "authorId": "2517118",
                    "name": "A. Tombros"
                },
                {
                    "authorId": "1746841",
                    "name": "Nicolas Usunier"
                },
                {
                    "authorId": "1684032",
                    "name": "M. Lalmas"
                },
                {
                    "authorId": "1741426",
                    "name": "P. Gallinari"
                }
            ]
        },
        {
            "paperId": "f6db5e61f9367c7cf761f215e78844052b5fb761",
            "title": "Ranking with Unlabeled Data: A First Study",
            "abstract": "In this paper, we present a general learning framework which treats the ranking problem for various Information Retrieval tasks. We extend the training set generalization error bound proposed by Matti Kaariannan to the ranking case and show that the use of unlabeled data can be beneficial for learning a ranking function. We finally discuss open issues regarding the use of the unlabeled data during training a ranking function.",
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "authors": [
                {
                    "authorId": "1746841",
                    "name": "Nicolas Usunier"
                },
                {
                    "authorId": "2612533",
                    "name": "Tuong-Vinh Truong"
                },
                {
                    "authorId": "144444438",
                    "name": "Massih-Reza Amini"
                },
                {
                    "authorId": "1741426",
                    "name": "P. Gallinari"
                }
            ]
        },
        {
            "paperId": "4ca0be1a1c27e3ee32e59c5b070b6b2bea1d3e83",
            "title": "Boosting Weak Ranking Functions to Enhance Passage Retrieval for Question Answering",
            "abstract": "We investigate the problem of passage retrieval for Question Answering (QA) systems. We adopt a machine learning approach and apply to QA a boosting algorithm initially proposed for ranking a set of objects by combining baseline ranking functions. The system operates in two steps. For a given question, it first retrieves passages using a conventional search engine and assigns each passage a series of scores. It then ranks the returned passages using a weighted feature combination. Weights express the feature importance for ranking and are learned to maximize the number of top ranked relevant passages over a training set. We empirically show that using questions from the TREC-11 question/answering track and the Aquaint collection, the proposed algorithm significantly increases both coverage and precision with respect to a conventional IR system.",
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "authors": [
                {
                    "authorId": "1746841",
                    "name": "Nicolas Usunier"
                },
                {
                    "authorId": "144444438",
                    "name": "Massih-Reza Amini"
                },
                {
                    "authorId": "1741426",
                    "name": "P. Gallinari"
                }
            ]
        },
        {
            "paperId": "ba2ae1cbd3a4ba3e104519fb8f775b28f49e9010",
            "title": "Unsupervised Learning with Term Clustering for Thematic Segmentation of Texts",
            "abstract": "In this paper we introduce a machine learning approach for automatic text segmentation. Our text segmenter clusters text-segments containing similar concepts. It first discovers the different concepts present in a text, each concept being defined as a set of representative terms. After that the text is partitioned into coherent paragraphs using a clustering technique based on the Classification Maximum Likelihood approach. We evaluate the effectiveness of this technique on sets of concatenated paragraphs from two collections, the 7 sectors and the 20 Newsgroups corpus, and compare it to a baseline text segmentation technique proposed by Salton et al.",
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "authors": [
                {
                    "authorId": "26498926",
                    "name": "Marc Caillet"
                },
                {
                    "authorId": "2099242119",
                    "name": "Jean-Fran\u00e7ois Pessiot"
                },
                {
                    "authorId": "144444438",
                    "name": "Massih-Reza Amini"
                },
                {
                    "authorId": "1741426",
                    "name": "P. Gallinari"
                }
            ]
        },
        {
            "paperId": "462e5f6e09bf3fd7a4e132bac582c676ba105df6",
            "title": "Semi-supervised learning with explicit misclassification modeling",
            "abstract": "This paper investigates a new approach for training discriminant classifiers when only a small set of labeled data is available together with a large set of unlabeled data. This algorithm optimizes the classification maximum likelihood of a set of labeled-unlabeled data, using a variant form of the Classification Expectation Maximization (CEM) algorithm. Its originality is that it makes use of both unlabeled data and of a probabilistic misclassification model for these data. The parameters of the label-error model are learned together with the classifier parameters. We demonstrate the effectiveness of the approach on four data-sets and show the advantages of this method over a previously developed semi-supervised algorithm which does not consider imperfections in the labeling process.",
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "authors": [
                {
                    "authorId": "144444438",
                    "name": "Massih-Reza Amini"
                },
                {
                    "authorId": "1741426",
                    "name": "P. Gallinari"
                }
            ]
        },
        {
            "paperId": "d5fb5f3f152236781faa0affd2f01fa3794479ae",
            "title": "The use of unlabeled data to improve supervised learning for text summarization",
            "abstract": "With the huge amount of information available electronically, there is an increasing demand for automatic text summarization systems. The use of machine learning techniques for this task allows one to adapt summaries to the user needs and to the corpus characteristics. These desirable properties have motivated an increasing amount of work in this field over the last few years. Most approaches attempt to generate summaries by extracting sentence segments and adopt the supervised learning paradigm which requires to label documents at the text span level. This is a costly process, which puts strong limitations on the applicability of these methods. We investigate here the use of semi-supervised algorithms for summarization. These techniques make use of few labeled data together with a larger amount of unlabeled data. We propose new semi-supervised algorithms for training classification models for text summarization. We analyze their performances on two data sets - the Reuters news-wire corpus and the Computation and Language (cmp_lg) collection of TIPSTER SUMMAC. We perform comparisons with a baseline - non learning - system, and a reference trainable summarizer system.",
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "authors": [
                {
                    "authorId": "144444438",
                    "name": "Massih-Reza Amini"
                },
                {
                    "authorId": "1741426",
                    "name": "P. Gallinari"
                }
            ]
        },
        {
            "paperId": "df7f8e4deade0da8428f9d6f38e2d2400cb77f07",
            "title": "Semi Supervised Logistic Regression",
            "abstract": "Semi-supervised learning has recently emerged as a new paradigm in the machine learning community. It aims at exploiting simultaneously labeled and unlabeled data for classification. We introduce here a new semi-supervised algorithm. Its originality is that it relies on a discriminative approach to semi-supervised learning rather than a generative approach, as it is usually the case. We present in details this algorithm for a logistic classifier and show that it can be interpreted as an instance of the Classification Expectation Maximization algorithm. We also provide empirical results on two data sets for sentence classification tasks and analyze the behavior of our methods.",
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "authors": [
                {
                    "authorId": "144444438",
                    "name": "Massih-Reza Amini"
                },
                {
                    "authorId": "1741426",
                    "name": "P. Gallinari"
                }
            ]
        },
        {
            "paperId": "cd7bdd56d286656687c04191016a0bf3caa440cf",
            "title": "Self supervised learning for automatic text summarization by text span extraction",
            "abstract": "We describe a system for automatic text summarization that operates by extracting the most relevant sentences from documents with regard to a query. The lack of labeled corpora makes it difficult to develop automatic techniques for summarization. We propose to use a self-supervised method which does not rely on the availability of labeled corpora for learning to rank sentences for the summary. The method operates in two steps: first a statistical similarity based system which does not require any training is developed, second a classifier is trained using self-supervised learning in order to improve this baseline method. This idea is evaluated on the Reuters news-wire corpus and compared to other strategies.",
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "authors": [
                {
                    "authorId": "144444438",
                    "name": "Massih-Reza Amini"
                },
                {
                    "authorId": "1741426",
                    "name": "P. Gallinari"
                }
            ]
        },
        {
            "paperId": "32f7da55fe2d1e672840b6d29df1d5457d5fb539",
            "title": "Learning for Sequence Extraction Tasks",
            "abstract": "We consider the application of machine learning techniques for sequence modeling to Information Retrieval (IR) and surface Information Extraction (IE) tasks. We introduce a generic sequence model and show how it can be used for dealing with different closed-query tasks. Taking into account the sequential nature of texts allows for a liner analysis than what is usually done in IR with static text representations. The task we are focusing on is the retrieval and labeling of texts passages, also known as highlighting and surface information extraction. We describe different implementations of our model based on Hidden Markov Models and Neural Networks. Experiments are performed using the MUC6 corpus from the information extraction community.",
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "authors": [
                {
                    "authorId": "144444438",
                    "name": "Massih-Reza Amini"
                },
                {
                    "authorId": "2833561",
                    "name": "H. Zaragoza"
                },
                {
                    "authorId": "1741426",
                    "name": "P. Gallinari"
                }
            ]
        },
        {
            "paperId": "3bd032fbec8175257567bde39a40e06d4b8e82bc",
            "title": "Interactive Learning for Text Summarization",
            "abstract": "This paper describes a query-relevant text summary system based on interactive learning. The system proceeds in two steps, it first extracts the most relevant sentences of a document with regard to a user query using a classical tf-idf term weighting scheme, it then learns the user feedback in order to improve its performances. Learning operates at two levels: query expansion and sentence scoring.",
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "authors": [
                {
                    "authorId": "144444438",
                    "name": "Massih-Reza Amini"
                }
            ]
        },
        {
            "paperId": "1dd30cbeab4f26e6fe66b9084e48e4325d48ee40",
            "title": "Sequence Models for Automatic Highlighting and Surface Information Extraction",
            "abstract": "With the increase of textual information available electronically, we assist to a great diversification of the demands on Information Retrieval (IR) and Information Extraction (IE) systems. In this paper we apply Machine Learning techniques of sequence analysis to the tasks of highlighting and labeling text with respect to an information extraction task. Specifically, dynamic probability models are used. Like IR systems, they use little semantics, are fully trainable and do not require any knowledge representation of the domain. Unlike IR approaches, documents are considered as a dynamic sequence of words. Furthermore, additional word information is naturally included in the representation. Models are evaluated on a sub-task of the MUC6 Scenario Template corpus. When morpho-syntactic word information is introduced into the representation, an increase in performances is observed.",
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "authors": [
                {
                    "authorId": "144444438",
                    "name": "Massih-Reza Amini"
                },
                {
                    "authorId": "2833561",
                    "name": "H. Zaragoza"
                },
                {
                    "authorId": "1741426",
                    "name": "P. Gallinari"
                }
            ]
        },
        {
            "paperId": "f590afbc263ecd1dc6278706292898b291a00e73",
            "title": "A new dynamic probability model from complex IR tasks",
            "abstract": "With the rapid increase of textual information available electronically, there is an acute need for automatic textual analysis tools. Two communities have dealt with the problem of automatic textual analysis: information retrieval (IR), and information extraction (IE). Information retrieval has been very successful at the \u201cdocument level\u201d: locating, categorizing and filtering entire documents from large corpus, etc. Unfortunately, it is very difficult to extend the information retrieval paradigm so as to realize more complex tasks such as topic segmentation, summarization, template information extraction, etc. Information extraction has been relatively successful at the \u201cword level\u201d: extracting meaningful terms, finding their relationships, extracting information patterns, abstracting, etc. Unfortunately, information extraction techniques require the use of extensive domain-dependant knowledge and are, for this reason, difficult to apply. In the last decade, artificial intelligence, and in particular machine learning (ML), have been applied to both IR and IE. For the most part, ML techniques have been used to estimate or parameterize certain functions within the standard IR or IE paradigms. This leads often to an increase of performances and portability, but without a substantial change of the underlying model, the full potential of ML cannot be exploited. Our research concentrates on the application of ML techniques with the objective of extending the capabilities of IR models and in particular extending the range and complexity of the tasks that can be handled. (1 page)",
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "authors": [
                {
                    "authorId": "2833561",
                    "name": "H. Zaragoza"
                },
                {
                    "authorId": "144444438",
                    "name": "Massih-Reza Amini"
                },
                {
                    "authorId": "1741426",
                    "name": "P. Gallinari"
                }
            ]
        },
        {
            "paperId": "fb146a4b4fd461caf466524516d6e25cd274f8d0",
            "title": "Stochastic models for surface information extraction in texts",
            "abstract": "We describe the application of numerical machine learning techniques to the extraction of information from a collection of textual data. More precisely, we consider the modeling of text sequences with hidden Markov models and multilayer perceptrons and show how these models can be used to perform specific surface extraction tasks (i.e. tasks which do not need in depth syntactic or semantic analysis). We consider different text representations using semantic and syntactic knowledge and analyze the influence of different grammatical constraints on the models using the MUC-6 corpus.",
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "authors": [
                {
                    "authorId": "144444438",
                    "name": "Massih-Reza Amini"
                },
                {
                    "authorId": "2833561",
                    "name": "H. Zaragoza"
                },
                {
                    "authorId": "1741426",
                    "name": "P. Gallinari"
                }
            ]
        }
    ]
}