{
    "authorId": "3091414",
    "papers": [
        {
            "paperId": "7adfef23d7fe79122a7ef052bd5be343cfc3f29e",
            "title": "Automated, Reliable, and Efficient Continental-Scale Replication of 7.3 Petabytes of Climate Simulation Data: A Case Study",
            "abstract": "We report on our experiences replicating 7.3 petabytes (PB) of Earth System Grid Federation (ESGF) climate simulation data from Lawrence Livermore National Laboratory (LLNL) in California to Argonne National Laboratory (ANL) in Illinois and Oak Ridge National Laboratory (ORNL) in Tennessee. This movement of some 29 million files, twice, undertaken in order to establish new ESGF nodes at ANL and ORNL, was performed largely automatically by a simple replication tool, a script that invoked Globus to transfer large bundles of files while tracking progress in a database. Under the covers, Globus organized transfers to make efficient use of the high-speed Energy Sciences network (ESnet) and the data transfer nodes deployed at participating sites, and also addressed security, integrity checking, and recovery from a variety of transient failures. This success demonstrates the considerable benefits that can accrue from the adoption of performant data replication infrastructure.",
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "authors": [
                {
                    "authorId": "3035939",
                    "name": "Lukasz Lacinski"
                },
                {
                    "authorId": "2299517204",
                    "name": "Liming Lee"
                },
                {
                    "authorId": "2298968830",
                    "name": "Steven Turoscy"
                },
                {
                    "authorId": "2298967946",
                    "name": "Cameron Harr"
                },
                {
                    "authorId": "3091414",
                    "name": "K. Chard"
                },
                {
                    "authorId": "2298967076",
                    "name": "Eli Dart"
                },
                {
                    "authorId": "2250448470",
                    "name": "Paul Durack"
                },
                {
                    "authorId": "2298968705",
                    "name": "Sasha Ames"
                },
                {
                    "authorId": "2298968165",
                    "name": "Forrest M. Hoffman"
                },
                {
                    "authorId": "2270007050",
                    "name": "Ian T. Foster"
                }
            ]
        },
        {
            "paperId": "d24f874c1d58ca42a9117c2896e878f184407672",
            "title": "Steering a Fleet: Adaptation for Large-Scale, Workflow-Based Experiments",
            "abstract": "Experimental science is increasingly driven by instruments that produce vast volumes of data and thus a need to manage, compute, describe, and index this data. High performance and distributed computing provide the means of addressing the computing needs; however, in practice, the variety of actions required and the distributed set of resources involved, requires sophisticated\"flows\"defining the steps to be performed on data. As each scan or measurement is performed by an instrument, a new instance of the flow is initiated resulting in a\"fleet\"of concurrently running flows, with the overall goal to process all the data collected during a potentially long-running experiment. During the course of the experiment, each flow may need to adapt its execution due to changes in the environment, such as computational or storage resource availability, or based on the progress of the fleet as a whole such as completion or discovery of an intermediate result leading to a change in subsequent flow's behavior. We introduce a cloud-based decision engine, Braid, which flows consult during execution to query their run-time environment and coordinate with other flows within their fleet. Braid accepts streams of measurements taken from the run-time environment or from within flow runs which can then be statistically aggregated and compared to other streams to determine a strategy to guide flow execution. For example, queue lengths in execution environments can be used to direct a flow to run computations in one environment or another, or experiment progress as measured by individual flows can be aggregated to determine the progress and subsequent direction of the flows within a fleet. We describe Braid, its interface, implementation and performance characteristics. We further show through examples and experience modifying an existing scientific flow how Braid is used to make adaptable flows.",
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "authors": [
                {
                    "authorId": "3264638",
                    "name": "J. Pruyne"
                },
                {
                    "authorId": "2308097253",
                    "name": "Val\u00e9rie Hayot-Sasson"
                },
                {
                    "authorId": "2290980475",
                    "name": "Weijian Zheng"
                },
                {
                    "authorId": "36319017",
                    "name": "Ryan Chard"
                },
                {
                    "authorId": "8962431",
                    "name": "J. Wozniak"
                },
                {
                    "authorId": "2323588",
                    "name": "Tekin Bicer"
                },
                {
                    "authorId": "3091414",
                    "name": "K. Chard"
                },
                {
                    "authorId": "2270007050",
                    "name": "Ian T. Foster"
                }
            ]
        },
        {
            "paperId": "f5c2d5b77f80eb4e7ca4965ba438d289297c1370",
            "title": "Enabling Remote Management of FaaS Endpoints with Globus Compute Multi-User Endpoints",
            "abstract": "Globus Compute implements a hybrid Function as a Service (FaaS) model in which a single cloud-hosted service is used by users to manage execution of Python functions on user-owned and - managed Globus Compute endpoints deployed on arbitrary compute resources. Here we describe a new multi-user and multi-configuration Globus Compute endpoint. This system, which can be deployed by administrators in a privileged account, enables dynamic creation of user endpoints that are forked as new processes in user space. The multi-user endpoint is designed to provide the security interfaces necessary for deployment on large, shared",
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "authors": [
                {
                    "authorId": "2538180",
                    "name": "R. Ananthakrishnan"
                },
                {
                    "authorId": "2115014071",
                    "name": "Y. Babuji"
                },
                {
                    "authorId": "46202504",
                    "name": "Matt Baughman"
                },
                {
                    "authorId": "36210910",
                    "name": "Josh Bryan"
                },
                {
                    "authorId": "3091414",
                    "name": "K. Chard"
                },
                {
                    "authorId": "36319017",
                    "name": "Ryan Chard"
                },
                {
                    "authorId": "2312041894",
                    "name": "Ben Clifford"
                },
                {
                    "authorId": "2270007050",
                    "name": "Ian T. Foster"
                },
                {
                    "authorId": "2312044808",
                    "name": "Daniel S. Katz"
                },
                {
                    "authorId": "2224016256",
                    "name": "Kevin Hunter Kesling"
                },
                {
                    "authorId": "2312043801",
                    "name": "Chris Janidlo"
                },
                {
                    "authorId": "2312042216",
                    "name": "Reid Mello"
                },
                {
                    "authorId": "2312115146",
                    "name": "Lei Wang"
                }
            ]
        },
        {
            "paperId": "0c58e94bee6939be0a1dfb4c25070c8b47856491",
            "title": "Globus Timers: Scheduling Periodic Data Management Actions on Distributed Research Infrastructure",
            "abstract": "The increasing complexity and scale of scientific problems presents new challenges to manage, analyze, and manipulate large volumes of data. Automation is critical to reducing the time spent on mundane and error-prone tasks, such as backing up data, purging old records, and even performing routine analysis. Globus provides a broad range of research automation services to empower users to outsource and automate data-oriented tasks, such as transfer, publication, and analysis. Here we present the newest addition to the Globus platform, the Globus Timers service. Timers is a cron-like service designed to simplify scheduling repeated actions. It leverages the Globus Auth service to engage securely any service exposing a compatible interface. Since its release in late 2021, Timers has been used by over 1300 users to perform more than 2.2 million tasks. We explain how Timers can be used, describe its implementation, and discuss its adoption.",
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "authors": [
                {
                    "authorId": "2538180",
                    "name": "R. Ananthakrishnan"
                },
                {
                    "authorId": "36210910",
                    "name": "Josh Bryan"
                },
                {
                    "authorId": "2182292559",
                    "name": "Kurt McKee"
                },
                {
                    "authorId": "2224607958",
                    "name": "Ada Nikolaidis"
                },
                {
                    "authorId": "3264638",
                    "name": "J. Pruyne"
                },
                {
                    "authorId": "2057787964",
                    "name": "Stephen Rosen"
                },
                {
                    "authorId": "2065944820",
                    "name": "I. Foster"
                },
                {
                    "authorId": "3091414",
                    "name": "K. Chard"
                },
                {
                    "authorId": "36319017",
                    "name": "Ryan Chard"
                },
                {
                    "authorId": "2224607397",
                    "name": "Kurt Mc-Kee"
                },
                {
                    "authorId": "2224607429",
                    "name": "GlobusTimers"
                }
            ]
        },
        {
            "paperId": "14111fe135232e0e935a1352d0895a66fdb7303d",
            "title": "The Changing Role of RSEs over the Lifetime of Parsl",
            "abstract": "This position paper describes the Parsl open source research software project and its various phases over seven years. It defines four types of research software engineers (RSEs) who have been important to the project in those phases; we believe this is also applicable to other research software projects.",
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "authors": [
                {
                    "authorId": "2059296354",
                    "name": "Daniel S. Katz"
                },
                {
                    "authorId": "2720709",
                    "name": "Ben Clifford"
                },
                {
                    "authorId": "2115014071",
                    "name": "Y. Babuji"
                },
                {
                    "authorId": "2224016256",
                    "name": "Kevin Hunter Kesling"
                },
                {
                    "authorId": "153642873",
                    "name": "A. Woodard"
                },
                {
                    "authorId": "3091414",
                    "name": "K. Chard"
                }
            ]
        },
        {
            "paperId": "17d2696c60b1df14354d7914595a6401aa2edea1",
            "title": "Lazy Python Dependency Management in Large-Scale Systems",
            "abstract": "Python has become the language of choice for managing many scientific applications. However, when distributing a Python application, it is necessary that all application dependencies be distributed and available in the target execution environment. A specific consequence is that Python workflows suffer from slow scale out due to the time required to import dependencies. We describe ProxyImports, a method to package and distribute Python dependencies in a lazy fashion while remaining transparent and easy to use. Using ProxyImports, Python packages are loaded only once (e.g., by a workflow head node) and are transferred asynchronously to compute nodes. We evaluate our implementation on the Perlmutter and Theta supercomputers and in an HPC cloud-bursting scenario. Our experiments show that ProxyImports significantly reduces the average time to import large modules across an HPC system and demonstrate that this method can be used easily to distribute user-packages to cloud resources. We conclude that ProxyImports improves application runtime, reduces contention on metadata servers and facilitates runtime portability of Python applications.",
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "authors": [
                {
                    "authorId": "2044357637",
                    "name": "Alok V. Kamatar"
                },
                {
                    "authorId": "2239104574",
                    "name": "Mansi Sakarvadia"
                },
                {
                    "authorId": "2308097253",
                    "name": "Val\u00e9rie Hayot-Sasson"
                },
                {
                    "authorId": "3091414",
                    "name": "K. Chard"
                },
                {
                    "authorId": "1698701",
                    "name": "Ian T Foster"
                }
            ]
        },
        {
            "paperId": "306a312c0bae22f30a406187ab18c5724cefb661",
            "title": "Memory Injections: Correcting Multi-Hop Reasoning Failures During Inference in Transformer-Based Language Models",
            "abstract": "Answering multi-hop reasoning questions requires retrieving and synthesizing information from diverse sources. Large Language Models (LLMs) struggle to perform such reasoning consistently. Here we propose an approach to pinpoint and rectify multi-hop reasoning failures through targeted memory injections on LLM attention heads. First, we analyze the per-layer activations of GPT-2 models in response to single and multi-hop prompts. We then propose a mechanism that allows users to inject pertinent prompt-specific information, which we refer to as \u201cmemories,\u201d at critical LLM locations during inference. By thus enabling the LLM to incorporate additional relevant information during inference, we enhance the quality of multi-hop prompt completions. We show empirically that a simple, efficient, and targeted memory injection into a key attention layer can often increase the probability of the desired next token in multi-hop tasks, by up to 424%.",
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "authors": [
                {
                    "authorId": "2239104574",
                    "name": "Mansi Sakarvadia"
                },
                {
                    "authorId": "144373088",
                    "name": "Aswathy Ajith"
                },
                {
                    "authorId": "2239168709",
                    "name": "Arham Khan"
                },
                {
                    "authorId": "2239102028",
                    "name": "Daniel Grzenda"
                },
                {
                    "authorId": "48808283",
                    "name": "Nathaniel Hudson"
                },
                {
                    "authorId": "2239105163",
                    "name": "Andr\u00e9 Bauer"
                },
                {
                    "authorId": "3091414",
                    "name": "K. Chard"
                },
                {
                    "authorId": "1698701",
                    "name": "Ian T Foster"
                }
            ]
        },
        {
            "paperId": "453d85311169486ad77980db3466677f2b627b9e",
            "title": "Tournament-Based Pretraining to Accelerate Federated Learning",
            "abstract": "Advances in hardware, proliferation of compute at the edge, and data creation at unprecedented scales have made federated learning (FL) necessary for the next leap forward in pervasive machine learning. For privacy and network reasons, large volumes of data remain stranded on endpoints located in geographically austere (or at least austere network-wise) locations. However, challenges exist to the effective use of these data. To solve the system and functional level challenges, we present an three novel variants of a serverless federated learning framework. We also present tournament-based pretraining, which we demonstrate significantly improves model performance in some experiments. Overall, these extensions to FL and our novel training method enable greater focus on science rather than ML development.",
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "authors": [
                {
                    "authorId": "46202504",
                    "name": "Matt Baughman"
                },
                {
                    "authorId": "48808283",
                    "name": "Nathaniel Hudson"
                },
                {
                    "authorId": "36319017",
                    "name": "Ryan Chard"
                },
                {
                    "authorId": "2239105163",
                    "name": "Andr\u00e9 Bauer"
                },
                {
                    "authorId": "2065944820",
                    "name": "I. Foster"
                },
                {
                    "authorId": "3091414",
                    "name": "K. Chard"
                }
            ]
        },
        {
            "paperId": "616ce32cd7f4aa2716caa42c238ef79f1d1ec53b",
            "title": "PSI/J: A Portable Interface for Submitting, Monitoring, and Managing Jobs",
            "abstract": "It is generally desirable for high-performance computing (HPC) applications to be portable between HPC systems, for example to make use of more performant hardware, make effective use of allocations, and to co-locate compute jobs with large datasets. Unfortunately, moving scientific applications between HPC systems is challenging for various reasons, most notably that HPC systems have different HPC schedulers. We introduce PSI/J, a job management abstraction API intended to simplify the construction of software components and applications that are portable over various HPC scheduler implementations. We argue that such a system is both necessary and that no viable alternative currently exists. We analyze similar notable APIs and attempt to determine the factors that influenced their evolution and adoption by the HPC community. We base the design of PSI/J on that analysis. We describe how PSI/J has been integrated in three workflow systems and one application, and also show via experiments that PSI/J imposes minimal overhead.",
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "authors": [
                {
                    "authorId": "2223589627",
                    "name": "Mihael Hategan-Marandiuc"
                },
                {
                    "authorId": "1678982",
                    "name": "Andr\u00e9 Merzky"
                },
                {
                    "authorId": "31845239",
                    "name": "Nicholson T. Collier"
                },
                {
                    "authorId": "145341601",
                    "name": "K. Maheshwari"
                },
                {
                    "authorId": "51299130",
                    "name": "J. Ozik"
                },
                {
                    "authorId": "1840916",
                    "name": "M. Turilli"
                },
                {
                    "authorId": "47832521",
                    "name": "Andreas Wilke"
                },
                {
                    "authorId": "8962431",
                    "name": "J. Wozniak"
                },
                {
                    "authorId": "3091414",
                    "name": "K. Chard"
                },
                {
                    "authorId": "2065944820",
                    "name": "I. Foster"
                },
                {
                    "authorId": "2140039842",
                    "name": "Rafael Ferreira da Silva"
                },
                {
                    "authorId": "1693678",
                    "name": "S. Jha"
                },
                {
                    "authorId": "33947553",
                    "name": "D. Laney"
                }
            ]
        },
        {
            "paperId": "640bbcb60145dad6ef36817e01c3fcfcf332f9e8",
            "title": "Accelerating Communications in Federated Applications with Transparent Object Proxies",
            "abstract": "Advances in networks, accelerators, and cloud services encourage programmers to reconsider where to compute-such as when fast networks make it cost-effective to compute on remote accelerators despite added latency. Workflow and cloud-hosted serverless computing frameworks can manage multi-step computations spanning federated collections of cloud, high-performance computing (HPC), and edge systems, but passing data among computational steps via cloud storage can incur high costs. Here, we overcome this obstacle with a new programming paradigm that decouples control flow from data flow by extending the pass-by-reference model to distributed applications. We describe ProxyStore, a system that implements this paradigm by providing object proxies that act as wide-area object references with just-in-time resolution. This proxy model enables data producers to communicate data unilaterally, transparently, and efficiently to both local and remote consumers. We demonstrate the benefits of this model with synthetic bench-marks and real-world scientific applications, running across various computing platforms.",
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "authors": [
                {
                    "authorId": "51916788",
                    "name": "J. G. Pauloski"
                },
                {
                    "authorId": "2308097253",
                    "name": "Val\u00e9rie Hayot-Sasson"
                },
                {
                    "authorId": "47766095",
                    "name": "Logan T. Ward"
                },
                {
                    "authorId": "48808283",
                    "name": "Nathaniel Hudson"
                },
                {
                    "authorId": "2217345175",
                    "name": "Charlie Sabino"
                },
                {
                    "authorId": "46202504",
                    "name": "Matt Baughman"
                },
                {
                    "authorId": "3091414",
                    "name": "K. Chard"
                },
                {
                    "authorId": "2065944820",
                    "name": "I. Foster"
                }
            ]
        }
    ]
}