{
    "authorId": "2119322767",
    "papers": [
        {
            "paperId": "09e06c155aaa0bbf1efd562b1dd85b32e39604b3",
            "title": "Affinity Uncertainty-Based Hard Negative Mining in Graph Contrastive Learning",
            "abstract": "Hard negative mining has shown effective in enhancing self-supervised contrastive learning (CL) on diverse data types, including graph CL (GCL). The existing hardness-aware CL methods typically treat negative instances that are most similar to the anchor instance as hard negatives, which helps improve the CL performance, especially on image data. However, this approach often fails to identify the hard negatives but leads to many false negatives on graph data. This is mainly due to that the learned graph representations are not sufficiently discriminative due to oversmooth representations and/or non-independent and identically distributed (non-i.i.d.) issues in graph data. To tackle this problem, this article proposes a novel approach that builds a discriminative model on collective affinity information (i.e., two sets of pairwise affinities between the negative instances and the anchor instance) to mine hard negatives in GCL. In particular, the proposed approach evaluates how confident/uncertain the discriminative model is about the affinity of each negative instance to an anchor instance to determine its hardness weight relative to the anchor instance. This uncertainty information is then incorporated into the existing GCL loss functions via a weighting term to enhance their performance. The enhanced GCL is theoretically grounded that the resulting GCL loss is equivalent to a triplet loss with an adaptive margin being exponentially proportional to the learned uncertainty of each negative instance. Extensive experiments on ten graph datasets show that our approach does the following: 1) consistently enhances different state-of-the-art (SOTA) GCL methods in both graph and node classification tasks and 2) significantly improves their robustness against adversarial attacks. Code is available at https://github.com/mala-lab/AUGCL.",
            "fieldsOfStudy": [
                "Medicine",
                "Computer Science"
            ],
            "authors": [
                {
                    "authorId": "79690137",
                    "name": "Chaoxi Niu"
                },
                {
                    "authorId": "3224619",
                    "name": "Guansong Pang"
                },
                {
                    "authorId": "2119322767",
                    "name": "Ling Chen"
                }
            ]
        },
        {
            "paperId": "100abe32337a9ffbd629a9aa81bc600d5e8ed169",
            "title": "Information Bottleneck Revisited: Posterior Probability Perspective with Optimal Transport",
            "abstract": "Information bottleneck (IB) is a paradigm to extract information in one target random variable from another relevant random variable, which has aroused great interest due to its potential to explain deep neural networks in terms of information compression and prediction. Despite its great importance, finding the optimal bottleneck variable involves a difficult nonconvex optimization problem due to the nonconvexity of mutual information constraint. The Blahut-Arimoto algorithm and its variants provide an approach by considering its Lagrangian with fixed Lagrange multiplier. However, only the strictly concave IB curve can be fully obtained by the BA algorithm, which strongly limits its application in machine learning and related fields, as strict concavity cannot be guaranteed in those problems. To overcome the above difficulty, we derive an entropy regularized optimal transport (OT) model for IB problem from a posterior probability perspective. Correspondingly, we use the alternating optimization procedure and generalize the Sinkhorn algorithm to solve the above OT model. The effectiveness and efficiency of our approach are demonstrated via numerical experiments.",
            "fieldsOfStudy": [
                "Computer Science",
                "Mathematics"
            ],
            "authors": [
                {
                    "authorId": "2119322767",
                    "name": "Ling Chen"
                },
                {
                    "authorId": "2181671622",
                    "name": "Shitong Wu"
                },
                {
                    "authorId": "2147205227",
                    "name": "Wen-Long Ye"
                },
                {
                    "authorId": "2180595552",
                    "name": "Huihui Wu"
                },
                {
                    "authorId": "2119799056",
                    "name": "Hao Wu"
                },
                {
                    "authorId": "2108348622",
                    "name": "Wen-Ying Zhang"
                },
                {
                    "authorId": "2064457585",
                    "name": "Bo Bai"
                },
                {
                    "authorId": "2108940335",
                    "name": "Yining Sun"
                }
            ]
        },
        {
            "paperId": "18240c1d699a1717de28a9804908123dc93717a2",
            "title": "Global-correlated 3D-decoupling Transformer for Clothed Avatar Reconstruction",
            "abstract": "Reconstructing 3D clothed human avatars from single images is a challenging task, especially when encountering complex poses and loose clothing. Current methods exhibit limitations in performance, largely attributable to their dependence on insufficient 2D image features and inconsistent query methods. Owing to this, we present the Global-correlated 3D-decoupling Transformer for clothed Avatar reconstruction (GTA), a novel transformer-based architecture that reconstructs clothed human avatars from monocular images. Our approach leverages transformer architectures by utilizing a Vision Transformer model as an encoder for capturing global-correlated image features. Subsequently, our innovative 3D-decoupling decoder employs cross-attention to decouple tri-plane features, using learnable embeddings as queries for cross-plane generation. To effectively enhance feature fusion with the tri-plane 3D feature and human body prior, we propose a hybrid prior fusion strategy combining spatial and prior-enhanced queries, leveraging the benefits of spatial localization and human body prior knowledge. Comprehensive experiments on CAPE and THuman2.0 datasets illustrate that our method outperforms state-of-the-art approaches in both geometry and texture reconstruction, exhibiting high robustness to challenging poses and loose clothing, and producing higher-resolution textures. Codes will be available at https://github.com/River-Zhang/GTA.",
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "authors": [
                {
                    "authorId": "2155279914",
                    "name": "Zechuan Zhang"
                },
                {
                    "authorId": "2110967045",
                    "name": "Li Sun"
                },
                {
                    "authorId": "15556978",
                    "name": "Zongxin Yang"
                },
                {
                    "authorId": "2119322767",
                    "name": "Ling Chen"
                },
                {
                    "authorId": "1698559",
                    "name": "Yi Yang"
                }
            ]
        },
        {
            "paperId": "1a62a62a4d6bdbe2e1d5ae2c66165c691975b8e8",
            "title": "Adversary for Social Good: Leveraging Adversarial Attacks to Protect Personal Attribute Privacy",
            "abstract": "Social media has drastically reshaped the world that allows billions of people to engage in such interactive environments to conveniently create and share content with the public. Among them, text data (e.g., tweets, blogs) maintains the basic yet important social activities and generates a rich source of user-oriented information. While those explicit sensitive user data like credentials have been significantly protected by all means, personal private attribute (e.g., age, gender, location) disclosure due to inference attacks is somehow challenging to avoid, especially when powerful natural language processing (NLP) techniques have been effectively deployed to automate attribute inferences from implicit text data. This puts users\u2019 attribute privacy at risk. To address this challenge, in this article, we leverage the inherent vulnerability of machine learning to adversarial attacks, and design a novel text-space Adversarial attack for Social Good, called Adv4SG. In other words, we cast the problem of protecting personal attribute privacy as an adversarial attack formulation problem over the social media text data to defend against NLP-based attribute inference attacks. More specifically, Adv4SG proceeds with a sequence of word perturbations under given constraints such that the probed attribute cannot be identified correctly. Different from the prior works, we advance Adv4SG by considering social media property, and introducing cost-effective mechanisms to expedite attribute obfuscation over text data under the black-box setting. Extensive experiments on real-world social media datasets have demonstrated that our method can effectively degrade the inference accuracy with less computational cost over different attribute settings, which substantially helps mitigate the impacts of inference attacks and thus achieve high performance in user attribute privacy protection.",
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "authors": [
                {
                    "authorId": "2145458559",
                    "name": "Xiaoting Li"
                },
                {
                    "authorId": "2119322767",
                    "name": "Ling Chen"
                },
                {
                    "authorId": "9180687",
                    "name": "Dinghao Wu"
                }
            ]
        },
        {
            "paperId": "244174b3898805fd0367266e9da060ef73a2b8ae",
            "title": "Disentangled Pre-training for Image Matting",
            "abstract": "Image matting requires high-quality pixel-level human annotations to support the training of a deep model in recent literature. Whereas such annotation is costly and hard to scale, significantly holding back the development of the research. In this work, we make the first attempt towards addressing this problem, by proposing a self-supervised pretraining approach that can leverage infinite numbers of data to boost the matting performance. The pre-training task is designed in a similar manner as image matting, where random trimap and alpha matte are generated to achieve an image disentanglement objective. The pre-trained model is then used as an initialisation of the downstream matting task for fine-tuning. Extensive experimental evaluations show that the proposed approach outperforms both the state-of-the-art matting methods and other alternative self-supervised initialisation approaches by a large margin. We also show the robustness of the proposed approach over different backbone architectures. Our project page is available at https://crystraldo.github.io/dpt_mat/.",
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "authors": [
                {
                    "authorId": "2110427126",
                    "name": "Yan-Da Li"
                },
                {
                    "authorId": "3462332",
                    "name": "Zilong Huang"
                },
                {
                    "authorId": "2116565951",
                    "name": "Gang Yu"
                },
                {
                    "authorId": "2119322767",
                    "name": "Ling Chen"
                },
                {
                    "authorId": "49020088",
                    "name": "Yunchao Wei"
                },
                {
                    "authorId": "2840852",
                    "name": "Jianbo Jiao"
                }
            ]
        },
        {
            "paperId": "32ce289c3f844ca937902d8ead240144aa0f0f48",
            "title": "GTRL: An Entity Group-Aware Temporal Knowledge Graph Representation Learning Method",
            "abstract": "Temporal Knowledge Graph (TKG) representation learning embeds entities and event types into a continuous low-dimensional vector space by integrating the temporal information, which is essential for downstream tasks, e.g., event prediction and question answering. Existing methods stack multiple graph convolution layers to model the influence of distant entities, leading to the over-smoothing problem. To alleviate the problem, recent studies infuse reinforcement learning to obtain paths that contribute to modeling the influence of distant entities. However, due to the limited number of hops, these studies fail to capture the correlation between entities that are far apart and even unreachable. To this end, we propose GTRL, an entity Group-aware Temporal knowledge graph Representation Learning method. GTRL is the first work that incorporates the entity group modeling to capture the correlation between entities by stacking only a finite number of layers. Specifically, the entity group mapper is proposed to generate entity groups from entities in a learning way. Based on entity groups, the implicit correlation encoder is introduced to capture implicit correlations between any pairwise entity groups. In addition, the hierarchical GCNs are exploited to accomplish the message aggregation and representation updating on the entity group graph and the entity graph. Finally, GRUs are employed to capture the temporal dependency in TKGs. Extensive experiments on six real-world datasets demonstrate that GTRL achieves the state-of-the-art performances on the event prediction task, outperforming the best baseline by an average of 7.35%, 6.09%, 8.31%, and 11.21% in MRR, Hits@1, Hits@3, and Hits@10, respectively.",
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "authors": [
                {
                    "authorId": "2109889052",
                    "name": "Xing Tang"
                },
                {
                    "authorId": "2119322767",
                    "name": "Ling Chen"
                }
            ]
        },
        {
            "paperId": "4a76db5fee05bdaeb46f14dffb61234f2244abdd",
            "title": "EasyHeC: Accurate and Automatic Hand-Eye Calibration Via Differentiable Rendering and Space Exploration",
            "abstract": "Hand-eye calibration is a critical task in robotics, as it directly affects the efficacy of critical operations such as manipulation and grasping. Traditional methods for achieving this objective necessitate the careful design of joint poses and the use of specialized calibration markers, while most recent learning-based approaches using solely pose regression are limited in their abilities to diagnose inaccuracies. In this work, we introduce a new approach to hand-eye calibration called EasyHeC, which is markerless, white-box, and delivers superior accuracy and robustness. We propose to use two key technologies: differentiable rendering-based camera pose optimization and consistency-based joint space exploration, which enables accurate end-to-end optimization of the calibration process and eliminates the need for the laborious manual design of robot joint poses. Our evaluation demonstrates superior performance in synthetic and real-world datasets, enhancing downstream manipulation tasks by providing precise camera poses for locating and interacting with objects.",
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "authors": [
                {
                    "authorId": "2119322767",
                    "name": "Ling Chen"
                },
                {
                    "authorId": "12701031",
                    "name": "Yuzhe Qin"
                },
                {
                    "authorId": "145453113",
                    "name": "Xiaowei Zhou"
                },
                {
                    "authorId": "2087042750",
                    "name": "Hao Su"
                }
            ]
        },
        {
            "paperId": "70ec04a269e2b72536dda8da1cd7cac71545d384",
            "title": "Are Your Explanations Reliable? Investigating the Stability of LIME in Explaining Textual Classification Models via Adversarial Perturbation",
            "abstract": "Local Surrogate models have increased in popularity for use in explaining complex black-box models for diverse types of data, including text, tabular, and image. One particular algo-rithm, LIME, continues to see use within the \ufb01eld of machine learning due to its inherently interpretable explanations and model-agnostic behavior. But despite continued use, questions about the stability of LIME persist. Stability, a property where similar instances result in similar explanations, has been shown to be lacking in explanations generated for tabular and image data, both of which are continuous domains. Here we explore the stability of LIME\u2019s explanations generated on textual data and con\ufb01rm the trend of instability shown in previous research for other data types.",
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "authors": [
                {
                    "authorId": "2218044799",
                    "name": "Christopher Burger"
                },
                {
                    "authorId": "2119322767",
                    "name": "Ling Chen"
                },
                {
                    "authorId": "145535348",
                    "name": "Thai Le"
                }
            ]
        },
        {
            "paperId": "85595e61986a7bcadc4e5aa99cafbedcc6c58b2c",
            "title": "A Review for Weighted MinHash Algorithms (Extended abstract)",
            "abstract": "Data similarity computation is a fundamental research topic which underpins many high-level applications based on similarity measures. However, the exact similarity computation has become daunting in large-scale real-world scenarios. Currently, MinHash is a popular technique for efficiently estimating the Jaccard similarity of binary sets and, furthermore, weighted MinHash is utilized to estimate the generalized Jaccard similarity of weighted sets. This review focuses on categorizing and discussing the existing works of weighted MinHash algorithms. Also, we have developed a Python toolbox for the algorithms, and released it in our github.",
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "authors": [
                {
                    "authorId": "2118256000",
                    "name": "Wei Wu"
                },
                {
                    "authorId": "2156072846",
                    "name": "Bin Li"
                },
                {
                    "authorId": "2119322767",
                    "name": "Ling Chen"
                },
                {
                    "authorId": "32278515",
                    "name": "Junbin Gao"
                },
                {
                    "authorId": "2200137408",
                    "name": "Chengqi Zhang"
                }
            ]
        },
        {
            "paperId": "951a6a4ac3591cc01e44e9b6271299de53fb9286",
            "title": "Knowledge Distillation on Cross-Modal Adversarial Reprogramming for Data-Limited Attribute Inference",
            "abstract": "Social media generates a rich source of text data with intrinsic user attributes (e.g., age, gender), where different parties benefit from disclosing them. Attribute inference can be cast as a text classification problem, which, however, suffers from labeled data scarcity. To address this challenge, we propose a data-limited learning model to distill knowledge on adversarial reprogramming of a visual transformer (ViT) for attribute inferences. Not only does this novel cross-modal model transfers the powerful learning capability from ViT, but also leverages unlabeled texts to reduce the demand on labeled data. Experiments on social media datasets demonstrate the state-of-the-art performance of our model on data-limited attribute inferences.",
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "authors": [
                {
                    "authorId": "2108647654",
                    "name": "Quan Li"
                },
                {
                    "authorId": "2119322767",
                    "name": "Ling Chen"
                },
                {
                    "authorId": "2142081358",
                    "name": "Shixiong Jing"
                },
                {
                    "authorId": "9180687",
                    "name": "Dinghao Wu"
                }
            ]
        }
    ]
}