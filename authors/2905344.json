{
    "authorId": "2905344",
    "papers": [
        {
            "paperId": "04de4032f76bee34c19ed106f611df11b344c475",
            "title": "Local Search For SMT On Linear and Multi-linear Real Arithmetic",
            "abstract": "Satisfiability Modulo Theories (SMT) has significant application in various domains. In this paper, we focus on quantifier-free Satisfiablity Modulo Real Arithmetic, referred to as SMT(RA), including both linear and non-linear real arithmetic theories. As for non-linear real arithmetic theory, we focus on one of its important fragments where the atomic constraints are multi-linear. We propose the first local search algorithm for SMT(RA), called LocalSMT(RA), based on two novel ideas. First, an interval-based operator is proposed to cooperate with the traditional local search operator by considering the interval information. Moreover, we propose a tie-breaking mechanism to further evaluate the operations when the operations are indistinguishable according to the score function. Experiments are conducted to evaluate LocalSMT(RA) on benchmarks from SMT-LIB. The results show that LocalSMT(RA) is competitive with the state-of-the-art SMT solvers, and performs particularly well on multi-linear instances.",
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "authors": [
                {
                    "authorId": "2905344",
                    "name": "Bohan Li"
                },
                {
                    "authorId": "38598067",
                    "name": "Shaowei Cai"
                }
            ]
        },
        {
            "paperId": "0511e7de3ca3ae413d89b0981a66a7c5c5165d50",
            "title": "Knowledge Enhancement for Contrastive Multi-Behavior Recommendation",
            "abstract": "A well-designed recommender system can accurately capture the attributes of users and items, reflecting the unique preferences of individuals. Traditional recommendation techniques usually focus on modeling the singular type of behaviors between users and items. However, in many practical recommendation scenarios (e.g., social media, e-commerce), there exist multi-typed interactive behaviors in user-item relationships, such as click, tag-as-favorite, and purchase in online shopping platforms. Thus, how to make full use of multi-behavior information for recommendation is of great importance to the existing system, which presents challenges in two aspects that need to be explored: (1) Utilizing users' personalized preferences to capture multi-behavioral dependencies; (2) Dealing with the insufficient recommendation caused by sparse supervision signal for target behavior. In this work, we propose a Knowledge Enhancement Multi-Behavior Contrastive Learning Recommendation (KMCLR) framework, including two Contrastive Learning tasks and three functional modules to tackle the above challenges, respectively. In particular, we design the multi-behavior learning module to extract users' personalized behavior information for user-embedding enhancement, and utilize knowledge graph in the knowledge enhancement module to derive more robust knowledge-aware representations for items. In addition, in the optimization stage, we model the coarse-grained commonalities and the fine-grained differences between multi-behavior of users to further improve the recommendation effect. Extensive experiments and ablation tests on the three real-world datasets indicate our KMCLR outperforms various state-of-the-art recommendation methods and verify the effectiveness of our method.",
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "authors": [
                {
                    "authorId": "2200836056",
                    "name": "Hongrui Xuan"
                },
                {
                    "authorId": "2153629568",
                    "name": "Yi Liu"
                },
                {
                    "authorId": "2905344",
                    "name": "Bohan Li"
                },
                {
                    "authorId": "2416851",
                    "name": "Hongzhi Yin"
                }
            ]
        },
        {
            "paperId": "6c88d10910bad16b13890813205d6914f4ebd028",
            "title": "Self-Supervised Dynamic Hypergraph Recommendation based on Hyper-Relational Knowledge Graph",
            "abstract": "Knowledge graphs (KGs) are commonly used as side information to enhance collaborative signals and improve recommendation quality. In the context of knowledge-aware recommendation (KGR), graph neural networks (GNNs) have emerged as promising solutions for modeling factual and semantic information in KGs. However, the long-tail distribution of entities leads to sparsity in supervision signals, which weakens the quality of item representation when utilizing KG enhancement. Additionally, the binary relation representation of KGs simplifies hyper-relational facts, making it challenging to model complex real-world information. Furthermore, the over-smoothing phenomenon results in indistinguishable representations and information loss. To address these challenges, we propose the SDK (Self-Supervised Dynamic Hypergraph Recommendation based on Hyper-Relational Knowledge Graph) framework. This framework establishes a cross-view hypergraph self-supervised learning mechanism for KG enhancement. Specifically, we model hyper-relational facts in KGs to capture interdependencies between entities under complete semantic conditions. With the refined representation, a hypergraph is dynamically constructed to preserve features in the deep vector space, thereby alleviating the over-smoothing problem. Furthermore, we mine external supervision signals from both the global perspective of the hypergraph and the local perspective of collaborative filtering (CF) to guide the model prediction process. Extensive experiments conducted on different datasets demonstrate the superiority of the SDK framework over state-of-the-art models. The results showcase its ability to alleviate the effects of over-smoothing and supervision signal sparsity.",
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "authors": [
                {
                    "authorId": "2153629568",
                    "name": "Yi Liu"
                },
                {
                    "authorId": "2200836056",
                    "name": "Hongrui Xuan"
                },
                {
                    "authorId": "2905344",
                    "name": "Bohan Li"
                },
                {
                    "authorId": "50469060",
                    "name": "Mei Wang"
                },
                {
                    "authorId": "1490931831",
                    "name": "Tong Chen"
                },
                {
                    "authorId": "2416851",
                    "name": "Hongzhi Yin"
                }
            ]
        },
        {
            "paperId": "827d1a5fc6d174c83aff9bcee61852e0afbc0cab",
            "title": "Revisit Finetuning strategy for Few-Shot Learning to Transfer the Emdeddings",
            "abstract": "Few-Shot Learning (FSL) aims to learn a simple and effective bias on limited novel samples. Recently, many methods have been focused on re-training a randomly initialized linear classifier to adapt it to the novel features extracted by a pre-trained feature extractor (called Linear-Probing-based methods). These methods typically assumed the pre-trained feature extractor was robust enough, i.e., finetuning was not needed, and hence the pre-trained feature extractor does not be adapted to the novel samples. However, the unadapted pre-trained feature extractor distorts the features of novel samples because the robustness assumption may not hold, especially on the out-of-distribution samples. To extract the undistorted features, we designed Linear-Probing-Finetuning with Firth-Bias (LP-FT-FB) to yield an accurate bias on the limited samples for better finetuning the pre-trained feature extractor, providing stronger transferring ability. In LP-FT-FB, we further proposed inverse Firth Bias Reduction (i-FBR) to regularize the over-parameterized feature extractor on which FBR does not work well. The proposed i-FBR effectively alleviates the over-fitting problem of the feature extractor in the process of finetuning and helps extract undistorted novel features. To show the effectiveness of the designed LP-FT-FB, we conducted comprehensive experiments on the commonly used FSL datasets under different backbones for in-domain and cross-domain FSL tasks. The experimental results show that the proposed FT-LP-FB outperforms the SOTA FSL methods. The code is available at https://github.com/whzyf951620/ LinearProbingFinetuningFirthBias.",
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "authors": [
                {
                    "authorId": "120241560",
                    "name": "Heng Wang"
                },
                {
                    "authorId": "2138223198",
                    "name": "Tan Yue"
                },
                {
                    "authorId": "2114145529",
                    "name": "Xiang Ye"
                },
                {
                    "authorId": "51122630",
                    "name": "Zihang He"
                },
                {
                    "authorId": "2905344",
                    "name": "Bohan Li"
                },
                {
                    "authorId": "2154404076",
                    "name": "Yong Li"
                }
            ]
        },
        {
            "paperId": "d9d96001f2c9ac1498144f7e55e07ca93df8aa53",
            "title": "Learned Image Compression Guided Adaptive Quantization for Perceptual Quality",
            "abstract": "Neural network based image compression has made significant progress in recent years. The learned image codecs are commonly reported to outperform their conventional counterparts in perceptual quality. Despite the superior performance, the learned image codecs are much more complex to decode, which hinders their usage in practice. Without a significant advance in hardware capability, the conventional image codec will likely remain a primary component for large scale image services. It is therefore desirable to improve the quality of conventional image codecs. In this paper, we present an adaptive quantization approach to the conventional image codec with the help of learned image codecs to improve its perceptual quality. It exploits the bit allocation of the neural network based image codec to adapt the quantizers on a block basis. It is experimentally shown that the proposed method provides considerable perceptual quality improvements over other leading contenders.",
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "authors": [
                {
                    "authorId": "2145775701",
                    "name": "Cheng Chen"
                },
                {
                    "authorId": "2239907959",
                    "name": "Ruiqi Geng"
                },
                {
                    "authorId": "2905344",
                    "name": "Bohan Li"
                },
                {
                    "authorId": "2239924629",
                    "name": "Maryla Ustarroz-Calonge"
                },
                {
                    "authorId": "2083551416",
                    "name": "Frank Galligan"
                },
                {
                    "authorId": "2239891250",
                    "name": "Jingning Han"
                },
                {
                    "authorId": "1788515",
                    "name": "Yaowu Xu"
                }
            ]
        },
        {
            "paperId": "e036ef0b14f55cda9077ca6df0373ca5c52e9189",
            "title": "Energy-Efficient Interference Cancellation in Integrated Sensing and Communication Scenarios",
            "abstract": "Recently, integrated sensing and communication (ISAC) has been a hot topic to alleviate the issue of low spectrum efficiency, pursuit the hardware gain and integration gain as far as possible. However, the coexistence of sensing and communication functions triggers the mutual interference therein, seriously affecting their respective performance. To solve this problem, the communication model and sensing model are built respectively in this paper, considering the interference between communication signals and between sensing signals and communication signals. Then, the ratio of the total transmitting data rate and the total power consumption is regarded as the optimization objection of this paper for energy-efficient interference cancellation. After that, the approximate solution of the optimization objection is obtained by Dinkelbach based scheme and semi-definite relaxation (SDR). Finally, the numerical simulations are conducted and the simulation results state that the proposed scheme can obtain a higher energy efficiency and outperforms the classical scheme.",
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "authors": [
                {
                    "authorId": "3454517",
                    "name": "Junsheng Mu"
                },
                {
                    "authorId": "2750067",
                    "name": "Wenjia Ouyang"
                },
                {
                    "authorId": "1471344005",
                    "name": "Zexuan Jing"
                },
                {
                    "authorId": "2905344",
                    "name": "Bohan Li"
                },
                {
                    "authorId": "13947363",
                    "name": "Fangpei Zhang"
                }
            ]
        },
        {
            "paperId": "e9318fbff96286ef9a9d94bd10112e0d3ca94d0c",
            "title": "Regulating confidence by corner discrepancy and center score in corner-based object detection methods",
            "abstract": "This paper proposes an approach that regulates the confidence of predicted boxes for corner-based detection methods. Corner-based methods have achieved state-of-the-art performance on MS-COCO by predicting corners and grouping them to generate boxes. However, the box confidence is simply defined to be the average score of grouped corners, ignoring the score and tag discrepancy between them. The discrepancy may lead to the generation of more false positives (FPs) since a larger discrepancy often means that the grouped corners less likely belong to the same object. Observing this, this paper proposes introducing the discrepancy of corners (DoC) to decrease the box confidence. Also, the score and location of center (SLoC) of a detection box is utilized to further finely regulate the confidence. DoC and SLoC can effectively reduce FPs and missings and hence improve the detection performance without changing any model parameter. Experimental results on MS-COCO also show improvements.",
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "authors": [
                {
                    "authorId": "51122630",
                    "name": "Zihang He"
                },
                {
                    "authorId": "40522404",
                    "name": "Kai Zhao"
                },
                {
                    "authorId": "2905344",
                    "name": "Bohan Li"
                },
                {
                    "authorId": "2154404076",
                    "name": "Yong Li"
                }
            ]
        },
        {
            "paperId": "0ade637337402b3a2270e75fd3869392937212dd",
            "title": "MetaPrompting: Learning to Learn Better Prompts",
            "abstract": "Prompting method is regarded as one of the crucial progress for few-shot nature language processing. Recent research on prompting moves from discrete tokens based \u201chard prompts\u201d to continuous \u201csoft prompts\u201d, which employ learnable vectors as pseudo prompt tokens and achieve better performance. Though showing promising prospects, these soft-prompting methods are observed to rely heavily on good initialization to take effect. Unfortunately, obtaining a perfect initialization for soft prompts requires understanding of inner language models working and elaborate design, which is no easy task and has to restart from scratch for each new task. To remedy this, we propose a generalized soft prompting method called MetaPrompting, which adopts the well-recognized model-agnostic meta-learning algorithm to automatically find better prompt initialization that facilitates fast adaptation to new prompting tasks. Extensive experiments show MetaPrompting tackles soft prompt initialization problem and brings significant improvement on three different datasets (over 6 points improvement in accuracy for 1-shot setting), achieving new state-of-the-art performance.",
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "authors": [
                {
                    "authorId": "8471176",
                    "name": "Yutai Hou"
                },
                {
                    "authorId": "71150245",
                    "name": "Hongyuan Dong"
                },
                {
                    "authorId": "2144801098",
                    "name": "Xinghao Wang"
                },
                {
                    "authorId": "2905344",
                    "name": "Bohan Li"
                },
                {
                    "authorId": "2256319",
                    "name": "Wanxiang Che"
                }
            ]
        },
        {
            "paperId": "4ce2f80ed82db05d63763812e6d51e787b9b5309",
            "title": "Multi-Rate Adaptive Transform Coding for Video Compression",
            "abstract": "Contemporary lossy image and video coding standards rely on transform coding, the process through which pixels are mapped to an alternative representation to facilitate efficient data compression. Despite impressive performance of end-to-end optimized compression with deep neural networks, the high computational and space demands of these models has prevented them from superseding the relatively simple transform coding found in conventional video codecs. In this study, we propose learned transforms and entropy coding that may either serve as (non)linear drop-in replacements, or enhancements for linear transforms in existing codecs. These transforms can be multi-rate, allowing a single model to operate along the entire rate-distortion curve. To demonstrate the utility of our framework, we augmented the DCT with learned quantization matrices and adaptive entropy coding to compress intra-frame AV1 block prediction residuals. We report substantial BD-rate and perceptual quality improvements over more complex nonlinear transforms at a fraction of the computational cost.",
            "fieldsOfStudy": [
                "Engineering",
                "Computer Science"
            ],
            "authors": [
                {
                    "authorId": "145346438",
                    "name": "Lyndon Duong"
                },
                {
                    "authorId": "2905344",
                    "name": "Bohan Li"
                },
                {
                    "authorId": "2145775701",
                    "name": "Cheng Chen"
                },
                {
                    "authorId": "2062128",
                    "name": "Jingning Han"
                }
            ]
        },
        {
            "paperId": "6339014b7ba18e19b138aab9e58778595f22081f",
            "title": "An Efficient Scheme of Multi-Hypothesis Motion Compensated Prediction for Video Coding Applications",
            "abstract": "Prior research has demonstrated that the multi-hypothesis motion compensated prediction (MCP) can theoretically provide a better prediction quality than single-reference MCP, thereby improving the compression efficiency in video coding. However, the existing multi-hypothesis MCP methods typically require either additional rate cost to transmit the motion vectors, or significant decoding complexity to conduct the motion search at the decoder end, which is usually expensive. In this work, we propose a novel scheme to materialize the multi-hypothesis MCP that requires no additional rate cost, nor extra motion search on either the encoder or decoder side. Various approaches to synthesize these available multiple references to form the inter prediction are presented. We experimentally demonstrate that the proposed scheme provides considerable and consistent coding gains across a wide range of operating points.",
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "authors": [
                {
                    "authorId": "2905344",
                    "name": "Bohan Li"
                },
                {
                    "authorId": "2062128",
                    "name": "Jingning Han"
                },
                {
                    "authorId": "1788515",
                    "name": "Yaowu Xu"
                }
            ]
        }
    ]
}