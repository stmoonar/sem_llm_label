{
    "authorId": "8499589",
    "papers": [
        {
            "paperId": "1304f88cf92fecccbcf2c26aaac3d4f0a7964e05",
            "title": "Local Causal Discovery with Linear non-Gaussian Cyclic Models",
            "abstract": "Local causal discovery is of great practical significance, as there are often situations where the discovery of the global causal structure is unnecessary, and the interest lies solely on a single target variable. Most existing local methods utilize conditional independence relations, providing only a partially directed graph, and assume acyclicity for the ground-truth structure, even though real-world scenarios often involve cycles like feedback mechanisms. In this work, we present a general, unified local causal discovery method with linear non-Gaussian models, whether they are cyclic or acyclic. We extend the application of independent component analysis from the global context to independent subspace analysis, enabling the exact identification of the equivalent local directed structures and causal strengths from the Markov blanket of the target variable. We also propose an alternative regression-based method in the particular acyclic scenarios. Our identifiability results are empirically validated using both synthetic and real-world datasets.",
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "authors": [
                {
                    "authorId": "2279087279",
                    "name": "Haoyue Dai"
                },
                {
                    "authorId": "1379925573",
                    "name": "Ignavier Ng"
                },
                {
                    "authorId": "8499589",
                    "name": "Yujia Zheng"
                },
                {
                    "authorId": "2293242384",
                    "name": "Zhengqing Gao"
                },
                {
                    "authorId": "2265073796",
                    "name": "Kun Zhang"
                }
            ]
        },
        {
            "paperId": "5aea80d0cad8fb2d94bf3c5f163f25034aa062df",
            "title": "Causal Representation Learning from Multiple Distributions: A General Setting",
            "abstract": "In many problems, the measured variables (e.g., image pixels) are just mathematical functions of the latent causal variables (e.g., the underlying concepts or objects). For the purpose of making predictions in changing environments or making proper changes to the system, it is helpful to recover the latent causal variables $Z_i$ and their causal relations represented by graph $\\mathcal{G}_Z$. This problem has recently been known as causal representation learning. This paper is concerned with a general, completely nonparametric setting of causal representation learning from multiple distributions (arising from heterogeneous data or nonstationary time series), without assuming hard interventions behind distribution changes. We aim to develop general solutions in this fundamental case; as a by product, this helps see the unique benefit offered by other assumptions such as parametric causal models or hard interventions. We show that under the sparsity constraint on the recovered graph over the latent variables and suitable sufficient change conditions on the causal influences, interestingly, one can recover the moralized graph of the underlying directed acyclic graph, and the recovered latent variables and their relations are related to the underlying causal model in a specific, nontrivial way. In some cases, most latent variables can even be recovered up to component-wise transformations. Experimental results verify our theoretical claims.",
            "fieldsOfStudy": [
                "Computer Science",
                "Mathematics"
            ],
            "authors": [
                {
                    "authorId": "2265073796",
                    "name": "Kun Zhang"
                },
                {
                    "authorId": "25106675",
                    "name": "Shaoan Xie"
                },
                {
                    "authorId": "1379925573",
                    "name": "Ignavier Ng"
                },
                {
                    "authorId": "8499589",
                    "name": "Yujia Zheng"
                }
            ]
        },
        {
            "paperId": "76736ef1826f53198df72e9ccc513410f403c9d4",
            "title": "On the Identifiability of Sparse ICA without Assuming Non-Gaussianity",
            "abstract": "Independent component analysis (ICA) is a fundamental statistical tool used to reveal hidden generative processes from observed data. However, traditional ICA approaches struggle with the rotational invariance inherent in Gaussian distributions, often necessitating the assumption of non-Gaussianity in the underlying sources. This may limit their applicability in broader contexts. To accommodate Gaussian sources, we develop an identifiability theory that relies on second-order statistics without imposing further preconditions on the distribution of sources, by introducing novel assumptions on the connective structure from sources to observed variables. Different from recent work that focuses on potentially restrictive connective structures, our proposed assumption of structural variability is both considerably less restrictive and provably necessary. Furthermore, we propose two estimation methods based on second-order statistics and sparsity constraint. Experimental results are provided to validate our identifiability theory and estimation methods.",
            "fieldsOfStudy": [
                "Computer Science",
                "Mathematics"
            ],
            "authors": [
                {
                    "authorId": "1379925573",
                    "name": "Ignavier Ng"
                },
                {
                    "authorId": "8499589",
                    "name": "Yujia Zheng"
                },
                {
                    "authorId": "2262501910",
                    "name": "Xinshuai Dong"
                },
                {
                    "authorId": "2265073796",
                    "name": "Kun Zhang"
                }
            ]
        },
        {
            "paperId": "0ef4993978f60b5065bac687746bc9857e2c99f7",
            "title": "Partial Identifiability for Domain Adaptation",
            "abstract": "Unsupervised domain adaptation is critical to many real-world applications where label information is unavailable in the target domain. In general, without further assumptions, the joint distribution of the features and the label is not identifiable in the target domain. To address this issue, we rely on the property of minimal changes of causal mechanisms across domains to minimize unnecessary influences of distribution shifts. To encode this property, we first formulate the data-generating process using a latent variable model with two partitioned latent subspaces: invariant components whose distributions stay the same across domains and sparse changing components that vary across domains. We further constrain the domain shift to have a restrictive influence on the changing components. Under mild conditions, we show that the latent variables are partially identifiable, from which it follows that the joint distribution of data and labels in the target domain is also identifiable. Given the theoretical insights, we propose a practical domain adaptation framework called iMSDA. Extensive experimental results reveal that iMSDA outperforms state-of-the-art domain adaptation algorithms on benchmark datasets, demonstrating the effectiveness of our framework.",
            "fieldsOfStudy": [
                "Computer Science",
                "Mathematics"
            ],
            "authors": [
                {
                    "authorId": "2069275317",
                    "name": "Lingjing Kong"
                },
                {
                    "authorId": "25106675",
                    "name": "Shaoan Xie"
                },
                {
                    "authorId": "2087699735",
                    "name": "Weiran Yao"
                },
                {
                    "authorId": "8499589",
                    "name": "Yujia Zheng"
                },
                {
                    "authorId": "2155315836",
                    "name": "Guan-Hong Chen"
                },
                {
                    "authorId": "6616282",
                    "name": "P. Stojanov"
                },
                {
                    "authorId": "32662204",
                    "name": "Victor Akinwande"
                },
                {
                    "authorId": "2175349484",
                    "name": "Kun Zhang"
                }
            ]
        },
        {
            "paperId": "2249035ff915951db6a7d4718cd6bf28ec3c3e93",
            "title": "Generalized Precision Matrix for Scalable Estimation of Nonparametric Markov Networks",
            "abstract": "A Markov network characterizes the conditional independence structure, or Markov property, among a set of random variables. Existing work focuses on specific families of distributions (e.g., exponential families) and/or certain structures of graphs, and most of them can only handle variables of a single data type (continuous or discrete). In this work, we characterize the conditional independence structure in general distributions for all data types (i.e., continuous, discrete, and mixed-type) with a Generalized Precision Matrix (GPM). Besides, we also allow general functional relations among variables, thus giving rise to a Markov network structure learning algorithm in one of the most general settings. To deal with the computational challenge of the problem, especially for large graphs, we unify all cases under the same umbrella of a regularized score matching framework. We validate the theoretical results and demonstrate the scalability empirically in various settings.",
            "fieldsOfStudy": [
                "Computer Science",
                "Mathematics"
            ],
            "authors": [
                {
                    "authorId": "8499589",
                    "name": "Yujia Zheng"
                },
                {
                    "authorId": "1379925573",
                    "name": "Ignavier Ng"
                },
                {
                    "authorId": "2166103953",
                    "name": "Yewen Fan"
                },
                {
                    "authorId": "2119016656",
                    "name": "Kun Zhang"
                }
            ]
        },
        {
            "paperId": "4ac14a3d12e027056e57c5a05b0414b6b0ff7002",
            "title": "Deep Dag Learning of Effective Brain Connectivity for FMRI Analysis",
            "abstract": "Functional magnetic resonance imaging (fMRI) has become one of the most common imaging modalities for brain function analysis. Recently, graph neural networks (GNN) have been adopted for fMRI analysis with superior performance. Unfortunately, traditional functional brain networks are mainly constructed based on similarities among region of interests (ROIs), which are noisy and can lead to inferior results for GNN models. To better adapt GNNs for fMRI analysis, we propose DABNet, a Deep DAG learning framework based on Brain Networks for fMRI analysis. DABNet adopts a brain network generator module, which harnesses the DAG learning approach to transform the raw time-series into effective brain connectivities. Experiments on two fMRI datasets demonstrate the efficacy of DABNet. The generated brain networks also highlight the prediction-related brain regions and thus provide interpretations for predictions.",
            "fieldsOfStudy": [
                "Medicine",
                "Computer Science"
            ],
            "authors": [
                {
                    "authorId": "1633124736",
                    "name": "Yue Yu"
                },
                {
                    "authorId": "2052319438",
                    "name": "Xuan Kan"
                },
                {
                    "authorId": "2112821580",
                    "name": "Hejie Cui"
                },
                {
                    "authorId": "47462790",
                    "name": "Ran Xu"
                },
                {
                    "authorId": "8499589",
                    "name": "Yujia Zheng"
                },
                {
                    "authorId": "19214393",
                    "name": "Xiangchen Song"
                },
                {
                    "authorId": "2653121",
                    "name": "Yanqiao Zhu"
                },
                {
                    "authorId": "2175349484",
                    "name": "Kun Zhang"
                },
                {
                    "authorId": "41034714",
                    "name": "Razieh Nabi"
                },
                {
                    "authorId": "2153202261",
                    "name": "Ying Guo"
                },
                {
                    "authorId": "40422511",
                    "name": "C. Zhang"
                },
                {
                    "authorId": "1390553618",
                    "name": "Carl Yang"
                }
            ]
        },
        {
            "paperId": "e35c6e468378555c5204c968c1cdec1a28e03a77",
            "title": "Causal-learn: Causal Discovery in Python",
            "abstract": "Causal discovery aims at revealing causal relations from observational data, which is a fundamental task in science and engineering. We describe $\\textit{causal-learn}$, an open-source Python library for causal discovery. This library focuses on bringing a comprehensive collection of causal discovery methods to both practitioners and researchers. It provides easy-to-use APIs for non-specialists, modular building blocks for developers, detailed documentation for learners, and comprehensive methods for all. Different from previous packages in R or Java, $\\textit{causal-learn}$ is fully developed in Python, which could be more in tune with the recent preference shift in programming languages within related communities. The library is available at https://github.com/py-why/causal-learn.",
            "fieldsOfStudy": [
                "Computer Science",
                "Mathematics"
            ],
            "authors": [
                {
                    "authorId": "8499589",
                    "name": "Yujia Zheng"
                },
                {
                    "authorId": "1938684",
                    "name": "Biwei Huang"
                },
                {
                    "authorId": "2154941589",
                    "name": "Wei Chen"
                },
                {
                    "authorId": "145500450",
                    "name": "J. Ramsey"
                },
                {
                    "authorId": "29393235",
                    "name": "Mingming Gong"
                },
                {
                    "authorId": "39913331",
                    "name": "Ruichu Cai"
                },
                {
                    "authorId": "2053931",
                    "name": "Shohei Shimizu"
                },
                {
                    "authorId": "143648560",
                    "name": "P. Spirtes"
                },
                {
                    "authorId": "2119016656",
                    "name": "Kun Zhang"
                }
            ]
        },
        {
            "paperId": "f57749e893c9d532e5b65845cea7adacedc0a4aa",
            "title": "Generalizing Nonlinear ICA Beyond Structural Sparsity",
            "abstract": "Nonlinear independent component analysis (ICA) aims to uncover the true latent sources from their observable nonlinear mixtures. Despite its significance, the identifiability of nonlinear ICA is known to be impossible without additional assumptions. Recent advances have proposed conditions on the connective structure from sources to observed variables, known as Structural Sparsity, to achieve identifiability in an unsupervised manner. However, the sparsity constraint may not hold universally for all sources in practice. Furthermore, the assumptions of bijectivity of the mixing process and independence among all sources, which arise from the setting of ICA, may also be violated in many real-world scenarios. To address these limitations and generalize nonlinear ICA, we propose a set of new identifiability results in the general settings of undercompleteness, partial sparsity and source dependence, and flexible grouping structures. Specifically, we prove identifiability when there are more observed variables than sources (undercomplete), and when certain sparsity and/or source independence assumptions are not met for some changing sources. Moreover, we show that even in cases with flexible grouping structures (e.g., part of the sources can be divided into irreducible independent groups with various sizes), appropriate identifiability results can also be established. Theoretical claims are supported empirically on both synthetic and real-world datasets.",
            "fieldsOfStudy": [
                "Computer Science",
                "Engineering",
                "Mathematics"
            ],
            "authors": [
                {
                    "authorId": "8499589",
                    "name": "Yujia Zheng"
                },
                {
                    "authorId": "2265073796",
                    "name": "Kun Zhang"
                }
            ]
        },
        {
            "paperId": "fbefd4b287c7fd6e169fba37d6366d2c771ecc5c",
            "title": "A Versatile Causal Discovery Framework to Allow Causally-Related Hidden Variables",
            "abstract": "Most existing causal discovery methods rely on the assumption of no latent confounders, limiting their applicability in solving real-life problems. In this paper, we introduce a novel, versatile framework for causal discovery that accommodates the presence of causally-related hidden variables almost everywhere in the causal network (for instance, they can be effects of observed variables), based on rank information of covariance matrix over observed variables. We start by investigating the efficacy of rank in comparison to conditional independence and, theoretically, establish necessary and sufficient conditions for the identifiability of certain latent structural patterns. Furthermore, we develop a Rank-based Latent Causal Discovery algorithm, RLCD, that can efficiently locate hidden variables, determine their cardinalities, and discover the entire causal structure over both measured and hidden ones. We also show that, under certain graphical conditions, RLCD correctly identifies the Markov Equivalence Class of the whole latent causal graph asymptotically. Experimental results on both synthetic and real-world personality data sets demonstrate the efficacy of the proposed approach in finite-sample cases.",
            "fieldsOfStudy": [
                "Computer Science",
                "Mathematics"
            ],
            "authors": [
                {
                    "authorId": "2262501910",
                    "name": "Xinshuai Dong"
                },
                {
                    "authorId": "1938684",
                    "name": "Biwei Huang"
                },
                {
                    "authorId": "1379925573",
                    "name": "Ignavier Ng"
                },
                {
                    "authorId": "2262495949",
                    "name": "Xiangchen Song"
                },
                {
                    "authorId": "8499589",
                    "name": "Yujia Zheng"
                },
                {
                    "authorId": "2275860780",
                    "name": "Songyao Jin"
                },
                {
                    "authorId": "2292327728",
                    "name": "Roberto Legaspi"
                },
                {
                    "authorId": "143648560",
                    "name": "P. Spirtes"
                },
                {
                    "authorId": "2119016656",
                    "name": "Kun Zhang"
                }
            ]
        },
        {
            "paperId": "141c137db6bd8f12fa0ce81968a4a8370d36ca74",
            "title": "On the Identifiability of Nonlinear ICA: Sparsity and Beyond",
            "abstract": "Nonlinear independent component analysis (ICA) aims to recover the underlying independent latent sources from their observable nonlinear mixtures. How to make the nonlinear ICA model identifiable up to certain trivial indeterminacies is a long-standing problem in unsupervised learning. Recent breakthroughs reformulate the standard independence assumption of sources as conditional independence given some auxiliary variables (e.g., class labels and/or domain/time indexes) as weak supervision or inductive bias. However, nonlinear ICA with unconditional priors cannot benefit from such developments. We explore an alternative path and consider only assumptions on the mixing process, such as Structural Sparsity. We show that under specific instantiations of such constraints, the independent latent sources can be identified from their nonlinear mixtures up to a permutation and a component-wise transformation, thus achieving nontrivial identifiability of nonlinear ICA without auxiliary variables. We provide estimation methods and validate the theoretical results experimentally. The results on image data suggest that our conditions may hold in a number of practical data generating processes.",
            "fieldsOfStudy": [
                "Computer Science",
                "Mathematics"
            ],
            "authors": [
                {
                    "authorId": "8499589",
                    "name": "Yujia Zheng"
                },
                {
                    "authorId": "1379925573",
                    "name": "Ignavier Ng"
                },
                {
                    "authorId": "143972711",
                    "name": "Kun Zhang"
                }
            ]
        }
    ]
}