{
    "authorId": "2265222599",
    "papers": [
        {
            "paperId": "d681e656f610734f177782b99daa40d76c87f38e",
            "title": "OCTCube: A 3D foundation model for optical coherence tomography that improves cross-dataset, cross-disease, cross-device and cross-modality analysis",
            "abstract": "Optical coherence tomography (OCT) has become critical for diagnosing retinal diseases as it enables 3D images of the retina and optic nerve. OCT acquisition is fast, non-invasive, affordable, and scalable. Due to its broad applicability, massive numbers of OCT images have been accumulated in routine exams, making it possible to train large-scale foundation models that can generalize to various diagnostic tasks using OCT images. Nevertheless, existing foundation models for OCT only consider 2D image slices, overlooking the rich 3D structure. Here, we present OCTCube, a 3D foundation model pre-trained on 26,605 3D OCT volumes encompassing 1.62 million 2D OCT images. OCTCube is developed based on 3D masked autoencoders and exploits FlashAttention to reduce the larger GPU memory usage caused by modeling 3D volumes. OCTCube outperforms 2D models when predicting 8 retinal diseases in both inductive and cross-dataset settings, indicating that utilizing the 3D structure in the model instead of 2D data results in significant improvement. OCTCube further shows superior performance on cross-device prediction and when predicting systemic diseases, such as diabetes and hypertension, further demonstrating its strong generalizability. Finally, we propose a contrastive-self-supervised-learning-based OCT-IR pre-training framework (COIP) for cross-modality analysis on OCT and infrared retinal (IR) images, where the OCT volumes are embedded using OCTCube. We demonstrate that COIP enables accurate alignment between OCT and IR en face images. Collectively, OCTCube, a 3D OCT foundation model, demonstrates significantly better performance against 2D models on 27 out of 29 tasks and comparable performance on the other two tasks, paving the way for AI-based retinal disease diagnosis.",
            "fieldsOfStudy": [
                "Engineering",
                "Computer Science"
            ],
            "authors": [
                {
                    "authorId": "2265222599",
                    "name": "Zixuan Liu"
                },
                {
                    "authorId": "2263936549",
                    "name": "Hanwen Xu"
                },
                {
                    "authorId": "2170076404",
                    "name": "Addie Woicik"
                },
                {
                    "authorId": "2316563670",
                    "name": "Linda G. Shapiro"
                },
                {
                    "authorId": "1768174127",
                    "name": "Marian Blazes"
                },
                {
                    "authorId": "2316577321",
                    "name": "Yue Wu"
                },
                {
                    "authorId": "2270973570",
                    "name": "Cecilia S. Lee"
                },
                {
                    "authorId": "2305029455",
                    "name": "Aaron Y Lee"
                },
                {
                    "authorId": "2257325568",
                    "name": "Sheng Wang"
                }
            ]
        },
        {
            "paperId": "fe8527541afd578326a51b885aef82da6bb32e95",
            "title": "T-Rex: Text-assisted Retrosynthesis Prediction",
            "abstract": "As a fundamental task in computational chemistry, retrosynthesis prediction aims to identify a set of reactants to synthesize a target molecule. Existing template-free approaches only consider the graph structures of the target molecule, which often cannot generalize well to rare reaction types and large molecules. Here, we propose T-Rex, a text-assisted retrosynthesis prediction approach that exploits pre-trained text language models, such as ChatGPT, to assist the generation of reactants. T-Rex first exploits ChatGPT to generate a description for the target molecule and rank candidate reaction centers based both the description and the molecular graph. It then re-ranks these candidates by querying the descriptions for each reactants and examines which group of reactants can best synthesize the target molecule. We observed that T-Rex substantially outperformed graph-based state-of-the-art approaches on two datasets, indicating the effectiveness of considering text information. We further found that T-Rex outperformed the variant that only use ChatGPT-based description without the re-ranking step, demonstrate how our framework outperformed a straightforward integration of ChatGPT and graph information. Collectively, we show that text generated by pre-trained language models can substantially improve retrosynthesis prediction, opening up new avenues for exploiting ChatGPT to advance computational chemistry. And the codes can be found at https://github.com/lauyikfung/T-Rex.",
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "authors": [
                {
                    "authorId": "2264342410",
                    "name": "Yifeng Liu"
                },
                {
                    "authorId": "2263936549",
                    "name": "Hanwen Xu"
                },
                {
                    "authorId": "2264489734",
                    "name": "Tangqi Fang"
                },
                {
                    "authorId": "2281644064",
                    "name": "Haocheng Xi"
                },
                {
                    "authorId": "2265222599",
                    "name": "Zixuan Liu"
                },
                {
                    "authorId": "72655349",
                    "name": "Sheng Zhang"
                },
                {
                    "authorId": "1759772",
                    "name": "Hoifung Poon"
                },
                {
                    "authorId": "2257325568",
                    "name": "Sheng Wang"
                }
            ]
        },
        {
            "paperId": "1c3b47117fb0877ecd9e7fc9e8db7b7948432d8f",
            "title": "ForeSeer: Product Aspect Forecasting Using Temporal Graph Embedding",
            "abstract": "Developing text mining approaches to mine aspects from customer reviews has been well-studied due to its importance in understanding customer needs and product attributes. In contrast, it remains unclear how to predict the future emerging aspects of a new product that currently has little review information. This task, which we named product aspect forecasting, is critical for recommending new products, but also challenging because of the missing reviews. Here, we propose ForeSeer, a novel textual mining and product embedding approach progressively trained on temporal product graphs for this novel product aspect forecasting task. ForeSeer transfers reviews from similar products on a large product graph and exploits these reviews to predict aspects that might emerge in future reviews. A key novelty of our method is to jointly provide review, product, and aspect embeddings that are both time-sensitive and less affected by extremely imbalanced aspect frequencies. We evaluated ForeSeer on a real-world product review system containing 11,536,382 reviews and 11,000 products over 3 years. We observe that ForeSeer substantially outperformed existing approaches with at least 49.1% AUPRC improvement under the real setting where aspect associations are not given. ForeSeer further improves future link prediction on the product graph and the review aspect association prediction. Collectively, Foreseer offers a novel framework for review forecasting by effectively integrating review text, product network, and temporal information, opening up new avenues for online shopping recommendation and e-commerce applications.",
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "authors": [
                {
                    "authorId": "2265222599",
                    "name": "Zixuan Liu"
                },
                {
                    "authorId": "46566733",
                    "name": "G. Hiranandani"
                },
                {
                    "authorId": "2257003517",
                    "name": "Kun Qian"
                },
                {
                    "authorId": "2057479333",
                    "name": "E-Wen Huang"
                },
                {
                    "authorId": "2257074252",
                    "name": "Yi Xu"
                },
                {
                    "authorId": "2007227598",
                    "name": "Belinda Zeng"
                },
                {
                    "authorId": "2691095",
                    "name": "Karthik Subbian"
                },
                {
                    "authorId": "2280550850",
                    "name": "Sheng Wang"
                }
            ]
        }
    ]
}