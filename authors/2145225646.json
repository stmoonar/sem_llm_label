{
    "authorId": "2145225646",
    "papers": [
        {
            "paperId": "203bf57f34e2e84e7dc9882f10142405cc63b462",
            "title": "MULAN: Multi-modal Causal Structure Learning and Root Cause Analysis for Microservice Systems",
            "abstract": "Effective root cause analysis (RCA) is vital for swiftly restoring services, minimizing losses, and ensuring the smooth operation and management of complex systems. Previous data-driven RCA methods, particularly those employing causal discovery techniques, have primarily focused on constructing dependency or causal graphs for backtracking the root causes. However, these methods often fall short as they rely solely on data from a single modality, thereby resulting in suboptimal solutions. In this work, we propose Mulan, a unified multi-modal causal structure learning method designed to identify root causes in microservice systems. We leverage a log-tailored language model to facilitate log representation learning, converting log sequences into time-series data. To explore intricate relationships across different modalities, we propose a contrastive learning-based approach to extract modality-invariant and modality-specific representations within a shared latent space. Additionally, we introduce a novel key performance indicator-aware attention mechanism for assessing modality reliability and co-learning a final causal graph. Finally, we employ random walk with restart to simulate system fault propagation and identify potential root causes. Extensive experiments on three real-world datasets validate the effectiveness of our proposed method.",
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "authors": [
                {
                    "authorId": "65990885",
                    "name": "Lecheng Zheng"
                },
                {
                    "authorId": "1720777201",
                    "name": "Zhengzhang Chen"
                },
                {
                    "authorId": "2258335272",
                    "name": "Jingrui He"
                },
                {
                    "authorId": "2145225646",
                    "name": "Haifeng Chen"
                }
            ]
        },
        {
            "paperId": "1d9911da8d46aaee7fd6af80566ac22097123b10",
            "title": "2nd Workshop on Ethical Artificial Intelligence: Methods and Applications (EAI)",
            "abstract": "Ethical AI has become increasingly important, and it has been attracting attention from academia and industry, due to its increased popularity in real-world applications with fairness concerns. It also places fundamental importance on ethical considerations in determining legitimate and illegitimate uses of AI. Organizations that apply ethical AI have clearly stated well-defined review processes to ensure adherence to legal guidelines. Therefore, the wave of research at the intersection of ethical AI in data mining and machine learning has also influenced other fields of science, including computer vision, natural language processing, reinforcement learning, and social science. Despite these successes, ethical AI still faces many challenges, such as a lack of interpretable and explainable methods for fairness-aware deep learning models, etc. Consequently, there is an urgent need to bring experts and researchers together at prestigious venues to discuss ethical AI, which has been rarely seen in previous KDD conferences. This workshop will provide a premium platform for both research and industry from different backgrounds to exchange ideas on opportunities, challenges, and cutting-edge techniques in ethical AI.",
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "authors": [
                {
                    "authorId": "48505082",
                    "name": "Chengli Zhao"
                },
                {
                    "authorId": "1399870469",
                    "name": "Feng Chen"
                },
                {
                    "authorId": "7916525",
                    "name": "Xintao Wu"
                },
                {
                    "authorId": "2145225646",
                    "name": "Haifeng Chen"
                },
                {
                    "authorId": "2310573749",
                    "name": "Jiayu Zhou"
                }
            ]
        },
        {
            "paperId": "639266d63317c6c0d16761a9e42d196c7cf363e0",
            "title": "Multi-Faceted Knowledge-Driven Pre-Training for Product Representation Learning",
            "abstract": "As a key component of e-commerce computing, product representation learning (PRL) provides benefits for a variety of applications, including product matching, search, and categorization. The existing PRL approaches have poor language understanding ability due to their inability to capture contextualized semantics. In addition, the learned representations by existing methods are not easily transferable to new products. Inspired by the recent advance of pre-trained language models (PLMs), we make the attempt to adapt PLMs for PRL to mitigate the above issues. In this article, we develop KINDLE, a Knowledge-drIven pre-trainiNg framework for proDuct representation LEarning, which can preserve the contextual semantics and multi-faceted product knowledge robustly and flexibly. Specifically, we first extend traditional one-stage pre-training to a two-stage pre-training framework, and exploit a deliberate knowledge encoder to ensure a smooth knowledge fusion into PLM. In addition, we propose a multi-objective heterogeneous embedding method to represent thousands of knowledge elements. This helps KINDLE calibrate knowledge noise and sparsity automatically by replacing isolated classes as training targets in knowledge acquisition tasks. Furthermore, an input-aware gating network is proposed to select the most relevant knowledge for different downstream tasks. Finally, extensive experiments have demonstrated the advantages of KINDLE over the state-of-the-art baselines across three downstream tasks.",
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "authors": [
                {
                    "authorId": "2109953207",
                    "name": "Denghui Zhang"
                },
                {
                    "authorId": "3215702",
                    "name": "Yanchi Liu"
                },
                {
                    "authorId": "1830453178",
                    "name": "Zixuan Yuan"
                },
                {
                    "authorId": "2274395",
                    "name": "Yanjie Fu"
                },
                {
                    "authorId": "2145225646",
                    "name": "Haifeng Chen"
                },
                {
                    "authorId": "2054473562",
                    "name": "Hui Xiong"
                }
            ]
        },
        {
            "paperId": "67633fb1b1e7d19a5cdc8775d551ab1bb55bae11",
            "title": "Unsupervised anomaly detection under a multiple modeling strategy via model set optimization through transfer learning",
            "abstract": "Unsupervised anomaly detection approaches have been widely accepted in applications for industrial systems. Industrial systems often operate with multiple modes since they work for multiple purposes or under different conditions. In order to deal with the difficulty of anomaly detection due to multiple operating modes, multiple modeling strategies are employed. However, estimating the optimal set of models is a challenging problem due to the lack of supervision and computational burden. In this paper, we propose DeconAnomaly, a deep learning framework to estimate the optimal set of models using transfer learning for unsupervised anomaly detection under a multiple modeling strategy. It reduces computational burden with transfer learning and optimizes the number of models based on a surrogate metric of detection performance. The experimental results show clear advantages of DeconAnomaly.",
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "authors": [
                {
                    "authorId": "39711812",
                    "name": "Masanao Natsumeda"
                },
                {
                    "authorId": "153406221",
                    "name": "Takehiko Mizoguchi"
                },
                {
                    "authorId": "145859270",
                    "name": "Wei Cheng"
                },
                {
                    "authorId": "47557891",
                    "name": "Yuncong Chen"
                },
                {
                    "authorId": "2145225646",
                    "name": "Haifeng Chen"
                }
            ]
        },
        {
            "paperId": "792664ad444ad99e6c352396294c1f28d85dba61",
            "title": "2nd Workshop on Uncertainty Reasoning and Quantification in Decision Making",
            "abstract": "Uncertainty reasoning and quantification play a critical role in decision making across various domains, prompting increased attention from both academia and industry. As real-world applications become more complex and data-driven, effectively handling uncertainty becomes paramount for accurate and reliable decision making. This workshop focuses on the critical topics of uncertainty reasoning and quantification in decision making. It provides a platform for experts and researchers from diverse backgrounds to exchange ideas on cutting-edge techniques and challenges in this field. The interdisciplinary nature of uncertainty reasoning and quantification, spanning artificial intelligence, machine learning, statistics, risk analysis, and decision science, will be explored. The workshop aims to address the need for robust and interpretable methods for modeling and quantifying uncertainty, fostering reasoning decision-making in various domains. Participants will have the opportunity to share research findings and practical experiences, promoting collaboration and advancing decision-making practices under uncertainty.",
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "authors": [
                {
                    "authorId": "50879401",
                    "name": "Xujiang Zhao"
                },
                {
                    "authorId": "48505082",
                    "name": "Chengli Zhao"
                },
                {
                    "authorId": "1399870469",
                    "name": "Feng Chen"
                },
                {
                    "authorId": "2148374177",
                    "name": "Jin-Hee Cho"
                },
                {
                    "authorId": "2145225646",
                    "name": "Haifeng Chen"
                }
            ]
        },
        {
            "paperId": "9c499647c3bec5ab4e2a9702309c44c92326000e",
            "title": "Interdependent Causal Networks for Root Cause Localization",
            "abstract": "The goal of root cause analysis is to identify the underlying causes of system problems by discovering and analyzing the causal structure from system monitoring data. It is indispensable for maintaining the stability and robustness of large-scale complex systems. Existing methods mainly focus on the construction of a single effective isolated causal network, whereas many real-world systems are complex and exhibit interdependent structures (i.e., multiple networks of a system are interconnected by cross-network links). In interdependent networks, the malfunctioning effects of problematic system entities can propagate to other networks or different levels of system entities. Consequently, ignoring the interdependency results in suboptimal root cause analysis outcomes. In this paper, we propose REASON, a novel framework that enables the automatic discovery of both intra-level (i.e., within-network) and inter-level (i.e., across-network) causal relationships for root cause localization. REASON consists of Topological Causal Discovery (TCD) and Individual Causal Discovery (ICD). The TCD component aims to model the fault propagation in order to trace back to the root causes. To achieve this, we propose novel hierarchical graph neural networks to construct interdependent causal networks by modeling both intra-level and inter-level non-linear causal relations. Based on the learned interdependent causal networks, we then leverage random walk with restarts to model the network propagation of a system fault. The ICD component focuses on capturing abrupt change patterns of a single system entity. This component examines the temporal patterns of each entity's metric data (i.e., time series), and estimates its likelihood of being a root cause based on the Extreme Value theory. Combining the topological and individual causal scores, the top K system entities are identified as root causes. Extensive experiments on three real-world datasets validate the effectiveness of the proposed framework.",
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "authors": [
                {
                    "authorId": "1669829502",
                    "name": "Dongjie Wang"
                },
                {
                    "authorId": "1766853",
                    "name": "Zhengzhang Chen"
                },
                {
                    "authorId": "2090567",
                    "name": "Jingchao Ni"
                },
                {
                    "authorId": "2227555279",
                    "name": "Liang Tong"
                },
                {
                    "authorId": "40072305",
                    "name": "Zheng Wang"
                },
                {
                    "authorId": "2274395",
                    "name": "Yanjie Fu"
                },
                {
                    "authorId": "2145225646",
                    "name": "Haifeng Chen"
                }
            ]
        },
        {
            "paperId": "9e761f4ac57239d68958c817858f5b6627c01e54",
            "title": "FedSkill: Privacy Preserved Interpretable Skill Learning via Imitation",
            "abstract": "Imitation learning that replicates experts' skills via their demonstrations has shown significant success in various decision-making tasks. However, two critical challenges still hinder the deployment of imitation learning techniques in real-world application scenarios. First, existing methods lack the intrinsic interpretability to explicitly explain the underlying rationale of the learned skill and thus making learned policy untrustworthy. Second, due to the scarcity of expert demonstrations from each end user (client), learning a policy based on different data silos is necessary but challenging in privacy-sensitive applications such as finance and healthcare. To this end, we present a privacy-preserved interpretable skill learning framework (FedSkill) that enables global policy learning to incorporate data from different sources and provides explainable interpretations to each local user without violating privacy and data sovereignty. Specifically, our proposed interpretable skill learning model can capture the varying patterns in the trajectories of expert demonstrations, and extract prototypical information as skills that provide implicit guidance for policy learning and explicit explanations in the reasoning process. Moreover, we design a novel aggregation mechanism coupled with the based skill learning model to preserve global information utilization and maintain local interpretability under the federated framework. Thoroughly experiments on three datasets and empirical studies demonstrate that our proposed FedSkill framework not only outperforms state-of-the-art imitation learning methods but also exhibits good interpretability under a federated setting. Our proposed FedSkill framework is the first attempt to bridge the gaps among federated learning, interpretable machine learning, and imitation learning.",
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "authors": [
                {
                    "authorId": "2214140574",
                    "name": "Yushan Jiang"
                },
                {
                    "authorId": "3007026",
                    "name": "Wenchao Yu"
                },
                {
                    "authorId": "2451800",
                    "name": "Dongjin Song"
                },
                {
                    "authorId": "2153516978",
                    "name": "Lu Wang"
                },
                {
                    "authorId": "145859270",
                    "name": "Wei Cheng"
                },
                {
                    "authorId": "2145225646",
                    "name": "Haifeng Chen"
                }
            ]
        },
        {
            "paperId": "f8de328be46416974b028284b77c1b318f35ca81",
            "title": "Incremental Causal Graph Learning for Online Root Cause Analysis",
            "abstract": "The task of root cause analysis (RCA) is to identify the root causes of system faults/failures by analyzing system monitoring data. Efficient RCA can greatly accelerate system failure recovery and mitigate system damages or financial losses. However, previous research has mostly focused on developing offline RCA algorithms, which often require manually initiating the RCA process, a significant amount of time and data to train a robust model, and then being retrained from scratch for a new system fault. In this paper, we propose CORAL, a novel online RCA framework that can automatically trigger the RCA process and incrementally update the RCA model. CORAL consists of Trigger Point Detection, Incremental Disentangled Causal Graph Learning, and Network Propagation-based Root Cause Localization. The Trigger Point Detection component aims to detect system state transitions automatically and in near-real-time. To achieve this, we develop an online trigger point detection approach based on multivariate singular spectrum analysis and cumulative sum statistics. To efficiently update the RCA model, we propose an incremental disentangled causal graph learning approach to decouple the state-invariant and state-dependent information. After that, CORAL applies a random walk with restarts to the updated causal graph to accurately identify root causes. The online RCA process terminates when the causal graph and the generated root cause list converge. Extensive experiments on three real-world datasets demonstrate the effectiveness and superiority of the proposed framework.",
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "authors": [
                {
                    "authorId": "1669829502",
                    "name": "Dongjie Wang"
                },
                {
                    "authorId": "1766853",
                    "name": "Zhengzhang Chen"
                },
                {
                    "authorId": "2274395",
                    "name": "Yanjie Fu"
                },
                {
                    "authorId": "3215702",
                    "name": "Yanchi Liu"
                },
                {
                    "authorId": "2145225646",
                    "name": "Haifeng Chen"
                }
            ]
        }
    ]
}