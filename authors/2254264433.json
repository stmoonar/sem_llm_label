{
    "authorId": "2254264433",
    "papers": [
        {
            "paperId": "d094c9e8b0231aaf61c7f89caed91cb99afb7c00",
            "title": "SemPool: Simple, robust, and interpretable KG pooling for enhancing language models",
            "abstract": "Knowledge Graph (KG) powered question answering (QA) performs complex reasoning over language semantics as well as knowledge facts. Graph Neural Networks (GNNs) learn to aggregate information from the underlying KG, which is combined with Language Models (LMs) for effective reasoning with the given question. However, GNN-based methods for QA rely on the graph information of the candidate answer nodes, which limits their effectiveness in more challenging settings where critical answer information is not included in the KG. We propose a simple graph pooling approach that learns useful semantics of the KG that can aid the LM's reasoning and that its effectiveness is robust under graph perturbations. Our method, termed SemPool, represents KG facts with pre-trained LMs, learns to aggregate their semantic information, and fuses it at different layers of the LM. Our experimental results show that SemPool outperforms state-of-the-art GNN-based methods by 2.27% accuracy points on average when answer information is missing from the KG. In addition, SemPool offers interpretability on what type of graph information is fused at different LM layers.",
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "authors": [
                {
                    "authorId": "1944251405",
                    "name": "Costas Mavromatis"
                },
                {
                    "authorId": "2254264433",
                    "name": "Petros Karypis"
                },
                {
                    "authorId": "50877490",
                    "name": "G. Karypis"
                }
            ]
        },
        {
            "paperId": "ecfa3f4802bf0feb6d4ecc5ff1ac19e8da784850",
            "title": "Pack of LLMs: Model Fusion at Test-Time via Perplexity Optimization",
            "abstract": "Fusing knowledge from multiple Large Language Models (LLMs) can combine their diverse strengths to achieve improved performance on a given task. However, current fusion approaches either rely on learning-based fusers that do not generalize to new LLMs, or do not take into account how well each LLM understands the input. In this work, we study LLM fusion at test-time, which enables leveraging knowledge from arbitrary user-specified LLMs during inference. We introduce Pack of LLMs (PackLLM), an effective method for test-time fusion that leverages each LLM's expertise, given an input prompt. PackLLM performs model fusion by solving an optimization problem for determining each LLM's importance, so that perplexity over the input prompt is minimized. First, our simple PackLLM-sim variant validates that perplexity is a good indicator for measuring each LLM's expertise. Second, our PackLLM-opt variant approximately solves the perplexity minimization problem via a greedy algorithm. The derived importance weights are used to combine the LLMs during inference. We conduct experiments with over 100 total LLMs on a diverse set of tasks. Experimental results show that (i) perplexity is a reliable measure for LLM fusion, (ii) PackLLM outperforms test-time fusion baselines by 1.89% accuracy points, and (iii) PackLLM can leverage new LLMs to improve performance over learning-based fusion approaches by 3.92-11.94% accuracy points.",
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "authors": [
                {
                    "authorId": "1944251405",
                    "name": "Costas Mavromatis"
                },
                {
                    "authorId": "2254264433",
                    "name": "Petros Karypis"
                },
                {
                    "authorId": "2064547804",
                    "name": "George Karypis"
                }
            ]
        },
        {
            "paperId": "9f1d4054d5a5daaca68ce7b2b7b398085bc2ff49",
            "title": "Extending Input Contexts of Language Models through Training on Segmented Sequences",
            "abstract": "Effectively training language models on long inputs poses many technical challenges. As a cost consideration, languages models are pretrained on a fixed sequence length before being adapted to longer sequences. We explore various methods for adapting models to longer inputs by training on segmented sequences and an interpolation-based method for extending absolute positional embeddings. We develop a training procedure to extend the input context size of pretrained models with no architectural changes and no additional memory costs than training on the original input lengths. By sub-sampling segments from long inputs while maintaining their original position the model is able to learn new positional interactions. Our method benefits both models trained with absolute positional embeddings, by extending their input contexts, as well as popular relative positional embedding methods showing a reduced perplexity on sequences longer than they were trained on. We demonstrate our method can extend input contexts by a factor of 4x while improving perplexity.",
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "authors": [
                {
                    "authorId": "2254264433",
                    "name": "Petros Karypis"
                },
                {
                    "authorId": "2254271546",
                    "name": "Julian J. McAuley"
                },
                {
                    "authorId": "50877490",
                    "name": "G. Karypis"
                }
            ]
        },
        {
            "paperId": "f1c406aa87f05c512f300bd45ce3c5135dec7bd1",
            "title": "Robust and Interpretable Medical Image Classifiers via Concept Bottleneck Models",
            "abstract": "Medical image classification is a critical problem for healthcare, with the potential to alleviate the workload of doctors and facilitate diagnoses of patients. However, two challenges arise when deploying deep learning models to real-world healthcare applications. First, neural models tend to learn spurious correlations instead of desired features, which could fall short when generalizing to new domains (e.g., patients with different ages). Second, these black-box models lack interpretability. When making diagnostic predictions, it is important to understand why a model makes a decision for trustworthy and safety considerations. In this paper, to address these two limitations, we propose a new paradigm to build robust and interpretable medical image classifiers with natural language concepts. Specifically, we first query clinical concepts from GPT-4, then transform latent image features into explicit concepts with a vision-language model. We systematically evaluate our method on eight medical image classification datasets to verify its effectiveness. On challenging datasets with strong confounding factors, our method can mitigate spurious correlations thus substantially outperform standard visual encoders and other baselines. Finally, we show how classification with a small number of concepts brings a level of interpretability for understanding model decisions through case studies in real medical data.",
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "authors": [
                {
                    "authorId": "2254201486",
                    "name": "An Yan"
                },
                {
                    "authorId": "2256185766",
                    "name": "Yu Wang"
                },
                {
                    "authorId": "2255932423",
                    "name": "Yiwu Zhong"
                },
                {
                    "authorId": "2116458151",
                    "name": "Zexue He"
                },
                {
                    "authorId": "2254264433",
                    "name": "Petros Karypis"
                },
                {
                    "authorId": "2255392606",
                    "name": "Zihan Wang"
                },
                {
                    "authorId": "2113540861",
                    "name": "Chengyu Dong"
                },
                {
                    "authorId": "2250624868",
                    "name": "Amilcare Gentili"
                },
                {
                    "authorId": "2257436141",
                    "name": "Chun-Nan Hsu"
                },
                {
                    "authorId": "2254284383",
                    "name": "Jingbo Shang"
                },
                {
                    "authorId": "2254271546",
                    "name": "Julian J. McAuley"
                }
            ]
        }
    ]
}