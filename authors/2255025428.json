{
    "authorId": "2255025428",
    "papers": [
        {
            "paperId": "301340099fbf098314eb31f6e8409e6d575c30ec",
            "title": "Sub-graph Based Diffusion Model for Link Prediction",
            "abstract": "Denoising Diffusion Probabilistic Models (DDPMs) represent a contemporary class of generative models with exceptional qualities in both synthesis and maximizing the data likelihood. These models work by traversing a forward Markov Chain where data is perturbed, followed by a reverse process where a neural network learns to undo the perturbations and recover the original data. There have been increasing efforts exploring the applications of DDPMs in the graph domain. However, most of them have focused on the generative perspective. In this paper, we aim to build a novel generative model for link prediction. In particular, we treat link prediction between a pair of nodes as a conditional likelihood estimation of its enclosing sub-graph. With a dedicated design to decompose the likelihood estimation process via the Bayesian formula, we are able to separate the estimation of sub-graph structure and its node features. Such designs allow our model to simultaneously enjoy the advantages of inductive learning and the strong generalization capability. Remarkably, comprehensive experiments across various datasets validate that our proposed method presents numerous advantages: (1) transferability across datasets without retraining, (2) promising generalization on limited training data, and (3) robustness against graph adversarial attacks.",
            "fieldsOfStudy": [
                "Computer Science",
                "Mathematics"
            ],
            "authors": [
                {
                    "authorId": "2321298358",
                    "name": "Hang Li"
                },
                {
                    "authorId": "144767914",
                    "name": "Wei Jin"
                },
                {
                    "authorId": "2127600715",
                    "name": "Geri Skenderi"
                },
                {
                    "authorId": "2220302956",
                    "name": "Harry Shomer"
                },
                {
                    "authorId": "2297995979",
                    "name": "Wenzhuo Tang"
                },
                {
                    "authorId": "2255025428",
                    "name": "Wenqi Fan"
                },
                {
                    "authorId": "2256937217",
                    "name": "Jiliang Tang"
                }
            ]
        },
        {
            "paperId": "37db151549206bfecfd82898caab6a8fe0253db2",
            "title": "A Comprehensive Survey on Graph Reduction: Sparsification, Coarsening, and Condensation",
            "abstract": "Many real-world datasets can be naturally represented as graphs, spanning a wide range of domains. However, the increasing complexity and size of graph datasets present significant challenges for analysis and computation. In response, graph reduction techniques have gained prominence for simplifying large graphs while preserving essential properties. In this survey, we aim to provide a comprehensive understanding of graph reduction methods, including graph sparsification, graph coarsening, and graph condensation. Specifically, we establish a unified definition for these methods and introduce a hierarchical taxonomy to categorize the challenges they address. Our survey then systematically reviews the technical details of these methods and emphasizes their practical applications across diverse scenarios. Furthermore, we outline critical research directions to ensure the continued effectiveness of graph reduction techniques.",
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "authors": [
                {
                    "authorId": "2282948080",
                    "name": "Mohammad Hashemi"
                },
                {
                    "authorId": "2282949117",
                    "name": "Shengbo Gong"
                },
                {
                    "authorId": "2282011606",
                    "name": "Juntong Ni"
                },
                {
                    "authorId": "2255025428",
                    "name": "Wenqi Fan"
                },
                {
                    "authorId": "2282004274",
                    "name": "B. A. Prakash"
                },
                {
                    "authorId": "2282319889",
                    "name": "Wei Jin"
                }
            ]
        },
        {
            "paperId": "dd48a47320111d60008f65207cf35b737b5711c5",
            "title": "Dual Test-time Training for Out-of-distribution Recommender System",
            "abstract": "Deep learning has been widely applied in recommender systems, which has achieved revolutionary progress recently. However, most existing learning-based methods assume that the user and item distributions remain unchanged between the training phase and the test phase. However, the distribution of user and item features can naturally shift in real-world scenarios, potentially resulting in a substantial decrease in recommendation performance. This phenomenon can be formulated as an Out-Of-Distribution (OOD) recommendation problem. To address this challenge, we propose a novel Dual Test-Time-Training framework for OOD Recommendation, termed DT3OR. In DT3OR, we incorporate a model adaptation mechanism during the test-time phase to carefully update the recommendation model, allowing the model to specially adapt to the shifting user and item features. To be specific, we propose a self-distillation task and a contrastive task to assist the model learning both the user's invariant interest preferences and the variant user/item characteristics during the test-time phase, thus facilitating a smooth adaptation to the shifting features. Furthermore, we provide theoretical analysis to support the rationale behind our dual test-time training framework. To the best of our knowledge, this paper is the first work to address OOD recommendation via a test-time-training strategy. We conduct experiments on three datasets with various backbones. Comprehensive experimental results have demonstrated the effectiveness of DT3OR compared to other state-of-the-art baselines.",
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "authors": [
                {
                    "authorId": "2154476091",
                    "name": "Xihong Yang"
                },
                {
                    "authorId": "2289502260",
                    "name": "Yiqi Wang"
                },
                {
                    "authorId": "2312345029",
                    "name": "Jin Chen"
                },
                {
                    "authorId": "2255025428",
                    "name": "Wenqi Fan"
                },
                {
                    "authorId": "2312340858",
                    "name": "Xiangyu Zhao"
                },
                {
                    "authorId": "2289198798",
                    "name": "En Zhu"
                },
                {
                    "authorId": "2268719211",
                    "name": "Xinwang Liu"
                },
                {
                    "authorId": "2312324042",
                    "name": "Defu Lian"
                }
            ]
        },
        {
            "paperId": "efd221731cee0e670ae2b65cb6649315d71cd01a",
            "title": "Rethinking Large Language Model Architectures for Sequential Recommendations",
            "abstract": "Recently, sequential recommendation has been adapted to the LLM paradigm to enjoy the power of LLMs. LLM-based methods usually formulate recommendation information into natural language and the model is trained to predict the next item in an auto-regressive manner. Despite their notable success, the substantial computational overhead of inference poses a significant obstacle to their real-world applicability. In this work, we endeavor to streamline existing LLM-based recommendation models and propose a simple yet highly effective model Lite-LLM4Rec. The primary goal of Lite-LLM4Rec is to achieve efficient inference for the sequential recommendation task. Lite-LLM4Rec circumvents the beam search decoding by using a straight item projection head for ranking scores generation. This design stems from our empirical observation that beam search decoding is ultimately unnecessary for sequential recommendations. Additionally, Lite-LLM4Rec introduces a hierarchical LLM structure tailored to efficiently handle the extensive contextual information associated with items, thereby reducing computational overhead while enjoying the capabilities of LLMs. Experiments on three publicly available datasets corroborate the effectiveness of Lite-LLM4Rec in both performance and inference efficiency (notably 46.8% performance improvement and 97.28% efficiency improvement on ML-1m) over existing LLM-based methods. Our implementations will be open sourced.",
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "authors": [
                {
                    "authorId": "2284304726",
                    "name": "Hanbing Wang"
                },
                {
                    "authorId": "2124928119",
                    "name": "Xiaorui Liu"
                },
                {
                    "authorId": "2255025428",
                    "name": "Wenqi Fan"
                },
                {
                    "authorId": "2116710405",
                    "name": "Xiangyu Zhao"
                },
                {
                    "authorId": "3245677",
                    "name": "Venkataramana B. Kini"
                },
                {
                    "authorId": "2284224395",
                    "name": "Devendra Yadav"
                },
                {
                    "authorId": "2284327268",
                    "name": "Fei Wang"
                },
                {
                    "authorId": "2284300150",
                    "name": "Zhen Wen"
                },
                {
                    "authorId": "2240599706",
                    "name": "Jiliang Tang"
                },
                {
                    "authorId": "2253533415",
                    "name": "Hui Liu"
                }
            ]
        },
        {
            "paperId": "9be934355f24c0c4f8757e839e352efab96649cb",
            "title": "Revisiting Link Prediction: A Data Perspective",
            "abstract": "Link prediction, a fundamental task on graphs, has proven indispensable in various applications, e.g., friend recommendation, protein analysis, and drug interaction prediction. However, since datasets span a multitude of domains, they could have distinct underlying mechanisms of link formation. Evidence in existing literature underscores the absence of a universally best algorithm suitable for all datasets. In this paper, we endeavor to explore principles of link prediction across diverse datasets from a data-centric perspective. We recognize three fundamental factors critical to link prediction: local structural proximity, global structural proximity, and feature proximity. We then unearth relationships among those factors where (i) global structural proximity only shows effectiveness when local structural proximity is deficient. (ii) The incompatibility can be found between feature and structural proximity. Such incompatibility leads to GNNs for Link Prediction (GNN4LP) consistently underperforming on edges where the feature proximity factor dominates. Inspired by these new insights from a data perspective, we offer practical instruction for GNN4LP model design and guidelines for selecting appropriate benchmark datasets for more comprehensive evaluations.",
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "authors": [
                {
                    "authorId": "2125202063",
                    "name": "Haitao Mao"
                },
                {
                    "authorId": "2162405317",
                    "name": "Juanhui Li"
                },
                {
                    "authorId": "2220302956",
                    "name": "Harry Shomer"
                },
                {
                    "authorId": "2254637024",
                    "name": "Bingheng Li"
                },
                {
                    "authorId": "2255025428",
                    "name": "Wenqi Fan"
                },
                {
                    "authorId": "2254813628",
                    "name": "Yao Ma"
                },
                {
                    "authorId": "2256340293",
                    "name": "Tong Zhao"
                },
                {
                    "authorId": "2253409421",
                    "name": "Neil Shah"
                },
                {
                    "authorId": "2240599706",
                    "name": "Jiliang Tang"
                }
            ]
        },
        {
            "paperId": "e77a6fca31b12298c87a41a4384f3d1be2afc8c2",
            "title": "FT-Shield: A Watermark Against Unauthorized Fine-tuning in Text-to-Image Diffusion Models",
            "abstract": "Text-to-image generative models, especially those based on latent diffusion models (LDMs), have demonstrated outstanding ability in generating high-quality and high-resolution images from textual prompts. With this advancement, various fine-tuning methods have been developed to personalize text-to-image models for specific applications such as artistic style adaptation and human face transfer. However, such advancements have raised copyright concerns, especially when the data are used for personalization without authorization. For example, a malicious user can employ fine-tuning techniques to replicate the style of an artist without consent. In light of this concern, we propose FT-Shield, a watermarking solution tailored for the fine-tuning of text-to-image diffusion models. FT-Shield addresses copyright protection challenges by designing new watermark generation and detection strategies. In particular, it introduces an innovative algorithm for watermark generation. It ensures the seamless transfer of watermarks from training images to generated outputs, facilitating the identification of copyrighted material use. To tackle the variability in fine-tuning methods and their impact on watermark detection, FT-Shield integrates a Mixture of Experts (MoE) approach for watermark detection. Comprehensive experiments validate the effectiveness of our proposed FT-Shield.",
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "authors": [
                {
                    "authorId": "2218740984",
                    "name": "Yingqian Cui"
                },
                {
                    "authorId": "2256589810",
                    "name": "Jie Ren"
                },
                {
                    "authorId": "2254140893",
                    "name": "Yuping Lin"
                },
                {
                    "authorId": "2253881697",
                    "name": "Han Xu"
                },
                {
                    "authorId": "2185740224",
                    "name": "Pengfei He"
                },
                {
                    "authorId": "2253469617",
                    "name": "Yue Xing"
                },
                {
                    "authorId": "2255025428",
                    "name": "Wenqi Fan"
                },
                {
                    "authorId": "2253533415",
                    "name": "Hui Liu"
                },
                {
                    "authorId": "2115879611",
                    "name": "Jiliang Tang"
                }
            ]
        },
        {
            "paperId": "ede2eb7697b5e0a41c4f832813b365eb10d0ad9b",
            "title": "AutoEmb: Automated Embedding Dimensionality Search in Streaming Recommendations",
            "abstract": "Deep learning-based recommender systems (DLRSs) often have embedding layers, which are utilized to lessen the dimension of categorical variables (e.g., user/item identifiers) and meaningfully transform them in the low-dimensional space. The majority of existing DLRSs empirically pre-define a fixed and unified dimension for all user/item embeddings. It is evident from recent researches that different embedding sizes are highly desired for different users/items according to their frequency. However, manually selecting embedding sizes in recommender systems can be very challenging due to a large number of users/items and the dynamic nature of their frequency. Thus, in this paper, we propose an AutoML based end-to-end framework (AutoEmb), enabling various embedding dimensions according to the frequency in an automated and dynamic manner. To be specific, we first enhance a typical DLRS to allow various embedding dimensions; then, we propose an end-to-end differentiable framework that can automatically select different embedding dimensions according to user/item frequency; finally, we propose an AutoML based optimization algorithm in a streaming recommendation setting. The experimental results based on widely used benchmark datasets demonstrate the effectiveness of the AutoEmb framework.",
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "authors": [
                {
                    "authorId": "2116710405",
                    "name": "Xiangyu Zhao"
                },
                {
                    "authorId": "66442354",
                    "name": "Haochen Liu"
                },
                {
                    "authorId": "2255025428",
                    "name": "Wenqi Fan"
                },
                {
                    "authorId": "2146672392",
                    "name": "Hui Liu"
                },
                {
                    "authorId": "2240599706",
                    "name": "Jiliang Tang"
                },
                {
                    "authorId": "2128077726",
                    "name": "Chong Wang"
                },
                {
                    "authorId": "2265558277",
                    "name": "Ming Chen"
                },
                {
                    "authorId": "2265622616",
                    "name": "Xudong Zheng"
                },
                {
                    "authorId": "2265595188",
                    "name": "Xiaobing Liu"
                },
                {
                    "authorId": "2265577657",
                    "name": "Xiwang Yang"
                }
            ]
        }
    ]
}