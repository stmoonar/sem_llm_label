{
    "authorId": "143995221",
    "papers": [
        {
            "paperId": "4b531e2e65ae2f8e989342fbe8e41d2822584be8",
            "title": "Fairness Aware Counterfactuals for Subgroups",
            "abstract": "In this work, we present Fairness Aware Counterfactuals for Subgroups (FACTS), a framework for auditing subgroup fairness through counterfactual explanations. We start with revisiting (and generalizing) existing notions and introducing new, more refined notions of subgroup fairness. We aim to (a) formulate different aspects of the difficulty of individuals in certain subgroups to achieve recourse, i.e. receive the desired outcome, either at the micro level, considering members of the subgroup individually, or at the macro level, considering the subgroup as a whole, and (b) introduce notions of subgroup fairness that are robust, if not totally oblivious, to the cost of achieving recourse. We accompany these notions with an efficient, model-agnostic, highly parameterizable, and explainable framework for evaluating subgroup fairness. We demonstrate the advantages, the wide applicability, and the efficiency of our approach through a thorough experimental evaluation of different benchmark datasets.",
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "authors": [
                {
                    "authorId": "3434260",
                    "name": "Loukas Kavouras"
                },
                {
                    "authorId": "2220631616",
                    "name": "Konstantinos Tsopelas"
                },
                {
                    "authorId": "40397337",
                    "name": "G. Giannopoulos"
                },
                {
                    "authorId": "1760642",
                    "name": "Dimitris Sacharidis"
                },
                {
                    "authorId": "2139143386",
                    "name": "Eleni Psaroudaki"
                },
                {
                    "authorId": "2220631614",
                    "name": "Nikolaos Theologitis"
                },
                {
                    "authorId": "150081157",
                    "name": "D. Rontogiannis"
                },
                {
                    "authorId": "143995221",
                    "name": "Dimitris Fotakis"
                },
                {
                    "authorId": "1804042",
                    "name": "I. Emiris"
                }
            ]
        },
        {
            "paperId": "c5fe40da42a4df3b58ab2a4204922dcf76368053",
            "title": "Optimizing Solution-Samplers for Combinatorial Problems: The Landscape of Policy-Gradient Methods",
            "abstract": "Deep Neural Networks and Reinforcement Learning methods have empirically shown great promise in tackling challenging combinatorial problems. In those methods a deep neural network is used as a solution generator which is then trained by gradient-based methods (e.g., policy gradient) to successively obtain better solution distributions. In this work we introduce a novel theoretical framework for analyzing the effectiveness of such methods. We ask whether there exist generative models that (i) are expressive enough to generate approximately optimal solutions; (ii) have a tractable, i.e, polynomial in the size of the input, number of parameters; (iii) their optimization landscape is benign in the sense that it does not contain sub-optimal stationary points. Our main contribution is a positive answer to this question. Our result holds for a broad class of combinatorial problems including Max- and Min-Cut, Max-$k$-CSP, Maximum-Weight-Bipartite-Matching, and the Traveling Salesman Problem. As a byproduct of our analysis we introduce a novel regularization process over vanilla gradient descent and provide theoretical and experimental evidence that it helps address vanishing-gradient issues and escape bad stationary points.",
            "fieldsOfStudy": [
                "Computer Science",
                "Mathematics"
            ],
            "authors": [
                {
                    "authorId": "1764494",
                    "name": "C. Caramanis"
                },
                {
                    "authorId": "143995221",
                    "name": "Dimitris Fotakis"
                },
                {
                    "authorId": "1796255018",
                    "name": "Alkis Kalavasis"
                },
                {
                    "authorId": "22185842",
                    "name": "Vasilis Kontonis"
                },
                {
                    "authorId": "2347899",
                    "name": "Christos Tzamos"
                }
            ]
        },
        {
            "paperId": "33fc1f2859d8f1bc0d36dc252e35566c91c367b4",
            "title": "Differentially Private Regression with Unbounded Covariates",
            "abstract": "We provide computationally efficient, differentially private algorithms for the classical regression settings of Least Squares Fitting, Binary Regression and Linear Regression with unbounded covariates. Prior to our work, privacy constraints in such regression settings were studied under strong a priori bounds on covariates. We consider the case of Gaussian marginals and extend recent differentially private techniques on mean and covariance estimation (Kamath et al., 2019; Karwa and Vadhan, 2018) to the sub-gaussian regime. We provide a novel technical analysis yielding differentially private algorithms for the above classical regression settings. Through the case of Binary Regression, we capture the fundamental and widely-studied models of logistic regression and linearly-separable SVMs, learning an unbiased estimate of the true regression vector, up to a scaling factor.",
            "fieldsOfStudy": [
                "Computer Science",
                "Mathematics"
            ],
            "authors": [
                {
                    "authorId": "16635884",
                    "name": "Jason Milionis"
                },
                {
                    "authorId": "1796255018",
                    "name": "Alkis Kalavasis"
                },
                {
                    "authorId": "143995221",
                    "name": "Dimitris Fotakis"
                },
                {
                    "authorId": "1776006",
                    "name": "Stratis Ioannidis"
                }
            ]
        },
        {
            "paperId": "4b64e105076aec8ce706f4a107871a23201e9e95",
            "title": "Dimensionality and Coordination in Voting: The Distortion of STV",
            "abstract": "We study the performance of voting mechanisms from a utilitarian standpoint, under the recently introduced framework of metric-distortion, offering new insights along two main lines. First, if d represents the doubling dimension of the metric space, we show that the distortion of STV is O(d log log m), where m represents the number of candidates. For doubling metrics this implies an exponential improvement over the lower bound for general metrics, and as a special case it effectively answers a question left open by Skowron and Elkind (AAAI '17) regarding the distortion of STV under low-dimensional Euclidean spaces. More broadly, this constitutes the first nexus between the performance of any voting rule and the ``intrinsic dimensionality'' of the underlying metric space. We also establish a nearly-matching lower bound, refining the construction of Skowron and Elkind. Moreover, motivated by the efficiency of STV, we investigate whether natural learning rules can lead to low-distortion outcomes. Specifically, we introduce simple, deterministic and decentralized exploration/exploitation dynamics, and we show that they converge to a candidate with O(1) distortion.",
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "authors": [
                {
                    "authorId": "1935668541",
                    "name": "Ioannis Anagnostides"
                },
                {
                    "authorId": "143995221",
                    "name": "Dimitris Fotakis"
                },
                {
                    "authorId": "68973905",
                    "name": "Panagiotis Patsilinakos"
                }
            ]
        },
        {
            "paperId": "b0bb34a9a63ca1c5e8d828f88099ad3ff57b576b",
            "title": "Sampling and Optimal Preference Elicitation in Simple Mechanisms",
            "abstract": "In this work we are concerned with the design of efficient mechanisms while eliciting limited information from the agents. First, we study the performance of sampling approximations in facility location games. Our key result is to show that for any $\\epsilon>0$, a sample of size $c(\\epsilon) = \\Theta(1/\\epsilon^2)$ yields in expectation a $1 + \\epsilon$ approximation with respect to the optimal social cost of the generalized median mechanism on the metric space $(\\mathbb{R}^d, \\| \\cdot \\|_1)$, while the number of agents $n \\to \\infty$. Moreover, we study a series of exemplar environments from auction theory through a communication complexity framework, measuring the expected number of bits elicited from the agents; we posit that any valuation can be expressed with $k$ bits, and we mainly assume that $k$ is independent of the number of agents $n$. In this context, we show that Vickrey's rule can be implemented with an expected communication of $1 + \\epsilon$ bits from an average bidder, for any $\\epsilon>0$, asymptotically matching the trivial lower bound. As a corollary, we provide a compelling method to increment the price in an English auction. We also leverage our single-item format with an efficient encoding scheme to prove that the same communication bound can be recovered in the domain of additive valuations through simultaneous ascending auctions, assuming that the number of items is a constant. Finally, we propose an ascending-type multi-unit auction under unit demand bidders; our mechanism announces at every round two separate prices and is based on a sampling algorithm that performs approximate selection with limited communication, leading again to asymptotically optimal communication. Our results do not require any prior knowledge on the agents' valuations, and mainly follow from natural sampling techniques.",
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "authors": [
                {
                    "authorId": "1935668541",
                    "name": "Ioannis Anagnostides"
                },
                {
                    "authorId": "143995221",
                    "name": "Dimitris Fotakis"
                },
                {
                    "authorId": "68973905",
                    "name": "Panagiotis Patsilinakos"
                }
            ]
        },
        {
            "paperId": "bf2ee5bb71037d1d796597d7a2223bed461f0f0e",
            "title": "Perfect Sampling from Pairwise Comparisons",
            "abstract": "In this work, we study how to efficiently obtain perfect samples from a discrete distribution $\\mathcal{D}$ given access only to pairwise comparisons of elements of its support. Specifically, we assume access to samples $(x, S)$, where $S$ is drawn from a distribution over sets $\\mathcal{Q}$ (indicating the elements being compared), and $x$ is drawn from the conditional distribution $\\mathcal{D}_S$ (indicating the winner of the comparison) and aim to output a clean sample $y$ distributed according to $\\mathcal{D}$. We mainly focus on the case of pairwise comparisons where all sets $S$ have size 2. We design a Markov chain whose stationary distribution coincides with $\\mathcal{D}$ and give an algorithm to obtain exact samples using the technique of Coupling from the Past. However, the sample complexity of this algorithm depends on the structure of the distribution $\\mathcal{D}$ and can be even exponential in the support of $\\mathcal{D}$ in many natural scenarios. Our main contribution is to provide an efficient exact sampling algorithm whose complexity does not depend on the structure of $\\mathcal{D}$. To this end, we give a parametric Markov chain that mixes significantly faster given a good approximation to the stationary distribution. We can obtain such an approximation using an efficient learning from pairwise comparisons algorithm (Shah et al., JMLR 17, 2016). Our technique for speeding up sampling from a Markov chain whose stationary distribution is approximately known is simple, general and possibly of independent interest.",
            "fieldsOfStudy": [
                "Computer Science",
                "Mathematics"
            ],
            "authors": [
                {
                    "authorId": "143995221",
                    "name": "Dimitris Fotakis"
                },
                {
                    "authorId": "1796255018",
                    "name": "Alkis Kalavasis"
                },
                {
                    "authorId": "2347899",
                    "name": "Christos Tzamos"
                }
            ]
        },
        {
            "paperId": "c0b39916232558a060269d33b76b26964ece3734",
            "title": "Graph Connectivity with Noisy Queries",
            "abstract": "Graph connectivity is a fundamental combinatorial optimization problem that arises in many practical applications, where usually a spanning subgraph of a network is used for its operation. However, in the real world, links may fail unexpectedly deeming the networks non-operational, while checking whether a link is damaged is costly and possibly erroneous. After an event that has damaged an arbitrary subset of the edges, the network operator must find a spanning tree of the network using non-damaged edges by making as few checks as possible. Motivated by such questions, we study the problem of finding a spanning tree in a network, when we only have access to noisy queries of the form\"Does edge e exist?\". We design efficient algorithms, even when edges fail adversarially, for all possible error regimes; 2-sided error (where any answer might be erroneous), false positives (where\"no\"answers are always correct) and false negatives (where\"yes\"answers are always correct). In the first two regimes we provide efficient algorithms and give matching lower bounds for general graphs. In the False Negative case we design efficient algorithms for large interesting families of graphs (e.g. bounded treewidth, sparse). Using the previous results, we provide tight algorithms for the practically useful family of planar graphs in all error regimes.",
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "authors": [
                {
                    "authorId": "143995221",
                    "name": "Dimitris Fotakis"
                },
                {
                    "authorId": "146606253",
                    "name": "Evangelia Gergatsouli"
                },
                {
                    "authorId": "2182292321",
                    "name": "Charilaos Pipis"
                },
                {
                    "authorId": "2182292645",
                    "name": "Miltiadis Stouras"
                },
                {
                    "authorId": "2347899",
                    "name": "Christos Tzamos"
                }
            ]
        },
        {
            "paperId": "f19b8a0b1ab445770c029b1252ef7e63596b1b40",
            "title": "Linear Label Ranking with Bounded Noise",
            "abstract": "Label Ranking (LR) is the supervised task of learning a sorting function that maps feature vectors \ud835\udc65 \u2208 R \ud835\udc51 to rankings \ud835\udf0e ( \ud835\udc65 ) \u2208 S \ud835\udc58 over a finite set of \ud835\udc58 labels. We focus on the fundamental case of learning linear sorting functions (LSFs) under Gaussian marginals: \ud835\udc65 is sampled from the \ud835\udc51 -dimensional standard normal and the ground truth ranking \ud835\udf0e \u22c6 ( \ud835\udc65 ) is the ordering induced by sorting the coordinates of the vector \ud835\udc4a \u22c6 \ud835\udc65 , where \ud835\udc4a \u22c6 \u2208 R \ud835\udc58 \u00d7 \ud835\udc51 is unknown. We consider learning LSFs in the presence of bounded noise: assuming that a noiseless example is of the form ( \ud835\udc65 , \ud835\udf0e \u22c6 ( \ud835\udc65 )) , we observe ( \ud835\udc65 , \ud835\udf0b ) , where for any pair of elements \ud835\udc56 \u0338 = \ud835\udc57 , the probability that the order of \ud835\udc56, \ud835\udc57 is different in \ud835\udf0b than in \ud835\udf0e \u22c6 ( \ud835\udc65 ) is at most \ud835\udf02 < 1 / 2 . We design efficient non-proper and proper learning algorithms that learn hypotheses within normalized Kendall\u2019s Tau distance \ud835\udf16 from the ground truth with \ud835\udc41 = \u0303\ufe00 \ud835\udc42 ( \ud835\udc51 log( \ud835\udc58 ) /\ud835\udf16 ) labeled examples and runtime poly ( \ud835\udc41, \ud835\udc58 ) . For the more challenging top-\ud835\udc5f disagreement loss, we give an efficient proper learning algorithm that achieves \ud835\udf16 top-\ud835\udc5f disagreement with the ground truth with \ud835\udc41 = \u0303\ufe00 \ud835\udc42 ( \ud835\udc51\ud835\udc58\ud835\udc5f/\ud835\udf16 ) samples and poly ( \ud835\udc41 ) runtime.",
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "authors": [
                {
                    "authorId": "143995221",
                    "name": "Dimitris Fotakis"
                },
                {
                    "authorId": "1796255018",
                    "name": "Alkis Kalavasis"
                },
                {
                    "authorId": "22185842",
                    "name": "Vasilis Kontonis"
                },
                {
                    "authorId": "2347899",
                    "name": "Christos Tzamos"
                }
            ]
        },
        {
            "paperId": "0112f6b4cddb383523d96c70901d2d2b5066f535",
            "title": "Assigning and Scheduling Generalized Malleable Jobs under Submodular Processing Speeds",
            "abstract": ",",
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "authors": [
                {
                    "authorId": "143995221",
                    "name": "Dimitris Fotakis"
                },
                {
                    "authorId": "1708015",
                    "name": "J. Matuschke"
                },
                {
                    "authorId": "2096937",
                    "name": "O. Papadigenopoulos"
                }
            ]
        },
        {
            "paperId": "07e5c6faa5e13938dc6742c52c4fb11a2418ed58",
            "title": "Efficient Online Learning for Dynamic k-Clustering",
            "abstract": "We study dynamic clustering problems from the perspective of online learning. We consider an online learning problem, called \\textit{Dynamic $k$-Clustering}, in which $k$ centers are maintained in a metric space over time (centers may change positions) such as a dynamically changing set of $r$ clients is served in the best possible way. The connection cost at round $t$ is given by the \\textit{$p$-norm} of the vector consisting of the distance of each client to its closest center at round $t$, for some $p\\geq 1$ or $p = \\infty$. We present a \\textit{$\\Theta\\left( \\min(k,r) \\right)$-regret} polynomial-time online learning algorithm and show that, under some well-established computational complexity conjectures, \\textit{constant-regret} cannot be achieved in polynomial-time. In addition to the efficient solution of Dynamic $k$-Clustering, our work contributes to the long line of research on combinatorial online learning.",
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "authors": [
                {
                    "authorId": "143995221",
                    "name": "Dimitris Fotakis"
                },
                {
                    "authorId": "1787822",
                    "name": "G. Piliouras"
                },
                {
                    "authorId": "31659584",
                    "name": "Stratis Skoulakis"
                }
            ]
        }
    ]
}