{
    "authorId": "3358065",
    "papers": [
        {
            "paperId": "42c6c93b2ed24cdb19ccb4013a27369afb6886f5",
            "title": "Continual Learning on Graphs: Challenges, Solutions, and Opportunities",
            "abstract": "Continual learning on graph data has recently attracted paramount attention for its aim to resolve the catastrophic forgetting problem on existing tasks while adapting the sequentially updated model to newly emerged graph tasks. While there have been efforts to summarize progress on continual learning research over Euclidean data, e.g., images and texts, a systematic review of progress in continual learning on graphs, a.k.a, continual graph learning (CGL) or lifelong graph learning, is still demanding. Graph data are far more complex in terms of data structures and application scenarios, making CGL task settings, model designs, and applications extremely challenging. To bridge the gap, we provide a comprehensive review of existing continual graph learning (CGL) algorithms by elucidating the different task settings and categorizing the existing methods based on their characteristics. We compare the CGL methods with traditional continual learning techniques and analyze the applicability of the traditional continual learning techniques to CGL tasks. Additionally, we review the benchmark works that are crucial to CGL research. Finally, we discuss the remaining challenges and propose several future directions. We will maintain an up-to-date GitHub repository featuring a comprehensive list of CGL algorithms, accessible at https://github.com/UConn-DSIS/Survey-of-Continual-Learning-on-Graphs.",
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "authors": [
                {
                    "authorId": "3358065",
                    "name": "Xikun Zhang"
                },
                {
                    "authorId": "2276324326",
                    "name": "Dongjin Song"
                },
                {
                    "authorId": "2276069056",
                    "name": "Dacheng Tao"
                }
            ]
        },
        {
            "paperId": "44f6cea2aa05620fef00d8dc9e566918dc6771c9",
            "title": "Empowering Time Series Analysis with Large Language Models: A Survey",
            "abstract": "Recently, remarkable progress has been made over large language models (LLMs), demonstrating their unprecedented capability in varieties of natural language tasks. However, completely training a large general-purpose model from the scratch is challenging for time series analysis, due to the large volumes and varieties of time series data, as well as the non-stationarity that leads to concept drift impeding continuous model adaptation and re-training. Recent advances have shown that pre-trained LLMs can be exploited to capture complex dependencies in time series data and facilitate various applications. In this survey, we provide a systematic overview of existing methods that leverage LLMs for time series analysis. Specifically, we first state the challenges and motivations of applying language models in the context of time series as well as brief preliminaries of LLMs. Next, we summarize the general pipeline for LLM-based time series analysis, categorize existing methods into different groups (\\textit{i.e.}, direct query, tokenization, prompt design, fine-tune, and model integration), and highlight the key ideas within each group. We also discuss the applications of LLMs for both general and spatial-temporal time series data, tailored to specific domains. Finally, we thoroughly discuss future research opportunities to empower time series analysis with LLMs.",
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "authors": [
                {
                    "authorId": "2214140574",
                    "name": "Yushan Jiang"
                },
                {
                    "authorId": "2281612988",
                    "name": "Zijie Pan"
                },
                {
                    "authorId": "3358065",
                    "name": "Xikun Zhang"
                },
                {
                    "authorId": "2257349440",
                    "name": "Sahil Garg"
                },
                {
                    "authorId": "2257349988",
                    "name": "Anderson Schneider"
                },
                {
                    "authorId": "2246897295",
                    "name": "Yuriy Nevmyvaka"
                },
                {
                    "authorId": "2276324326",
                    "name": "Dongjin Song"
                }
            ]
        },
        {
            "paperId": "45dfa18409290d3cbed71d97b9dd435783cc7384",
            "title": "Topology-aware Embedding Memory for Continual Learning on Expanding Networks",
            "abstract": "Memory replay based techniques have shown great success for continual learning with incrementally accumulated Euclidean data. Directly applying them to continually expanding networks, however, leads to the potential memory explosion problem due to the need to buffer representative nodes and their associated topological neighborhood structures. To this end, we systematically analyze the key challenges in the memory explosion problem, and present a general framework, \\textit{i.e.}, Parameter Decoupled Graph Neural Networks (PDGNNs) with Topology-aware Embedding Memory (TEM), to tackle this issue. The proposed framework not only reduces the memory space complexity from $\\mathcal{O}(nd^L)$ to $\\mathcal{O}(n)$~\\footnote{$n$: memory budget, $d$: average node degree, $L$: the radius of the GNN receptive field}, but also fully utilizes the topological information for memory replay. Specifically, PDGNNs decouple trainable parameters from the computation ego-subnetwork via \\textit{Topology-aware Embeddings} (TEs), which compress ego-subnetworks into compact vectors (\\textit{i.e.}, TEs) to reduce the memory consumption. Based on this framework, we discover a unique \\textit{pseudo-training effect} in continual learning on expanding networks and this effect motivates us to develop a novel \\textit{coverage maximization sampling} strategy that can enhance the performance with a tight memory budget. Thorough empirical studies demonstrate that, by tackling the memory explosion problem and incorporating topological information into memory replay, PDGNNs with TEM significantly outperform state-of-the-art techniques, especially in the challenging class-incremental setting.",
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "authors": [
                {
                    "authorId": "3358065",
                    "name": "Xikun Zhang"
                },
                {
                    "authorId": "2276324326",
                    "name": "Dongjin Song"
                },
                {
                    "authorId": "2223152252",
                    "name": "Yixin Chen"
                },
                {
                    "authorId": "2276069056",
                    "name": "Dacheng Tao"
                }
            ]
        },
        {
            "paperId": "c4d4149a0d0bf727b22d3e3c297ddd7760cd69c0",
            "title": "Topology-aware Embedding Memory for Learning on Expanding Graphs",
            "abstract": "Memory replay based techniques have shown great success for continual learning with incrementally accumulated Euclidean data. Directly applying them to continually expanding graphs, however, leads to the potential memory explosion problem due to the need to buffer representative nodes and their associated topological neighborhood structures. To this end, we systematically analyze the key challenges in the memory explosion problem, and present a general framework, i.e. , Parameter Decoupled Graph Neural Networks (PDGNNs) with Topology-aware Embedding Memory (TEM), to tackle this issue. The proposed framework not only reduces the memory space complexity from O( \ud835\udc5b\ud835\udc51 \ud835\udc3f ) to O( \ud835\udc5b ) 1 , but also fully utilizes the topological information for memory replay. Specifically, PDGNNs decouple trainable parameters from the computation ego-subgraph via Topology-aware Embeddings (TEs), which compress ego-subgraphs into compact vectors ( i.e. , TEs) to reduce the memory consumption. Based on this framework, we discover a unique pseudo-training effect in continual learning on expanding graphs and this effect motivates us to develop a novel coverage maximization sampling strategy that can enhance the performance with a tight memory budget. Thorough empirical studies demonstrate that, by tackling the memory explosion problem and incorporating topological information into memory replay, PDGNNs with TEM significantly outperform state-of-the-art techniques, especially in the challenging class-incremental setting. All code will be publicly available.",
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "authors": [
                {
                    "authorId": "3358065",
                    "name": "Xikun Zhang"
                },
                {
                    "authorId": "2276324326",
                    "name": "Dongjin Song"
                },
                {
                    "authorId": "2223152252",
                    "name": "Yixin Chen"
                },
                {
                    "authorId": "2276069056",
                    "name": "Dacheng Tao"
                }
            ]
        },
        {
            "paperId": "cb4045f3e6f4dfdaceedc6d8a70fc7a232722b3e",
            "title": "Learning System Dynamics without Forgetting",
            "abstract": "Predicting the trajectories of systems with unknown dynamics (\\textit{i.e.} the governing rules) is crucial in various research fields, including physics and biology. This challenge has gathered significant attention from diverse communities. Most existing works focus on learning fixed system dynamics within one single system. However, real-world applications often involve multiple systems with different types of dynamics or evolving systems with non-stationary dynamics (dynamics shifts). When data from those systems are continuously collected and sequentially fed to machine learning models for training, these models tend to be biased toward the most recently learned dynamics, leading to catastrophic forgetting of previously observed/learned system dynamics. To this end, we aim to learn system dynamics via continual learning. Specifically, we present a novel framework of Mode-switching Graph ODE (MS-GODE), which can continually learn varying dynamics and encode the system-specific dynamics into binary masks over the model parameters. During the inference stage, the model can select the most confident mask based on the observational data to identify the system and predict future trajectories accordingly. Empirically, we systematically investigate the task configurations and compare the proposed MS-GODE with state-of-the-art techniques. More importantly, we construct a novel benchmark of biological dynamic systems, featuring diverse systems with disparate dynamics and significantly enriching the research field of machine learning for dynamic systems.",
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "authors": [
                {
                    "authorId": "3358065",
                    "name": "Xikun Zhang"
                },
                {
                    "authorId": "2276324326",
                    "name": "Dongjin Song"
                },
                {
                    "authorId": "2214140574",
                    "name": "Yushan Jiang"
                },
                {
                    "authorId": "2223152252",
                    "name": "Yixin Chen"
                },
                {
                    "authorId": "2276069056",
                    "name": "Dacheng Tao"
                }
            ]
        },
        {
            "paperId": "6d18dcd4b562ea15f3270551b71596b2a1980b07",
            "title": "Tutorials at The Web Conference 2023",
            "abstract": "This paper summarizes the content of the 28 tutorials that have been given at The Web Conference 2023.",
            "fieldsOfStudy": [
                "Computer Science",
                "Physics"
            ],
            "authors": [
                {
                    "authorId": "1705291",
                    "name": "Valeria Fionda"
                },
                {
                    "authorId": "2215622430",
                    "name": "Olaf Hartig"
                },
                {
                    "authorId": "1805958417",
                    "name": "Reyhaneh Abdolazimi"
                },
                {
                    "authorId": "1403657578",
                    "name": "S. Amer-Yahia"
                },
                {
                    "authorId": "2215690996",
                    "name": "Hongzhi Chen"
                },
                {
                    "authorId": "2117027107",
                    "name": "Xiao Chen"
                },
                {
                    "authorId": "2052469774",
                    "name": "P. Cui"
                },
                {
                    "authorId": "145269114",
                    "name": "Jeffrey Dalton"
                },
                {
                    "authorId": "2215596266",
                    "name": "Xin Luna Dong"
                },
                {
                    "authorId": "2957808",
                    "name": "Lisette Espin Noboa"
                },
                {
                    "authorId": "41031455",
                    "name": "Wenqi Fan"
                },
                {
                    "authorId": "2132398392",
                    "name": "Manuela Fritz"
                },
                {
                    "authorId": "47594426",
                    "name": "Quan Gan"
                },
                {
                    "authorId": "2161309826",
                    "name": "Jingtong Gao"
                },
                {
                    "authorId": "46909769",
                    "name": "Xiaojie Guo"
                },
                {
                    "authorId": "2215622544",
                    "name": "Torsten Hahmann"
                },
                {
                    "authorId": "145325584",
                    "name": "Jiawei Han"
                },
                {
                    "authorId": "2046142",
                    "name": "S. Han"
                },
                {
                    "authorId": "1842532",
                    "name": "Estevam Hruschka"
                },
                {
                    "authorId": "2118850040",
                    "name": "Liang Hu"
                },
                {
                    "authorId": "2139299903",
                    "name": "Jiaxin Huang"
                },
                {
                    "authorId": "47247243",
                    "name": "Utkarshani Jaimini"
                },
                {
                    "authorId": "2299944027",
                    "name": "Olivier Jeunen"
                },
                {
                    "authorId": "2214140574",
                    "name": "Yushan Jiang"
                },
                {
                    "authorId": "51118506",
                    "name": "F. Karimi"
                },
                {
                    "authorId": "50877490",
                    "name": "G. Karypis"
                },
                {
                    "authorId": "1769861",
                    "name": "K. Kenthapadi"
                },
                {
                    "authorId": "1892673",
                    "name": "Himabindu Lakkaraju"
                },
                {
                    "authorId": "3309003",
                    "name": "Hady W. Lauw"
                },
                {
                    "authorId": "145535348",
                    "name": "Thai Le"
                },
                {
                    "authorId": "1808423005",
                    "name": "Trung-Hoang Le"
                },
                {
                    "authorId": "2158951945",
                    "name": "Dongwon Lee"
                },
                {
                    "authorId": "2110855835",
                    "name": "Geon Lee"
                },
                {
                    "authorId": "19326298",
                    "name": "Liat Levontin"
                },
                {
                    "authorId": "2144231489",
                    "name": "Cheng-Te Li"
                },
                {
                    "authorId": "144911687",
                    "name": "Haoyang Li"
                },
                {
                    "authorId": "2110471246",
                    "name": "Ying Li"
                },
                {
                    "authorId": "2030126978",
                    "name": "Jay Chiehen Liao"
                },
                {
                    "authorId": "2157067900",
                    "name": "Qidong Liu"
                },
                {
                    "authorId": "46189109",
                    "name": "Usha Lokala"
                },
                {
                    "authorId": "2085850",
                    "name": "Ben London"
                },
                {
                    "authorId": "32545338",
                    "name": "Siqu Long"
                },
                {
                    "authorId": "153612944",
                    "name": "H. Mcginty"
                },
                {
                    "authorId": "145391513",
                    "name": "Yu Meng"
                },
                {
                    "authorId": "29072828",
                    "name": "Seungwhan Moon"
                },
                {
                    "authorId": "1394609613",
                    "name": "Usman Naseem"
                },
                {
                    "authorId": "49824581",
                    "name": "P. Natarajan"
                },
                {
                    "authorId": "1403851743",
                    "name": "Behrooz Omidvar-Tehrani"
                },
                {
                    "authorId": "2069543964",
                    "name": "Zijie Pan"
                },
                {
                    "authorId": "48331451",
                    "name": "Devesh Parekh"
                },
                {
                    "authorId": "2188744953",
                    "name": "Jian Pei"
                },
                {
                    "authorId": "2101664",
                    "name": "Tiago P. Peixoto"
                },
                {
                    "authorId": "144615425",
                    "name": "S. Pemberton"
                },
                {
                    "authorId": "144179461",
                    "name": "Josiah Poon"
                },
                {
                    "authorId": "2065812052",
                    "name": "Filip Radlinski"
                },
                {
                    "authorId": "48890086",
                    "name": "Federico Rossetto"
                },
                {
                    "authorId": "2091913080",
                    "name": "Kaushik Roy"
                },
                {
                    "authorId": "2911888",
                    "name": "Aghiles Salah"
                },
                {
                    "authorId": "2128305",
                    "name": "M. Sameki"
                },
                {
                    "authorId": "2064342729",
                    "name": "Amit P. Sheth"
                },
                {
                    "authorId": "28908689",
                    "name": "C. Shimizu"
                },
                {
                    "authorId": "40553270",
                    "name": "Kijung Shin"
                },
                {
                    "authorId": "2451800",
                    "name": "Dongjin Song"
                },
                {
                    "authorId": "1682824",
                    "name": "Julia Stoyanovich"
                },
                {
                    "authorId": "2064266862",
                    "name": "Dacheng Tao"
                },
                {
                    "authorId": "2528063",
                    "name": "Johanne R. Trippas"
                },
                {
                    "authorId": "39603708",
                    "name": "Quoc-Tuan Truong"
                },
                {
                    "authorId": "1896151979",
                    "name": "Yu-Che Tsai"
                },
                {
                    "authorId": "150035131",
                    "name": "Adaku Uchendu"
                },
                {
                    "authorId": "2215624802",
                    "name": "Bram Van Den Akker"
                },
                {
                    "authorId": "3265905",
                    "name": "Linshan Wang"
                },
                {
                    "authorId": "2144295736",
                    "name": "Minjie Wang"
                },
                {
                    "authorId": "2116951322",
                    "name": "Shoujin Wang"
                },
                {
                    "authorId": "2153691630",
                    "name": "Xin Wang"
                },
                {
                    "authorId": "1684687",
                    "name": "Ingmar Weber"
                },
                {
                    "authorId": "69047048",
                    "name": "H. Weld"
                },
                {
                    "authorId": "2116666963",
                    "name": "Lingfei Wu"
                },
                {
                    "authorId": "2181385841",
                    "name": "D. Xu"
                },
                {
                    "authorId": "2138609128",
                    "name": "E. Xu"
                },
                {
                    "authorId": "2111044480",
                    "name": "Shuyuan Xu"
                },
                {
                    "authorId": "2156653838",
                    "name": "Bo Yang"
                },
                {
                    "authorId": "2125559318",
                    "name": "Keyue Yang"
                },
                {
                    "authorId": "1388775854",
                    "name": "E. Yom-Tov"
                },
                {
                    "authorId": "31888223",
                    "name": "Jaemin Yoo"
                },
                {
                    "authorId": "144007938",
                    "name": "Zhou Yu"
                },
                {
                    "authorId": "2281410",
                    "name": "R. Zafarani"
                },
                {
                    "authorId": "2499986",
                    "name": "Hamed Zamani"
                },
                {
                    "authorId": "41154657",
                    "name": "Meike Zehlike"
                },
                {
                    "authorId": "2145906426",
                    "name": "Qi Zhang"
                },
                {
                    "authorId": "3358065",
                    "name": "Xikun Zhang"
                },
                {
                    "authorId": "1739818",
                    "name": "Yongfeng Zhang"
                },
                {
                    "authorId": "49891156",
                    "name": "Yu Zhang"
                },
                {
                    "authorId": "2148904413",
                    "name": "Zhengqi Zhang"
                },
                {
                    "authorId": "144010790",
                    "name": "Liang Zhao"
                },
                {
                    "authorId": "2116710405",
                    "name": "Xiangyu Zhao"
                },
                {
                    "authorId": "2156154955",
                    "name": "Wenwu Zhu"
                }
            ]
        },
        {
            "paperId": "7559e646d1aa8e47dc60c513bcb9b97357e8833f",
            "title": "Sparsified Subgraph Memory for Continual Graph Representation Learning",
            "abstract": "Memory replay, which stores a subset of representative historical data from previous tasks to replay while learning new tasks, exhibits state-of-the-art performance for various continual learning applications on Euclidean data. While topological information plays a critical role in characterizing graph data, existing memory replay based graph learning techniques only store individual nodes for replay and do not consider their associated edge information. To this end, we propose a sparsified subgraph memory (SSM), which sparsifies the selected computation graphs into fixed size before storing them into the memory. In this way, we can reduce the memory consumption of a computation subgraph from $\\mathcal{O}(d^{L})$ to $\\mathcal{O}(1)$, and for the first time enable GNNs to utilize the explicit topological information for memory replay. Finally, our empirical studies show that SSM outperforms state-of-the-art approaches by up to 27.8% on four different public datasets. Unlike existing methods which focus on task incremental learning (task-IL) setting, SSM succeeds in the challenging class incremental learning (class-IL) setting in which a model is required to distinguish all learned classes without task indicators, and even achieves comparable performance to joint training which is the performance upper bound for continual learning. Our code is available at https://github.com/QueuQ/SSM.",
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "authors": [
                {
                    "authorId": "3358065",
                    "name": "Xikun Zhang"
                },
                {
                    "authorId": "2451800",
                    "name": "Dongjin Song"
                },
                {
                    "authorId": "143719920",
                    "name": "D. Tao"
                }
            ]
        },
        {
            "paperId": "d47a920f3a22377ff01e38b25f12bf1b1f3825e1",
            "title": "CGLB: Benchmark Tasks for Continual Graph Learning",
            "abstract": "Continual learning on graph data, which aims to accommodate new tasks over newly emerged graph data while maintaining the model performance over existing tasks, is attracting increasing attention from the community. Unlike continual learning on Euclidean data ( e.g. , images, texts, etc.) that has established benchmarks and unified experimental settings, benchmark tasks are rare for Continual Graph Learning (CGL). Moreover, due to the variety of graph data and its complex topological structures, existing works adopt different protocols to configure datasets and experimental settings. This creates a great obstacle to compare different techniques and thus hinders the development of CGL. To this end, we systematically study the task configurations in different application scenarios and develop a comprehensive Continual Graph Learning Benchmark (CGLB) curated from different public datasets. Specifically, CGLB contains both node-level and graph-level continual graph learning tasks under task-incremental (currently widely adopted) and class-incremental (more practical, challenging, yet underexplored) settings, as well as a toolkit for training, evaluating, and visualizing different CGL methods. Within CGLB, we also systematically explain the difference among these task configurations by comparing them to classical continual learning settings. Finally, we comprehensively compare state-of-the-art baselines on CGLB to investigate their effectiveness. Given CGLB and the developed toolkit, the barrier to exploring CGL has been greatly lowered and researchers can focus more on the model development without worrying about tedious work on pre-processing of datasets or encountering unseen pitfalls. The benchmark and the toolkit are available through https://github.com/QueuQ/CGLB .",
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "authors": [
                {
                    "authorId": "3358065",
                    "name": "Xikun Zhang"
                },
                {
                    "authorId": "2451800",
                    "name": "Dongjin Song"
                },
                {
                    "authorId": "2064266862",
                    "name": "Dacheng Tao"
                }
            ]
        },
        {
            "paperId": "080bd9fc763cb4d69044012abc62de23cc8b32d9",
            "title": "Context Aware Graph Convolution for Skeleton-Based Action Recognition",
            "abstract": "Graph convolutional models have gained impressive successes on skeleton based human action recognition task. As graph convolution is a local operation, it cannot fully investigate non-local joints that could be vital to recognizing the action. For example, actions like typing and clapping request the cooperation of two hands, which are distant from each other in a human skeleton graph. Multiple graph convolutional layers thus tend to be stacked together to increase receptive field, which brings in computational inefficiency and optimization difficulty. But there is still no guarantee that distant joints (e.g. two hands) can be well integrated. In this paper, we propose a context aware graph convolutional network (CA-GCN). Besides the computation of localized graph convolution, CA-GCN considers a context term for each vertex by integrating information of all other vertices. Long range dependencies among joints are thus naturally integrated in context information, which then eliminates the need of stacking multiple layers to enlarge receptive field and greatly simplifies the network. Moreover, we further propose an advanced CA-GCN, in which asymmetric relevance measurement and higher level representation are utilized to compute context information for more flexibility and better performance. Besides the joint features, our CA-GCN could also be extended to handle graphs with edge (limb) features. Extensive experiments on two real-world datasets demonstrate the importance of context information and the effectiveness of the proposed CA-GCN in skeleton based action recognition.",
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "authors": [
                {
                    "authorId": "3358065",
                    "name": "Xikun Zhang"
                },
                {
                    "authorId": null,
                    "name": "Chang Xu"
                },
                {
                    "authorId": "143719920",
                    "name": "D. Tao"
                }
            ]
        },
        {
            "paperId": "c8ca7b5212f22981e2867e51f17b2987e61add52",
            "title": "Graph Edge Convolutional Neural Networks for Skeleton-Based Action Recognition",
            "abstract": "Body joints, directly obtained from a pose estimation model, have proven effective for action recognition. Existing works focus on analyzing the dynamics of human joints. However, except joints, humans also explore motions of limbs for understanding actions. Given this observation, we investigate the dynamics of human limbs for skeleton-based action recognition. Specifically, we represent an edge in a graph of a human skeleton by integrating its spatial neighboring edges (for encoding the cooperation between different limbs) and its temporal neighboring edges (for achieving the consistency of movements in an action). Based on this new edge representation, we devise a graph edge convolutional neural network (CNN). Considering the complementarity between graph node convolution and edge convolution, we further construct two hybrid networks by introducing different shared intermediate layers to integrate graph node and edge CNNs. Our contributions are twofold, graph edge convolution and hybrid networks for integrating the proposed edge convolution and the conventional node convolution. Experimental results on the Kinetics and NTU-RGB+D data sets demonstrate that our graph edge convolution is effective at capturing the characteristics of actions and that our graph edge CNN significantly outperforms the existing state-of-the-art skeleton-based action recognition methods.",
            "fieldsOfStudy": [
                "Computer Science",
                "Medicine"
            ],
            "authors": [
                {
                    "authorId": "3358065",
                    "name": "Xikun Zhang"
                },
                {
                    "authorId": "48258751",
                    "name": "Chang Xu"
                },
                {
                    "authorId": "40434674",
                    "name": "Xinmei Tian"
                },
                {
                    "authorId": "143719920",
                    "name": "D. Tao"
                }
            ]
        }
    ]
}