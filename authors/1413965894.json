{
    "authorId": "1413965894",
    "papers": [
        {
            "paperId": "8d34c95aa916094f5668500c76d154b441df9afc",
            "title": "Re-Think Before You Share: A Comprehensive Study on Prioritizing Check-Worthy Claims",
            "abstract": "The massive amount of misinformation spreading on the internet on a daily basis has enormous negative impacts on societies. Therefore, we need systems to help fact-checkers to combat misinformation and to raise public awareness of this important problem. In this article, we propose a hybrid model which combines bidirectional encoder representations from transformer (BERT) model with various features to prioritize claims based on their check-worthiness. Features we use include domain-specific controversial topics (CT), word embeddings (WE), part-of-speech (POS) tags, and others. In addition, we explore various ways of increasing labeled data size to effectively train the models, such as increasing positive (IncPos) samples, active learning (AL), and utilizing labeled data in other languages. In our extensive experiments, we show that our model outperforms all state-of-the-art models in test collections of Conference and Labs of Evaluation Forum (CLEF) CheckThat! Lab (CTL) 2018 and 2019. In addition, when positive samples are increased in the training set, our model achieves the best mean average precision (MAP) score reported so far for the test collection of CTL 2020. Furthermore, we show that cross-lingual training is effective for prioritizing Arabic and Turkish claims, but not for English.",
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "authors": [
                {
                    "authorId": "1413965894",
                    "name": "Yavuz Selim Kartal"
                },
                {
                    "authorId": "38330039",
                    "name": "Mucahid Kutlu"
                }
            ]
        },
        {
            "paperId": "2a75cf81f1cafbcdc99d15467bdd4b8fca9a6902",
            "title": "Overview of the CLEF-2022 CheckThat! Lab Task 1 on Identifying Relevant Claims in Tweets",
            "abstract": "We present an overview of CheckThat! lab 2022 Task 1, part of the 2022 Conference and Labs of the Evaluation Forum (CLEF). Task 1 asked to predict which posts in a Twitter stream are worth fact-checking, focusing on COVID-19 and politics in six languages: Arabic, Bulgarian, Dutch, English, Spanish, and Turkish. A total of 19 teams participated and most submissions managed to achieve sizable improvements over the baselines using Transformer-based models such as BERT and GPT-3. Across the four subtasks, approaches that targetted multiple languages (be it individually or in conjunction, in general obtained the best performance. We describe the dataset and the task setup, including the evaluation settings, and we give a brief overview of the participating systems. As usual in the CheckThat! lab, we release to the research community all datasets from the lab as well as the evaluation scripts, which should enable further research on finding relevant tweets that can help different stakeholders such as fact-checkers, journalists, and policymakers. \u00a9 2022 Copyright for this paper by its authors.",
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "authors": [
                {
                    "authorId": "2026545715",
                    "name": "Preslav Nakov"
                },
                {
                    "authorId": "1397442049",
                    "name": "Alberto Barr\u00f3n-Cede\u00f1o"
                },
                {
                    "authorId": "34086979",
                    "name": "Giovanni Da San Martino"
                },
                {
                    "authorId": "37784060",
                    "name": "Firoj Alam"
                },
                {
                    "authorId": "31329752",
                    "name": "Rub\u00e9n M\u00edguez"
                },
                {
                    "authorId": "1864635",
                    "name": "Tommaso Caselli"
                },
                {
                    "authorId": "38330039",
                    "name": "Mucahid Kutlu"
                },
                {
                    "authorId": "2034351",
                    "name": "W. Zaghouani"
                },
                {
                    "authorId": "2128664093",
                    "name": "Chengkai Li"
                },
                {
                    "authorId": "65877664",
                    "name": "Shaden Shaar"
                },
                {
                    "authorId": "143779235",
                    "name": "Hamdy Mubarak"
                },
                {
                    "authorId": "47195288",
                    "name": "Alex Nikolov"
                },
                {
                    "authorId": "1413965894",
                    "name": "Yavuz Selim Kartal"
                }
            ]
        },
        {
            "paperId": "304229dd4671ee009503b7258df06b442ea2f3f0",
            "title": "Overview of the SV-Ident 2022 Shared Task on Survey Variable Identification in Social Science Publications",
            "abstract": "In this paper, we provide an overview of the SV-Ident shared task as part of the 3rd Workshop on Scholarly Document Processing (SDP) at COLING 2022. In the shared task, participants were provided with a sentence and a vocabulary of variables, and asked to identify which variables, if any, are mentioned in individual sentences from scholarly documents in full text. Two teams made a total of 9 submissions to the shared task leaderboard. While none of the teams improve on the baseline systems, we still draw insights from their submissions. Furthermore, we provide a detailed evaluation. Data and baselines for our shared task are freely available at https://github.com/vadis-project/sv-ident.",
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "authors": [
                {
                    "authorId": "2139739556",
                    "name": "Tornike Tsereteli"
                },
                {
                    "authorId": "1413965894",
                    "name": "Yavuz Selim Kartal"
                },
                {
                    "authorId": "2029669151",
                    "name": "Simone Paolo Ponzetto"
                },
                {
                    "authorId": "38977364",
                    "name": "Andrea Zielinski"
                },
                {
                    "authorId": "145216461",
                    "name": "K. Eckert"
                },
                {
                    "authorId": "1729725",
                    "name": "Philipp Mayr"
                }
            ]
        },
        {
            "paperId": "755d70ec67f247ebc22cb359ea06243d639fb64a",
            "title": "Towards Automated Survey Variable Search and Summarization in Social Science Publications",
            "abstract": "Nowadays there is a growing trend in many scientific disciplines to support researchers by providing enhanced information access through linking of publications and underlying datasets, so as to support research with infrastructure to enhance reproducibility and reusability of research results. In this research note, we present an overview of an ongoing research project, named VADIS (VAriable Detection, Interlinking and Summarization), that aims at developing technology and infrastructure for enhanced information access in the Social Sciences via search and summarization of publications on the basis of automatic identification and indexing of survey variables in text. We provide an overview of the overarching vision underlying our project, its main components, and related challenges, as well as a thorough discussion of how these are meant to address the limitations of current information access systems for publications in the Social Sciences. We show how this goal can be concretely implemented in an end-user system by presenting a search prototype, which is based on user requirements collected from qualitative interviews with empirical Social Science researchers.",
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "authors": [
                {
                    "authorId": "1413965894",
                    "name": "Yavuz Selim Kartal"
                },
                {
                    "authorId": "9390836",
                    "name": "Sotaro Takeshita"
                },
                {
                    "authorId": "2139739556",
                    "name": "Tornike Tsereteli"
                },
                {
                    "authorId": "145216461",
                    "name": "K. Eckert"
                },
                {
                    "authorId": "2184771570",
                    "name": "Henning Kroll"
                },
                {
                    "authorId": "1729725",
                    "name": "Philipp Mayr"
                },
                {
                    "authorId": "2029669151",
                    "name": "Simone Paolo Ponzetto"
                },
                {
                    "authorId": "2307659",
                    "name": "Benjamin Zapilko"
                },
                {
                    "authorId": "38977364",
                    "name": "Andrea Zielinski"
                }
            ]
        },
        {
            "paperId": "d4fe8aa354261bc82c21ad74d0e3802874cc3da3",
            "title": "Varanalysis@SV-Ident 2022: Variable Detection and Disambiguation Based on Semantic Similarity",
            "abstract": "This paper describes an approach to the SV-Ident Shared Task which requires the detection and disambiguation of survey variables in sentences taken from social science publications. It deals with both subtasks as problems of semantic textual similarity (STS) and relies on the use of sentence transformers. Sentences and variables are examined for semantic similarity for both detecting sentences containing variables and disambiguating the respective variables. The focus is placed on analyzing the effects of including different parts of the variables and observing the differences between English and German instances. Additionally, for the variable detection task a bag of words model is used to filter out sentences which are likely to contain a variable mention as a preselection of sentences to perform the semantic similarity comparison on.",
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "authors": [
                {
                    "authorId": "2181138688",
                    "name": "Alica H\u00f6velmeyer"
                },
                {
                    "authorId": "1413965894",
                    "name": "Yavuz Selim Kartal"
                }
            ]
        },
        {
            "paperId": "069cff8081de01bd9210b00677b77f9d0b2c869c",
            "title": "Overview of the CLEF-2021 CheckThat! Lab Task 1 on Check-Worthiness Estimation in Tweets and Political Debates",
            "abstract": "We present an overview of Task 1 of the fourth edition of the CheckThat! Lab, part of the 2021 Conference and Labs of the Evaluation Forum (CLEF). The task asks to predict which posts in a Twitter stream are worth fact-checking, focusing on COVID-19 and politics in five languages: Arabic, Bulgarian, English, Spanish, and Turkish. A total of 15 teams participated in this task and most submissions managed to achieve sizable improvements over the baselines using Transformer-based models such as BERT and RoBERTa. Here, we describe the process of data collection and the task setup, including the evaluation measures, and we give a brief overview of the participating systems. We release to the research community all datasets from the lab as well as the evaluation scripts, which should enable further research in check-worthiness estimation for tweets and political debates. \u00a9 2021 Copyright for this paper by its authors. Use permitted under Creative Commons License Attribution 4.0 International (CC BY 4.0).",
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "authors": [
                {
                    "authorId": "2121286474",
                    "name": "S. Shaar"
                },
                {
                    "authorId": "2905745",
                    "name": "Maram Hasanain"
                },
                {
                    "authorId": "2065206121",
                    "name": "Bayan Hamdan"
                },
                {
                    "authorId": "151267539",
                    "name": "Zien Sheikh Ali"
                },
                {
                    "authorId": "8685373",
                    "name": "Fatima Haouari"
                },
                {
                    "authorId": "47195288",
                    "name": "Alex Nikolov"
                },
                {
                    "authorId": "38330039",
                    "name": "Mucahid Kutlu"
                },
                {
                    "authorId": "1413965894",
                    "name": "Yavuz Selim Kartal"
                },
                {
                    "authorId": "37784060",
                    "name": "Firoj Alam"
                },
                {
                    "authorId": "34086979",
                    "name": "Giovanni Da San Martino"
                },
                {
                    "authorId": "1397442049",
                    "name": "Alberto Barr\u00f3n-Cede\u00f1o"
                },
                {
                    "authorId": "31329752",
                    "name": "Rub\u00e9n M\u00edguez"
                },
                {
                    "authorId": "2065257134",
                    "name": "Javier Beltr\u00e1n"
                },
                {
                    "authorId": "1693370300",
                    "name": "Tamer Elsayed"
                },
                {
                    "authorId": "2026545715",
                    "name": "Preslav Nakov"
                }
            ]
        },
        {
            "paperId": "79e3031cf53b6b59906ef59765a82351347510b2",
            "title": "TOBB ETU at CheckThat!\u00a02021: Data Engineering for Detecting Check-Worthy Claims",
            "abstract": "In this paper, we present our participation in CLEF 2021 CheckThat! Lab\u2019s Task 1 on check-worthiness estimation in tweets. We explore how to \uf6d5ne-tune transformer models e\u200cectively by changing the train set. The methods we explore include language-speci\uf6d5c training, weak supervision, data augmentation by machine translation, undersampling, and cross-lingual training. As our primary model submitted for o\uf6d4cial results, we \uf6d5ne-tune language-speci\uf6d5c BERT-based models using cleaned tweets for each language. Our models ranked 1 \ud835\udc60\ud835\udc61 in Spanish and Turkish datasets. However, our rank in Arabic, Bulgarian, and English datasets is 6 \ud835\udc61\u210e , 4 \ud835\udc61\u210e , and 10 \ud835\udc61\u210e , respectively.",
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "authors": [
                {
                    "authorId": "2120339869",
                    "name": "Muhammed Said Zengin"
                },
                {
                    "authorId": "1413965894",
                    "name": "Yavuz Selim Kartal"
                },
                {
                    "authorId": "38330039",
                    "name": "Mucahid Kutlu"
                }
            ]
        },
        {
            "paperId": "15302344aecfa6278af5bf10a94836ae0aca5efa",
            "title": "TrClaim-19: The First Collection for Turkish Check-Worthy Claim Detection with Annotator Rationales",
            "abstract": "Massive misinformation spread over Internet has many negative impacts on our lives. While spreading a claim is easy, investigating its veracity is hard and time consuming, Therefore, we urgently need systems to help human fact-checkers. However, available data resources to develop effective systems are limited and the vast majority of them is for English. In this work, we introduce TrClaim-19, which is the very first labeled dataset for Turkish check-worthy claims. TrClaim-19 consists of labeled 2287 Turkish tweets with annotator rationales, enabling us to better understand the characteristics of check-worthy claims. The rationales we collected suggest that claims\u2019 topics and their possible negative impacts are the main factors affecting their check-worthiness.",
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "authors": [
                {
                    "authorId": "1413965894",
                    "name": "Yavuz Selim Kartal"
                },
                {
                    "authorId": "38330039",
                    "name": "Mucahid Kutlu"
                }
            ]
        },
        {
            "paperId": "3ef82f52b840bdb3677e246337e21db4fdab02dd",
            "title": "Machine Learning Based Text Summarization for Turkish News",
            "abstract": "In this paper, we propose an automatic text summarization model for Turkish news articles using machine learning models. Our proposed model uses sentence position, speech expression, presence of named entities and statements, term frequency and title similarity as features. We construct and share a new dataset for Turkish text summarization. In our experiments, we show that all our features we use have a positive impact on the performance of the system. In addition, we show that our model outperforms the latent semantic analysis based baseline method.",
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "authors": [
                {
                    "authorId": "1413965894",
                    "name": "Yavuz Selim Kartal"
                },
                {
                    "authorId": "38330039",
                    "name": "Mucahid Kutlu"
                }
            ]
        },
        {
            "paperId": "832b87bc306d904abd2c3e9bc108d1ee06cb6577",
            "title": "Too Many Claims to Fact-Check: Prioritizing Political Claims Based on Check-Worthiness",
            "abstract": "The massive amount of misinformation spreading on the Internet on a daily basis has enormous negative impacts on societies. Therefore, we need automated systems helping fact-checkers in the combat against misinformation. In this paper, we propose a model prioritizing the claims based on their check-worthiness. We use BERT model with additional features including domain-specific controversial topics, word embeddings, and others. In our experiments, we show that our proposed model outperforms all state-of-the-art models in both test collections of CLEF Check That! Lab in 2018 and 2019. We also conduct a qualitative analysis to shed light-detecting check-worthy claims. We suggest requesting rationales behind judgments are needed to understand subjective nature of the task and problematic labels.",
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "authors": [
                {
                    "authorId": "1413965894",
                    "name": "Yavuz Selim Kartal"
                },
                {
                    "authorId": "1641671316",
                    "name": "B. Guvenen"
                },
                {
                    "authorId": "38330039",
                    "name": "Mucahid Kutlu"
                }
            ]
        }
    ]
}