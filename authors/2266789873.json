{
    "authorId": "2266789873",
    "papers": [
        {
            "paperId": "3a6e41b3bb092157ef6af2dd630e24d52471a789",
            "title": "CSRec: Rethinking Sequential Recommendation from A Causal Perspective",
            "abstract": "The essence of sequential recommender systems (RecSys) lies in understanding how users make decisions. Most existing approaches frame the task as sequential prediction based on users' historical purchase records. While effective in capturing users' natural preferences, this formulation falls short in accurately modeling actual recommendation scenarios, particularly in accounting for how unsuccessful recommendations influence future purchases. Furthermore, the impact of the RecSys itself on users' decisions has not been appropriately isolated and quantitatively analyzed. To address these challenges, we propose a novel formulation of sequential recommendation, termed Causal Sequential Recommendation (CSRec). Instead of predicting the next item in the sequence, CSRec aims to predict the probability of a recommended item's acceptance within a sequential context and backtrack how current decisions are made. Critically, CSRec facilitates the isolation of various factors that affect users' final decisions, especially the influence of the recommender system itself, thereby opening new avenues for the design of recommender systems. CSRec can be seamlessly integrated into existing methodologies. Experimental evaluations on both synthetic and real-world datasets demonstrate that the proposed implementation significantly improves upon state-of-the-art baselines.",
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "authors": [
                {
                    "authorId": "2158018357",
                    "name": "Xiaoyu Liu"
                },
                {
                    "authorId": "2261901774",
                    "name": "Jiaxin Yuan"
                },
                {
                    "authorId": "2266789873",
                    "name": "Yuhang Zhou"
                },
                {
                    "authorId": "2291078963",
                    "name": "Jingling Li"
                },
                {
                    "authorId": "2257407889",
                    "name": "Furong Huang"
                },
                {
                    "authorId": "2218202090",
                    "name": "Wei Ai"
                }
            ]
        },
        {
            "paperId": "3a74772a6011675ce2bdc87100fffcf4d18f5907",
            "title": "Large Language Models and Causal Inference in Collaboration: A Comprehensive Survey",
            "abstract": "Causal inference has shown potential in enhancing the predictive accuracy, fairness, robustness, and explainability of Natural Language Processing (NLP) models by capturing causal relationships among variables. The emergence of generative Large Language Models (LLMs) has significantly impacted various NLP domains, particularly through their advanced reasoning capabilities. This survey focuses on evaluating and improving LLMs from a causal view in the following areas: understanding and improving the LLMs' reasoning capacity, addressing fairness and safety issues in LLMs, complementing LLMs with explanations, and handling multimodality. Meanwhile, LLMs' strong reasoning capacities can in turn contribute to the field of causal inference by aiding causal relationship discovery and causal effect estimations. This review explores the interplay between causal inference frameworks and LLMs from both perspectives, emphasizing their collective potential to further the development of more advanced and equitable artificial intelligence systems.",
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "authors": [
                {
                    "authorId": "2158018357",
                    "name": "Xiaoyu Liu"
                },
                {
                    "authorId": "103226724",
                    "name": "Paiheng Xu"
                },
                {
                    "authorId": "2146666303",
                    "name": "Junda Wu"
                },
                {
                    "authorId": "2261901774",
                    "name": "Jiaxin Yuan"
                },
                {
                    "authorId": "2257361107",
                    "name": "Yifan Yang"
                },
                {
                    "authorId": "2266789873",
                    "name": "Yuhang Zhou"
                },
                {
                    "authorId": "52220309",
                    "name": "Fuxiao Liu"
                },
                {
                    "authorId": "2291143084",
                    "name": "Tianrui Guan"
                },
                {
                    "authorId": "2291313121",
                    "name": "Haoliang Wang"
                },
                {
                    "authorId": "1500399016",
                    "name": "Tong Yu"
                },
                {
                    "authorId": "2284680226",
                    "name": "Julian McAuley"
                },
                {
                    "authorId": "2218202090",
                    "name": "Wei Ai"
                },
                {
                    "authorId": "2257407889",
                    "name": "Furong Huang"
                }
            ]
        },
        {
            "paperId": "4499afc74bda1c7d521a516df040facfe39943ed",
            "title": "Enhancing Visual-Language Modality Alignment in Large Vision Language Models via Self-Improvement",
            "abstract": "Large vision-language models (LVLMs) have achieved impressive results in various visual question-answering and reasoning tasks through vision instruction tuning on specific datasets. However, there is still significant room for improvement in the alignment between visual and language modalities. Previous methods to enhance this alignment typically require external models or data, heavily depending on their capabilities and quality, which inevitably sets an upper bound on performance. In this paper, we propose SIMA, a framework that enhances visual and language modality alignment through self-improvement, eliminating the needs for external models or data. SIMA leverages prompts from existing vision instruction tuning datasets to self-generate responses and employs an in-context self-critic mechanism to select response pairs for preference tuning. The key innovation is the introduction of three vision metrics during the in-context self-critic process, which can guide the LVLM in selecting responses that enhance image comprehension. Through experiments across 14 hallucination and comprehensive benchmarks, we demonstrate that SIMA not only improves model performance across all benchmarks but also achieves superior modality alignment, outperforming previous approaches.",
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "authors": [
                {
                    "authorId": "2302790705",
                    "name": "Xiyao Wang"
                },
                {
                    "authorId": "1391200710",
                    "name": "Jiuhai Chen"
                },
                {
                    "authorId": "2303664290",
                    "name": "Zhaoyang Wang"
                },
                {
                    "authorId": "2266789873",
                    "name": "Yuhang Zhou"
                },
                {
                    "authorId": "2250759613",
                    "name": "Yiyang Zhou"
                },
                {
                    "authorId": "18307037",
                    "name": "Huaxiu Yao"
                },
                {
                    "authorId": "2303390941",
                    "name": "Tianyi Zhou"
                },
                {
                    "authorId": "2283845854",
                    "name": "Tom Goldstein"
                },
                {
                    "authorId": "2303385525",
                    "name": "Parminder Bhatia"
                },
                {
                    "authorId": "2268686199",
                    "name": "Furong Huang"
                },
                {
                    "authorId": "2303426039",
                    "name": "Cao Xiao"
                }
            ]
        },
        {
            "paperId": "4a402c7f4f2a5aaa1f8429be9dd19469d24b6d67",
            "title": "Emojis Decoded: Leveraging ChatGPT for Enhanced Understanding in Social Media Communications",
            "abstract": "Emojis, which encapsulate semantics beyond mere words or phrases, have become prevalent in social network communications. This has spurred increasing scholarly interest in exploring their attributes and functionalities. However, emoji-related research and application face two primary challenges. First, researchers typically rely on crowd-sourcing to annotate emojis in order to understand their sentiments, usage intentions, and semantic meanings. Second, subjective interpretations by users can often lead to misunderstandings of emojis and cause the communication barrier. Large Language Models (LLMs) have achieved significant success in various annotation tasks, with ChatGPT demonstrating expertise across multiple domains. In our study, we assess ChatGPT's effectiveness in handling previously annotated and downstream tasks. Our objective is to validate the hypothesis that ChatGPT can serve as a viable alternative to human annotators in emoji research and that its ability to explain emoji meanings can enhance clarity and transparency in online communications. Our findings indicate that ChatGPT has extensive knowledge of emojis. It is adept at elucidating the meaning of emojis across various application scenarios and demonstrates the potential to replace human annotators in a range of tasks.",
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "authors": [
                {
                    "authorId": "2266789873",
                    "name": "Yuhang Zhou"
                },
                {
                    "authorId": "103226724",
                    "name": "Paiheng Xu"
                },
                {
                    "authorId": "2282902714",
                    "name": "Xiyao Wang"
                },
                {
                    "authorId": "2282572921",
                    "name": "Xuan Lu"
                },
                {
                    "authorId": "2282528493",
                    "name": "Ge Gao"
                },
                {
                    "authorId": "2218202090",
                    "name": "Wei Ai"
                }
            ]
        },
        {
            "paperId": "6fa3544f42bc026ac684cf6c7a8cd50f59b3ee7d",
            "title": "Multi-Stage Balanced Distillation: Addressing Long-Tail Challenges in Sequence-Level Knowledge Distillation",
            "abstract": "Large language models (LLMs) have significantly advanced various natural language processing tasks, but deploying them remains computationally expensive. Knowledge distillation (KD) is a promising solution, enabling the transfer of capabilities from larger teacher LLMs to more compact student models. Particularly, sequence-level KD, which distills rationale-based reasoning processes instead of merely final outcomes, shows great potential in enhancing students' reasoning capabilities. However, current methods struggle with sequence level KD under long-tailed data distributions, adversely affecting generalization on sparsely represented domains. We introduce the Multi-Stage Balanced Distillation (BalDistill) framework, which iteratively balances training data within a fixed computational budget. By dynamically selecting representative head domain examples and synthesizing tail domain examples, BalDistill achieves state-of-the-art performance across diverse long-tailed datasets, enhancing both the efficiency and efficacy of the distilled models.",
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "authors": [
                {
                    "authorId": "2266789873",
                    "name": "Yuhang Zhou"
                },
                {
                    "authorId": "2307469621",
                    "name": "Jing Zhu"
                },
                {
                    "authorId": "103226724",
                    "name": "Paiheng Xu"
                },
                {
                    "authorId": "2158018357",
                    "name": "Xiaoyu Liu"
                },
                {
                    "authorId": "2282902714",
                    "name": "Xiyao Wang"
                },
                {
                    "authorId": "2479152",
                    "name": "Danai Koutra"
                },
                {
                    "authorId": "2218202090",
                    "name": "Wei Ai"
                },
                {
                    "authorId": "2268686199",
                    "name": "Furong Huang"
                }
            ]
        },
        {
            "paperId": "c315de920f4538b5a27219fd6bbb3cd4b50659f5",
            "title": "From Adoption to Adaption: Tracing the Diffusion of New Emojis on Twitter",
            "abstract": "In the rapidly evolving landscape of social media, the introduction of new emojis in Unicode release versions presents a structured opportunity to explore digital language evolution. Analyzing a large dataset of sampled English tweets, we examine how newly released emojis gain traction and evolve in meaning. We find that community size of early adopters and emoji semantics are crucial in determining their popularity. Certain emojis experienced notable shifts in the meanings and sentiment associations during the diffusion process. Additionally, we propose a novel framework utilizing language models to extract words and pre-existing emojis with semantically similar contexts, which enhances interpretation of new emojis. The framework demonstrates its effectiveness in improving sentiment classification performance by substituting unknown new emojis with familiar ones. This study offers a new perspective in understanding how new language units are adopted, adapted, and integrated into the fabric of online communication.",
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "authors": [
                {
                    "authorId": "2266789873",
                    "name": "Yuhang Zhou"
                },
                {
                    "authorId": "2282572921",
                    "name": "Xuan Lu"
                },
                {
                    "authorId": "2218202090",
                    "name": "Wei Ai"
                }
            ]
        },
        {
            "paperId": "f236d6f9c376dc453d7db11d15c8d9bc519adf65",
            "title": "Teaching-Assistant-in-the-Loop: Improving Knowledge Distillation from Imperfect Teacher Models in Low-Budget Scenarios",
            "abstract": "There is increasing interest in distilling task-specific knowledge from large language models (LLM) to smaller student models. Nonetheless, LLM distillation presents a dual challenge: 1) there is a high cost associated with querying the teacher LLM, such as GPT-4, for gathering an ample number of demonstrations; 2) the teacher LLM might provide imperfect outputs with a negative impact on the student's learning process. To enhance sample efficiency within resource-constrained, imperfect teacher scenarios, we propose a three-component framework leveraging three signal types. The first signal is the student's self-consistency (consistency of student multiple outputs), which is a proxy of the student's confidence. Specifically, we introduce a ``teaching assistant'' (TA) model to assess the uncertainty of both the student's and the teacher's outputs via confidence scoring, which serves as another two signals for student training. Furthermore, we propose a two-stage training schema to first warm up the student with a small proportion of data to better utilize student's signal. Experiments have shown the superiority of our proposed framework for four complex reasoning tasks. On average, our proposed two-stage framework brings a relative improvement of up to 20.79% compared to fine-tuning without any signals across datasets.",
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "authors": [
                {
                    "authorId": "2266789873",
                    "name": "Yuhang Zhou"
                },
                {
                    "authorId": "2218202090",
                    "name": "Wei Ai"
                }
            ]
        },
        {
            "paperId": "6ce4684a197465c4a77390bf2bd2486d51f3199e",
            "title": "SpotTarget: Rethinking the Effect of Target Edges for Link Prediction in Graph Neural Networks",
            "abstract": "Graph Neural Networks (GNNs) have demonstrated promising outcomes across various tasks, including node classification and link prediction. Despite their remarkable success in various high-impact applications, we have identified three common pitfalls in message passing for link prediction, especially within industrial settings. Particularly, in prevalent GNN frameworks (e.g., DGL and PyTorch-Geometric), the target edges (i.e., the edges being predicted) consistently exist as message passing edges in the graph during training. Consequently, this results in overfitting and distribution shift , both of which adversely impact the generalizability to test the target edges. Additionally, during test time, the failure to exclude the test target edges leads to implicit test leakage caused by neighborhood aggregation. In this paper, we analyze these three pitfalls and investigate the impact of including or excluding target edges on the performance of nodes with varying degrees during training and test phases. Our theoretical and empirical analysis demonstrates that low-degree nodes are more susceptible to these pitfalls. These pitfalls can have detrimental consequences when GNNs are implemented in production systems. To systematically address these pitfalls, we propose SpotTarget, an effective and efficient GNN training framework. During training, SpotTarget leverages our insight regarding low-degree nodes and excludes train target edges connected to at least one low-degree node. During test time, it emulates real-world scenarios of GNN usage in production and excludes all test target edges. Our experiments conducted on diverse real-world datasets, demonstrate that SpotTarget significantly enhances GNNs, achieving up to a 15 \u00d7 increase in accuracy in sparse graphs. Furthermore, SpotTarget consistently and dramatically improves the performance for low-degree nodes in dense graphs.",
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "authors": [
                {
                    "authorId": "2146272629",
                    "name": "Jing Zhu"
                },
                {
                    "authorId": "2266789873",
                    "name": "Yuhang Zhou"
                },
                {
                    "authorId": "40043851",
                    "name": "V. Ioannidis"
                },
                {
                    "authorId": "2282529091",
                    "name": "Shengyi Qian"
                },
                {
                    "authorId": "2218202090",
                    "name": "Wei Ai"
                },
                {
                    "authorId": "2282638703",
                    "name": "Xiang Song"
                },
                {
                    "authorId": "2479152",
                    "name": "Danai Koutra"
                }
            ]
        }
    ]
}