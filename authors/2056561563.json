{
    "authorId": "2056561563",
    "papers": [
        {
            "paperId": "5f11d7f1e4c0204e3b38f364b24b4403d482a39a",
            "title": "ABC: Attention with Bilinear Correlation for Infrared Small Target Detection",
            "abstract": "Infrared small target detection (ISTD) has a wide range of applications in early warning, rescue, and guidance. However, CNN based deep learning methods are not effective at segmenting infrared small target (IRST) that it lack of clear contour and texture features, and transformer based methods also struggle to achieve significant results due to the absence of convolution induction bias. To address these issues, we propose a new model called attention with bilinear correlation (ABC), which is based on the transformer architecture and includes a convolution linear fusion transformer (CLFT) module with a novel attention mechanism for feature extraction and fusion, which effectively enhances target features and suppresses noise. Additionally, our model includes a u-shaped convolution-dilated convolution (UCDC) module located deeper layers of the network, which takes advantage of the smaller resolution of deeper features to obtain finer semantic information. Experimental results on public datasets demonstrate that our approach achieves state-of-the-art performance. Code is available at https://github.com/PANPEIWEN/ABC",
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "authors": [
                {
                    "authorId": "2145227626",
                    "name": "Peiwen Pan"
                },
                {
                    "authorId": "46507194",
                    "name": "Haiquan Wang"
                },
                {
                    "authorId": "2109502246",
                    "name": "Chenyi Wang"
                },
                {
                    "authorId": "2056561563",
                    "name": "Chang Nie"
                }
            ]
        },
        {
            "paperId": "69e5e4f61a68d5b39f889aba5514673631673cb2",
            "title": "HGWaveNet: A Hyperbolic Graph Neural Network for Temporal Link Prediction",
            "abstract": "Temporal link prediction, aiming to predict future edges between paired nodes in a dynamic graph, is of vital importance in diverse applications. However, existing methods are mainly built upon uniform Euclidean space, which has been found to be conflict with the power-law distributions of real-world graphs and unable to represent the hierarchical connections between nodes effectively. With respect to the special data characteristic, hyperbolic geometry offers an ideal alternative due to its exponential expansion property. In this paper, we propose HGWaveNet, a novel hyperbolic graph neural network that fully exploits the fitness between hyperbolic spaces and data distributions for temporal link prediction. Specifically, we design two key modules to learn the spatial topological structures and temporal evolutionary information separately. On the one hand, a hyperbolic diffusion graph convolution (HDGC) module effectively aggregates information from a wider range of neighbors. On the other hand, the internal order of causal correlation between historical states is captured by hyperbolic dilated causal convolution (HDCC) modules. The whole model is built upon the hyperbolic spaces to preserve the hierarchical structural information in the entire data flow. To prove the superiority of HGWaveNet, extensive experiments are conducted on six real-world graph datasets and the results show a relative improvement by up to 6.67% on AUC for temporal link prediction over SOTA methods.",
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "authors": [
                {
                    "authorId": "107674597",
                    "name": "Qijie Bai"
                },
                {
                    "authorId": "2056561563",
                    "name": "Chang Nie"
                },
                {
                    "authorId": "46702498",
                    "name": "Haiwei Zhang"
                },
                {
                    "authorId": "2110996023",
                    "name": "Dongming Zhao"
                },
                {
                    "authorId": "1721029",
                    "name": "Xiaojie Yuan"
                }
            ]
        },
        {
            "paperId": "fcc2d963377d8086f5c526dc5e9f5f766637c05e",
            "title": "RLSAC: Reinforcement Learning enhanced Sample Consensus for End-to-End Robust Estimation",
            "abstract": "Robust estimation is a crucial and still challenging task, which involves estimating model parameters in noisy environments. Although conventional sampling consensus-based algorithms sample several times to achieve robustness, these algorithms cannot use data features and historical information effectively. In this paper, we propose RLSAC, a novel Reinforcement Learning enhanced SAmple Consensus framework for end-to-end robust estimation. RLSAC employs a graph neural network to utilize both data and memory features to guide exploring directions for sampling the next minimum set. The feedback of downstream tasks serves as the reward for unsupervised training. Therefore, RL-SAC can avoid differentiating to learn the features and the feedback of downstream tasks for end-to-end robust estimation. In addition, RLSAC integrates a state transition module that encodes both data and memory features. Our experimental results demonstrate that RLSAC can learn from features to gradually explore a better hypothesis. Through analysis, it is apparent that RLSAC can be easily transferred to other sampling consensus-based robust estimation tasks. To the best of our knowledge, RLSAC is also the first method that uses reinforcement learning to sample consensus for end-to-end robust estimation. We release our codes at https://github.com/IRMVLab/RLSAC.",
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "authors": [
                {
                    "authorId": "2056561563",
                    "name": "Chang Nie"
                },
                {
                    "authorId": "2152583098",
                    "name": "Guangming Wang"
                },
                {
                    "authorId": "47781621",
                    "name": "Zhe Liu"
                },
                {
                    "authorId": "101240969",
                    "name": "Luca Cavalli"
                },
                {
                    "authorId": "1742208",
                    "name": "M. Pollefeys"
                },
                {
                    "authorId": "2149695144",
                    "name": "Hesheng Wang"
                }
            ]
        },
        {
            "paperId": "33ce0055008685c504523720fac26539d579bb53",
            "title": "STN: Scalable Tensorizing Networks via Structure-Aware Training and Adaptive Compression",
            "abstract": "Deep neural networks (DNNs) have delivered a remarkable performance in many tasks of computer vision. How-ever, over-parameter- ized representations of popular architectures dramatically increase their computational complexity and storage costs, and hinder their availability in edge devices with constrained resources. Regardless of many tensor decomposition (TD) methods that have been well-studied for compressing DNNs to learn compact representations, they suffer from non-negligible performance degradation in practice. In this paper, we propose Scalable Tensorizing Networks (STN), which dynamically and adaptively adjust the model size and decomposition structure without retraining. First, we account for compression during training by adding a low-rank regularizer to guarantee networks\u2019 desired low-rank characteristics in full tensor format. Then, considering network layers exhibit various low-rank structures, STN is obtained by a data-driven adaptive TD approach, for which the topological structure of decomposition per layer is learned from the pre-trained model, and the ranks are selected appropriately under speci\ufb01ed storage constraints. As a result, STN is com-patible with arbitrary network architectures and achieves higher compression performance and \ufb02exibility over other tensorizing versions. Comprehensive experiments on several popular architectures and benchmarks substantiate the superiority of our model towards improving parameter ef\ufb01ciency.",
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "authors": [
                {
                    "authorId": "2056561563",
                    "name": "Chang Nie"
                },
                {
                    "authorId": "46507194",
                    "name": "Haiquan Wang"
                },
                {
                    "authorId": "2167226462",
                    "name": "Lu Zhao"
                }
            ]
        },
        {
            "paperId": "69df56f5b6134ab85fbf878593eb17a968453538",
            "title": "TaCo: Textual Attribute Recognition via Contrastive Learning",
            "abstract": "As textual attributes like font are core design elements of document format and page style, automatic attributes recognition favor comprehensive practical applications. Existing approaches already yield satisfactory performance in differentiating disparate attributes, but they still suffer in distinguishing similar attributes with only subtle difference. Moreover, their performance drop severely in real-world scenarios where unexpected and obvious imaging distortions appear. In this paper, we aim to tackle these problems by proposing TaCo, a contrastive framework for textual attribute recognition tailored toward the most common document scenes. Specifically, TaCo leverages contrastive learning to dispel the ambiguity trap arising from vague and open-ended attributes. \nTo realize this goal, we design the learning paradigm from three perspectives: 1) generating attribute views, 2) extracting subtle but crucial details, and 3) exploiting valued view pairs for learning, to fully unlock the pre-training potential. \nExtensive experiments show that TaCo surpasses the supervised counterparts and advances the state-of-the-art remarkably on multiple attribute recognition tasks. Online services of TaCo will be made available.",
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "authors": [
                {
                    "authorId": "2056561563",
                    "name": "Chang Nie"
                },
                {
                    "authorId": "2149298493",
                    "name": "Yiqing Hu"
                },
                {
                    "authorId": "2182294237",
                    "name": "Yanqiu Qu"
                },
                {
                    "authorId": "2175008825",
                    "name": "Hao Liu"
                },
                {
                    "authorId": "3336726",
                    "name": "Deqiang Jiang"
                },
                {
                    "authorId": "2064646914",
                    "name": "Bo Ren"
                }
            ]
        },
        {
            "paperId": "af77e949df1ede85bf66c1667de955302d62b1e3",
            "title": "Adaptive Tensor Networks Decomposition",
            "abstract": "Tensor Decomposition (TD) is a powerful technique in solving high-dimensional optimization problems and has been widely used in machine learning and data science. Many TD models aim to establish a trade-off between computational complexity and representation ability. However, they have the problem of tensor rank selection and latent factor arrangement, and the neglected internal correlation between different modes. In this paper, we propose a data-adaptive TD model established on a generalized tensor rank and name it adaptive tensor network (ATN) decomposition, which constructs an optimal topological structure for TD according to the intrinsic properties of the data. We exploit the generalized tensor rank to measure the correlation between two modes of the data and establish a multilinear connection between the corresponding latent factors with an adaptive rank. ATN possesses the merits of permutation invariance, strong robustness, and represents high-order data with fewer parameters. We veri\ufb01ed ATN\u2019s effectiveness and superiority on three typical tasks: tensor completion, image denoising, and neural network compression. Experimental results on synthetic data and real datasets demonstrate that the overall performance of ATN surpasses the state-of-the-art TD methods.",
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "authors": [
                {
                    "authorId": "2056561563",
                    "name": "Chang Nie"
                },
                {
                    "authorId": "2113269591",
                    "name": "Huan Wang"
                },
                {
                    "authorId": "1655903595",
                    "name": "Le Tian"
                }
            ]
        },
        {
            "paperId": "e34718e16f96706d8d8fabac3834668b5618d556",
            "title": "Multi-Tensor Network Representation for High-Order Tensor Completion",
            "abstract": "This work studies the problem of high-dimensional data (referred to as tensors) completion from partially observed samplings. We consider that a tensor is a superposition of multiple low-rank components. In particular, each component can be represented as multilinear connections over several latent factors and naturally mapped to a specific tensor network (TN) topology. In this paper, we propose a fundamental tensor decomposition (TD) framework: Multi-Tensor Network Representation (MTNR), which can be regarded as a linear combination of a range of TD models, e.g., CANDECOMP/PARAFAC (CP) decomposition, Tensor Train (TT), and Tensor Ring (TR). Specifically, MTNR represents a high-order tensor as the addition of multiple TN models, and the topology of each TN is automatically generated instead of manually pre-designed. For the optimization phase, an adaptive topology learning (ATL) algorithm is presented to obtain latent factors of each TN based on a rank incremental strategy and a projection error measurement strategy. In addition, we theoretically establish the fundamental multilinear operations for the tensors with TN representation, and reveal the structural transformation of MTNR to a single TN. Finally, MTNR is applied to a typical task, tensor completion, and two effective algorithms are proposed for the exact recovery of incomplete data based on the Alternating Least Squares (ALS) scheme and Alternating Direction Method of Multiplier (ADMM) framework. Extensive numerical experiments on synthetic data and real-world datasets demonstrate the effectiveness of MTNR compared with the start-of-the-art methods.",
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "authors": [
                {
                    "authorId": "2056561563",
                    "name": "Chang Nie"
                },
                {
                    "authorId": "2197900626",
                    "name": "Huan Wang"
                },
                {
                    "authorId": "50737981",
                    "name": "Zhihui Lai"
                }
            ]
        }
    ]
}