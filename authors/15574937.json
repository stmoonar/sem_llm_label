{
    "authorId": "15574937",
    "papers": [
        {
            "paperId": "02d4096c030d052e1866d52fbc3b83480e1ed9f5",
            "title": "Towards Next-Generation Intelligent Assistants Leveraging LLM Techniques",
            "abstract": "Virtual Intelligent Assistants take user requests in the voice form, perform actions such as setting an alarm, turning on a light, and answering a question, and provide answers or confirmations in the voice form or through other channels such as a screen. Assistants have become prevalent in the past decade, and users have been taking services from assistants like Amazon Alexa, Apple Siri, Google Assistant, and Microsoft Cortana. The emergence of AR/VR devices raised many new challenges for building intelligent assistants. The unique requirements have inspired new research directions such as (a) understanding users' situated multi-modal contexts (e.g. vision, sensor signals) as well as language-oriented conversational contexts, (b) personalizing the assistant services by grounding interactions on growing public and personal knowledge graphs and online search engines, and (c) on- device model inference and training techniques that satisfy strict resource and privacy constraints. In this tutorial, we will provide an in-depth walk-through of techniques in the afore-mentioned areas in the recent literature. We aim to introduce techniques for researchers and practitioners who are building intelligent assistants, and inspire research that will bring us one step closer to realizing the dream of building an all-day accompanying assistant. Additionally, we will highlight the significant role that Large Language Models (LLMs) play in enhancing these strategies, underscoring their potential to reshape the future landscape of intelligent assistance.",
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "authors": [
                {
                    "authorId": "2143918656",
                    "name": "X. Dong"
                },
                {
                    "authorId": "29072828",
                    "name": "Seungwhan Moon"
                },
                {
                    "authorId": "15574937",
                    "name": "Y. Xu"
                },
                {
                    "authorId": "40243893",
                    "name": "Kshitiz Malik"
                },
                {
                    "authorId": "2167255986",
                    "name": "Zhou Yu"
                }
            ]
        },
        {
            "paperId": "92f82b8752712c12253b64d53b79b4a4833670a8",
            "title": "Tab-Cleaner: Weakly Supervised Tabular Data Cleaning via Pre-training for E-commerce Catalog",
            "abstract": "Product catalogs, conceptually in the form of text-rich tables, are self-reported by individual retailers and thus inevitably contain noisy facts. Verifying such textual attributes in product catalogs is essential to improve their reliability. However, popular methods for processing free-text content, such as pre-trained language models, are not particularly effective on structured tabular data since they are typically trained on free-form natural language texts. In this paper, we present Tab-Cleaner, a model designed to handle error detection over text-rich tabular data following a pre-training / fine-tuning paradigm. We train Tab-Cleaner on a real-world Amazon Product Catalog table w.r.t millions of products and show improvements over state-of-the-art methods by 16\\% on PR AUC over attribute applicability classification task and by 11\\% on PR AUC over attribute value validation task.",
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "authors": [
                {
                    "authorId": "3161399",
                    "name": "Kewei Cheng"
                },
                {
                    "authorId": "2157096355",
                    "name": "Xian Li"
                },
                {
                    "authorId": "1879297505",
                    "name": "Zhengyang Wang"
                },
                {
                    "authorId": "2047145237",
                    "name": "Chenwei Zhang"
                },
                {
                    "authorId": "9544714",
                    "name": "Binxuan Huang"
                },
                {
                    "authorId": "15574937",
                    "name": "Y. Xu"
                },
                {
                    "authorId": "2143918656",
                    "name": "X. Dong"
                },
                {
                    "authorId": "2109461904",
                    "name": "Yizhou Sun"
                }
            ]
        },
        {
            "paperId": "a4642d90c8cc31216821eb36db1f06f60bf67471",
            "title": "Handling Chinese OOV with a Combination of Radical-based Sub-words and Glyph Features",
            "abstract": "In natural language processing tasks, dictionaries must be built and words must be converted into their corresponding embeddings, creating problems such as out of vocabulary (OOV). To solve this problem, algorithms such as byte pair encoding (BPE) have been widely used to generate sub-words from known words and decompose OOV words into existing sub-words. However, Chinese has many types of characters called Kanji, and their distribution in the text is sparse, reducing the performance of BPE algorithms that rely on the frequency of occurrence. Compared with Kanji characters, radicals are less varied and more densely distributed. Moreover, because Kanji characters are hieroglyphs, their glyphs contain a rich amount of information and are unique. In this paper, we take advantage of these characteristics of Chinese and apply the BPE algorithm after converting the characters to the corresponding radicals, and combining sub-word embedding with the glyph feature vector. Experiments show that converting more Kanji characters to radicals results in a more even distribution of characters in the converted Chinese text, and the number of OOV words continues to decrease. Furthermore, at a 30% conversion ratio, the effect of radical-based embedding can outperform the effect of character-level embedding that keeps all Kanji characters unchanged. The results also indicate that combining with embedding using glyph features can improve performance despite the different conversion ratios.",
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "authors": [
                {
                    "authorId": "15574937",
                    "name": "Y. Xu"
                },
                {
                    "authorId": "144477020",
                    "name": "Yohei Seki"
                }
            ]
        },
        {
            "paperId": "fb00016c1e048b9373803add001c1ec7e877cb23",
            "title": "Head-to-Tail: How Knowledgeable are Large Language Models (LLMs)? A.K.A. Will LLMs Replace Knowledge Graphs?",
            "abstract": "Since the recent prosperity of Large Language Models (LLMs), there have been interleaved discussions regarding how to reduce hallucinations from LLM responses, how to increase the factuality of LLMs, and whether Knowledge Graphs (KGs), which store the world knowledge in a symbolic form, will be replaced with LLMs. In this paper, we try to answer these questions from a new angle: How knowledgeable are LLMs?To answer this question, we constructed Head-to-Tail, a benchmark that consists of 18K question-answer (QA) pairs regarding head, torso, and tail facts in terms of popularity. We designed an automated evaluation method and a set of metrics that closely approximate the knowledge an LLM confidently internalizes. Through a comprehensive evaluation of 16 publicly available LLMs, we show that existing LLMs are still far from being perfect in terms of their grasp of factual knowledge, especially for facts of torso-to-tail entities.",
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "authors": [
                {
                    "authorId": "49871029",
                    "name": "Kai Sun"
                },
                {
                    "authorId": "15574937",
                    "name": "Y. Xu"
                },
                {
                    "authorId": "47291370",
                    "name": "Hanwen Zha"
                },
                {
                    "authorId": "2229372676",
                    "name": "Yue Liu"
                },
                {
                    "authorId": "2152050780",
                    "name": "Xinhsuai Dong"
                }
            ]
        },
        {
            "paperId": "12bf4fc33ca5345841ee533682a8789b474f3f23",
            "title": "Profiling Irony and Stereotype Spreaders on Twitter with BERT",
            "abstract": "This paper summarises the participation at the \"Profiling Irony and Stereotype Spreaders on Twitter\" shared task at PAN at CLEF 2022, and proposes a method which can detect irony and stereotype spreaders automatically. We detect whether a user is a irony and stereotype spreader instead of detecting a single content. In this paper, we use BERT embeddings and autogluon which can automates classic machine learning methods to train a classifier.We upload the forecast results to TIRA[1] Platform. Using our method, an accuracy of 94.3 % is achieved on the English training set. On the English test set, our system achieved an accuracy result of 94.4 %.",
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "authors": [
                {
                    "authorId": "15574937",
                    "name": "Y. Xu"
                },
                {
                    "authorId": "47399680",
                    "name": "Hui Ning"
                }
            ]
        },
        {
            "paperId": "94afe81266143128d08d4a1d2fb9d3fdb9c08d5c",
            "title": "Evaluation of Steady-State Visual Evoked Potentials (SSVEP) Stimuli Design for Visual Field Assessment",
            "abstract": "The Brain-Computer Interface(BCI) technologies can complement with Human-Computer interaction principles enabling personalized assessment and assistance in individual\u2019s mental well-beings. SSVEP BCI modality is not only useful in assistive and communication but also has the potential in vision assessment by leveraging unique frequency tagged responses from the visual cortex. Ocular diseases like glaucoma render necessity to detect early vision loss symptoms. SSVEP shows promising results in assessing abnormality in visual functional defects. But SSVEP characteristics and optimal performance of visual speller differ significantly from visual field assessment application scenarios. But there is no study available yet to evaluate SSVEP stimuli design optimized for visual field assessment in discriminating abnormal from normal vision conditions. So we propose three stimuli designs and evaluate them under different normal and simulated abnormal visual field scenarios. We collected both quantitative and qualitative data from twenty-one healthy subjects according to the experiment protocol. Our evaluation of the layouts considers both their usability and their visual field classification performance. We use features extracted from Canonical Correlation Analysis to evaluate the classification performance among stimuli designs and experiment parameters. Our quantitative evaluation shows the multifocal layout achieved the highest mean accuracy, 86.88\u00b11.47%, to discriminate between normal and two abnormal visual fields. But qualitative ratings representing subjects\u2019 preferences, mainly influenced by visual comfort, favor the concentric design over the others. Therefore, we conclude that SSVEP multifocal layout detects the changes in visual field characteristics and creates comfortable testing scenarios enabling desirable objective visual field assessment.",
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "authors": [
                {
                    "authorId": "15574937",
                    "name": "Y. Xu"
                },
                {
                    "authorId": "1731072",
                    "name": "Aung Aung Phyo Wai"
                }
            ]
        },
        {
            "paperId": "e468efa59a621f49709ded07ba18ca7751ab91e5",
            "title": "PGE: Robust Product Graph Embedding Learning for Error Detection",
            "abstract": "Although product graphs (PGs) have gained increasing attentions in recent years for their successful applications in product search and recommendations, the extensive power of PGs can be limited by the inevitable involvement of various kinds of errors. Thus, it is critical to validate the correctness of triples in PGs to improve their reliability. Knowledge graph (KG) embedding methods have strong error detection abilities. Yet, existing KG embedding methods may not be directly applicable to a PG due to its distinct characteristics: (1) PG contains rich textual signals, which necessitates a joint exploration of both text information and graph structure; (2) PG contains a large number of attribute triples, in which attribute values are represented by free texts. Since free texts are too flexible to define entities in KGs, traditional way to map entities to their embeddings using ids is no longer appropriate for attribute value representation; (3) Noisy triples in a PG mislead the embedding learning and significantly hurt the performance of error detection. To address the aforementioned challenges, we propose an end-to-end noise-tolerant embedding learning framework, PGE, to jointly leverage both text information and graph structure in PG to learn embeddings for error detection. Experimental results on real-world product graph demonstrate the effectiveness of the proposed framework comparing with the state-of-the-art approaches.",
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "authors": [
                {
                    "authorId": "3161399",
                    "name": "Kewei Cheng"
                },
                {
                    "authorId": "2157096355",
                    "name": "Xian Li"
                },
                {
                    "authorId": "15574937",
                    "name": "Y. Xu"
                },
                {
                    "authorId": "2143918656",
                    "name": "X. Dong"
                },
                {
                    "authorId": "2109461904",
                    "name": "Yizhou Sun"
                }
            ]
        },
        {
            "paperId": "b115230c4e590f4dca8c56186515e0e246fd00b8",
            "title": "Efficiently Answering Durability Prediction Queries",
            "abstract": "We consider a class of queries called durability prediction queries that arise commonly in predictive analytics, where we use a given predictive model to answer questions about possible futures to inform our decisions. Examples of durability prediction queries include \"what is the probability that this financial product will keep losing money over the next 12 quarters before turning in any profit?\" and \"what is the chance for our proposed server cluster to fail the required service-level agreement before its term ends?\" We devise a general method called Multi-Level Splitting Sampling (MLSS) that can efficiently handle complex queries and complex models---including those involving black-box functions---as long as the models allow us to simulate possible futures step by step. Our method addresses the inefficiency of standard Monte Carlo (MC) methods by applying the idea of importance splitting to let one \"promising\" sample path prefix generate multiple \"offspring\" paths, thereby directing simulation efforts toward more promising paths. We propose practical techniques for designing splitting strategies, freeing users from manual tuning. Experiments show that our approach is able to achieve unbiased estimates and the same error guarantees as standard MC while offering an order-of-magnitude cost reduction.",
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "authors": [
                {
                    "authorId": "145961125",
                    "name": "Junyang Gao"
                },
                {
                    "authorId": "15574937",
                    "name": "Y. Xu"
                },
                {
                    "authorId": "1705077",
                    "name": "P. Agarwal"
                },
                {
                    "authorId": "9125547",
                    "name": "Jun Yang"
                }
            ]
        },
        {
            "paperId": "2e44f39e9887e1cdd91d48ab18a0bae53ff7f81a",
            "title": "AutoKnow: Self-Driving Knowledge Collection for Products of Thousands of Types",
            "abstract": "Can one build a knowledge graph (KG) for all products in the world? Knowledge graphs have firmly established themselves as valuable sources of information for search and question answering, and it is natural to wonder if a KG can contain information about products offered at online retail sites. There have been several successful examples of generic KGs, but organizing information about products poses many additional challenges, including sparsity and noise of structured data for products, complexity of the domain with millions of product types and thousands of attributes, heterogeneity across large number of categories, as well as large and constantly growing number of products. We describe AutoKnow, our automatic (self-driving) system that addresses these challenges. The system includes a suite of novel techniques for taxonomy construction, product property identification, knowledge extraction, anomaly detection, and synonym discovery. AutoKnow is (a) automatic, requiring little human intervention, (b) multi-scalable, scalable in multiple dimensions (many domains, many products, and many attributes), and (c) integrative, exploiting rich customer behavior logs. AutoKnow has been operational in collecting product knowledge for over 11K product types.",
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "authors": [
                {
                    "authorId": "2143917898",
                    "name": "Xin Dong"
                },
                {
                    "authorId": "2111080293",
                    "name": "Xiang He"
                },
                {
                    "authorId": "2063962350",
                    "name": "Andrey Kan"
                },
                {
                    "authorId": "2116235540",
                    "name": "Xian Li"
                },
                {
                    "authorId": "2116799460",
                    "name": "Yan Liang"
                },
                {
                    "authorId": "65743795",
                    "name": "Jun Ma"
                },
                {
                    "authorId": "15574937",
                    "name": "Y. Xu"
                },
                {
                    "authorId": "2418496",
                    "name": "Chenwei Zhang"
                },
                {
                    "authorId": "2152225582",
                    "name": "Tong Zhao"
                },
                {
                    "authorId": "1753857667",
                    "name": "Gabriel Blanco Saldana"
                },
                {
                    "authorId": "2054184362",
                    "name": "Saurabh Deshpande"
                },
                {
                    "authorId": "153307803",
                    "name": "A. Manduca"
                },
                {
                    "authorId": "1753812304",
                    "name": "Jay Ren"
                },
                {
                    "authorId": "2109039708",
                    "name": "Surender Pal Singh"
                },
                {
                    "authorId": "2057533745",
                    "name": "Fan Xiao"
                },
                {
                    "authorId": "144827671",
                    "name": "Haw-Shiuan Chang"
                },
                {
                    "authorId": "8458211",
                    "name": "Giannis Karamanolakis"
                },
                {
                    "authorId": "3375249",
                    "name": "Yuning Mao"
                },
                {
                    "authorId": "2143381988",
                    "name": "Yaqing Wang"
                },
                {
                    "authorId": "1702392",
                    "name": "C. Faloutsos"
                },
                {
                    "authorId": "143753639",
                    "name": "A. McCallum"
                },
                {
                    "authorId": "153034701",
                    "name": "Jiawei Han"
                }
            ]
        },
        {
            "paperId": "bf2174c69f84f4e57813e0bed4571c6dbff123ed",
            "title": "Automatic Validation of Textual Attribute Values in E-commerce Catalog by Learning with Limited Labeled Data",
            "abstract": "Product catalogs are valuable resources for eCommerce website. In the catalog, a product is associated with multiple attributes whose values are short texts, such as product name, brand, functionality and flavor. Usually individual retailers self-report these key values, and thus the catalog information unavoidably contains noisy facts. It is very important to validate the correctness of these values in order to improve shopper experiences and enable more effective product recommendation. Due to the huge volume of products, an effective automatic validation approach is needed. In this paper, we propose to develop an automatic validation approach that verifies the correctness of textual attribute values for products. This can be formulated as a task as cross-checking a textual attribute value against product profile, which is a short textual description of the product on eCommerce website. Although existing deep neural network models have shown success in conducting cross-checking between two pieces of texts, their success has to be dependent upon a large set of quality labeled data, which are hard to obtain in this validation task: products span a variety of categories. Due to the category difference, annotation has to be done on all the categories, which is impossible to achieve in real practice. To address the aforementioned challenges, we propose a novel meta-learning latent variable approach, called MetaBridge, which can learn transferable knowledge from a subset of categories with limited labeled data and capture the uncertainty of never-seen categories with unlabeled data. More specifically, we make the following contributions. (1) We formalize the problem of validating the textual attribute values of products from a variety of categories as a natural language inference task in the few-shot learning setting, and propose a meta-learning latent variable model to jointly process the signals obtained from product profiles and textual attribute values. (2) We propose to integrate meta learning and latent variable in a unified model to effectively capture the uncertainty of various categories. With this model, annotation costs can be significantly reduced as we make best use of labeled data from limited categories. (3) We propose a novel objective function based on latent variable model in the few-shot learning setting, which ensures distribution consistency between unlabeled and labeled data and prevents overfitting by sampling different records from the learned distribution. Extensive experiments on real eCommerce datasets from hundreds of categories demonstrate the effectiveness of MetaBridge on textual attribute validation and its outstanding performance compared with state-of-the-art approaches.",
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "authors": [
                {
                    "authorId": "2115793087",
                    "name": "Yaqing Wang"
                },
                {
                    "authorId": "15574937",
                    "name": "Y. Xu"
                },
                {
                    "authorId": "2116235540",
                    "name": "Xian Li"
                },
                {
                    "authorId": "2143917898",
                    "name": "Xin Dong"
                },
                {
                    "authorId": "144407304",
                    "name": "Jing Gao"
                }
            ]
        }
    ]
}