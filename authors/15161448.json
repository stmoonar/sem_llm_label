{
    "authorId": "15161448",
    "papers": [
        {
            "paperId": "3434f582cc9c2818785e2920241d43d932625539",
            "title": "ModelShield: Adaptive and Robust Watermark against Model Extraction Attack",
            "abstract": "Large language models (LLMs) demonstrate general intelligence across a variety of machine learning tasks, thereby enhancing the commercial value of their intellectual property (IP). To protect this IP, model owners typically allow user access only in a black-box manner, however, adversaries can still utilize model extraction attacks to steal the model intelligence encoded in model generation. Watermarking technology offers a promising solution for defending against such attacks by embedding unique identifiers into the model-generated content. However, existing watermarking methods often compromise the quality of generated content due to heuristic alterations and lack robust mechanisms to counteract adversarial strategies, thus limiting their practicality in real-world scenarios. In this paper, we introduce an adaptive and robust watermarking method (named ModelShield) to protect the IP of LLMs. Our method incorporates a self-watermarking mechanism that allows LLMs to autonomously insert watermarks into their generated content to avoid the degradation of model content. We also propose a robust watermark detection mechanism capable of effectively identifying watermark signals under the interference of varying adversarial strategies. Besides, ModelShield is a plug-and-play method that does not require additional model training, enhancing its applicability in LLM deployments. Extensive evaluations on two real-world datasets and three LLMs demonstrate that our method surpasses existing methods in terms of defense effectiveness and robustness while significantly reducing the degradation of watermarking on the model-generated content.",
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "authors": [
                {
                    "authorId": "2268206463",
                    "name": "Kaiyi Pang"
                },
                {
                    "authorId": "2285941555",
                    "name": "Tao Qi"
                },
                {
                    "authorId": "15161448",
                    "name": "Chuhan Wu"
                },
                {
                    "authorId": "2268206799",
                    "name": "Minhao Bai"
                },
                {
                    "authorId": "2261907799",
                    "name": "Minghu Jiang"
                },
                {
                    "authorId": "2293999062",
                    "name": "Yongfeng Huang"
                }
            ]
        },
        {
            "paperId": "eda84e4a546a2316a32fa5654c1cfda5a6d4aeec",
            "title": "Adaptive and robust watermark against model extraction attack",
            "abstract": "\u2014Large language models have boosted Large Models as a Service (LMaaS) into a thriving business sector. But even model owners offering only API access while keeping model parameters and internal workings private, their Intellectual Property (IP) are still at risk of theft through model extraction attacks. To safeguard the IP of these models and mitigate unfair competition in the language model market, watermarking technology serves as an efficient post-hoc solution for identifying IP infringements. However, existing IP protection watermarking methods either explicitly alter the original output of the language model or implant watermark signals in the model logits. These methods forcefully distort the original distribution of the language model and impact the sampling process, leading to a decline in the quality of the generated text. The existing method also fails to achieve end-to-end adaptive watermark embedding and lack robustness verification in complex scenarios where watermark detection is subject to interference. To overcome these challenges, we propose PromptShield, a plug-and-play IP protection watermarking method to resist model extraction attacks without training additional modules. Leveraging the self-reminding properties inherent in large language models, we encapsulate the user\u2019s query with a watermark self-generated instruction, nudging the LLMs to automatically generate watermark words in its output without compromising generation quality. Our method does not require access to the model\u2019s internal logits and minimizes alterations to the model\u2019s distribution using prompt-guided cues. Comprehensive experimental results consistently demonstrate the effectiveness, harmlessness, and robustness of our watermark. Moreover, Our watermark detection method remains robust and high detection sensitivity even when subjected to interference.",
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "authors": [
                {
                    "authorId": "2268206463",
                    "name": "Kaiyi Pang"
                },
                {
                    "authorId": "2285941555",
                    "name": "Tao Qi"
                },
                {
                    "authorId": "15161448",
                    "name": "Chuhan Wu"
                },
                {
                    "authorId": "2268206799",
                    "name": "Minhao Bai"
                }
            ]
        },
        {
            "paperId": "487000bfc0bc3a56334edbe5a81648ac557824d0",
            "title": "Task Adaptive Multi-learner Network for Joint CTR and CVR Estimation",
            "abstract": "CTR and CVR are critical factors in personalized applications, and many methods jointly estimate them via multi-task learning to alleviate the ultra-sparsity of conversion behaviors. However, it is still difficult to predict CVR accurately and robustly due to the limited and even biased knowledge extracted by the single model tower optimized on insufficient conversion samples. In this paper, we propose a task adaptive multi-learner (TAML) framework for joint CTR and CVR prediction. We design a hierarchical task adaptive knowledge representation module with different experts to capture knowledge in different granularities, which can effectively exploit the commonalities between CTR and CVR estimation tasks meanwhile keeping their unique characteristics. We apply multiple learners to extract data knowledge from various views and fuse their predictions to obtain accurate and robust scores. To facilitate knowledge sharing across learners, we further perform self-distillation that uses the fused scores to teach different learners. Thorough offline and online experiments show the superiority of TAML in different Ad ranking tasks, and we have deployed it in Huawei\u2019s online advertising platform to serve the main traffic.",
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "authors": [
                {
                    "authorId": "2144500584",
                    "name": "Xiaofan Liu"
                },
                {
                    "authorId": "3789712",
                    "name": "Qinglin Jia"
                },
                {
                    "authorId": "15161448",
                    "name": "Chuhan Wu"
                },
                {
                    "authorId": "2143375428",
                    "name": "Jingjie Li"
                },
                {
                    "authorId": "2215625511",
                    "name": "Dai Quanyu"
                },
                {
                    "authorId": "2215701244",
                    "name": "Lin Bo"
                },
                {
                    "authorId": "144142354",
                    "name": "Rui Zhang"
                },
                {
                    "authorId": "2824766",
                    "name": "Ruiming Tang"
                }
            ]
        },
        {
            "paperId": "5e61d8504ed4ab3999a2118b9b1ba5c6cf322c7c",
            "title": "Contrastive Multi-view Framework for Customer Lifetime Value Prediction",
            "abstract": "Accurate customer lifetime value (LTV) prediction can help service providers optimize their marketing policies in customer-centric applications. However, the heavy sparsity of consumption events and the interference of data variance and noise obstruct LTV estimation. Many existing LTV prediction methods directly train a single-view LTV predictor on consumption samples, which may yield inaccurate and even biased knowledge extraction. In this paper, we propose a contrastive multi-view framework for LTV prediction, which is a plug-and-play solution compatible with various backbone models. It synthesizes multiple heterogeneous LTV regressors with complementary knowledge to improve model robustness and captures sample relatedness via contrastive learning to mitigate the dependency on data abundance. Concretely, we use a decomposed scheme that converts the LTV prediction problem into a combination of estimating consumption probability and payment amount. To alleviate the impact of noisy data on model learning, we propose a multi-view framework that jointly optimizes multiple types of regressors with diverse characteristics and advantages to encode and fuse comprehensive knowledge. To fully exploit the potential of limited training samples, we propose a hybrid contrastive learning method to help capture the relatedness between samples in both classification and regression tasks. We conduct extensive experiments on a real-world game LTV prediction dataset and the results validate the effectiveness of our method. We have deployed our solution online in Huawei's mobile game center and achieved 32.26% of total payment amount gains.",
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "authors": [
                {
                    "authorId": "15161448",
                    "name": "Chuhan Wu"
                },
                {
                    "authorId": "2143375428",
                    "name": "Jingjie Li"
                },
                {
                    "authorId": "3789712",
                    "name": "Qinglin Jia"
                },
                {
                    "authorId": "2149670667",
                    "name": "Hong Zhu"
                },
                {
                    "authorId": "2220572561",
                    "name": "Yuan Fang"
                },
                {
                    "authorId": "2824766",
                    "name": "Ruiming Tang"
                }
            ]
        },
        {
            "paperId": "613a74e59c395011323a5e60ace0a61498471b46",
            "title": "Customer Lifetime Value Prediction: Towards the Paradigm Shift of Recommender System Objectives",
            "abstract": "The ultimate goal of recommender systems is satisfying users\u2019 information needs in the long term. Despite the success of current recommendation techniques in targeting user interest, optimizing long-term user engagement and platform revenue is still challenging due to the restriction of optimization objectives such as clicks, ratings, and dwell time. Customer lifetime value (LTV) reflects the total monetary value of a customer to a business over the course of their relationship. Accurate LTV prediction can guide personalized service providers to optimize their marketing, sales, and service strategies to maximize customer retention, satisfaction, and profitability. However, the extreme sparsity, volatility, and randomness of consumption behaviors make LTV prediction rather intricate and challenging. In this tutorial, we give a detailed introduction to the key technologies and problems in LTV prediction. We present a systematic technique chronicle of LTV prediction over decades, including probabilistic models, traditional machine learning methods, and deep learning techniques. Based on this overview, we introduce several critical challenges in algorithm design, performance evaluation and system deployment from an industrial perspective, from which we derive potential directions for future exploration. From this tutorial, the RecSys community can gain a better understanding of the unique characteristics and challenges of LTV prediction, and it may serve as a catalyst to shift the focus of recommender systems from short-term targets to long-term ones.",
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "authors": [
                {
                    "authorId": "15161448",
                    "name": "Chuhan Wu"
                },
                {
                    "authorId": "3789712",
                    "name": "Qinglin Jia"
                },
                {
                    "authorId": "3065080",
                    "name": "Zhenhua Dong"
                },
                {
                    "authorId": "2240536007",
                    "name": "Ruiming Tang"
                }
            ]
        },
        {
            "paperId": "8bbf89288888066eaff28cff4cc259dd9dcaf437",
            "title": "DualFair: Fair Representation Learning at Both Group and Individual Levels via Contrastive Self-supervision",
            "abstract": "Algorithmic fairness has become an important machine learning problem, especially for mission-critical Web applications. This work presents a self-supervised model, called DualFair, that can debias sensitive attributes like gender and race from learned representations. Unlike existing models that target a single type of fairness, our model jointly optimizes for two fairness criteria\u2014group fairness and counterfactual fairness\u2014and hence makes fairer predictions at both the group and individual levels. Our model uses contrastive loss to generate embeddings that are indistinguishable for each protected group, while forcing the embeddings of counterfactual pairs to be similar. It then uses a self-knowledge distillation method to maintain the quality of representation for the downstream tasks. Extensive analysis over multiple datasets confirms the model\u2019s validity and further shows the synergy of jointly addressing two fairness criteria, suggesting the model\u2019s potential value in fair intelligent Web applications.",
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "authors": [
                {
                    "authorId": "1444699639",
                    "name": "Sungwon Han"
                },
                {
                    "authorId": "2116971826",
                    "name": "Seungeon Lee"
                },
                {
                    "authorId": "2397264",
                    "name": "Fangzhao Wu"
                },
                {
                    "authorId": "35637055",
                    "name": "Sundong Kim"
                },
                {
                    "authorId": "15161448",
                    "name": "Chuhan Wu"
                },
                {
                    "authorId": "2108045320",
                    "name": "Xiting Wang"
                },
                {
                    "authorId": "2149195520",
                    "name": "Xing Xie"
                },
                {
                    "authorId": "1775511",
                    "name": "Meeyoung Cha"
                }
            ]
        },
        {
            "paperId": "becce70a2723e05085eb671b654389467ecb2d3a",
            "title": "A Token-wise Graph-based Framework for Multimodal Named Entity Recognition",
            "abstract": "Multimodal Named Entity Recognition (MNER) on social media posts is a leading but challenging task. However, most existing MNER methods fail to effectively exploit the visual information from the image. Besides, the multimodal interaction and alignment remains unsettled. In this paper, we propose a novel token-wise graph-based framework to deal with the MNER task. Specifically, a token-wise image processing manner is established. A muti-modal graph is constructed based on the textual token derived from BERT and the visual token derived from SwinT. Then, the muti-modal graph is fed into a multi-layer Transformer-based module for intra- and inter-modal information fusion. In addition, multiple contrastive learning is devised to perform the global and local alignment between textual and visual nodes. Experimental results on two benchmark multimodal datasets indicate that our model achieves state-of-the-art performance in MNER tasks.",
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "authors": [
                {
                    "authorId": "2191377691",
                    "name": "Zhengxuan Zhang"
                },
                {
                    "authorId": "2232332856",
                    "name": "Weixing Mai"
                },
                {
                    "authorId": "2189744559",
                    "name": "Haoliang Xiong"
                },
                {
                    "authorId": "15161448",
                    "name": "Chuhan Wu"
                },
                {
                    "authorId": "2114922740",
                    "name": "Yun Xue"
                }
            ]
        },
        {
            "paperId": "049403c99dc44718c22b61007912abd1da020a81",
            "title": "Are Big Recommendation Models Fair to Cold Users?",
            "abstract": "Big models are widely used by online recommender systems to boost recommendation performance. They are usually learned on historical user behavior data to infer user interest and predict future user behaviors (e.g., clicks). In fact, the behaviors of heavy users with more historical behaviors can usually provide richer clues than cold users in interest modeling and future behavior prediction. Big models may favor heavy users by learning more from their behavior patterns and bring unfairness to cold users. In this paper, we study whether big recommendation models are fair to cold users. We empirically demonstrate that optimizing the overall performance of big recommendation models may lead to unfairness to cold users in terms of performance degradation. To solve this problem, we propose a BigFair method based on self-distillation, which uses the model predictions on original user data as a teacher to regularize predictions on augmented data with randomly dropped user behaviors, which can encourage the model to fairly capture interest distributions of heavy and cold users. Experiments on two datasets show that BigFair can effectively improve the performance fairness of big recommendation models on cold users without harming the performance on heavy users.",
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "authors": [
                {
                    "authorId": "15161448",
                    "name": "Chuhan Wu"
                },
                {
                    "authorId": "2397264",
                    "name": "Fangzhao Wu"
                },
                {
                    "authorId": "50329599",
                    "name": "Tao Qi"
                },
                {
                    "authorId": "2145525387",
                    "name": "Yongfeng Huang"
                }
            ]
        },
        {
            "paperId": "17c88fab4e678443c132a2c8e06ba2e6a3a52380",
            "title": "Game of Privacy: Towards Better Federated Platform Collaboration under Privacy Restriction",
            "abstract": "Vertical federated learning (VFL) aims to train models from cross-silo data with different feature spaces stored on different platforms. Existing VFL methods usually assume all data on each platform can be used for model training. However, due to the intrinsic privacy risks of federated learning, the total amount of involved data may be constrained. In addition, existing VFL studies usually assume only one platform has task labels and can benefit from the collaboration, making it difficult to attract other platforms to join in the collaborative learning. In this paper, we study the platform collaboration problem in VFL under privacy constraint. We propose to incent different platforms through a reciprocal collaboration, where all platforms can exploit multi-platform information in the VFL framework to benefit their own tasks. With limited privacy budgets, each platform needs to wisely allocate its data quotas for collaboration with other platforms. Thereby, they naturally form a multi-party game. There are two core problems in this game, i.e., how to appraise other platforms' data value to compute game rewards and how to optimize policies to solve the game. To evaluate the contributions of other platforms' data, each platform offers a small amount of\"deposit\"data to participate in the VFL. We propose a performance estimation method to predict the expected model performance when involving different amount combinations of inter-platform data. To solve the game, we propose a platform negotiation method that simulates the bargaining among platforms and locally optimizes their policies via gradient descent. Extensive experiments on two real-world datasets show that our approach can effectively facilitate the collaborative exploitation of multi-platform data in VFL under privacy restrictions.",
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "authors": [
                {
                    "authorId": "15161448",
                    "name": "Chuhan Wu"
                },
                {
                    "authorId": "2397264",
                    "name": "Fangzhao Wu"
                },
                {
                    "authorId": "50329599",
                    "name": "Tao Qi"
                },
                {
                    "authorId": "46394376",
                    "name": "Yanlin Wang"
                },
                {
                    "authorId": "1731776",
                    "name": "Yongfeng Huang"
                },
                {
                    "authorId": "2149195520",
                    "name": "Xing Xie"
                }
            ]
        },
        {
            "paperId": "1d8ac8bf9c53ebd1e2aa0a5e4db9723683d9c67b",
            "title": "Semi-FairVAE: Semi-supervised Fair Representation Learning with Adversarial Variational Autoencoder",
            "abstract": "Adversarial learning is a widely used technique in fair representation learning to remove the biases on sensitive attributes from data representations. It usually requires incorporating the sensitive attribute labels as prediction targets. However, in many scenarios the sensitive attribute labels of many samples can be unknown, and it is difficult to train a strong discriminator based on the scarce data with observed attribute labels, which may lead to generate unfair representations. In this paper, we propose a semi-supervised fair representation learning approach based on an adversarial variational autoencoder, which can reduce the dependency of adversarial fair models on data with labeled sensitive attributes. More specifically, we use a bias-aware model to capture inherent bias information on sensitive attributes by accurately predicting sensitive attributes from input data, and use a bias-free model to learn debi-ased fair representations by using adversarial learning to remove bias information from them. The hidden representations learned by the two models are regularized to be orthogonal. In addition, the soft labels predicted by the two models are further integrated into a semi-supervised variational autoencoder to reconstruct the input data, and we apply an additional entropy regularization to encourage the attribute labels inferred from the bias-free model to be high-entropy. In this way, the bias-aware model can better capture attribute information while the bias-free model is less discriminative on sensitive attributes if the input data is well reconstructed. Extensive experiments on two datasets for different tasks validate that our approach can achieve good representation learning fairness under limited data with sensitive attribute labels.",
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "authors": [
                {
                    "authorId": "15161448",
                    "name": "Chuhan Wu"
                },
                {
                    "authorId": "2397264",
                    "name": "Fangzhao Wu"
                },
                {
                    "authorId": "50329599",
                    "name": "Tao Qi"
                },
                {
                    "authorId": "2145525387",
                    "name": "Yongfeng Huang"
                }
            ]
        }
    ]
}