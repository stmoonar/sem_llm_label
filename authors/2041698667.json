{
    "authorId": "2041698667",
    "papers": [
        {
            "paperId": "002bf0720404e5dc6bf43eff64f116ec755b405f",
            "title": "SciMON: Scientific Inspiration Machines Optimized for Novelty",
            "abstract": "We explore and enhance the ability of neural language models to generate novel scientific directions grounded in literature. Work on literature-based hypothesis generation has traditionally focused on binary link prediction--severely limiting the expressivity of hypotheses. This line of work also does not focus on optimizing novelty. We take a dramatic departure with a novel setting in which models use as input background contexts (e.g., problems, experimental settings, goals), and output natural language ideas grounded in literature. We present SciMON, a modeling framework that uses retrieval of\"inspirations\"from past scientific papers, and explicitly optimizes for novelty by iteratively comparing to prior papers and updating idea suggestions until sufficient novelty is achieved. Comprehensive evaluations reveal that GPT-4 tends to generate ideas with overall low technical depth and novelty, while our methods partially mitigate this issue. Our work represents a first step toward evaluating and developing language models that generate new ideas derived from the scientific literature",
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "authors": [
                {
                    "authorId": "1786863",
                    "name": "Qingyun Wang"
                },
                {
                    "authorId": "145612610",
                    "name": "Doug Downey"
                },
                {
                    "authorId": "2072975661",
                    "name": "Heng Ji"
                },
                {
                    "authorId": "2041698667",
                    "name": "Tom Hope"
                }
            ]
        },
        {
            "paperId": "316a011bf461d3a96965fb9f69398888da19bd9f",
            "title": "SynerGPT: In-Context Learning for Personalized Drug Synergy Prediction and Drug Design",
            "abstract": "Predicting synergistic drug combinations can help accelerate discovery of cancer treatments, particularly therapies personalized to a patient\u2019s specific tumor via biopsied cells. In this paper, we propose a novel setting and models for in-context drug synergy learning. We are given a small \u201cpersonalized dataset\u201d of 10-20 drug synergy relationships in the context of specific cancer cell targets. Our goal is to predict additional drug synergy relationships in that context. Inspired by recent work that pre-trains a GPT language model (LM) to \u201cin-context learn\u201d common function classes, we devise novel pre-training schemes that enable a GPT model to in-context learn \u201cdrug synergy functions\u201d. Our model\u2014which does not use any textual corpora, molecular fingerprints, protein interaction or any other domain-specific knowledge\u2014 is able to achieve competitive results. We further integrate our in-context approach with a genetic algorithm to optimize model prompts and select synergy candidates to test after conducting a patient biopsy. Finally, we explore a novel task of inverse drug design which can potentially enable the design of drugs that synergize specifically to target a given patient\u2019s \u201cpersonalized dataset\u201d. Our findings can potentially have an important impact on precision cancer medicine, and also raise intriguing questions on non-textual pre-training for LMs.",
            "fieldsOfStudy": [
                "Computer Science",
                "Biology"
            ],
            "authors": [
                {
                    "authorId": "48870109",
                    "name": "Carl N. Edwards"
                },
                {
                    "authorId": "23175870",
                    "name": "Aakanksha Naik"
                },
                {
                    "authorId": "2236429",
                    "name": "Tushar Khot"
                },
                {
                    "authorId": "2199258773",
                    "name": "Martin Burke"
                },
                {
                    "authorId": "2181650518",
                    "name": "Heng Ji"
                },
                {
                    "authorId": "2041698667",
                    "name": "Tom Hope"
                }
            ]
        },
        {
            "paperId": "8eaebaf8fc01049ee2812607642f1ac0dabc6c6e",
            "title": "Beyond Good Intentions: Reporting the Research Landscape of NLP for Social Good",
            "abstract": "With the recent advances in natural language processing (NLP), a vast number of applications have emerged across various use cases. Among the plethora of NLP applications, many academic researchers are motivated to do work that has a positive social impact, in line with the recent initiatives of NLP for Social Good (NLP4SG). However, it is not always obvious to researchers how their research efforts are tackling today's big social problems. Thus, in this paper, we introduce NLP4SG Papers, a scientific dataset with three associated tasks that can help identify NLP4SG papers and characterize the NLP4SG landscape by: (1) identifying the papers that address a social problem, (2) mapping them to the corresponding UN Sustainable Development Goals (SDGs), and (3) identifying the task they are solving and the methods they are using. Using state-of-the-art NLP models, we address each of these tasks and use them on the entire ACL Anthology, resulting in a visualization workspace that gives researchers a comprehensive overview of the field of NLP4SG. Our website is available at https://nlp4sg.vercel.app. We released our data at https://huggingface.co/datasets/feradauto/NLP4SGPapers and code at https://github.com/feradauto/nlp4sg",
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "authors": [
                {
                    "authorId": "2111747266",
                    "name": "F. Gonz\u00e1lez"
                },
                {
                    "authorId": "2111472502",
                    "name": "Zhijing Jin"
                },
                {
                    "authorId": "2190982849",
                    "name": "Jade Beydoun"
                },
                {
                    "authorId": "1707625",
                    "name": "B. Scholkopf"
                },
                {
                    "authorId": "2041698667",
                    "name": "Tom Hope"
                },
                {
                    "authorId": "2790926",
                    "name": "Mrinmaya Sachan"
                },
                {
                    "authorId": "2105984203",
                    "name": "Rada Mihalcea"
                }
            ]
        },
        {
            "paperId": "ce865a1d2ad7ac6850bfc72edcea9e6cf3930976",
            "title": "Increasing Textual Context Size Boosts Medical Image-Text Matching",
            "abstract": "This short technical report demonstrates a simple technique that yields state of the art results in medical image-text matching tasks. We analyze the use of OpenAI's CLIP, a general image-text matching model, and observe that CLIP's limited textual input size has negative impact on downstream performance in the medical domain where encoding longer textual contexts is often required. We thus train and release ClipMD, which is trained with a simple sliding window technique to encode textual captions. ClipMD was tested on two medical image-text datasets and compared with other image-text matching models. The results show that ClipMD outperforms other models on both datasets by a large margin. We make our code and pretrained model publicly available.",
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "authors": [
                {
                    "authorId": "17137806",
                    "name": "I. Glassberg"
                },
                {
                    "authorId": "2041698667",
                    "name": "Tom Hope"
                }
            ]
        },
        {
            "paperId": "fd8c64d0b912795e1cefc0aba4c6d90499132755",
            "title": "ARIES: A Corpus of Scientific Paper Edits Made in Response to Peer Reviews",
            "abstract": "We introduce the task of automatically revising scientific papers based on peer feedback and release ARIES, a dataset of review comments and their corresponding paper edits. The data is drawn from real reviewer-author interactions from computer science, and we provide labels linking each reviewer comment to the specific paper edits made by the author in response. We automatically create a high-precision silver training set, as well as an expert-labeled test set that shows high inter-annotator agreement. In experiments with 10 models covering the state of the art, we find that they struggle even to identify which edits correspond to a comment -- especially when the relationship between the edit and the comment is indirect and requires reasoning to uncover. We also extensively analyze GPT-4's ability to generate edits given a comment and the original paper. We find that it often succeeds on a superficial level, but tends to rigidly follow the wording of the feedback rather than the underlying intent, and lacks technical details compared to human-written edits.",
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "authors": [
                {
                    "authorId": "40480862",
                    "name": "Mike D'Arcy"
                },
                {
                    "authorId": "32739287",
                    "name": "Alexis Ross"
                },
                {
                    "authorId": "2203427167",
                    "name": "Erin Bransom"
                },
                {
                    "authorId": "2003338023",
                    "name": "Bailey Kuehl"
                },
                {
                    "authorId": "2699105",
                    "name": "Jonathan Bragg"
                },
                {
                    "authorId": "2041698667",
                    "name": "Tom Hope"
                },
                {
                    "authorId": "145612610",
                    "name": "Doug Downey"
                }
            ]
        },
        {
            "paperId": "449e58a29a3971d4d54d9bb28df3b31c60d20483",
            "title": "ACCoRD: A Multi-Document Approach to Generating Diverse Descriptions of Scientific Concepts",
            "abstract": "Systems that can automatically define unfamiliar terms hold the promise of improving the accessibility of scientific texts, especially for readers who may lack prerequisite background knowledge. However, current systems assume a single\"best\"description per concept, which fails to account for the many potentially useful ways a concept can be described. We present ACCoRD, an end-to-end system tackling the novel task of generating sets of descriptions of scientific concepts. Our system takes advantage of the myriad ways a concept is mentioned across the scientific literature to produce distinct, diverse descriptions of target scientific concepts in terms of different reference concepts. To support research on the task, we release an expert-annotated resource, the ACCoRD corpus, which includes 1,275 labeled contexts and 1,787 hand-authored concept descriptions. We conduct a user study demonstrating that (1) users prefer descriptions produced by our end-to-end system, and (2) users prefer multiple descriptions to a single\"best\"description.",
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "authors": [
                {
                    "authorId": "2092829026",
                    "name": "Sonia K. Murthy"
                },
                {
                    "authorId": "46258841",
                    "name": "Kyle Lo"
                },
                {
                    "authorId": "145104486",
                    "name": "Daniel King"
                },
                {
                    "authorId": "1857797",
                    "name": "Chandra Bhagavatula"
                },
                {
                    "authorId": "2003338023",
                    "name": "Bailey Kuehl"
                },
                {
                    "authorId": "1406046265",
                    "name": "Sophie Johnson"
                },
                {
                    "authorId": "32196774",
                    "name": "Jon Borchardt"
                },
                {
                    "authorId": "1780531",
                    "name": "Daniel S. Weld"
                },
                {
                    "authorId": "2041698667",
                    "name": "Tom Hope"
                },
                {
                    "authorId": "145612610",
                    "name": "Doug Downey"
                }
            ]
        },
        {
            "paperId": "65443f7d7106a36439326d7a5028a67c45d35e22",
            "title": "Augmenting Scientific Creativity with an Analogical Search Engine",
            "abstract": "Analogies have been central to creative problem-solving throughout the history of science and technology. As the number of scientific articles continues to increase exponentially, there is a growing opportunity for finding diverse solutions to existing problems. However, realizing this potential requires the development of a means for searching through a large corpus that goes beyond surface matches and simple keywords. Here we contribute the first end-to-end system for analogical search on scientific articles and evaluate its effectiveness with scientists\u2019 own problems. Using a human-in-the-loop AI system as a probe we find that our system facilitates creative ideation, and that ideation success is mediated by an intermediate level of matching on the problem abstraction (i.e., high versus low). We also demonstrate a fully automated AI search engine that achieves a similar accuracy with the human-in-the-loop system. We conclude with design implications for enabling automated analogical inspiration engines to accelerate scientific innovation.",
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "authors": [
                {
                    "authorId": "26997666",
                    "name": "Hyeonsu B Kang"
                },
                {
                    "authorId": "1665150187",
                    "name": "Xin Qian"
                },
                {
                    "authorId": "2041698667",
                    "name": "Tom Hope"
                },
                {
                    "authorId": "1805894",
                    "name": "Dafna Shahaf"
                },
                {
                    "authorId": "34753665",
                    "name": "Joel Chan"
                },
                {
                    "authorId": "145234497",
                    "name": "A. Kittur"
                }
            ]
        },
        {
            "paperId": "6c5c6f883604a3abaa829b83d2958de8c343beeb",
            "title": "A Computational Inflection for Scientific Discovery",
            "abstract": "Enabling researchers to leverage systems to overcome the limits of human cognitive capacity.",
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "authors": [
                {
                    "authorId": "2041698667",
                    "name": "Tom Hope"
                },
                {
                    "authorId": "145612610",
                    "name": "Doug Downey"
                },
                {
                    "authorId": "1741101",
                    "name": "Oren Etzioni"
                },
                {
                    "authorId": "1780531",
                    "name": "Daniel S. Weld"
                },
                {
                    "authorId": "145479841",
                    "name": "E. Horvitz"
                }
            ]
        },
        {
            "paperId": "9f37278355ae2820a08f4145e476d3499bfef693",
            "title": "A Dataset for N-ary Relation Extraction of Drug Combinations",
            "abstract": "Combination therapies have become the standard of care for diseases such as cancer, tuberculosis, malaria and HIV. However, the combinatorial set of available multi-drug treatments creates a challenge in identifying effective combination therapies available in a situation.To assist medical professionals in identifying beneficial drug-combinations, we construct an expert-annotated dataset for extracting information about the efficacy of drug combinations from the scientific literature. Beyond its practical utility, the dataset also presents a unique NLP challenge, as the first relation extraction dataset consisting of variable-length relations. Furthermore, the relations in this dataset predominantly require language understanding beyond the sentence level, adding to the challenge of this task. We provide a promising baseline model and identify clear areas for further improvement. We release our dataset (https://huggingface.co/datasets/allenai/drug-combo-extraction), code (https://github.com/allenai/drug-combo-extraction) and baseline models (https://huggingface.co/allenai/drug-combo-classifier-pubmedbert-dapt) publicly to encourage the NLP community to participate in this task.",
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "authors": [
                {
                    "authorId": "1667847713",
                    "name": "Aryeh Tiktinsky"
                },
                {
                    "authorId": "2061499362",
                    "name": "Vijay Viswanathan"
                },
                {
                    "authorId": "2137325504",
                    "name": "Danna Niezni"
                },
                {
                    "authorId": "2164170693",
                    "name": "D. Azagury"
                },
                {
                    "authorId": "49944517",
                    "name": "Y. Shamay"
                },
                {
                    "authorId": "1409499701",
                    "name": "Hillel Taub-Tabib"
                },
                {
                    "authorId": "2041698667",
                    "name": "Tom Hope"
                },
                {
                    "authorId": "79775260",
                    "name": "Yoav Goldberg"
                }
            ]
        },
        {
            "paperId": "cd0c0772b6946ab835bd6dcbdd87e66c8ca7fd17",
            "title": "CascadER: Cross-Modal Cascading for Knowledge Graph Link Prediction",
            "abstract": "Knowledge graph (KG) link prediction is a fundamental task in artificial intelligence, with applications in natural language processing, information retrieval, and biomedicine. Recently, promising results have been achieved by leveraging cross-modal information in KGs, using ensembles that combine knowledge graph embeddings (KGEs) and contextual language models (LMs). However, existing ensembles are either (1) not consistently effective in terms of ranking accuracy gains or (2) impractically inefficient on larger datasets due to the combinatorial explosion problem of pairwise ranking with deep language models. In this paper, we propose a novel tiered ranking architecture CascadER to maintain the ranking accuracy of full ensembling while improving efficiency considerably. CascadER uses LMs to rerank the outputs of more efficient base KGEs, relying on an adaptive subset selection scheme aimed at invoking the LMs minimally while maximizing accuracy gain over the KGE. Extensive experiments demonstrate that CascadER improves MRR by up to 9 points over KGE baselines, setting new state-of-the-art performance on four benchmarks while improving efficiency by one or more orders of magnitude over competitive cross-modal baselines. Our empirical analyses reveal that diversity of models across modalities and preservation of individual models' confidence signals help explain the effectiveness of CascadER, and suggest promising directions for cross-modal cascaded architectures. Code and pretrained models are available at https://github.com/tsafavi/cascader.",
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "authors": [
                {
                    "authorId": "8495818",
                    "name": "Tara Safavi"
                },
                {
                    "authorId": "145612610",
                    "name": "Doug Downey"
                },
                {
                    "authorId": "2041698667",
                    "name": "Tom Hope"
                }
            ]
        }
    ]
}