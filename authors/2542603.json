{
    "authorId": "2542603",
    "papers": [
        {
            "paperId": "0383e049e98c9eedbc61be728d4ef037300bbedf",
            "title": "Recommendation as Instruction Following: A Large Language Model Empowered Recommendation Approach",
            "abstract": "In the past decades, recommender systems have attracted much attention in both research and industry communities, and a large number of studies have been devoted to developing effective recommendation models. Basically speaking, these models mainly learn the underlying user preference from historical behavior data, and then estimate the user-item matching relationships for recommendations. Inspired by the recent progress on large language models (LLMs), we take a different approach to developing the recommendation models, considering recommendation as instruction following by LLMs. The key idea is that the preferences or needs of a user can be expressed in natural language descriptions (called instructions), so that LLMs can understand and further execute the instruction for fulfilling the recommendation task. Instead of using public APIs of LLMs, we instruction tune an open-source LLM (3B Flan-T5-XL), in order to better adapt LLMs to recommender systems. For this purpose, we first design a general instruction format for describing the preference, intention, task form and context of a user in natural language. Then we manually design 39 instruction templates and automatically generate a large amount of user-personalized instruction data (252K instructions) with varying types of preferences and intentions. To demonstrate the effectiveness of our approach, we instantiate the instruction templates into several widely-studied recommendation (or search) tasks, and conduct extensive experiments on these tasks with real-world datasets. Experiment results show that the proposed approach can outperform several competitive baselines, including the powerful GPT-3.5, on these evaluation tasks. Our approach sheds light on developing more user-friendly recommender systems, in which users can freely communicate with the system and obtain more accurate recommendations via natural language instructions.",
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "authors": [
                {
                    "authorId": "2120518257",
                    "name": "Junjie Zhang"
                },
                {
                    "authorId": "3360722",
                    "name": "Ruobing Xie"
                },
                {
                    "authorId": "151472453",
                    "name": "Yupeng Hou"
                },
                {
                    "authorId": "2542603",
                    "name": "Wayne Xin Zhao"
                },
                {
                    "authorId": "4950224",
                    "name": "Leyu Lin"
                },
                {
                    "authorId": "153693432",
                    "name": "Ji-rong Wen"
                }
            ]
        },
        {
            "paperId": "0a0ba2a90a4a5871d58e78b333f805eac896a1b1",
            "title": "Not All Metrics Are Guilty: Improving NLG Evaluation with LLM Paraphrasing",
            "abstract": "Most research about natural language generation (NLG) relies on evaluation benchmarks with limited references for a sample, which may result in poor correlations with human judgements. The underlying reason is that one semantic meaning can actually be expressed in different forms, and the evaluation with a single or few references may not accurately reflect the quality of the model\u2019s hypotheses. To address this issue, this paper presents a novel method, named Para-Ref , to enhance existing evaluation benchmarks by enriching the number of references. We leverage large language models (LLMs) to paraphrase a single reference into multiple high-quality ones in diverse expressions. Experimental results on representative NLG tasks of machine translation, text summarization, and image caption demonstrate that our method can effectively improve the correlation with human evaluation for sixteen automatic evaluation metrics by +7.82% in ratio. We release the code and data at https://github.com/RUCAIBox/Para-Ref .",
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "authors": [
                {
                    "authorId": "1997234792",
                    "name": "Tianyi Tang"
                },
                {
                    "authorId": "2156273800",
                    "name": "Hongyuan Lu"
                },
                {
                    "authorId": "2134457930",
                    "name": "Yuchen Jiang"
                },
                {
                    "authorId": "15086992",
                    "name": "Haoyang Huang"
                },
                {
                    "authorId": "40232931",
                    "name": "Dongdong Zhang"
                },
                {
                    "authorId": "2542603",
                    "name": "Wayne Xin Zhao"
                },
                {
                    "authorId": "49807919",
                    "name": "Furu Wei"
                }
            ]
        },
        {
            "paperId": "0b01df6ce3fedf2d3093cb3e16e4bf7215f05d90",
            "title": "Multi-modal Mixture of Experts Represetation Learning for Sequential Recommendation",
            "abstract": "Within online platforms, it is critical to capture the dynamic user preference from the sequential interaction behaviors for making accurate recommendation over time. Recently, significant progress has been made in sequential recommendation with deep learning. However, existing neural sequential recommender often suffer from the data sparsity issue in real-world applications. To tackle this problem, we propose a Multi-Modal Mixture of experts model for Sequential Recommendation, named M3SRec, which leverage rich multi-modal interaction data for improving sequential recommendation. Different from existing multi-modal recommendation models, our approach jointly considers reducing the semantic gap across modalities and adapts multi-modal semantics to fit recommender systems. For this purpose, we make two important technical contributions in architecture and training. Firstly, we design a novel multi-modal mixture-of-experts (MoE) fusion network, which can deeply fuse the across-modal semantics and largely enhance the modeling capacity of complex user intents. For training, we design specific pre-training tasks that can mimic the goal of the recommendation, which help model learn the semantic relatedness between the multi-modal sequential context and the target item. Extensive experiments conducted on both public and industry datasets demonstrate the superiority of our proposed method over existing state-of-the-art methods, especially when only limited training data is available.",
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "authors": [
                {
                    "authorId": "40901446",
                    "name": "Shuqing Bian"
                },
                {
                    "authorId": "2261366963",
                    "name": "Xingyu Pan"
                },
                {
                    "authorId": "2542603",
                    "name": "Wayne Xin Zhao"
                },
                {
                    "authorId": "2260827528",
                    "name": "Jinpeng Wang"
                },
                {
                    "authorId": "2260827558",
                    "name": "Chuyuan Wang"
                },
                {
                    "authorId": "2260701602",
                    "name": "Ji-Rong Wen"
                }
            ]
        },
        {
            "paperId": "0b29ff236bb8f547d017bf747ad74ad2b8303851",
            "title": "Not All Languages Are Created Equal in LLMs: Improving Multilingual Capability by Cross-Lingual-Thought Prompting",
            "abstract": "Large language models (LLMs) demonstrate impressive multilingual capability, but their performance varies substantially across different languages. In this work, we introduce a simple yet effective method, called cross-lingual-thought prompting (XLT), to systematically improve the multilingual capability of LLMs. Specifically, XLT is a generic template prompt that stimulates cross-lingual and logical reasoning skills to enhance task performance across languages. We conduct comprehensive evaluations on 7 typical benchmarks related to reasoning, understanding, and generation tasks, covering both high-resource and low-resource languages. Experimental results show that XLT not only remarkably enhances the performance of various multilingual tasks but also significantly reduces the gap between the average performance and the best performance of each task in different languages. Notably, XLT brings over 10 points of average improvement in arithmetic reasoning and open-domain question-answering tasks.",
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "authors": [
                {
                    "authorId": "15086992",
                    "name": "Haoyang Huang"
                },
                {
                    "authorId": "1997234792",
                    "name": "Tianyi Tang"
                },
                {
                    "authorId": "40232931",
                    "name": "Dongdong Zhang"
                },
                {
                    "authorId": "2542603",
                    "name": "Wayne Xin Zhao"
                },
                {
                    "authorId": "2212903837",
                    "name": "Ting Song"
                },
                {
                    "authorId": "2111130689",
                    "name": "Yan Xia"
                },
                {
                    "authorId": "49807919",
                    "name": "Furu Wei"
                }
            ]
        },
        {
            "paperId": "14e9f752dfabb8ce34e310ed26c26a3f72a00e74",
            "title": "Learning to Perturb for Contrastive Learning of Unsupervised Sentence Representations",
            "abstract": "Recently, contrastive learning has been shown effective in fine-tuning pre-trained language models (PLM) to learn sentence representations, which incorporates perturbations into unlabeled sentences to augment semantically related positive examples for training. However, previous works mostly adopt heuristic perturbation methods that are independent of the sentence representations. Since the perturbations are unaware of the goal or process of sentence representation learning during training, it is likely to lead to sub-optimal augmentations for conducting constrative learning. To address this issue, we propose a new framework L2P-CSR that adopts a learnable perturbation strategy for improving contrastive learning of sentence representations. In our L2P-CSR, we design a safer perturbation mechanism that only weakens the influence of tokens and features on the sentence representation, which avoids dramatically changing the semantics of the sentence representations. Besides, we devise a gradient-based algorithm to generate adaptive perturbations specially for the dynamically updated sentence representation during training. Such a way is more capable of augmenting high-quality examples that guide the sentence representation learning. Extensive experiments on diverse sentence-related tasks show that our approach outperforms competitive baselines.",
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "authors": [
                {
                    "authorId": "1423651904",
                    "name": "Kun Zhou"
                },
                {
                    "authorId": "2116568362",
                    "name": "Yuanhang Zhou"
                },
                {
                    "authorId": "2542603",
                    "name": "Wayne Xin Zhao"
                },
                {
                    "authorId": "153693432",
                    "name": "Ji-rong Wen"
                }
            ]
        },
        {
            "paperId": "1d24f26cfde2b39849db4119d2044b071b2431c1",
            "title": "Towards a More User-Friendly and Easy-to-Use Benchmark Library for Recommender Systems",
            "abstract": "In recent years, the reproducibility of recommendation models has become a severe concern in recommender systems. In light of this challenge, we have previously released a unified, comprehensive and efficient recommendation library called RecBole, attracting much attention from the research community. With the increasing number of users, we have received a number of suggestions and update requests. This motivates us to make further improvements on our library, so as to meet the user requirements and contribute to the research community. In this paper, we present a significant update of RecBole, making it more user-friendly and easy-to-use as a comprehensive benchmark library for recommendation. More specifically, the highlights of this update are summarized as: (1) we include more benchmark models and datasets, improve the benchmark framework in terms of data processing, training and evaluation, and release reproducible configurations to benchmark the recommendation models; (2) we upgrade the user friendliness of our library by providing more detailed documentation and well-organized frequently asked questions, and (3) we propose several development guidelines for the open-source library developers. These extensions make it much easier to reproduce the benchmark results and stay up-to-date with the recent advances on recommender systems. Our update is released at the link: https://github.com/RUCAIBox/RecBole.",
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "authors": [
                {
                    "authorId": "2167464968",
                    "name": "Lanling Xu"
                },
                {
                    "authorId": "2152251597",
                    "name": "Zhen Tian"
                },
                {
                    "authorId": "2404181",
                    "name": "Gaowei Zhang"
                },
                {
                    "authorId": "2120518257",
                    "name": "Junjie Zhang"
                },
                {
                    "authorId": "2152509786",
                    "name": "Lei Wang"
                },
                {
                    "authorId": "2223753455",
                    "name": "Bowen Zheng"
                },
                {
                    "authorId": "2209136299",
                    "name": "Yifan Li"
                },
                {
                    "authorId": "144010962",
                    "name": "Jiakai Tang"
                },
                {
                    "authorId": "2223760889",
                    "name": "Zeyu Zhang"
                },
                {
                    "authorId": "151472453",
                    "name": "Yupeng Hou"
                },
                {
                    "authorId": "1471329930",
                    "name": "Xingyu Pan"
                },
                {
                    "authorId": "2542603",
                    "name": "Wayne Xin Zhao"
                },
                {
                    "authorId": "2144230136",
                    "name": "Xu Chen"
                },
                {
                    "authorId": "153693432",
                    "name": "Ji-rong Wen"
                }
            ]
        },
        {
            "paperId": "1f70ca7c9cc9257a16b9705c60b20ed1fc4d872c",
            "title": "Improving Conversational Recommendation Systems via Counterfactual Data Simulation",
            "abstract": "Conversational recommender systems~(CRSs) aim to provide recommendation services via natural language conversations. Although a number of approaches have been proposed for developing capable CRSs, they typically rely on sufficient training data for training. Since it is difficult to annotate recommendation-oriented dialogue datasets, existing CRS approaches often suffer from the issue of insufficient training due to the scarcity of training data. To address this issue, in this paper, we propose a CounterFactual data simulation approach for CRS, named CFCRS, to alleviate the issue of data scarcity in CRSs. Our approach is developed based on the framework of counterfactual data augmentation, which gradually incorporates the rewriting to the user preference from a real dialogue without interfering with the entire conversation flow. To develop our approach, we characterize user preference and organize the conversation flow by the entities involved in the dialogue, and design a multi-stage recommendation dialogue simulator based on a conversation flow language model. Under the guidance of the learned user preference and dialogue schema, the flow language model can produce reasonable, coherent conversation flows, which can be further realized into complete dialogues. Based on the simulator, we perform the intervention at the representations of the interacted entities of target users, and design an adversarial training method with a curriculum schedule that can gradually optimize the data augmentation strategy. Extensive experiments show that our approach can consistently boost the performance of several competitive CRSs, and outperform other data augmentation methods, especially when the training data is limited. Our code is publicly available at https://github.com/RUCAIBox/CFCRS.",
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "authors": [
                {
                    "authorId": "72541556",
                    "name": "Xiaolei Wang"
                },
                {
                    "authorId": "1423651904",
                    "name": "Kun Zhou"
                },
                {
                    "authorId": "2109887979",
                    "name": "Xinyu Tang"
                },
                {
                    "authorId": "2542603",
                    "name": "Wayne Xin Zhao"
                },
                {
                    "authorId": "2218966021",
                    "name": "Fan Pan"
                },
                {
                    "authorId": "2106400572",
                    "name": "Zhao Cao"
                },
                {
                    "authorId": "153693432",
                    "name": "Ji-rong Wen"
                }
            ]
        },
        {
            "paperId": "1fd6f33f6429b248e983193d2278ab3e1814471c",
            "title": "Unified Data Management and Comprehensive Performance Evaluation for Urban Spatial-Temporal Prediction [Experiment, Analysis & Benchmark]",
            "abstract": "The field of urban spatial-temporal prediction is advancing rapidly with the development of deep learning techniques and the availability of large-scale datasets. However, challenges persist in accessing and utilizing diverse urban spatial-temporal datasets from different sources and stored in different formats, as well as determining effective model structures and components with the proliferation of deep learning models. This work addresses these challenges and provides three significant contributions. Firstly, we introduce\"atomic files\", a unified storage format designed for urban spatial-temporal big data, and validate its effectiveness on 40 diverse datasets, simplifying data management. Secondly, we present a comprehensive overview of technological advances in urban spatial-temporal prediction models, guiding the development of robust models. Thirdly, we conduct extensive experiments using diverse models and datasets, establishing a performance leaderboard and identifying promising research directions. Overall, this work effectively manages urban spatial-temporal data, guides future efforts, and facilitates the development of accurate and efficient urban spatial-temporal prediction models. It can potentially make long-term contributions to urban spatial-temporal data management and prediction, ultimately leading to improved urban living standards.",
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "authors": [
                {
                    "authorId": "1720749264",
                    "name": "Jiawei Jiang"
                },
                {
                    "authorId": "2202077400",
                    "name": "Chengkai Han"
                },
                {
                    "authorId": "2542603",
                    "name": "Wayne Xin Zhao"
                },
                {
                    "authorId": "2115891766",
                    "name": "Jingyuan Wang"
                }
            ]
        },
        {
            "paperId": "206400aba5f12f734cdd2e4ab48ef6014ea60773",
            "title": "Evaluating Object Hallucination in Large Vision-Language Models",
            "abstract": "Inspired by the superior language abilities of large language models (LLM), large vision-language models (LVLM) have been recently explored by integrating powerful LLMs for improving the performance on complex multimodal tasks. Despite the promising progress on LVLMs, we find that LVLMs suffer from the hallucination problem, i.e. they tend to generate objects that are inconsistent with the target images in the descriptions. To investigate it, this work presents the first systematic study on object hallucination of LVLMs. We conduct the evaluation experiments on several representative LVLMs, and show that they mostly suffer from severe object hallucination issue. We further discuss that the visual instructions may influence the hallucination, and find that: objects that frequently occur in the visual instructions or co-occur with the image objects, are obviously prone to be hallucinated by LVLMs. Besides, we find that existing evaluation methods might be affected by the input instructions and generation styles of LVLMs. Thus, we further design an improved evaluation method for object hallucination by proposing a polling-based query method called POPE. Experiment results demonstrate that our POPE can evaluate the object hallucination in a more stable and flexible way. Our codes and data are publicly available at https://github.com/RUCAIBox/POPE.",
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "authors": [
                {
                    "authorId": "2209136299",
                    "name": "Yifan Li"
                },
                {
                    "authorId": "2111895473",
                    "name": "Yifan Du"
                },
                {
                    "authorId": "1423651904",
                    "name": "Kun Zhou"
                },
                {
                    "authorId": "1823719",
                    "name": "Jinpeng Wang"
                },
                {
                    "authorId": "2542603",
                    "name": "Wayne Xin Zhao"
                },
                {
                    "authorId": "153693432",
                    "name": "Ji-rong Wen"
                }
            ]
        },
        {
            "paperId": "27f6598be5380d5a934b688e246cdf3488ccea0f",
            "title": "LibCity: A Unified Library Towards Efficient and Comprehensive Urban Spatial-Temporal Prediction",
            "abstract": "As deep learning technology advances and more urban spatial-temporal data accumulates, an increasing number of deep learning models are being proposed to solve urban spatial-temporal prediction problems. However, there are limitations in the existing field, including open-source data being in various formats and difficult to use, few papers making their code and data openly available, and open-source models often using different frameworks and platforms, making comparisons challenging. A standardized framework is urgently needed to implement and evaluate these methods. To address these issues, we propose LibCity, an open-source library that offers researchers a credible experimental tool and a convenient development framework. In this library, we have reproduced 65 spatial-temporal prediction models and collected 55 spatial-temporal datasets, allowing researchers to conduct comprehensive experiments conveniently. By enabling fair model comparisons, designing a unified data storage format, and simplifying the process of developing new models, LibCity is poised to make significant contributions to the spatial-temporal prediction field.",
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "authors": [
                {
                    "authorId": "1720749264",
                    "name": "Jiawei Jiang"
                },
                {
                    "authorId": "2202077400",
                    "name": "Chengkai Han"
                },
                {
                    "authorId": "2155573046",
                    "name": "Wenjun Jiang"
                },
                {
                    "authorId": "2542603",
                    "name": "Wayne Xin Zhao"
                },
                {
                    "authorId": "2115891766",
                    "name": "Jingyuan Wang"
                }
            ]
        }
    ]
}