{
    "authorId": "1802817",
    "papers": [
        {
            "paperId": "daee411d04dfc52d2270b3b611c42525522aeefa",
            "title": "BUNNI: Learning Repair Actions in Rule-driven Data Cleaning",
            "abstract": "In this work, we address the challenging and open problem of involving non-expert users in the data repairing problem as first-class citizens. Despite a large number of proposals that have been devoted to cleaning data from the point of view of expert users (IT staff and data scientists), there is a lack of studies from the perspective of non-expert ones. Given a set of available data quality rules, we exploit machine learning techniques to guide the user to identify the dirty values for each violation and repair them. We show that with a low user effort, it is possible to identify the values in tuples that can be trusted and the ones that are most likely errors. We show experimentally how this machine learning approach leads to a unique clean solution with high quality in scenarios where other approaches fail.",
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "authors": [
                {
                    "authorId": "1785690",
                    "name": "G. Mecca"
                },
                {
                    "authorId": "1802817",
                    "name": "Paolo Papotti"
                },
                {
                    "authorId": "145530628",
                    "name": "Donatello Santoro"
                },
                {
                    "authorId": "2091355118",
                    "name": "Enzo Veltri"
                }
            ]
        },
        {
            "paperId": "0efb1dabf282922140c18e6a14da7885a524436a",
            "title": "Analyzing COVID-Related Social Discourse on Twitter using Emotion, Sentiment, Political Bias, Stance, Veracity and Conspiracy Theories",
            "abstract": "Online misinformation has become a major concern in recent years, and it has been further emphasized during the COVID-19 pandemic. Social media platforms, such as Twitter, can be serious vectors of misinformation online. In order to better understand the spread of these fake-news, lies, deceptions, and rumours, we analyze the correlations between the following textual features in tweets: emotion, sentiment, political bias, stance, veracity and conspiracy theories. We train several transformer-based classifiers from multiple datasets to detect these textual features and identify potential correlations using conditional distributions of the labels. Our results show that the online discourse regarding some topics, such as COVID-19 regulations or conspiracy theories, is highly controversial and reflects the actual U.S. political landscape.",
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "authors": [
                {
                    "authorId": "1753655600",
                    "name": "Youri Peskine"
                },
                {
                    "authorId": "1684267",
                    "name": "Raphael Troncy"
                },
                {
                    "authorId": "1802817",
                    "name": "Paolo Papotti"
                }
            ]
        },
        {
            "paperId": "18ff1542d5a2a4490c7b3f21522bf1343889f700",
            "title": "Transformers for Tabular Data Representation: A Survey of Models and Applications",
            "abstract": "In the last few years, the natural language processing community has witnessed advances in neural representations of free texts with transformer-based language models (LMs). Given the importance of knowledge available in tabular data, recent research efforts extend LMs by developing neural representations for structured data. In this article, we present a survey that analyzes these efforts. We first abstract the different systems according to a traditional machine learning pipeline in terms of training data, input representation, model training, and supported downstream tasks. For each aspect, we characterize and compare the proposed solutions. Finally, we discuss future work directions.",
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "authors": [
                {
                    "authorId": "97472056",
                    "name": "Gilbert Badaro"
                },
                {
                    "authorId": "2073358417",
                    "name": "Mohammed Saeed"
                },
                {
                    "authorId": "1802817",
                    "name": "Paolo Papotti"
                }
            ]
        },
        {
            "paperId": "26e843426cdbe0991a1f4cec02006d1dd1ed955a",
            "title": "Integrity 2023: Integrity in Social Networks and Media",
            "abstract": "Integrity 2023 is the fourth edition of the successful Workshop on Integrity in Social Networks and Media, held in conjunction with the ACM Conference on Web Search and Data Mining (WSDM) in the past three years. The goal of the workshop is to bring together researchers and practitioners to discuss content and interaction integrity challenges in social networks and social media platforms. The event consists of a combination of invited talks by reputed members of the Integrity community from both academia and industry and peer-reviewed contributed talks and posters solicited via an open call-for-papers.",
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "authors": [
                {
                    "authorId": "2209212295",
                    "name": "Llu\u00eds Garcia-Pueyo"
                },
                {
                    "authorId": "1701195",
                    "name": "Panayiotis Tsaparas"
                },
                {
                    "authorId": "2209214648",
                    "name": "Prathyusha Senthil Kumar"
                },
                {
                    "authorId": "144302930",
                    "name": "T. Sellis"
                },
                {
                    "authorId": "1802817",
                    "name": "Paolo Papotti"
                },
                {
                    "authorId": "3139418",
                    "name": "Sibel Adali"
                },
                {
                    "authorId": "2062659381",
                    "name": "G. Manco"
                },
                {
                    "authorId": "2209217180",
                    "name": "Tudor Trufinescu"
                },
                {
                    "authorId": "144172811",
                    "name": "G. Ranade"
                },
                {
                    "authorId": "5392958",
                    "name": "J. Verbus"
                },
                {
                    "authorId": "1413035003",
                    "name": "Mehmet Tek"
                },
                {
                    "authorId": "144000523",
                    "name": "Anthony McCosker"
                }
            ]
        },
        {
            "paperId": "448ef86f7c6dae82b7767dedca213a84724ecc43",
            "title": "Maximizing Neutrality in News Ordering",
            "abstract": "The detection of fake news has received increasing attention over the past few years, but there are more subtle ways of deceiving one's audience. In addition to the content of news stories, their presentation can also be made misleading or biased. In this work, we study the impact of the ordering of news stories on audience perception. We introduce the problems of detecting cherry-picked news orderings and maximizing neutrality in news orderings. We prove hardness results and present several algorithms for approximately solving these problems. Furthermore, we provide extensive experimental results and present evidence of potential cherry-picking in the real world.",
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "authors": [
                {
                    "authorId": "152163307",
                    "name": "Rishi Advani"
                },
                {
                    "authorId": "1802817",
                    "name": "Paolo Papotti"
                },
                {
                    "authorId": "1717283",
                    "name": "Abolfazl Asudeh"
                }
            ]
        },
        {
            "paperId": "7649bf74ce96faadd5dbaba989c3f83024bdfd04",
            "title": "Tactics, Threats & Targets: Modeling Disinformation and its Mitigation",
            "abstract": "\u2014Disinformation can be used to sway public opinion toward a certain political or economic direction, adversely impact public health, and mobilize groups to engage in violent disobedi- ence. A major challenge in mitigation is scarcity: disinformation is widespread but its mitigators are few. In this work, we interview fact-checkers, journalists, trust and safety specialists, researchers, and analysts who work in different organizations tackling problematic information across the world. From this interview study, we develop an understanding of the reality of combating disinformation across domains, and we use our findings to derive a cybersecurity-inspired framework to characterize the threat of disinformation. While related work has developed similar frameworks for conducting analyses and assessment, our work is distinct in providing the means to thoroughly consider the attacker side, their tactics and approaches. We demonstrate the applicability of our framework on several examples of recent disinformation campaigns.",
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "authors": [
                {
                    "authorId": "153583201",
                    "name": "Muhammad Shujaat Mirza"
                },
                {
                    "authorId": "1471727518",
                    "name": "Labeeba Begum"
                },
                {
                    "authorId": "2142195285",
                    "name": "Liangyun Niu"
                },
                {
                    "authorId": "2211466012",
                    "name": "Sarah Pardo"
                },
                {
                    "authorId": "1698925",
                    "name": "A. Abouzeid"
                },
                {
                    "authorId": "1802817",
                    "name": "Paolo Papotti"
                },
                {
                    "authorId": "2223613",
                    "name": "Christina P\u00f6pper"
                }
            ]
        },
        {
            "paperId": "80c7072e09baef9065b9536b86685dc4b1dfa119",
            "title": "Models and Practice of Neural Table Representations",
            "abstract": "In the last few years, the natural language processing community witnessed advances in neural representations of free-form text with transformer-based language models (LMs). Given the importance of knowledge available in relational tables, recent research efforts extend LMs by developing neural representations for tabular data. In this tutorial, we present these proposals with three main goals. First, we aim at introducing the potentials and limitations of current models to a database audience. Second, we want the attendees to see the benefit of such line of work in a large variety of data applications. Third, we would like to empower the audience with a new set of tools and to inspire them to tackle some of the important directions for neural table representations, including model and system design, evaluation, application and deployment. To achieve these goals, the tutorial is organized in two parts. The first part covers the background for neural table representations, including a survey of the most important systems. The second part is designed as a hands-on session, where attendees will use their laptop to explore this new framework and test neural models involving text and tabular data.",
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "authors": [
                {
                    "authorId": "51309767",
                    "name": "Madelon Hulsebos"
                },
                {
                    "authorId": "145924070",
                    "name": "Xiang Deng"
                },
                {
                    "authorId": "11121990",
                    "name": "Huan Sun"
                },
                {
                    "authorId": "1802817",
                    "name": "Paolo Papotti"
                }
            ]
        },
        {
            "paperId": "944713b47f133847bf810b6af3e472b22c18cf45",
            "title": "The Community Notes Observatory: Can Crowdsourced Fact-Checking be Trusted in Practice?",
            "abstract": "Fact-checking is an important tool in fighting online misinformation. However, it requires expert human resources, and thus does not scale well on social media because of the flow of new content. Crowdsourcing has been proposed to tackle this challenge, as it can scale with a smaller cost, but it has always been studied in controlled environments. In this demo, we present the Community Notes Observatory, an online system to evaluate the first large-scale effort of crowdsourced fact-checking deployed in practice. We let demo attendees search and analyze tweets that are fact-checked by Community Notes users and compare the crowd\u2019s activity against professional fact-checkers. The attendees will explore evidence of i) differences in how the crowd and experts select content to be checked, ii) how the crowd and the experts retrieve different resources to fact-check, and iii) the edge the crowd shows in fact-checking scalability and efficiency as compared to expert checkers.",
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "authors": [
                {
                    "authorId": "2215620251",
                    "name": "Luca Righes"
                },
                {
                    "authorId": "2073358417",
                    "name": "Mohammed Saeed"
                },
                {
                    "authorId": "1694274",
                    "name": "Gianluca Demartini"
                },
                {
                    "authorId": "1802817",
                    "name": "Paolo Papotti"
                }
            ]
        },
        {
            "paperId": "9fe8954d9ef4190598785c14e844a89452ea6943",
            "title": "Generation of Training Examples for Tabular Natural Language Inference",
            "abstract": "Tabular data is becoming increasingly important in Natural Language Processing (NLP) tasks, such as Tabular Natural Language Inference (TNLI). Given a table and a hypothesis expressed in NL text, the goal is to assess if the former structured data supports or refutes the latter. In this work, we focus on the role played by the annotated data in training the inference model. We introduce a system, Tenet, for the automatic augmentation and generation of training examples for TNLI. Given the tables, existing approaches are either based on human annotators, and thus expensive, or on methods that produce simple examples that lack data variety and complex reasoning. Instead, our approach is built around the intuition that SQL queries are the right tool to achieve variety in the generated examples, both in terms of data variety and reasoning complexity. The first is achieved by evidence-queries that identify cell values over tables according to different data patterns. Once the data for the example is identified, semantic-queries describe the different ways such data can be identified with standard SQL clauses. These rich descriptions are then verbalized as text to create the annotated examples for the TNLI task. The same approach is also extended to create counterfactual examples, i.e., examples where the hypothesis is false, with a method based on injecting errors in the original (clean) table. For all steps, we introduce generic generation algorithms that take as input only the tables. For our experimental study, we use three datasets from the TNLI literature and two crafted by us on more complex tables. Tenet generates human-like examples, which lead to the effective training of several inference models with results comparable to those obtained by training the same models with manually-written examples.",
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "authors": [
                {
                    "authorId": "2268337959",
                    "name": "Eurecom JEAN-FLAVIEN BUSSOTTI"
                },
                {
                    "authorId": "2091355118",
                    "name": "Enzo Veltri"
                },
                {
                    "authorId": "145530628",
                    "name": "Donatello Santoro"
                },
                {
                    "authorId": "1802817",
                    "name": "Paolo Papotti"
                },
                {
                    "authorId": "2268339002",
                    "name": "Dem Michelle"
                },
                {
                    "authorId": "2268338997",
                    "name": "Donald Rep"
                },
                {
                    "authorId": "2268333697",
                    "name": "Nancy Dem"
                }
            ]
        },
        {
            "paperId": "bdbe2c1a430d8a15d20964bfd5d7e828ccae73d0",
            "title": "Querying Large Language Models with SQL",
            "abstract": "In many use-cases, information is stored in text but not available in structured data. However, extracting data from natural language text to precisely fit a schema, and thus enable querying, is a challenging task. With the rise of pre-trained Large Language Models (LLMs), there is now an effective solution to store and use information extracted from massive corpora of text documents. Thus, we envision the use of SQL queries to cover a broad range of data that is not captured by traditional databases by tapping the information in LLMs. To ground this vision, we present Galois, a prototype based on a traditional database architecture, but with new physical operators for querying the underlying LLM. The main idea is to execute some operators of the the query plan with prompts that retrieve data from the LLM. For a large class of SQL queries, querying LLMs returns well structured relations, with encouraging qualitative results. Preliminary experimental results make pre-trained LLMs a promising addition to the field of database systems, introducing a new direction for hybrid query processing. However, we pinpoint several research challenges that must be addressed to build a DBMS that exploits LLMs. While some of these challenges necessitate integrating concepts from the NLP literature, others offer novel research avenues for the DB community.",
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "authors": [
                {
                    "authorId": "2073358417",
                    "name": "Mohammed Saeed"
                },
                {
                    "authorId": "41019080",
                    "name": "Nicola De Cao"
                },
                {
                    "authorId": "1802817",
                    "name": "Paolo Papotti"
                }
            ]
        }
    ]
}