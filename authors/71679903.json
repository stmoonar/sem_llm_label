{
    "authorId": "71679903",
    "papers": [
        {
            "paperId": "867d33d4a008151b6b6f0614512c2cfc3421b78f",
            "title": "Towards A Question Answering System over Temporal Knowledge Graph Embedding",
            "abstract": "Question Answering (QA) over knowledge graphs is a vital topic within information retrieval. Questions with temporal intent are a special case of questions for QA systems that have received only limited attention so far. In this paper, we study using temporal knowledge graph embeddings (TKGEs) for temporal QA. Firstly, we propose a microservice-based architecture for building temporal QA systems on pre-trained TKGE models. Secondly, we present a Bayesian model average (BMA) ensemble method, where results of several link prediction tasks on separated TKGE models are combined to find better answers. Within the system built using the microservice-based architecture, the experiments on two benchmark datasets show that BMA provides better results than the individual models.",
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "authors": [
                {
                    "authorId": "2074816587",
                    "name": "Kristian Otte"
                },
                {
                    "authorId": "2190536939",
                    "name": "Kristian Simoni Vestermark"
                },
                {
                    "authorId": "2108857864",
                    "name": "Huan Li"
                },
                {
                    "authorId": "71679903",
                    "name": "Daniele Dell'Aglio"
                }
            ]
        },
        {
            "paperId": "de80d676c26f8568afeec56f28837e1fe505f911",
            "title": "Transforming RDF-star to Property Graphs: A Preliminary Analysis of Transformation Approaches",
            "abstract": "RDF and property graph models have many similarities, such as using basic graph concepts like nodes and edges. However, such models differ in their modeling approach, expressivity, serialization, and the nature of applications. RDF is the de-facto standard model for knowledge graphs on the Semantic Web and supported by a rich ecosystem for inference and processing. The property graph model, in contrast, provides advantages in scalable graph analytical tasks, such as graph matching, path analysis, and graph traversal. RDF-star extends RDF and allows capturing metadata as a first-class citizen. To tap on the advantages of alternative models, the literature proposes different ways of transforming knowledge graphs between property graphs and RDF. However, most of these approaches cannot provide complete transformations for RDF-star graphs. Hence, this paper provides a step towards transforming RDF-star graphs into property graphs. In particular, we identify different cases to evaluate transformation approaches from RDF-star to property graphs. Specifically, we categorize two classes of transformation approaches and analyze them based on the test cases. The obtained insights will form the foundation for building complete transformation approaches in the future.",
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "authors": [
                {
                    "authorId": "10667713",
                    "name": "Ghadeer Abuoda"
                },
                {
                    "authorId": "71679903",
                    "name": "Daniele Dell'Aglio"
                },
                {
                    "authorId": "2002349",
                    "name": "Arthur K. Keen"
                },
                {
                    "authorId": "1682407",
                    "name": "K. Hose"
                }
            ]
        },
        {
            "paperId": "3dc6026d5846bad87af75523f74d6bebffbee3d3",
            "title": "Toward Measuring the Resemblance of Embedding Models for Evolving Ontologies",
            "abstract": "Updates on ontologies affect the operations built on top of them. But not all changes are equal: some updates drastically change the result of operations; others lead to minor variations, if any. Hence, estimating the impact of a change ex-ante is highly important, as it might make ontology engineers aware of the consequences of their action during editing. However, in order to estimate the impact of changes, we need to understand how to measure them. To address this gap for embeddings, we propose a new measure called Embedding Resemblance Indicator (ERI), which takes into account both the stochasticity of learning embeddings as well as the shortcomings of established comparison methods. We base ERI on (i) a similarity score, (ii) a robustness factor $\\hat\u03bc $ (based on the embedding method, similarity measure, and dataset), and (iii) the number of added or deleted entities to the embedding computed with the Jaccard index. To evaluate ERI, we investigate its usage in the context of two biomedical ontologies and three embedding methods---GraRep, LINE, and DeepWalk---as well as the two standard benchmark datasets---FB15k-237 and Wordnet-18-RR---with TransE and RESCAL embeddings. To study different aspects of ERI, we introduce synthetic changes in the knowledge graphs, generating two test-cases with five versions each and compare their impact with the expected behaviour. Our studies suggests that ERI behaves as expected and captures the similarity of embeddings based on the severity of changes. ERI is crucial for enabling further studies into impact of changes on embeddings.",
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "authors": [
                {
                    "authorId": "2089111587",
                    "name": "Romana Pernisch"
                },
                {
                    "authorId": "71679903",
                    "name": "Daniele Dell'Aglio"
                },
                {
                    "authorId": "145704191",
                    "name": "A. Bernstein"
                }
            ]
        },
        {
            "paperId": "6dc084ab871dff0eafe6c918e517d43b0cb5654d",
            "title": "Single Point Incremental Fourier Transform on 2D Data Streams",
            "abstract": "In radio astronomy, antennas monitor portions of the sky to collect radio signals. The antennas produce data streams that are of high volume and velocity (~2.5 GB/s) and the inverse Fourier transform is used to convert the collected signals into sky images that astrophysicists use to conduct their research. Applying the inverse Fourier transform in a streaming setting, however, is not ideal since its computational complexity is quadratic in the size of the image.In this article, we propose the Single Point Incremental Fourier Transform (SPIFT), a novel incremental algorithm to produce sequences of sky images. SPIFT computes the Fourier transform for a new signal in a linear number of complex multiplications by exploiting twiddle factors, multiplicative constant coefficients. We prove that twiddle factors are periodic and show how circular shifts can be exploited to reuse multiplication results. The cost of the additive operations can be curbed by exploiting the embarrassingly parallel nature of the additions, which modern big data streaming frameworks can leverage to compute slices of the image in parallel. Our experiments suggest that SPIFT can efficiently generate sequences of sky images: it computes the complex multiplications 4 to 12x faster than the Discrete Fourier Transform, and its parallelisation of the additive operations shows linear speedup.",
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "authors": [
                {
                    "authorId": "2143446268",
                    "name": "Muhammad Saad"
                },
                {
                    "authorId": "145704191",
                    "name": "A. Bernstein"
                },
                {
                    "authorId": "2272920728",
                    "name": "Michael H. B\u00f6hlen"
                },
                {
                    "authorId": "71679903",
                    "name": "Daniele Dell'Aglio"
                }
            ]
        },
        {
            "paperId": "8202ffafc7cd307fd0acdb222871c35bea363af0",
            "title": "The Complex Community Structure of the Bitcoin Address Correspondence Network",
            "abstract": "Bitcoin is built on a blockchain, an immutable decentralized ledger that allows entities (users) to exchange Bitcoins in a pseudonymous manner. Bitcoins are associated with alpha-numeric addresses and are transferred via transactions. Each transaction is composed of a set of input addresses (associated with unspent outputs received from previous transactions) and a set of output addresses (to which Bitcoins are transferred). Despite Bitcoin was designed with anonymity in mind, different heuristic approaches exist to detect which addresses in a specific transaction belong to the same entity. By applying these heuristics, we build an Address Correspondence Network: in this representation, addresses are nodes are connected with edges if at least one heuristic detects them as belonging to the same entity. In this paper, we analyze for the first time the Address Correspondence Network and show it is characterized by a complex topology, signaled by a broad, skewed degree distribution and a power-law component size distribution. Using a large-scale dataset of addresses for which the controlling entities are known, we show that a combination of external data coupled with standard community detection algorithms can reliably identify entities. The complex nature of the Address Correspondence Network reveals that usage patterns of individual entities create statistical regularities; and that these regularities can be leveraged to more accurately identify entities and gain a deeper understanding of the Bitcoin economy as a whole.",
            "fieldsOfStudy": [
                "Computer Science",
                "Physics"
            ],
            "authors": [
                {
                    "authorId": "1853107",
                    "name": "J. Fischer"
                },
                {
                    "authorId": "2097713841",
                    "name": "Andres Palechor"
                },
                {
                    "authorId": "71679903",
                    "name": "Daniele Dell'Aglio"
                },
                {
                    "authorId": "145704191",
                    "name": "A. Bernstein"
                },
                {
                    "authorId": "2146531",
                    "name": "C. Tessone"
                }
            ]
        },
        {
            "paperId": "84a4a2ef9b2a3e558179992dab28c89d8ac61d7e",
            "title": "Entity Prediction in Knowledge Graphs with Joint Embeddings",
            "abstract": "Knowledge Graphs (KGs) have become increasingly popular in the recent years. However, as knowledge constantly grows and changes, it is inevitable to extend existing KGs with entities that emerged or became relevant to the scope of the KG after its creation. Research on updating KGs typically relies on extracting named entities and relations from text. However, these approaches cannot infer entities or relations that were not explicitly stated. Alternatively, embedding models exploit implicit structural regularities to predict missing relations, but cannot predict missing entities. In this article, we introduce a novel method to enrich a KG with new entities given their textual description. Our method leverages joint embedding models, hence does not require entities or relations to be named explicitly. We show that our approach can identify new concepts in a document corpus and transfer them into the KG, and we find that the performance of our method improves substantially when extended with techniques from association rule mining, text mining, and active learning.",
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "authors": [
                {
                    "authorId": "48953764",
                    "name": "Matthias Baumgartner"
                },
                {
                    "authorId": "71679903",
                    "name": "Daniele Dell'Aglio"
                },
                {
                    "authorId": "145704191",
                    "name": "A. Bernstein"
                }
            ]
        },
        {
            "paperId": "42f2b9d2a9767afda6c5259431d5d5d8a9e50fd1",
            "title": "Differentially Private Stream Processing for the Semantic Web",
            "abstract": "Data often contains sensitive information, which poses a major obstacle to publishing it. Some suggest to obfuscate the data or only releasing some data statistics. These approaches have, however, been shown to provide insufficient safeguards against de-anonymisation. Recently, differential privacy (DP), an approach that injects noise into the query answers to provide statistical privacy guarantees, has emerged as a solution to release sensitive data. This study investigates how to continuously release privacy-preserving histograms (or distributions) from online streams of sensitive data by combining DP and semantic web technologies. We focus on distributions, as they are the basis for many analytic applications. Specifically, we propose SihlQL, a query language that processes RDF streams in a privacy-preserving fashion. SihlQL builds on top of SPARQL and the w-event DP framework. We show how some peculiarities of w-event privacy constrain the expressiveness of SihlQL queries. Addressing these constraints, we propose an extension of w-event privacy that provides answers to a larger class of queries while preserving their privacy. To evaluate SihlQL, we implemented a prototype engine that compiles queries to Apache Flink topologies and studied its privacy properties using real-world data from an IPTV provider and an online e-commerce web site.",
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "authors": [
                {
                    "authorId": "71679903",
                    "name": "Daniele Dell'Aglio"
                },
                {
                    "authorId": "145704191",
                    "name": "A. Bernstein"
                }
            ]
        },
        {
            "paperId": "c735b32b98020d360c274734f44642abca044ea5",
            "title": "ChImp: Visualizing Ontology Changes and their Impact in Prot\u00e9g\u00e9",
            "abstract": "Today, ontologies are an established part of many applications and research. \nHowever, ontologies evolve over time, and ontology editors---engineers and domain experts---need to be aware of the consequences of changes while editing. \nOntology editors might not be fully aware of how they are influencing consistency, quality, or the structure of the ontology, possibly causing applications to fail. \nTo support editors and increase their sensitivity towards the consequences of their actions, we conducted a user survey to elicit preferences for representing changes, e.g., with ontology metrics such as number of classes and properties. \nBased on the survey, we developed ChImp---a Protege plug-in to display information about the impact of changes in real-time. \nDuring editing of the ontology, ChImp lists the applied changes, checks and displays the consistency status, and reports measures describing the effect on the structure of the ontology. \nAkin to software IDEs and integrated testing approaches, we hope that displaying such metrics will help to improve ontology evolution processes in the long run.",
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "authors": [
                {
                    "authorId": "51249600",
                    "name": "Romana Pernischov\u00e1"
                },
                {
                    "authorId": "2098080675",
                    "name": "Mirko Serbak"
                },
                {
                    "authorId": "71679903",
                    "name": "Daniele Dell'Aglio"
                },
                {
                    "authorId": "145704191",
                    "name": "A. Bernstein"
                }
            ]
        },
        {
            "paperId": "5581dfbb4eac4cd176b60f6f562440c73a7f7ecf",
            "title": "Toward Predicting Impact of Changes in Evolving Knowledge Graphs",
            "abstract": ": The updates on knowledge graphs (KGs) affect the services built on top of them. However, changes are not all the same: some updates drastically change the result of operations based on knowledge graph content; others do not lead to any variation. Estimating the impact of a change ex-ante is highly important, as it might make KG engineers aware of the consequences of their action during KG editing or may be used to highlight the importance of a new fragment of knowledge to be added to the KG for some application. The main goal of this contribution is to offer a formalization of the problem. Additionally, it presents some preliminary experiments on three different datasets considering embeddings as operation.Results show that the estimation can reach AUCs of 0.85, suggesting the feasibility of this research.",
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "authors": [
                {
                    "authorId": "51249600",
                    "name": "Romana Pernischov\u00e1"
                },
                {
                    "authorId": "71679903",
                    "name": "Daniele Dell'Aglio"
                },
                {
                    "authorId": "1802820",
                    "name": "M. Horridge"
                },
                {
                    "authorId": "48953764",
                    "name": "Matthias Baumgartner"
                },
                {
                    "authorId": "145704191",
                    "name": "A. Bernstein"
                }
            ]
        },
        {
            "paperId": "a7c632399a796f21ad242f18b0e420ef66d3afd8",
            "title": "Collaborative Streaming: Trust Requirements for Price Sharing",
            "abstract": "Stream Processing (SP) is an important Big Data technology enabling continuous querying of data streams. The stream setting offers the opportunity to exploit synergies and, theoretically, share the access and processing costs between multiple different collaborators. But what should be the monetary contribution of each consumer when they do not trust each other and have varying valuations of the differing outcomes? In this article, we present Collaborative Stream Processing (CSP), a model where the costs, which are set exogenously by providers, are shared between multiple consumers, the collaborators. For this, we identify three important requirements for CSP to establish trust between the collaborators and propose a CSP algorithm, ENCSPA, adhering to these requirements. Based on the collaborators\u2019 outcome valuations and the costs of the raw data streams, ENCSPA computes the payment for each collaborator. At the same time, ENCSPA ensures that no collaborator has an incentive to manipulate the system by providing misinformation about her/his value, budget, or time limit. We show that ENCSPA can calculate payments in a reasonable amount of time for up to one thousand collaborators.",
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "authors": [
                {
                    "authorId": "3431016",
                    "name": "Tobias Grubenmann"
                },
                {
                    "authorId": "71679903",
                    "name": "Daniele Dell'Aglio"
                },
                {
                    "authorId": "145704191",
                    "name": "A. Bernstein"
                }
            ]
        }
    ]
}