{
    "authorId": "2116235540",
    "papers": [
        {
            "paperId": "18f230688bf37a56598474f96e081c2327f9a554",
            "title": "All You Need to Know to Build a Product Knowledge Graph",
            "abstract": "Knowledge graphs have been pivotal in supporting downstream applications like search, recommendation, and question answering, among others. Therefore, knowledge graphs have naturally become key enabling technologies in e-Commerce platforms. Developing a high coverage product knowledge graph is more challenging than generic knowledge graphs. The highly specific and complex domain, the sparsity of training data, along with the dynamic taxonomies and product types, can constrain the resulting knowledge graphs. In this tutorial we present best practices and ML innovations in industry towards building a scalable product knowledge graph. Contributions in this domain benefit from the general literature in areas including information extraction and data mining, tailored to address the specific characteristics of e-Commerce platforms.",
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "authors": [
                {
                    "authorId": "2814303",
                    "name": "Nasser Zalmout"
                },
                {
                    "authorId": "2047145237",
                    "name": "Chenwei Zhang"
                },
                {
                    "authorId": "2116235540",
                    "name": "Xian Li"
                },
                {
                    "authorId": "2116799460",
                    "name": "Yan Liang"
                },
                {
                    "authorId": "2143917898",
                    "name": "Xin Dong"
                }
            ]
        },
        {
            "paperId": "2e44f39e9887e1cdd91d48ab18a0bae53ff7f81a",
            "title": "AutoKnow: Self-Driving Knowledge Collection for Products of Thousands of Types",
            "abstract": "Can one build a knowledge graph (KG) for all products in the world? Knowledge graphs have firmly established themselves as valuable sources of information for search and question answering, and it is natural to wonder if a KG can contain information about products offered at online retail sites. There have been several successful examples of generic KGs, but organizing information about products poses many additional challenges, including sparsity and noise of structured data for products, complexity of the domain with millions of product types and thousands of attributes, heterogeneity across large number of categories, as well as large and constantly growing number of products. We describe AutoKnow, our automatic (self-driving) system that addresses these challenges. The system includes a suite of novel techniques for taxonomy construction, product property identification, knowledge extraction, anomaly detection, and synonym discovery. AutoKnow is (a) automatic, requiring little human intervention, (b) multi-scalable, scalable in multiple dimensions (many domains, many products, and many attributes), and (c) integrative, exploiting rich customer behavior logs. AutoKnow has been operational in collecting product knowledge for over 11K product types.",
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "authors": [
                {
                    "authorId": "2143917898",
                    "name": "Xin Dong"
                },
                {
                    "authorId": "2111080293",
                    "name": "Xiang He"
                },
                {
                    "authorId": "2063962350",
                    "name": "Andrey Kan"
                },
                {
                    "authorId": "2116235540",
                    "name": "Xian Li"
                },
                {
                    "authorId": "2116799460",
                    "name": "Yan Liang"
                },
                {
                    "authorId": "65743795",
                    "name": "Jun Ma"
                },
                {
                    "authorId": "15574937",
                    "name": "Y. Xu"
                },
                {
                    "authorId": "2418496",
                    "name": "Chenwei Zhang"
                },
                {
                    "authorId": "2152225582",
                    "name": "Tong Zhao"
                },
                {
                    "authorId": "1753857667",
                    "name": "Gabriel Blanco Saldana"
                },
                {
                    "authorId": "2054184362",
                    "name": "Saurabh Deshpande"
                },
                {
                    "authorId": "153307803",
                    "name": "A. Manduca"
                },
                {
                    "authorId": "1753812304",
                    "name": "Jay Ren"
                },
                {
                    "authorId": "2109039708",
                    "name": "Surender Pal Singh"
                },
                {
                    "authorId": "2057533745",
                    "name": "Fan Xiao"
                },
                {
                    "authorId": "144827671",
                    "name": "Haw-Shiuan Chang"
                },
                {
                    "authorId": "8458211",
                    "name": "Giannis Karamanolakis"
                },
                {
                    "authorId": "3375249",
                    "name": "Yuning Mao"
                },
                {
                    "authorId": "2143381988",
                    "name": "Yaqing Wang"
                },
                {
                    "authorId": "1702392",
                    "name": "C. Faloutsos"
                },
                {
                    "authorId": "143753639",
                    "name": "A. McCallum"
                },
                {
                    "authorId": "153034701",
                    "name": "Jiawei Han"
                }
            ]
        },
        {
            "paperId": "bf2174c69f84f4e57813e0bed4571c6dbff123ed",
            "title": "Automatic Validation of Textual Attribute Values in E-commerce Catalog by Learning with Limited Labeled Data",
            "abstract": "Product catalogs are valuable resources for eCommerce website. In the catalog, a product is associated with multiple attributes whose values are short texts, such as product name, brand, functionality and flavor. Usually individual retailers self-report these key values, and thus the catalog information unavoidably contains noisy facts. It is very important to validate the correctness of these values in order to improve shopper experiences and enable more effective product recommendation. Due to the huge volume of products, an effective automatic validation approach is needed. In this paper, we propose to develop an automatic validation approach that verifies the correctness of textual attribute values for products. This can be formulated as a task as cross-checking a textual attribute value against product profile, which is a short textual description of the product on eCommerce website. Although existing deep neural network models have shown success in conducting cross-checking between two pieces of texts, their success has to be dependent upon a large set of quality labeled data, which are hard to obtain in this validation task: products span a variety of categories. Due to the category difference, annotation has to be done on all the categories, which is impossible to achieve in real practice. To address the aforementioned challenges, we propose a novel meta-learning latent variable approach, called MetaBridge, which can learn transferable knowledge from a subset of categories with limited labeled data and capture the uncertainty of never-seen categories with unlabeled data. More specifically, we make the following contributions. (1) We formalize the problem of validating the textual attribute values of products from a variety of categories as a natural language inference task in the few-shot learning setting, and propose a meta-learning latent variable model to jointly process the signals obtained from product profiles and textual attribute values. (2) We propose to integrate meta learning and latent variable in a unified model to effectively capture the uncertainty of various categories. With this model, annotation costs can be significantly reduced as we make best use of labeled data from limited categories. (3) We propose a novel objective function based on latent variable model in the few-shot learning setting, which ensures distribution consistency between unlabeled and labeled data and prevents overfitting by sampling different records from the learned distribution. Extensive experiments on real eCommerce datasets from hundreds of categories demonstrate the effectiveness of MetaBridge on textual attribute validation and its outstanding performance compared with state-of-the-art approaches.",
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "authors": [
                {
                    "authorId": "2115793087",
                    "name": "Yaqing Wang"
                },
                {
                    "authorId": "15574937",
                    "name": "Y. Xu"
                },
                {
                    "authorId": "2116235540",
                    "name": "Xian Li"
                },
                {
                    "authorId": "2143917898",
                    "name": "Xin Dong"
                },
                {
                    "authorId": "144407304",
                    "name": "Jing Gao"
                }
            ]
        },
        {
            "paperId": "f0af6aefea61e1817a3edc9e82244b19838349bc",
            "title": "Efficient Knowledge Graph Accuracy Evaluation",
            "abstract": "Estimation of the accuracy of a large-scale knowledge graph (KG) often requires humans to annotate samples from the graph. How to obtain statistically meaningful estimates for accuracy evaluation while keeping human annotation costs low is a problem critical to the development cycle of a KG and its practical applications. Surprisingly, this challenging problem has largely been ignored in prior research. To address the problem, this paper proposes an efficient sampling and evaluation framework, which aims to provide quality accuracy evaluation with strong statistical guarantee while minimizing human efforts. Motivated by the properties of the annotation cost function observed in practice, we propose the use of cluster sampling to reduce the overall cost. We further apply weighted and two-stage sampling as well as stratification for better sampling designs. We also extend our framework to enable efficient incremental evaluation on evolving KG, introducing two solutions based on stratified sampling and a weighted variant of reservoir sampling. Extensive experiments on real-world datasets demonstrate the effectiveness and efficiency of our proposed solution. Compared to baseline approaches, our best solutions can provide up to 60% cost reduction on static KG evaluation and up to 80% cost reduction on evolving KG evaluation, without loss of evaluation quality.",
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "authors": [
                {
                    "authorId": "145961125",
                    "name": "Junyang Gao"
                },
                {
                    "authorId": "2116235540",
                    "name": "Xian Li"
                },
                {
                    "authorId": "15574937",
                    "name": "Y. Xu"
                },
                {
                    "authorId": "2582063",
                    "name": "Bunyamin Sisman"
                },
                {
                    "authorId": "2143917898",
                    "name": "Xin Dong"
                },
                {
                    "authorId": "2146157506",
                    "name": "Jun Yang"
                }
            ]
        },
        {
            "paperId": "cf893671f23e9f728a4af13b9ce9988570d3661a",
            "title": "Verification of Fact Statements with Multiple Truthful Alternatives",
            "abstract": "When people are not sure about certain facts, they tend to use the Web to find the answers. Two problems make finding correct answers from the Web challenging. First, the Web contains a significant amount of untruthful information. Second, currently there is a lack of systems/tools that can verify the truthfulness or untruthfulness of a random fact statement and also provide alternative answers. In this paper, we propose a method that aims to determine whether a given statement is truthful and to identify alternative truthful statements that are highly relevant to the given statement. Existing solutions consider only statements with a single expected correct answer. In this paper, we focus on statements that may have multiple relevant alternative answers. We first present a straightforward extension to the previous method to solve such type of statements and show that such a simple extension is inadequate. We then present solutions to two types of such statements. Our evaluation indicates that our proposed solutions are very effective.",
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "authors": [
                {
                    "authorId": "2116235540",
                    "name": "Xian Li"
                },
                {
                    "authorId": "38699354",
                    "name": "W. Meng"
                },
                {
                    "authorId": "2642131",
                    "name": "Clement T. Yu"
                }
            ]
        },
        {
            "paperId": "d1b8f3ad22210828beacdef296d5c25faedca032",
            "title": "Scaling up copy detection",
            "abstract": "Recent research shows that copying is prevalent for Deep-Web data and considering copying can significantly improve truth finding from conflicting values. However, existing copy detection techniques do not scale for large sizes and numbers of data sources, so truth finding can be slowed down by one to two orders of magnitude compared with the corresponding techniques that do not consider copying. In this paper, we study how to improve scalability of copy detection on structured data. Our algorithm builds an inverted index for each shared value and processes the index entries in decreasing order of how much the shared value can contribute to the conclusion of copying. We show how we use the index to prune the data items we consider for each pair of sources, and to incrementally refine our results in iterative copy detection. We also apply a sampling strategy with which we are able to further reduce copy-detection time while still obtaining very similar results as on the whole data set. Experiments on various real data sets show that our algorithm can reduce the time for copy detection by two to three orders of magnitude; in other words, truth finding can benefit from copy detection with very little overhead.",
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "authors": [
                {
                    "authorId": "2116235540",
                    "name": "Xian Li"
                },
                {
                    "authorId": "145867172",
                    "name": "X. Dong"
                },
                {
                    "authorId": "2073317592",
                    "name": "Kenneth Lyons"
                },
                {
                    "authorId": "38699354",
                    "name": "W. Meng"
                },
                {
                    "authorId": "145860176",
                    "name": "D. Srivastava"
                }
            ]
        },
        {
            "paperId": "2b7d75497df9e8d93197c0900df0e1bb2047a086",
            "title": "DiscWord: Learning Discriminative Topics",
            "abstract": "Topic modeling is a popular research topic and is widely used in text mining based applications. Many researchers realize that the learned topics in the LDA model, each as a multinomial distribution on the word vocabulary space, are often not intuitive in term of human recognition and communication. Based on our observation, given a topic, the most frequent words in it are usually less important than some words that are dedicated to it. In this paper, aiming at learning discriminative topics, we introduce a measure named word discriminability to capture a word's ability to identify different topics, and propose an iterative algorithm that is able to train and utilize word discriminability information during the topic learning process. Experimental results show that applying our method on the LDA topic model can improve its document classification accuracy significantly, the learned topics are more discriminative, and the top words of a topic are usually more representative.",
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "authors": [
                {
                    "authorId": "2116341260",
                    "name": "Yu Jiang"
                },
                {
                    "authorId": "2116235540",
                    "name": "Xian Li"
                },
                {
                    "authorId": "38699354",
                    "name": "W. Meng"
                }
            ]
        },
        {
            "paperId": "46b416896cd48484603447e3aec38a719468f068",
            "title": "Truth Finding on the Deep Web: Is the Problem Solved?",
            "abstract": "The amount of useful information available on the Web has been growing at a dramatic pace in recent years and people rely more and more on the Web to fulfill their information needs. In this paper, we study truthfulness of Deep Web data in two domains where we believed data are fairly clean and data quality is important to people's lives: Stock and Flight. To our surprise, we observed a large amount of inconsistency on data from different sources and also some sources with quite low accuracy. We further applied on these two data sets state-of-the-art data fusion methods that aim at resolving conflicts and finding the truth, analyzed their strengths and limitations, and suggested promising research directions. We wish our study can increase awareness of the seriousness of conflicting data on the Web and in turn inspire more research in our community to tackle this problem.",
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "authors": [
                {
                    "authorId": "2116235540",
                    "name": "Xian Li"
                },
                {
                    "authorId": "145867172",
                    "name": "X. Dong"
                },
                {
                    "authorId": "2073317592",
                    "name": "Kenneth Lyons"
                },
                {
                    "authorId": "38699354",
                    "name": "W. Meng"
                },
                {
                    "authorId": "145860176",
                    "name": "D. Srivastava"
                }
            ]
        },
        {
            "paperId": "1eeb12122fcd9e4c68b3e214ca3a002baa721092",
            "title": "T-verifier: Verifying truthfulness of fact statements",
            "abstract": "The Web has become the most popular place for people to acquire information. Unfortunately, it is widely recognized that the Web contains a significant amount of untruthful information. As a result, good tools are needed to help Web users determine the truthfulness of certain information. In this paper, we propose a two-step method that aims to determine whether a given statement is truthful, and if it is not, find out the truthful statement most related to the given statement. In the first step, we try to find a small number of alternative statements of the same topic as the given statement and make sure that one of these statements is truthful. In the second step, we identify the truthful statement from the given statement and the alternative statements. Both steps heavily rely on analysing various features extracted from the search results returned by a popular search engine for appropriate queries. Our experimental results show the best variation of the proposed method can achieve a precision of about 90%.",
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "authors": [
                {
                    "authorId": "2116235540",
                    "name": "Xian Li"
                },
                {
                    "authorId": "38699354",
                    "name": "W. Meng"
                },
                {
                    "authorId": "2642131",
                    "name": "Clement T. Yu"
                }
            ]
        },
        {
            "paperId": "4caed11cde2ec671341449af9e5f5206c162c597",
            "title": "Truthfulness Analysis of Fact Statements Using the Web",
            "abstract": "Web users increasingly treat the Web as a very large knowledge base and use it to acquire all kinds of knowledge. In this article, we introduce a method that leverages the information on the Web to determine the truthfulness of any statement that attempts to state a fact. This method accomplishes the goal by checking whether there is an alternative statement that is more likely to be truthful. As a result, this method can find an alternative truthful statement when the given statement is not truthful. Our experimental results show that the proposed method is effective. In this article, we also provide some insights on how to extend this work and how to leverage this technique to estimate the trustworthiness of web pages and websites.",
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "authors": [
                {
                    "authorId": "2116235540",
                    "name": "Xian Li"
                },
                {
                    "authorId": "38699354",
                    "name": "W. Meng"
                },
                {
                    "authorId": "2642131",
                    "name": "Clement T. Yu"
                }
            ]
        }
    ]
}