{
    "authorId": "2064423453",
    "papers": [
        {
            "paperId": "0c6010d2b9ad416df544735e5165c77502618706",
            "title": "Towards Safe Autonomy in Hybrid Traffic: Detecting Unpredictable Abnormal Behaviors of Human Drivers via Information Sharing",
            "abstract": "Hybrid traffic which involves both autonomous and human-driven vehicles would be the norm of the autonomous vehicles\u2019 practice for a while. On the one hand, unlike autonomous vehicles, human-driven vehicles could exhibit sudden abnormal behaviors such as unpredictably switching to dangerous driving modes \u2013 putting its neighboring vehicles under risks; such undesired mode switching could arise from numbers of human driver factors, including fatigue, drunkenness, distraction, aggressiveness, etc. On the other hand, modern vehicle-to-vehicle (V2V) communication technologies enable the autonomous vehicles to efficiently and reliably share the scarce run-time information with each other [1]. In this paper, we propose, to the best of our knowledge, the first efficient algorithm that can (1) significantly improve trajectory prediction by effectively fusing the run-time information shared by surrounding autonomous vehicles, and can (2) accurately and quickly detect abnormal human driving mode switches or abnormal driving behavior with formal assurance without hurting human drivers\u2019 privacy. To validate our proposed algorithm, we first evaluate our proposed trajectory predictor on NGSIM and Argoverse datasets and show that our proposed predictor outperforms the baseline methods. Then through extensive experiments on SUMO simulator, we show that our proposed algorithm has great detection performance in both highway and urban traffic. The best performance achieves detection rate of \\(97.3\\% \\) , average detection delay of 1.2s, and 0 false alarm.",
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "authors": [
                {
                    "authorId": "2184291210",
                    "name": "Jiangwei Wang"
                },
                {
                    "authorId": "2243384234",
                    "name": "Lili Su"
                },
                {
                    "authorId": "3408700",
                    "name": "Songyang Han"
                },
                {
                    "authorId": "2243381360",
                    "name": "Dongjin Song"
                },
                {
                    "authorId": "2064423453",
                    "name": "Fei Miao"
                }
            ]
        },
        {
            "paperId": "31c4a99f246b62fc70909acad4a0df5f2909144a",
            "title": "Shared Information-Based Safe And Efficient Behavior Planning For Connected Autonomous Vehicles",
            "abstract": "The recent advancements in wireless technology enable connected autonomous vehicles (CAVs) to gather data via vehicle-to-vehicle (V2V) communication, such as processed LIDAR and camera data from other vehicles. In this work, we design an integrated information sharing and safe multi-agent reinforcement learning (MARL) framework for CAVs, to take advantage of the extra information when making decisions to improve traffic efficiency and safety. We first use weight pruned convolutional neural networks (CNN) to process the raw image and point cloud LIDAR data locally at each autonomous vehicle, and share CNN-output data with neighboring CAVs. We then design a safe actor-critic algorithm that utilizes both a vehicle's local observation and the information received via V2V communication to explore an efficient behavior planning policy with safety guarantees. Using the CARLA simulator for experiments, we show that our approach improves the CAV system's efficiency in terms of average velocity and comfort under different CAV ratios and different traffic densities. We also show that our approach avoids the execution of unsafe actions and always maintains a safe distance from other vehicles. We construct an obstacle-at-corner scenario to show that the shared vision can help CAVs to observe obstacles earlier and take action to avoid traffic jams.",
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "authors": [
                {
                    "authorId": "2115659675",
                    "name": "Songyang Han"
                },
                {
                    "authorId": "3147635",
                    "name": "Shangli Zhou"
                },
                {
                    "authorId": "1491246017",
                    "name": "Lynn Pepin"
                },
                {
                    "authorId": "2184291210",
                    "name": "Jiangwei Wang"
                },
                {
                    "authorId": "2881873",
                    "name": "Caiwen Ding"
                },
                {
                    "authorId": "2064423453",
                    "name": "Fei Miao"
                }
            ]
        },
        {
            "paperId": "4ac0208c996c5cc7a97b477d52d05f1da637bdf0",
            "title": "Robust Electric Vehicle Balancing of Autonomous Mobility-on-Demand System: A Multi-Agent Reinforcement Learning Approach",
            "abstract": "Electric autonomous vehicles (EAVs) are getting attention in future autonomous mobility-on-demand (AMoD) systems due to their economic and societal benefits. However, EAVs' unique charging patterns (long charging time, high charging frequency, unpredictable charging behaviors, etc.) make it challenging to accurately predict the EAVs supply in E-AMoD systems. Furthermore, the mobility demand's prediction uncertainty makes it an urgent and challenging task to design an integrated vehicle balancing solution under supply and demand uncertainties. Despite the success of reinforcement learning-based E-AMoD balancing algorithms, state uncertainties under the EV supply or mobility demand remain unexplored. In this work, we design a multi-agent reinforcement learning (MARL)-based framework for EAVs balancing in E-AMoD systems, with adversarial agents to model both the EAVs supply and mobility demand uncertainties that may undermine the vehicle balancing solutions. We then propose a robust E-AMoD Balancing MARL (REBAMA) algorithm to train a robust EAVs balancing policy to balance both the supply-demand ratio and charging utilization rate across the whole city. Experiments show that our proposed robust method performs better compared with a non-robust MARL method that does not consider state uncertainties; it improves the reward, charging utilization fairness, and supply-demand fairness by 19.28%, 28.18%, and 3.97%, respectively. Compared with a robust optimization-based method, the proposed MARL algorithm can improve the reward, charging utilization fairness, and supply-demand fairness by 8.21%, 8.29%, and 9.42%, respectively.",
            "fieldsOfStudy": [
                "Computer Science",
                "Engineering"
            ],
            "authors": [
                {
                    "authorId": "2049027478",
                    "name": "Sihong He"
                },
                {
                    "authorId": "144525193",
                    "name": "Shuo Han"
                },
                {
                    "authorId": "2064423453",
                    "name": "Fei Miao"
                }
            ]
        },
        {
            "paperId": "60d8cafd69c68f0ee64cefaa92417d9fcddde7c2",
            "title": "Multi-Agent Reinforcement Learning Guided by Signal Temporal Logic Specifications",
            "abstract": "Reward design is a key component of deep reinforcement learning, yet some tasks and designer's objectives may be unnatural to define as a scalar cost function. Among the various techniques, formal methods integrated with DRL have garnered considerable attention due to their expressiveness and flexibility to define the reward and requirements for different states and actions of the agent. However, how to leverage Signal Temporal Logic (STL) to guide multi-agent reinforcement learning reward design remains unexplored. Complex interactions, heterogeneous goals and critical safety requirements in multi-agent systems make this problem even more challenging. In this paper, we propose a novel STL-guided multi-agent reinforcement learning framework. The STL requirements are designed to include both task specifications according to the objective of each agent and safety specifications, and the robustness values of the STL specifications are leveraged to generate rewards. We validate the advantages of our method through empirical studies. The experimental results demonstrate significant reward performance improvements compared to MARL without STL guidance, along with a remarkable increase in the overall safety rate of the multi-agent systems.",
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "authors": [
                {
                    "authorId": "2184291210",
                    "name": "Jiangwei Wang"
                },
                {
                    "authorId": "2155666170",
                    "name": "Shuo Yang"
                },
                {
                    "authorId": "2069650742",
                    "name": "Ziyan An"
                },
                {
                    "authorId": "2115659675",
                    "name": "Songyang Han"
                },
                {
                    "authorId": "2187055621",
                    "name": "Zhili Zhang"
                },
                {
                    "authorId": "1785009",
                    "name": "Rahul Mangharam"
                },
                {
                    "authorId": "2113428096",
                    "name": "Meiyi Ma"
                },
                {
                    "authorId": "2064423453",
                    "name": "Fei Miao"
                }
            ]
        },
        {
            "paperId": "b1dd351bab053ea1acac9c1822034480fa3a201e",
            "title": "Robust Multi-Agent Reinforcement Learning with State Uncertainty",
            "abstract": "In real-world multi-agent reinforcement learning (MARL) applications, agents may not have perfect state information (e.g., due to inaccurate measurement or malicious attacks), which challenges the robustness of agents' policies. Though robustness is getting important in MARL deployment, little prior work has studied state uncertainties in MARL, neither in problem formulation nor algorithm design. Motivated by this robustness issue and the lack of corresponding studies, we study the problem of MARL with state uncertainty in this work. We provide the first attempt to the theoretical and empirical analysis of this challenging problem. We first model the problem as a Markov Game with state perturbation adversaries (MG-SPA) by introducing a set of state perturbation adversaries into a Markov Game. We then introduce robust equilibrium (RE) as the solution concept of an MG-SPA. We conduct a fundamental analysis regarding MG-SPA such as giving conditions under which such a robust equilibrium exists. Then we propose a robust multi-agent Q-learning (RMAQ) algorithm to find such an equilibrium, with convergence guarantees. To handle high-dimensional state-action space, we design a robust multi-agent actor-critic (RMAAC) algorithm based on an analytical expression of the policy gradient derived in the paper. Our experiments show that the proposed RMAQ algorithm converges to the optimal value function; our RMAAC algorithm outperforms several MARL and robust MARL methods in multiple multi-agent environments when state uncertainty is present. The source code is public on \\url{https://github.com/sihongho/robust_marl_with_state_uncertainty}.",
            "fieldsOfStudy": [
                "Computer Science",
                "Engineering"
            ],
            "authors": [
                {
                    "authorId": "2049027478",
                    "name": "Sihong He"
                },
                {
                    "authorId": "2115659675",
                    "name": "Songyang Han"
                },
                {
                    "authorId": "2066631067",
                    "name": "Sanbao Su"
                },
                {
                    "authorId": "144525193",
                    "name": "Shuo Han"
                },
                {
                    "authorId": "1805108",
                    "name": "Shaofeng Zou"
                },
                {
                    "authorId": "2064423453",
                    "name": "Fei Miao"
                }
            ]
        },
        {
            "paperId": "ba52fb25f322e03f858eca75ce168be01831c8e6",
            "title": "Surrogate Lagrangian Relaxation: A Path to Retrain-Free Deep Neural Network Pruning",
            "abstract": "Network pruning is a widely used technique to reduce computation cost and model size for deep neural networks. However, the typical three-stage pipeline (i.e., training, pruning, and retraining (fine-tuning)) significantly increases the overall training time. In this article, we develop a systematic weight-pruning optimization approach based on surrogate Lagrangian relaxation (SLR), which is tailored to overcome difficulties caused by the discrete nature of the weight-pruning problem. We further prove that our method ensures fast convergence of the model compression problem, and the convergence of the SLR is accelerated by using quadratic penalties. Model parameters obtained by SLR during the training phase are much closer to their optimal values as compared to those obtained by other state-of-the-art methods. We evaluate our method on image classification tasks using CIFAR-10 and ImageNet with state-of-the-art multi-layer perceptron based networks such as MLP-Mixer; attention-based networks such as Swin Transformer; and convolutional neural network based models such as VGG-16, ResNet-18, ResNet-50, ResNet-110, and MobileNetV2. We also evaluate object detection and segmentation tasks on COCO, the KITTI benchmark, and the TuSimple lane detection dataset using a variety of models. Experimental results demonstrate that our SLR-based weight-pruning optimization approach achieves a higher compression rate than state-of-the-art methods under the same accuracy requirement and also can achieve higher accuracy under the same compression rate requirement. Under classification tasks, our SLR approach converges to the desired accuracy \u00d7 faster on both of the datasets. Under object detection and segmentation tasks, SLR also converges 2\u00d7 faster to the desired accuracy. Further, our SLR achieves high model accuracy even at the hardpruning stage without retraining, which reduces the traditional three-stage pruning into a two-stage process. Given a limited budget of retraining epochs, our approach quickly recovers the model\u2019s accuracy.",
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "authors": [
                {
                    "authorId": "3147635",
                    "name": "Shangli Zhou"
                },
                {
                    "authorId": "2418402",
                    "name": "Mikhail A. Bragin"
                },
                {
                    "authorId": "1491246017",
                    "name": "Lynn Pepin"
                },
                {
                    "authorId": "1753362334",
                    "name": "Deniz Gurevin"
                },
                {
                    "authorId": "2064423453",
                    "name": "Fei Miao"
                },
                {
                    "authorId": "2881873",
                    "name": "Caiwen Ding"
                }
            ]
        },
        {
            "paperId": "dd2efa8361ca7e6ee585bb31c8bf18f626c51606",
            "title": "Collaborative Multi-Object Tracking With Conformal Uncertainty Propagation",
            "abstract": "Object detection and multiple object tracking (MOT) are essential components of self-driving systems. Accurate detection and uncertainty quantification are both critical for onboard modules, such as perception, prediction, and planning, to improve the safety and robustness of autonomous vehicles. Collaborative object detection (COD) has been proposed to improve detection accuracy and reduce uncertainty by leveraging the viewpoints of multiple agents. However, little attention has been paid to how to leverage the uncertainty quantification from COD to enhance MOT performance. In this letter, as the first attempt to address this challenge, we design an uncertainty propagation framework called MOT-CUP. Our framework first quantifies the uncertainty of COD through direct modeling and conformal prediction, and propagates this uncertainty information into the motion prediction and association steps. MOT-CUP is designed to work with different collaborative object detectors and baseline MOT algorithms. We evaluate MOT-CUP on V2X-Sim, a comprehensive collaborative perception dataset, and demonstrate a 2% improvement in accuracy and a $2.67\\times$ reduction in uncertainty compared to the baselines, e.g. SORT and ByteTrack. In scenarios characterized by high occlusion levels, our MOT-CUP demonstrates a noteworthy 4.01% improvement in accuracy. MOT-CUP demonstrates the importance of uncertainty quantification in both COD and MOT, and provides the first attempt to improve the accuracy and reduce the uncertainty in MOT based on COD through uncertainty propagation.",
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "authors": [
                {
                    "authorId": "2066631067",
                    "name": "Sanbao Su"
                },
                {
                    "authorId": "2115659675",
                    "name": "Songyang Han"
                },
                {
                    "authorId": "47002748",
                    "name": "Yiming Li"
                },
                {
                    "authorId": "2187055621",
                    "name": "Zhili Zhang"
                },
                {
                    "authorId": "2117345656",
                    "name": "Chen Feng"
                },
                {
                    "authorId": "2881873",
                    "name": "Caiwen Ding"
                },
                {
                    "authorId": "2064423453",
                    "name": "Fei Miao"
                }
            ]
        },
        {
            "paperId": "e4b0579d9d52a947033d85ea54e034cb7355a129",
            "title": "Privacy-Preserving and Uncertainty-Aware Federated Trajectory Prediction for Connected Autonomous Vehicles",
            "abstract": "Deep learning is the method of choice for trajectory prediction for autonomous vehicles. Unfortunately, its data-hungry nature implicitly requires the availability of sufficiently rich and high-quality centralized datasets, which easily leads to privacy leakage. Besides, uncertainty-awareness becomes increasingly important for safety-crucial cyber physical systems whose prediction module heavily relies on machine learning tools. In this paper, we relax the data collection requirement and enhance uncertainty-awareness by using Federated Learning on Connected Autonomous Vehicles with an uncertainty-aware global objective. We name our algorithm as FLTP. We further introduce ALFLTP which boosts FLTP via using active learning techniques in adaptatively selecting participating clients. We consider two different metrics negative log-likelihood (NLL) and aleatoric uncertainty (AU) for client selection. Experiments on Argoverse dataset show that FLTP significantly outperforms the model trained on local data. In addition, ALFLTP-AU converges faster in training regression loss and performs better in terms of Miss Rate (MR) than FLTP in most rounds, and has more stable round-wise performance than ALFLTP-NLL.",
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "authors": [
                {
                    "authorId": "2210984484",
                    "name": "Muzi Peng"
                },
                {
                    "authorId": "2184291210",
                    "name": "Jiangwei Wang"
                },
                {
                    "authorId": "2451800",
                    "name": "Dongjin Song"
                },
                {
                    "authorId": "2064423453",
                    "name": "Fei Miao"
                },
                {
                    "authorId": "2255869",
                    "name": "Lili Su"
                }
            ]
        },
        {
            "paperId": "42bbaf03e76a9132cd05137aa762b8dc70087bd9",
            "title": "A Secure and Efficient Federated Learning Framework for NLP",
            "abstract": "In this work, we consider the problem of designing secure and efficient federated learning (FL) frameworks for NLP. Existing solutions under this literature either consider a trusted aggregator or require heavy-weight cryptographic primitives, which makes the performance significantly degraded. Moreover, many existing secure FL designs work only under the restrictive assumption that none of the clients can be dropped out from the training protocol. To tackle these problems, we propose SEFL, a secure and efficient federated learning framework that (1) eliminates the need for the trusted entities; (2) achieves similar and even better model accuracy compared with existing FL designs; (3) is resilient to client dropouts.",
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "authors": [
                {
                    "authorId": "2144523645",
                    "name": "Chenghong Wang"
                },
                {
                    "authorId": "153302621",
                    "name": "Jieren Deng"
                },
                {
                    "authorId": "8399126",
                    "name": "Xianrui Meng"
                },
                {
                    "authorId": "2108765431",
                    "name": "Yijue Wang"
                },
                {
                    "authorId": "2118400741",
                    "name": "Ji Li"
                },
                {
                    "authorId": "152386403",
                    "name": "Sheng Lin"
                },
                {
                    "authorId": "2206298901",
                    "name": "Shuo Han"
                },
                {
                    "authorId": "2064423453",
                    "name": "Fei Miao"
                },
                {
                    "authorId": "143856869",
                    "name": "S. Rajasekaran"
                },
                {
                    "authorId": "2881873",
                    "name": "Caiwen Ding"
                }
            ]
        },
        {
            "paperId": "b5facdd02c18c5292f5132794d56ce505741404b",
            "title": "Uncertainty Quantification of Collaborative Detection for Self-Driving",
            "abstract": "Sharing information between connected and autonomous vehicles (CAVs) fundamentally improves the performance of collaborative object detection for self-driving. However, CAVs still have uncertainties on object detection due to practical challenges, which will affect the later modules in self-driving such as planning and control. Hence, uncertainty quantification is crucial for safety-critical systems such as CAVs. Our work is the first to estimate the uncertainty of collaborative object detection. We propose a novel uncertainty quantification method, called Double- M Quantification, which tailors a moving block bootstrap (MBB) algorithm with direct modeling of the multivariant Gaussian distribution of each corner of the bounding box. Our method captures both the epistemic uncertainty and aleatoric uncertainty with one inference pass based on the offline Double- M training process. And it can be used with different collaborative object detectors. Through experiments on the comprehensive collaborative perception dataset, we show that our Double-M method achieves more than 4\u00d7 improvement on uncertainty score and more than 3% accuracy improvement, compared with the state-of-the-art uncertainty quantification methods. Our code is public on https://coperception.github.io/double-m-quantification/.",
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "authors": [
                {
                    "authorId": "2066631067",
                    "name": "Sanbao Su"
                },
                {
                    "authorId": "47002748",
                    "name": "Yiming Li"
                },
                {
                    "authorId": "2049027478",
                    "name": "Sihong He"
                },
                {
                    "authorId": "2115659675",
                    "name": "Songyang Han"
                },
                {
                    "authorId": "144066717",
                    "name": "Chen Feng"
                },
                {
                    "authorId": "2881873",
                    "name": "Caiwen Ding"
                },
                {
                    "authorId": "2064423453",
                    "name": "Fei Miao"
                }
            ]
        }
    ]
}