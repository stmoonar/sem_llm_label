{
    "authorId": "2273915435",
    "papers": [
        {
            "paperId": "5f9195769eb8ea3ac9ae3d513b4c3123551842ea",
            "title": "COSMO: A Large-Scale E-commerce Common Sense Knowledge Generation and Serving System at Amazon",
            "abstract": "Applications of large-scale knowledge graphs in the e-commerce platforms can improve shopping experience for their customers. While existing e-commerce knowledge graphs (KGs) integrate a large volume of concepts or product attributes, they fail to discover user intentions, leaving the gap with how people think, behave, and interact with the surrounding world. In this work, we present COSMO, a scalable system to mine user-centric commonsense knowledge from massive behaviors and construct industry-scale knowledge graphs to empower diverse online services. In particular, we describe a pipeline for collecting high-quality seed knowledge assertions that are distilled from large language models (LLMs) and further refined by critic classifiers trained over human-in-the-loop annotated data.Since those generations may not always align with human preferences and contain noises, we then describe how we adopt instruction tuning to finetune an efficient language model~(COSMO-LM) for faithful e-commerce commonsense knowledge generation at scale. COSMO-LM effectively expands our knowledge graph to 18 major categories at Amazon, producing millions of high-quality knowledge with only 30k annotated instructions. Finally COSMO has been deployed in Amazon search applications such as search navigation. Both offline and online A/B experiments demonstrate our proposed system achieves significant improvement. Furthermore, these experiments highlight the immense potential of commonsense knowledge extracted from instruction-finetuned large language models.",
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "authors": [
                {
                    "authorId": "2302894470",
                    "name": "Changlong Yu"
                },
                {
                    "authorId": "2303356399",
                    "name": "Xin Liu"
                },
                {
                    "authorId": "2302859152",
                    "name": "Jefferson Maia"
                },
                {
                    "authorId": "2303238267",
                    "name": "Yang Li"
                },
                {
                    "authorId": "2151070",
                    "name": "Tianyu Cao"
                },
                {
                    "authorId": "2273915435",
                    "name": "Yifan Gao"
                },
                {
                    "authorId": "2275626612",
                    "name": "Yangqiu Song"
                },
                {
                    "authorId": "3057049",
                    "name": "R. Goutam"
                },
                {
                    "authorId": "2184766165",
                    "name": "Haiyang Zhang"
                },
                {
                    "authorId": "2273675661",
                    "name": "Bing Yin"
                },
                {
                    "authorId": "2301274918",
                    "name": "Zheng Li"
                }
            ]
        },
        {
            "paperId": "f42b97cdfbf1a78c02e78cfce6f8b0e277766ae2",
            "title": "Inductive or Deductive? Rethinking the Fundamental Reasoning Abilities of LLMs",
            "abstract": "Reasoning encompasses two typical types: deductive reasoning and inductive reasoning. Despite extensive research into the reasoning capabilities of Large Language Models (LLMs), most studies have failed to rigorously differentiate between inductive and deductive reasoning, leading to a blending of the two. This raises an essential question: In LLM reasoning, which poses a greater challenge - deductive or inductive reasoning? While the deductive reasoning capabilities of LLMs, (i.e. their capacity to follow instructions in reasoning tasks), have received considerable attention, their abilities in true inductive reasoning remain largely unexplored. To investigate into the true inductive reasoning capabilities of LLMs, we propose a novel framework, SolverLearner. This framework enables LLMs to learn the underlying function (i.e., $y = f_w(x)$), that maps input data points $(x)$ to their corresponding output values $(y)$, using only in-context examples. By focusing on inductive reasoning and separating it from LLM-based deductive reasoning, we can isolate and investigate inductive reasoning of LLMs in its pure form via SolverLearner. Our observations reveal that LLMs demonstrate remarkable inductive reasoning capabilities through SolverLearner, achieving near-perfect performance with ACC of 1 in most cases. Surprisingly, despite their strong inductive reasoning abilities, LLMs tend to relatively lack deductive reasoning capabilities, particularly in tasks involving ``counterfactual'' reasoning.",
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "authors": [
                {
                    "authorId": "2260755600",
                    "name": "Kewei Cheng"
                },
                {
                    "authorId": "2276746186",
                    "name": "Jingfeng Yang"
                },
                {
                    "authorId": "2274172460",
                    "name": "Haoming Jiang"
                },
                {
                    "authorId": "2312598740",
                    "name": "Zhengyang Wang"
                },
                {
                    "authorId": "2315087538",
                    "name": "Binxuan Huang"
                },
                {
                    "authorId": "2257590787",
                    "name": "Ruirui Li"
                },
                {
                    "authorId": "2314348843",
                    "name": "Shiyang Li"
                },
                {
                    "authorId": "2273766311",
                    "name": "Zheng Li"
                },
                {
                    "authorId": "2273915435",
                    "name": "Yifan Gao"
                },
                {
                    "authorId": "2273816798",
                    "name": "Xian Li"
                },
                {
                    "authorId": "2273675661",
                    "name": "Bing Yin"
                },
                {
                    "authorId": "2261083995",
                    "name": "Yizhou Sun"
                }
            ]
        },
        {
            "paperId": "a072dc70413c02e6bcf80769eade6bb0bc4c1f98",
            "title": "Improving Consistency for Text Summarization with Energy Functions",
            "abstract": "Current abstractive summarization models often generate inconsistent content, i.e. texts that are not directly inferable from the source document, are not consistent with respect to world knowledge, or are self-contradictory. These inconsistencies motivate a new consistency taxonomy that we define as faithfulness, factuality, and self-supportiveness. However, most recent work on reducing inconsistency in document summarization only focuses on faithfulness detection and correction while ignoring other inconsistency phenomena, which limits the model\u2019s scalability. To improve the general consistency we introduce EnergySum, where we apply the Residual Energy-based Model by designing energy scorers that reflect each type of consistency. These energy scores are utilized in candidate re-ranking during the sampling process. Experiments on XSUM and CNN/DM datasets show that EnergySum mitigates the trade-off between accuracy and consistency.",
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "authors": [
                {
                    "authorId": "2273693612",
                    "name": "Qi Zeng"
                },
                {
                    "authorId": "3393799",
                    "name": "Qingyu Yin"
                },
                {
                    "authorId": "2273766311",
                    "name": "Zheng Li"
                },
                {
                    "authorId": "2273915435",
                    "name": "Yifan Gao"
                },
                {
                    "authorId": "7529854",
                    "name": "Sreyashi Nag"
                },
                {
                    "authorId": "2274037416",
                    "name": "Zhengyang Wang"
                },
                {
                    "authorId": "2273675661",
                    "name": "Bing Yin"
                },
                {
                    "authorId": "2274622328",
                    "name": "Heng Ji"
                },
                {
                    "authorId": "2256776354",
                    "name": "Chao Zhang"
                }
            ]
        },
        {
            "paperId": "af6da5e89b61e43bf9af2233cb003deea3d4bff1",
            "title": "Knowledge-Selective Pretraining for Attribute Value Extraction",
            "abstract": ",",
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "authors": [
                {
                    "authorId": "2275053439",
                    "name": "Hui Liu"
                },
                {
                    "authorId": "3393799",
                    "name": "Qingyu Yin"
                },
                {
                    "authorId": "2274037416",
                    "name": "Zhengyang Wang"
                },
                {
                    "authorId": "2047145237",
                    "name": "Chenwei Zhang"
                },
                {
                    "authorId": "2274172460",
                    "name": "Haoming Jiang"
                },
                {
                    "authorId": "2273915435",
                    "name": "Yifan Gao"
                },
                {
                    "authorId": "2273766311",
                    "name": "Zheng Li"
                },
                {
                    "authorId": "2273816798",
                    "name": "Xian Li"
                },
                {
                    "authorId": "2256776354",
                    "name": "Chao Zhang"
                },
                {
                    "authorId": "2273675661",
                    "name": "Bing Yin"
                },
                {
                    "authorId": "2273814369",
                    "name": "William Wang"
                },
                {
                    "authorId": "2274054096",
                    "name": "Xiao-Dan Zhu"
                }
            ]
        },
        {
            "paperId": "e23cafac4fefdf7fd80e920224f264ccade4fac2",
            "title": "Enhancing User Intent Capture in Session-Based Recommendation with Attribute Patterns",
            "abstract": "The goal of session-based recommendation in E-commerce is to predict the next item that an anonymous user will purchase based on the browsing and purchase history. However, constructing global or local transition graphs to supplement session data can lead to noisy correlations and user intent vanishing. In this work, we propose the Frequent Attribute Pattern Augmented Transformer (FAPAT) that characterizes user intents by building attribute transition graphs and matching attribute patterns. Specifically, the frequent and compact attribute patterns are served as memory to augment session representations, followed by a gate and a transformer block to fuse the whole session information. Through extensive experiments on two public benchmarks and 100 million industrial data in three domains, we demonstrate that FAPAT consistently outperforms state-of-the-art methods by an average of 4.5% across various evaluation metrics (Hits, NDCG, MRR). Besides evaluating the next-item prediction, we estimate the models' capabilities to capture user intents via predicting items' attributes and period-item recommendations.",
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "authors": [
                {
                    "authorId": "2260287837",
                    "name": "Xin Liu"
                },
                {
                    "authorId": "2276199775",
                    "name": "Zheng Li"
                },
                {
                    "authorId": "2273915435",
                    "name": "Yifan Gao"
                },
                {
                    "authorId": "2276746186",
                    "name": "Jingfeng Yang"
                },
                {
                    "authorId": "2151070",
                    "name": "Tianyu Cao"
                },
                {
                    "authorId": "2274037416",
                    "name": "Zhengyang Wang"
                },
                {
                    "authorId": "2273675661",
                    "name": "Bing Yin"
                },
                {
                    "authorId": "2275626612",
                    "name": "Yangqiu Song"
                }
            ]
        }
    ]
}