{
    "authorId": "1783239",
    "papers": [
        {
            "paperId": "3474de0b2e4ecf87f51de8a77aa9d991fd8e9dcf",
            "title": "Self-Weighted Contrastive Fusion for Deep Multi-View Clustering",
            "abstract": "Multi-view clustering can explore consensus information from multiple views and has attracted increasing attention in the past two decades. However, existing works face two major challenges: i) how to deal with the conflict between learning view-consensus information and reconstructing inconsistent view-private information and ii) how to mitigate representation degeneration caused by implementing the consistency objective for multi-view data. To address these challenges, we propose a novel framework of self-weighted contrastive fusion for deep multi-view clustering (SCMVC). First, our method establishes a hierarchical feature fusion framework, effectively segregating the consistency objective from the reconstruction objective. Then, multi-view contrastive fusion is implemented via maximizing consistency expression between the view-consensus representation and global representation, fully exploring the view consistency and complementary. More importantly, we propose to measure the discrepancy between pairwise representations, and then introduce a self-weighting method, which adaptively strengthens useful views in feature fusion and weakens unreliable views, to mitigate representation degeneration. Extensive experiments on nine public datasets demonstrate that our proposed method achieves state-of-the-art clustering performance.",
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "authors": [
                {
                    "authorId": "2205969447",
                    "name": "Song Wu"
                },
                {
                    "authorId": "2267154352",
                    "name": "Yan Zheng"
                },
                {
                    "authorId": "2261908032",
                    "name": "Yazhou Ren"
                },
                {
                    "authorId": "2276722188",
                    "name": "Jing He"
                },
                {
                    "authorId": "1783239",
                    "name": "X. Pu"
                },
                {
                    "authorId": "2237407099",
                    "name": "Shudong Huang"
                },
                {
                    "authorId": "2261752358",
                    "name": "Zhifeng Hao"
                },
                {
                    "authorId": "2278526458",
                    "name": "Lifang He"
                }
            ]
        },
        {
            "paperId": "6c620d914336793fde50c97eb5bd795c4b071440",
            "title": "Cross-Domain Low-Dose CT Image Denoising With Semantic Preservation and Noise Alignment",
            "abstract": "Deep learning (DL)-based Low-dose CT (LDCT) image denoising methods may face domain shift problem, where data from different domains (i.e., hospitals) may have similar anatomical regions but exhibit different intrinsic noise characteristics. Therefore, we propose a plug-and-play model called Low- and High-frequency Alignment (LHFA) to address this issue by leveraging semantic features and aligning noise distributions of different CT datasets, while maintaining diagnostic image quality and suppressing noise. Specifically, the LHFA model consists of a Low-frequency Alignment (LFA) module that preserves semantic features (i.e., low-frequency components) with fewer perturbations from both domains for reconstruction. Notably, a High-frequency Alignment (HFA) module is proposed to quantify the discrepancy between noise representations (i.e., high-frequency components) in a latent space mapped by an auto-encoder. Experimental results demonstrate that the LHFA model effectively alleviates the domain shift problem and significantly improves the performance of DL-based methods on cross-domain LDCT image denoising task, outperforming other domain adaptation-based methods.",
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "authors": [
                {
                    "authorId": "2189917492",
                    "name": "Jiaxin Huang"
                },
                {
                    "authorId": "2000512096",
                    "name": "Kecheng Chen"
                },
                {
                    "authorId": "2261908032",
                    "name": "Yazhou Ren"
                },
                {
                    "authorId": "2145751547",
                    "name": "Jiayu Sun"
                },
                {
                    "authorId": "1783239",
                    "name": "X. Pu"
                },
                {
                    "authorId": "2291996342",
                    "name": "Ce Zhu"
                }
            ]
        },
        {
            "paperId": "b82cc411c64afff5f223826c336ebad5ff16ef32",
            "title": "Sparse Bayesian Deep Learning for Cross Domain Medical Image Reconstruction",
            "abstract": "Cross domain medical image reconstruction aims to address the issue that deep learning models trained solely on one source dataset might not generalize effectively to unseen target datasets from different hospitals. Some recent methods achieve satisfactory reconstruction performance, but often at the expense of extensive parameters and time consumption. To strike a balance between cross domain image reconstruction quality and model computational efficiency, we propose a lightweight sparse Bayesian deep learning method. Notably, we apply a fixed-form variational Bayes (FFVB) approach to quantify pixel-wise uncertainty priors derived from degradation distribution of the source domain. Furthermore, by integrating the uncertainty prior into the posterior sampled through stochastic gradient Langevin dynamics (SGLD), we develop a training strategy that dynamically generates and optimizes the prior distribution on the network weights for each unseen domain. This strategy enhances generalizability and ensures robust reconstruction performance. When evaluated on medical image reconstruction tasks, our proposed approach demonstrates impressive performance across various previously unseen domains.",
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "authors": [
                {
                    "authorId": "2189917492",
                    "name": "Jiaxin Huang"
                },
                {
                    "authorId": "2293349774",
                    "name": "Qi Wu"
                },
                {
                    "authorId": "2261908032",
                    "name": "Yazhou Ren"
                },
                {
                    "authorId": "2293563862",
                    "name": "Fan Yang"
                },
                {
                    "authorId": "2294145867",
                    "name": "Aodi Yang"
                },
                {
                    "authorId": "2293460950",
                    "name": "Qianqian Yang"
                },
                {
                    "authorId": "1783239",
                    "name": "X. Pu"
                }
            ]
        },
        {
            "paperId": "d271548071b8acd57def499bcc86cb9329d71e65",
            "title": "Homophily-Related: Adaptive Hybrid Graph Filter for Multi-View Graph Clustering",
            "abstract": "Recently there is a growing focus on graph data, and multi-view graph clustering has become a popular area of research interest. Most of the existing methods are only applicable to homophilous graphs, yet the extensive real-world graph data can hardly fulfill the homophily assumption, where the connected nodes tend to belong to the same class. Several studies have pointed out that the poor performance on heterophilous graphs is actually due to the fact that conventional graph neural networks (GNNs), which are essentially low-pass filters, discard information other than the low-frequency information on the graph. Nevertheless, on certain graphs, particularly heterophilous ones, neglecting high-frequency information and focusing solely on low-frequency information impedes the learning of node representations. To break this limitation, our motivation is to perform graph filtering that is closely related to the homophily degree of the given graph, with the aim of fully leveraging both low-frequency and high-frequency signals to learn distinguishable node embedding. In this work, we propose Adaptive Hybrid Graph Filter for Multi-View Graph Clustering (AHGFC). Specifically, a graph joint process and graph joint aggregation matrix are first designed by using the intrinsic node features and adjacency relationship, which makes the low and high-frequency signals on the graph more distinguishable. Then we design an adaptive hybrid graph filter that is related to the homophily degree, which learns the node embedding based on the graph joint aggregation matrix. After that, the node embedding of each view is weighted and fused into a consensus embedding for the downstream task. Experimental results show that our proposed model performs well on six datasets containing homophilous and heterophilous graphs.",
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "authors": [
                {
                    "authorId": "2278221257",
                    "name": "Zichen Wen"
                },
                {
                    "authorId": "47396038",
                    "name": "Yawen Ling"
                },
                {
                    "authorId": "2261908032",
                    "name": "Yazhou Ren"
                },
                {
                    "authorId": "2279283210",
                    "name": "Tianyi Wu"
                },
                {
                    "authorId": "2135294453",
                    "name": "Jianpeng Chen"
                },
                {
                    "authorId": "1783239",
                    "name": "X. Pu"
                },
                {
                    "authorId": "2261752358",
                    "name": "Zhifeng Hao"
                },
                {
                    "authorId": "2278526458",
                    "name": "Lifang He"
                }
            ]
        },
        {
            "paperId": "e8d34fa76ea840807823304af295f2e327ce7533",
            "title": "Adaptive Feature Imputation with Latent Graph for Deep Incomplete Multi-View Clustering",
            "abstract": "In recent years, incomplete multi-view clustering (IMVC), which studies the challenging multi-view clustering problem on missing views, has received growing research interests. Previous IMVC methods suffer from the following issues: (1) the inaccurate imputation for missing data, which leads to suboptimal clustering performance, and (2) most existing IMVC models merely consider the explicit presence of graph structure in data, ignoring the fact that latent graphs of different views also provide valuable information for the clustering task. To overcome such challenges, we present a novel method, termed Adaptive feature imputation with latent graph for incomplete multi-view clustering (AGDIMC). Specifically, it captures the embbedded features of each view by incorporating the view-specific deep encoders. Then, we construct partial latent graphs on complete data, which can consolidate the intrinsic relationships within each view while preserving the topological information. With the aim of estimating the missing sample based on the available information, we utilize an adaptive imputation layer to impute the embedded feature of missing data by using cross-view soft cluster assignments and global cluster centroids. As the imputation progresses, the portion of complete data increases, contributing to enhancing the discriminative information contained in global pseudo-labels. Meanwhile, to alleviate the negative impact caused by inferior impute samples and the discrepancy of cluster structures, we further design an adaptive imputation strategy based on the global pseudo-label and the local cluster assignment. Experimental results on multiple real-world datasets demonstrate the effectiveness of our method over existing approaches.",
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "authors": [
                {
                    "authorId": "2004864336",
                    "name": "Jingyu Pu"
                },
                {
                    "authorId": "2216785845",
                    "name": "Chenhang Cui"
                },
                {
                    "authorId": "2292026964",
                    "name": "Xinyue Chen"
                },
                {
                    "authorId": "2261908032",
                    "name": "Yazhou Ren"
                },
                {
                    "authorId": "1783239",
                    "name": "X. Pu"
                },
                {
                    "authorId": "2261752358",
                    "name": "Zhifeng Hao"
                },
                {
                    "authorId": "2268418395",
                    "name": "Philip S. Yu"
                },
                {
                    "authorId": "40901820",
                    "name": "Lifang He"
                }
            ]
        },
        {
            "paperId": "16dc534362dabbb5473de850a6fe39353596f43e",
            "title": "Generative Neutral Features-Disentangled Learning for Facial Expression Recognition",
            "abstract": "Facial expression recognition (FER) plays a critical role in human-computer interaction and affective computing. Traditional FER methods typically rely on comparing the difference between an examined facial expression and a neutral face of the same person to extract the motion of facial features and filter out expression-irrelevant information. With the extensive use of deep learning, the performance of FER has been further improved. However, existing deep learning-based methods rarely utilize neutral faces. To address this gap, we propose a novel deep learning-based FER method called Generative Neutral Features-Disentangled Learning (GNDL), which draws inspiration from the facial feature manifold. Our approach integrates a neutral feature generator (NFG) that generates neutral features in scenarios where the neutral face of the same subject is not available. The NFG uses fine-grained features from examined images as input and produces corresponding neutral features with the same identity. We train the NFG using a neutral feature reconstruction loss to ensure that the generative neutral features are consistent with the actual neutral features. We then disentangle the generative neutral features from the examined features to remove disturbance features and generate an expression deviation embedding for classification. Extensitive experimental results on three popular databases (CK+, Oulu-CASIA, and MMI) demonstrate that our proposed GNDL method outperforms state-of-the-art FER methods.",
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "authors": [
                {
                    "authorId": "2187384062",
                    "name": "Zhenqian Wu"
                },
                {
                    "authorId": "2261908032",
                    "name": "Yazhou Ren"
                },
                {
                    "authorId": "1783239",
                    "name": "X. Pu"
                },
                {
                    "authorId": "2261752358",
                    "name": "Zhifeng Hao"
                },
                {
                    "authorId": "2148919788",
                    "name": "Lifang He"
                }
            ]
        },
        {
            "paperId": "399c35dcde2eac017b875af1a21916a9ecb10434",
            "title": "Self-Supervised Graph Attention Networks for Deep Weighted Multi-View Clustering",
            "abstract": "As one of the most important research topics in the unsupervised learning field, Multi-View Clustering (MVC) has been widely studied in the past decade and numerous MVC methods have been developed. Among these methods, the recently emerged Graph Neural Networks (GNN) shine a light on modeling both topological structure and node attributes in the form of graphs, to guide unified embedding learning and clustering. However, the effectiveness of existing GNN-based MVC methods is still limited due to the insufficient consideration in utilizing the self-supervised information and graph information, which can be reflected from the following two aspects: 1) most of these models merely use the self-supervised information to guide the feature learning and fail to realize that such information can be also applied in graph learning and sample weighting; 2) the usage of graph information is generally limited to the feature aggregation in these models, yet it also provides valuable evidence in detecting noisy samples. To this end, in this paper we propose Self-Supervised Graph Attention Networks for Deep Weighted Multi-View Clustering (SGDMC), which promotes the performance of GNN-based deep MVC models by making full use of the self-supervised information and graph information. Specifically, a novel attention-allocating approach that considers both the similarity of node attributes and the self-supervised information is developed to comprehensively evaluate the relevance among different nodes. Meanwhile, to alleviate the negative impact caused by noisy samples and the discrepancy of cluster structures, we further design a sample-weighting strategy based on the attention graph as well as the discrepancy between the global pseudo-labels and the local cluster assignment. Experimental results on multiple real-world datasets demonstrate the effectiveness of our method over existing approaches.",
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "authors": [
                {
                    "authorId": "1443734032",
                    "name": "Zongmo Huang"
                },
                {
                    "authorId": "2041980",
                    "name": "Yazhou Ren"
                },
                {
                    "authorId": "1783239",
                    "name": "X. Pu"
                },
                {
                    "authorId": "2712233",
                    "name": "Shudong Huang"
                },
                {
                    "authorId": "1683510",
                    "name": "Zenglin Xu"
                },
                {
                    "authorId": "40901820",
                    "name": "Lifang He"
                }
            ]
        },
        {
            "paperId": "455c2c883b31a7fb4e608c4870ce376751ae9716",
            "title": "Deep Multi-View Subspace Clustering with Anchor Graph",
            "abstract": "Deep multi-view subspace clustering (DMVSC) has recently attracted increasing attention due to its promising performance. However, existing DMVSC methods still have two issues: (1) they mainly focus on using autoencoders to nonlinearly embed the data, while the embedding may be suboptimal for clustering because the clustering objective is rarely considered in autoencoders, and (2) existing methods typically have a quadratic or even cubic complexity, which makes it challenging to deal with large-scale data. To address these issues, in this paper we propose a novel deep multi-view subspace clustering method with anchor graph (DMCAG). To be specific, DMCAG firstly learns the embedded features for each view independently, which are used to obtain the subspace representations. To significantly reduce the complexity, we construct an anchor graph with small size for each view. Then, spectral clustering is performed on an integrated anchor graph to obtain pseudo-labels. To overcome the negative impact caused by suboptimal embedded features, we use pseudo-labels to refine the embedding process to make it more suitable for the clustering task. Pseudo-labels and embedded features are updated alternately. Furthermore, we design a strategy to keep the consistency of the labels based on contrastive learning to enhance the clustering performance. Empirical studies on real-world datasets show that our method achieves superior clustering performance over other state-of-the-art methods.",
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "authors": [
                {
                    "authorId": "2216785845",
                    "name": "Chenhang Cui"
                },
                {
                    "authorId": "2041980",
                    "name": "Yazhou Ren"
                },
                {
                    "authorId": "2004864336",
                    "name": "Jingyu Pu"
                },
                {
                    "authorId": "1783239",
                    "name": "X. Pu"
                },
                {
                    "authorId": "40901820",
                    "name": "Lifang He"
                }
            ]
        },
        {
            "paperId": "7eaef7398c0ef82529d8d9b7077380acaf859aea",
            "title": "Self-Paced Neutral Expression-Disentangled Learning for Facial Expression Recognition",
            "abstract": "The accuracy of facial expression recognition is typically influenced by the following factors: high similarities across different expressions, disturbing factors, and the subtle and rapid micro-movements of the face. One potential solution to overcome these obstacles is to leverage the hidden neutral information present in neutral expression images. In this paper, we propose a Self-Paced Neutral Expression-Disentangled Learning (SPNDL) model, which aims to disentangle the neutral information from facial expressions, facilitating the extraction of crucial features and variations. This approach enables the capture of discriminative details within similar expressions and the detection of micro-facial movements. To enhance the learning of these neutral expression-disentangled features (NDFs) and mitigate the challenges posed by non-convex optimization, we propose a self-paced learning (SPL) strategy based on NDFs during the training phase. SPL learns samples from easy to complex by increasing the number of samples selected into the training process, which enables to effectively suppress the negative impacts caused by low-quality samples and inconsistently distributed NDFs. Experiments on three popular databases (i.e., CK+, Oulu-CASIA, and RAF-DB) show the effectiveness of our proposed method.",
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "authors": [
                {
                    "authorId": "2187384062",
                    "name": "Zhenqian Wu"
                },
                {
                    "authorId": "2212116478",
                    "name": "Xiaoyuan Li"
                },
                {
                    "authorId": "2041980",
                    "name": "Yazhou Ren"
                },
                {
                    "authorId": "1783239",
                    "name": "X. Pu"
                },
                {
                    "authorId": "46875503",
                    "name": "Xiaofeng Zhu"
                },
                {
                    "authorId": "40901820",
                    "name": "Lifang He"
                }
            ]
        },
        {
            "paperId": "89fdbaa025a339558438160fbcca2e0812abfb56",
            "title": "Dual Label-Guided Graph Refinement for Multi-View Graph Clustering",
            "abstract": "With the increase of multi-view graph data, multi-view graph clustering (MVGC) that can discover the hidden clusters without label supervision has attracted growing attention from researchers. Existing MVGC methods are often sensitive to the given graphs, especially influenced by the low quality graphs, i.e., they tend to be limited by the homophily assumption. However, the widespread real-world data hardly satisfy the homophily assumption. This gap limits the performance of existing MVGC methods on low homophilous graphs. To mitigate this limitation, our motivation is to extract high-level view-common information which is used to refine each view's graph, and reduce the influence of non-homophilous edges. To this end, we propose dual label-guided graph refinement for multi-view graph clustering (DuaLGR), to alleviate the vulnerability in facing low homophilous graphs. Specifically, DuaLGR consists of two modules named dual label-guided graph refinement module and graph encoder module. The first module is designed to extract the soft label from node features and graphs, and then learn a refinement matrix. In cooperation with the pseudo label from the second module, these graphs are refined and aggregated adaptively with different orders. Subsequently, a consensus graph can be generated in the guidance of the pseudo label. Finally, the graph encoder module encodes the consensus graph along with node features to produce the high-level pseudo label for iteratively clustering. The experimental results show the superior performance on coping with low homophilous graph data. The source code for DuaLGR is available at https://github.com/YwL-zhufeng/DuaLGR.",
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "authors": [
                {
                    "authorId": "47396038",
                    "name": "Yawen Ling"
                },
                {
                    "authorId": "2135294453",
                    "name": "Jianpeng Chen"
                },
                {
                    "authorId": "2041980",
                    "name": "Yazhou Ren"
                },
                {
                    "authorId": "1783239",
                    "name": "X. Pu"
                },
                {
                    "authorId": "2145753839",
                    "name": "Jie Xu"
                },
                {
                    "authorId": "46875503",
                    "name": "Xiaofeng Zhu"
                },
                {
                    "authorId": "40901820",
                    "name": "Lifang He"
                }
            ]
        }
    ]
}