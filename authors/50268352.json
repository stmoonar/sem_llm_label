{
    "authorId": "50268352",
    "papers": [
        {
            "paperId": "1e8fcf495dbc386591fcbab75df75ac41a503859",
            "title": "Single Cells Are Spatial Tokens: Transformers for Spatial Transcriptomic Data Imputation",
            "abstract": "Spatially resolved transcriptomics brings exciting breakthroughs to single-cell analysis by providing physical locations along with gene expression. However, as a cost of the extremely high spatial resolution, the cellular level spatial transcriptomic data suffer significantly from missing values. While a standard solution is to perform imputation on the missing values, most existing methods either overlook spatial information or only incorporate localized spatial context without the ability to capture long-range spatial information. Using multi-head self-attention mechanisms and positional encoding, transformer models can readily grasp the relationship between tokens and encode location information. In this paper, by treating single cells as spatial tokens, we study how to leverage transformers to facilitate spatial tanscriptomics imputation. In particular, investigate the following two key questions: (1) $\\textit{how to encode spatial information of cells in transformers}$, and (2) $\\textit{ how to train a transformer for transcriptomic imputation}$. By answering these two questions, we present a transformer-based imputation framework, SpaFormer, for cellular-level spatial transcriptomic data. Extensive experiments demonstrate that SpaFormer outperforms existing state-of-the-art imputation algorithms on three large-scale datasets while maintaining superior computational efficiency.",
            "fieldsOfStudy": [
                "Computer Science",
                "Biology"
            ],
            "authors": [
                {
                    "authorId": "30580446",
                    "name": "Haifang Wen"
                },
                {
                    "authorId": "2188792890",
                    "name": "Wenzhuo Tang"
                },
                {
                    "authorId": "144767914",
                    "name": "Wei Jin"
                },
                {
                    "authorId": "46496977",
                    "name": "Jiayuan Ding"
                },
                {
                    "authorId": "50268352",
                    "name": "Renming Liu"
                },
                {
                    "authorId": "2199025797",
                    "name": "Feng Shi"
                },
                {
                    "authorId": "2154871510",
                    "name": "Yuying Xie"
                },
                {
                    "authorId": "1736632",
                    "name": "Jiliang Tang"
                }
            ]
        },
        {
            "paperId": "7fdce9a00ae132cc8bb3f893788a19d0c1649e6a",
            "title": "Graph Positional and Structural Encoder",
            "abstract": "Positional and structural encodings (PSE) enable better identifiability of nodes within a graph, rendering them essential tools for empowering modern GNNs, and in particular graph Transformers. However, designing PSEs that work optimally for all graph prediction tasks is a challenging and unsolved problem. Here, we present the Graph Positional and Structural Encoder (GPSE), the first-ever graph encoder designed to capture rich PSE representations for augmenting any GNN. GPSE learns an efficient common latent representation for multiple PSEs, and is highly transferable: The encoder trained on a particular graph dataset can be used effectively on datasets drawn from markedly different distributions and modalities. We show that across a wide range of benchmarks, GPSE-enhanced models can significantly outperform those that employ explicitly computed PSEs, and at least match their performance in others. Our results pave the way for the development of foundational pre-trained graph encoders for extracting positional and structural information, and highlight their potential as a more powerful and efficient alternative to explicitly computed PSEs and existing self-supervised pre-training approaches. Our framework and pre-trained models are publicly available at https://github.com/G-Taxonomy-Workgroup/GPSE. For convenience, GPSE has also been integrated into the PyG library to facilitate downstream applications.",
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "authors": [
                {
                    "authorId": "50268352",
                    "name": "Renming Liu"
                },
                {
                    "authorId": "2135548959",
                    "name": "Semih Cant\u00fcrk"
                },
                {
                    "authorId": "2140578386",
                    "name": "Olivier Lapointe-Gagn'e"
                },
                {
                    "authorId": "2067158294",
                    "name": "Vincent L'etourneau"
                },
                {
                    "authorId": "2683398",
                    "name": "Guy Wolf"
                },
                {
                    "authorId": "51034451",
                    "name": "D. Beaini"
                },
                {
                    "authorId": "2125913",
                    "name": "Ladislav Ramp\u00e1\u0161ek"
                }
            ]
        },
        {
            "paperId": "c194de20b4e1c5cd1978a05f192d492d2699db90",
            "title": "Single-Cell Multimodal Prediction via Transformers",
            "abstract": "The recent development of multimodal single-cell technology has made the possibility of acquiring multiple omics data from individual cells, thereby enabling a deeper understanding of cellular states and dynamics. Nevertheless, the proliferation of multimodal single-cell data also introduces tremendous challenges in modeling the complex interactions among different modalities. The recently advanced methods focus on constructing static interaction graphs and applying graph neural networks (GNNs) to learn from multimodal data. However, such static graphs can be suboptimal as they do not take advantage of the downstream task information; meanwhile GNNs also have some inherent limitations when deeply stacking GNN layers. To tackle these issues, in this work, we investigate how to leverage transformers for multimodal single-cell data in an end-to-end manner while exploiting downstream task information. In particular, we propose a scMoFormer framework which can readily incorporate external domain knowledge and model the interactions within each modality and cross modalities. Extensive experiments demonstrate that scMoFormer achieves superior performance on various benchmark datasets. Remarkably, scMoFormer won a Kaggle silver medal with the rank of 24/1221 (Top 2%) without ensemble in a NeurIPS 2022 competition1. Our implementation is publicly available at Github2.",
            "fieldsOfStudy": [
                "Computer Science",
                "Biology",
                "Medicine"
            ],
            "authors": [
                {
                    "authorId": "2188792890",
                    "name": "Wenzhuo Tang"
                },
                {
                    "authorId": "30580446",
                    "name": "Haifang Wen"
                },
                {
                    "authorId": "50268352",
                    "name": "Renming Liu"
                },
                {
                    "authorId": "46496977",
                    "name": "Jiayuan Ding"
                },
                {
                    "authorId": "144767914",
                    "name": "Wei Jin"
                },
                {
                    "authorId": "2154871510",
                    "name": "Yuying Xie"
                },
                {
                    "authorId": "2146672392",
                    "name": "Hui Liu"
                },
                {
                    "authorId": "1736632",
                    "name": "Jiliang Tang"
                }
            ]
        },
        {
            "paperId": "f5f54a38729925c98e71e3e59fbf884bde23de60",
            "title": "Joint representation of molecular networks from multiple species improves gene classification",
            "abstract": "Network-based machine learning (ML) has the potential for predicting novel genes associated with nearly any health and disease context. However, this approach often uses network information from only the single species under consideration even though networks for most species are noisy and incomplete. While some recent methods have begun addressing this shortcoming by using networks from more than one species, they lack one or more key desirable properties: handling networks from multiple species, incorporating many-to-many orthology information, or generating a network representation that is reusable across different types of and newly-defined prediction tasks. Here, we present GenePlexusZoo, a framework that casts molecular networks from multiple species into a single reusable feature space for network-based ML. We demonstrate that this multi-species network representation improves both gene classification within a single species and knowledge-transfer across species, even in cases where the inter-species correspondence is undetectable based on shared orthologous genes. Thus, GenePlexusZoo enables effectively leveraging the high evolutionary molecular, functional, and phenotypic conservation across species to discover novel genes associated with diverse biological contexts.",
            "fieldsOfStudy": [
                "Medicine",
                "Biology",
                "Computer Science"
            ],
            "authors": [
                {
                    "authorId": "2053375043",
                    "name": "Christopher A Mancuso"
                },
                {
                    "authorId": "46785815",
                    "name": "Kayla A Johnson"
                },
                {
                    "authorId": "50268352",
                    "name": "Renming Liu"
                },
                {
                    "authorId": "143790218",
                    "name": "Arjun Krishnan"
                }
            ]
        },
        {
            "paperId": "23e9e18c09f9cf4b3f10a09499a24ca1a3957004",
            "title": "GenePlexus: a web-server for gene discovery using network-based machine learning",
            "abstract": "Abstract Biomedical researchers take advantage of high-throughput, high-coverage technologies to routinely generate sets of genes of interest across a wide range of biological conditions. Although these technologies have directly shed light on the molecular underpinnings of various biological processes and diseases, the list of genes from any individual experiment is often noisy and incomplete. Additionally, interpreting these lists of genes can be challenging in terms of how they are related to each other and to other genes in the genome. In this work, we present GenePlexus (https://www.geneplexus.net/), a web-server that allows a researcher to utilize a powerful, network-based machine learning method to gain insights into their gene set of interest and additional functionally similar genes. Once a user uploads their own set of human genes and chooses between a number of different human network representations, GenePlexus provides predictions of how associated every gene in the network is to the input set. The web-server also provides interpretability through network visualization and comparison to other machine learning models trained on thousands of known process/pathway and disease gene sets. GenePlexus is free and open to all users without the need for registration.",
            "fieldsOfStudy": [
                "Computer Science",
                "Medicine"
            ],
            "authors": [
                {
                    "authorId": "2053375043",
                    "name": "Christopher A Mancuso"
                },
                {
                    "authorId": "39711945",
                    "name": "P. Bills"
                },
                {
                    "authorId": "2165467765",
                    "name": "Douglas Krum"
                },
                {
                    "authorId": "2165467506",
                    "name": "Jacob Newsted"
                },
                {
                    "authorId": "50268352",
                    "name": "Renming Liu"
                },
                {
                    "authorId": "143790218",
                    "name": "Arjun Krishnan"
                }
            ]
        },
        {
            "paperId": "4f660f06a0f0a12c09871a4dbf97bcc9f2489701",
            "title": "PyGenePlexus: a Python package for gene discovery using network-based machine learning",
            "abstract": "PyGenePlexus is a Python package that enables a user to gain insight into any gene set of interest based on a molecular interaction network using supervised machine learning. PyGenePlexus provides predictions of how associated every gene in the network is to the input gene set, offers interpretability by comparing the model trained on the input gene set to models trained on thousands of known gene sets, and returns the network connectivity of the top predicted genes. Availability and Implementation https://pypi.org/project/geneplexus/ and https://github.com/krishnanlab/PyGenePlexus Contact arjun@msu.edu",
            "fieldsOfStudy": [
                "Computer Science",
                "Medicine",
                "Biology"
            ],
            "authors": [
                {
                    "authorId": "2053375043",
                    "name": "Christopher A Mancuso"
                },
                {
                    "authorId": "50268352",
                    "name": "Renming Liu"
                },
                {
                    "authorId": "143790218",
                    "name": "Arjun Krishnan"
                }
            ]
        },
        {
            "paperId": "b1b4309c9837d16bb8f696a8f2ede0c1b1931c8b",
            "title": "Deep Learning in Single-cell Analysis",
            "abstract": "Single-cell technologies are revolutionizing the entire field of biology. The large volumes of data generated by single-cell technologies are high dimensional, sparse, and heterogeneous and have complicated dependency structures, making analyses using conventional machine learning approaches challenging and impractical. In tackling these challenges, deep learning often demonstrates superior performance compared to traditional machine learning methods. In this work, we give a comprehensive survey on deep learning in single-cell analysis. We first introduce background on single-cell technologies and their development, as well as fundamental concepts of deep learning including the most popular deep architectures. We present an overview of the single-cell analytic pipeline pursued in research applications while noting divergences due to data sources or specific applications. We then review seven popular tasks spanning different stages of the single-cell analysis pipeline, including multimodal integration, imputation, clustering, spatial domain identification, cell-type deconvolution, cell segmentation, and cell-type annotation. Under each task, we describe the most recent developments in classical and deep learning methods and discuss their advantages and disadvantages. Deep learning tools and benchmark datasets are also summarized for each task. Finally, we discuss the future directions and the most recent challenges. This survey will serve as a reference for biologists and computer scientists, encouraging collaborations.",
            "fieldsOfStudy": [
                "Computer Science",
                "Biology"
            ],
            "authors": [
                {
                    "authorId": "2188737365",
                    "name": "Dylan Molho"
                },
                {
                    "authorId": "46496977",
                    "name": "Jiayuan Ding"
                },
                {
                    "authorId": "2188802257",
                    "name": "Zhaoheng Li"
                },
                {
                    "authorId": "30580446",
                    "name": "Haifang Wen"
                },
                {
                    "authorId": "2188792890",
                    "name": "Wenzhuo Tang"
                },
                {
                    "authorId": "2143443305",
                    "name": "Yixin Wang"
                },
                {
                    "authorId": "1768191205",
                    "name": "Julian Venegas"
                },
                {
                    "authorId": "144767914",
                    "name": "Wei Jin"
                },
                {
                    "authorId": "50268352",
                    "name": "Renming Liu"
                },
                {
                    "authorId": "1943369921",
                    "name": "Runze Su"
                },
                {
                    "authorId": "2011416",
                    "name": "P. Danaher"
                },
                {
                    "authorId": "2115688334",
                    "name": "Robert Yang"
                },
                {
                    "authorId": "71157169",
                    "name": "Y. Lei"
                },
                {
                    "authorId": "2154871510",
                    "name": "Yuying Xie"
                },
                {
                    "authorId": "1736632",
                    "name": "Jiliang Tang"
                }
            ]
        },
        {
            "paperId": "cb962a6f24e01143d5aa2959777841773f26198f",
            "title": "Accurately modeling biased random walks on weighted networks using node2vec+",
            "abstract": "Motivation Accurately representing biological networks in a low-dimensional space, also known as network embedding, is a critical step in network-based machine learning and is carried out widely using node2vec, an unsupervised method based on biased random walks. However, while many networks, including functional gene interaction networks, are dense, weighted graphs, node2vec is fundamentally limited in its ability to use edge weights during the biased random walk generation process, thus under-using all the information in the network. Results Here, we present node2vec+, a natural extension of node2vec that accounts for edge weights when calculating walk biases and reduces to node2vec in the cases of unweighted graphs or unbiased walks. Using two synthetic datasets, we empirically show that node2vec+ is more robust to additive noise than node2vec in weighted graphs. Then, using genome-scale functional gene networks to solve a wide range of gene function and disease prediction tasks, we demonstrate the superior performance of node2vec+ over node2vec in the case of weighted graphs. Notably, due to the limited amount of training data in the gene classification tasks, graph neural networks such as GCN and GraphSAGE are outperformed by both node2vec and node2vec+ Contact arjun.krishnan@cuanschutz.edu Code Availability https://github.com/krishnanlab/node2vecplus_benchmarks Supplementary information Supplementary data are available at Bioinformatics online.",
            "fieldsOfStudy": [
                "Medicine",
                "Biology",
                "Computer Science"
            ],
            "authors": [
                {
                    "authorId": "50268352",
                    "name": "Renming Liu"
                },
                {
                    "authorId": "145500870",
                    "name": "M. Hirn"
                },
                {
                    "authorId": "143790218",
                    "name": "Arjun Krishnan"
                }
            ]
        },
        {
            "paperId": "e1a0c574adda2480f81c631fb3b5aca8f4641c8c",
            "title": "Taxonomy of Benchmarks in Graph Representation Learning",
            "abstract": "Graph Neural Networks (GNNs) extend the success of neural networks to graph-structured data by accounting for their intrinsic geometry. While extensive research has been done on developing GNN models with superior performance according to a collection of graph representation learning benchmarks, it is currently not well understood what aspects of a given model are probed by them. For example, to what extent do they test the ability of a model to leverage graph structure vs. node features? Here, we develop a principled approach to taxonomize benchmarking datasets according to a $\\textit{sensitivity profile}$ that is based on how much GNN performance changes due to a collection of graph perturbations. Our data-driven analysis provides a deeper understanding of which benchmarking data characteristics are leveraged by GNNs. Consequently, our taxonomy can aid in selection and development of adequate graph benchmarks, and better informed evaluation of future GNN methods. Finally, our approach and implementation in $\\texttt{GTaxoGym}$ package are extendable to multiple graph prediction task types and future datasets.",
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "authors": [
                {
                    "authorId": "50268352",
                    "name": "Renming Liu"
                },
                {
                    "authorId": "2135548959",
                    "name": "Semih Cant\u00fcrk"
                },
                {
                    "authorId": "1573578820",
                    "name": "Frederik Wenkel"
                },
                {
                    "authorId": "2118740916",
                    "name": "Dylan Sandfelder"
                },
                {
                    "authorId": "2107709516",
                    "name": "Devin Kreuzer"
                },
                {
                    "authorId": "3169981",
                    "name": "A. Little"
                },
                {
                    "authorId": "2057138492",
                    "name": "Sarah McGuire"
                },
                {
                    "authorId": "2007782619",
                    "name": "Leslie O\u2019Bray"
                },
                {
                    "authorId": "32099299",
                    "name": "Michael Perlmutter"
                },
                {
                    "authorId": "2208337",
                    "name": "Bastian Alexander Rieck"
                },
                {
                    "authorId": "145500870",
                    "name": "M. Hirn"
                },
                {
                    "authorId": "2683398",
                    "name": "Guy Wolf"
                },
                {
                    "authorId": "2125913",
                    "name": "Ladislav Ramp\u00e1\u0161ek"
                }
            ]
        },
        {
            "paperId": "5f40cdbb540d4bde02c8e399f9599017770d90ae",
            "title": "Accurately Modeling Biased Random Walks on Weighted Graphs Using Node2vec+",
            "abstract": "Node embedding is a powerful approach for representing the structural role of each node in a graph. $\\textit{Node2vec}$ is a widely used method for node embedding that works by exploring the local neighborhoods via biased random walks on the graph. However, $\\textit{node2vec}$ does not consider edge weights when computing walk biases. This intrinsic limitation prevents $\\textit{node2vec}$ from leveraging all the information in weighted graphs and, in turn, limits its application to many real-world networks that are weighted and dense. Here, we naturally extend $\\textit{node2vec}$ to $\\textit{node2vec+}$ in a way that accounts for edge weights when calculating walk biases, but which reduces to $\\textit{node2vec}$ in the cases of unweighted graphs or unbiased walks. We empirically show that $\\textit{node2vec+}$ is more robust to additive noise than $\\textit{node2vec}$ in weighted graphs using two synthetic datasets. We also demonstrate that $\\textit{node2vec+}$ significantly outperforms $\\textit{node2vec}$ on a commonly benchmarked multi-label dataset (Wikipedia). Furthermore, we test $\\textit{node2vec+}$ against GCN and GraphSAGE using various challenging gene classification tasks on two protein-protein interaction networks. Despite some clear advantages of GCN and GraphSAGE, they show comparable performance with $\\textit{node2vec+}$. Finally, $\\textit{node2vec+}$ can be used as a general approach for generating biased random walks, benefiting all existing methods built on top of $\\textit{node2vec}$. $\\textit{Node2vec+}$ is implemented as part of $\\texttt{PecanPy}$, which is available at https://github.com/krishnanlab/PecanPy .",
            "fieldsOfStudy": [
                "Computer Science",
                "Biology"
            ],
            "authors": [
                {
                    "authorId": "50268352",
                    "name": "Renming Liu"
                },
                {
                    "authorId": "145500870",
                    "name": "M. Hirn"
                },
                {
                    "authorId": "143790218",
                    "name": "Arjun Krishnan"
                }
            ]
        }
    ]
}