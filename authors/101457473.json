{
    "authorId": "101457473",
    "papers": [
        {
            "paperId": "09c47cf6e0b173057ebd28c60086db627c1b4bf3",
            "title": "Continuous Input Embedding Size Search For Recommender Systems",
            "abstract": "Latent factor models are the most popular backbones for today's recommender systems owing to their prominent performance. Latent factor models represent users and items as real-valued embedding vectors for pairwise similarity computation, and all embeddings are traditionally restricted to a uniform size that is relatively large (e.g., 256-dimensional). With the exponentially expanding user base and item catalog in contemporary e commerce, this design is admittedly becoming memory-inefficient. To facilitate lightweight recommendation, reinforcement learning (RL) has recently opened up opportunities for identifying varying embedding sizes for different users/items. However, challenged by search efficiency and learning an optimal RL policy, existing RL-based methods are restricted to highly discrete, predefined embedding size choices. This leads to a largely overlooked potential of introducing finer granularity into embedding sizes to obtain better recommendation effectiveness under a given memory budget. In this paper, we propose continuous input embedding size search (CIESS), a novel RL-based method that operates on a continuous search space with arbitrary embedding sizes to choose from. In CIESS, we further present an innovative random walk-based exploration strategy to allow the RL policy to efficiently explore more candidate embedding sizes and converge to a better decision. CIESS is also model-agnostic and hence generalizable to a variety of latent factor RSs, whilst experiments on two real-world datasets have shown state-of-the-art performance of CIESS under different memory budgets when paired with three popular recommendation models.",
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "authors": [
                {
                    "authorId": "2147288412",
                    "name": "Yunke Qu"
                },
                {
                    "authorId": "1490931831",
                    "name": "Tong Chen"
                },
                {
                    "authorId": "2116711312",
                    "name": "Xiang Zhao"
                },
                {
                    "authorId": "101457473",
                    "name": "Li-zhen Cui"
                },
                {
                    "authorId": "2052687617",
                    "name": "Kai Zheng"
                },
                {
                    "authorId": "2416851",
                    "name": "Hongzhi Yin"
                }
            ]
        },
        {
            "paperId": "0ee150402fb03c7c867aa7c9f8dfcbef51275687",
            "title": "FedMAE: Federated Self-Supervised Learning with One-Block Masked Auto-Encoder",
            "abstract": "Latest federated learning (FL) methods started to focus on how to use unlabeled data in clients for training due to users' privacy concerns, high labeling costs, or lack of expertise. However, current Federated Semi-Supervised/Self-Supervised Learning (FSSL) approaches fail to learn large-scale images because of the limited computing resources of local clients. In this paper, we introduce a new framework FedMAE, which stands for Federated Masked AutoEncoder, to address the problem of how to utilize unlabeled large-scale images for FL. Specifically, FedMAE can pre-train one-block Masked AutoEncoder (MAE) using large images in lightweight client devices, and then cascades multiple pre-trained one-block MAEs in the server to build a multi-block ViT backbone for downstream tasks. Theoretical analysis and experimental results on image reconstruction and classification show that our FedMAE achieves superior performance compared to the state-of-the-art FSSL methods.",
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "authors": [
                {
                    "authorId": "2153402103",
                    "name": "Nan Yang"
                },
                {
                    "authorId": "2108968034",
                    "name": "Xuanyu Chen"
                },
                {
                    "authorId": "2209300309",
                    "name": "Charles Z. Liu"
                },
                {
                    "authorId": "2068903938",
                    "name": "Dong Yuan"
                },
                {
                    "authorId": "144794486",
                    "name": "Wei Bao"
                },
                {
                    "authorId": "101457473",
                    "name": "Li-zhen Cui"
                }
            ]
        },
        {
            "paperId": "234d5911d7c53c1c0f671f6d1fdfbfe398923ddf",
            "title": "Logic Event Graph Enhanced Narrative Generation",
            "abstract": "Narrative generation aims at producing fluent long texts from input data, which is widely used in event prediction, story generation and other fields. Previous work mainly relied on text data, picture data, knowledge graphs, etc. Unfortunately, these static data only focused on entities and their relationships, cannot reflect the dynamic development of events in the real world. In addition, because the language model itself does not have the ability of logical reasoning, the generated results often lack logical reasoning. To address these challenges, several studies incorporate logic event graphs into the task of narrative generation. The Logic Event Graph(LEG) is essentially an event logic knowledge base, which describes the event evolution law and development modes. With the help of the LEG, the narrative generation system will acquire the human \"reasoning\" ability, and generate narratives that better reflect the objective evolution laws of human behaviors and events. While significant research has been conducted in these areas, gaps in the surveying literature still exist. In this survey, we\u2014(1)analyze the context of narrative generation; (2)discuss the advantages of joining the LEG in narrative generate; (3)review common strategies in narrative generation; (4)summarize the evaluation metricse of narrative generate, and the advantages and disadvantages of each evaluation metrics are discussed; (5)present current challenges and future research directions. This survey can guide researchers and practitioners to understand the research progress in these areas.",
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "authors": [
                {
                    "authorId": "2220477766",
                    "name": "Caiyan Li"
                },
                {
                    "authorId": "101457473",
                    "name": "Li-zhen Cui"
                },
                {
                    "authorId": "2146648924",
                    "name": "Yonghui Xu"
                },
                {
                    "authorId": "2163813812",
                    "name": "Ning Liu"
                }
            ]
        },
        {
            "paperId": "4b1bc95030c8f35886aec4b27bdfc48ad1bb3b45",
            "title": "HeteFedRec: Federated Recommender Systems with Model Heterogeneity",
            "abstract": "Owing to the nature of privacy protection, feder-ated recommender systems (FedRecs) have garnered increasing interest in the realm of on-device recommender systems. However, most existing FedRecs only allow participating clients to collaboratively train a recommendation model of the same public parameter size. Training a model of the same size for all clients can lead to suboptimal performance since clients possess varying resources. For example, clients with limited training data may prefer to train a smaller recommendation model to avoid excessive data consumption, while clients with sufficient data would benefit from a larger model to achieve higher recommendation accuracy. To address the above challenge, this paper introduces HeteFedRec, a novel FedRec framework that enables the assignment of personalized model sizes to partici-pants. Specifically, we present a heterogeneous recommendation model aggregation strategy, including a unified dual-task learning mechanism and a dimensional decorrelation regularization, to allow knowledge aggregation among recommender models of different sizes. Additionally, a relation-based ensemble knowledge distillation method is proposed to effectively distil knowledge from heterogeneous item embeddings. Extensive experiments conducted on three real-world recommendation datasets demonstrate the effectiveness and efficiency of HeteFedRec in training federated recommender systems under heterogeneous settings.",
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "authors": [
                {
                    "authorId": "2106755543",
                    "name": "Wei Yuan"
                },
                {
                    "authorId": "2056322340",
                    "name": "Liang Qu"
                },
                {
                    "authorId": "101457473",
                    "name": "Li-zhen Cui"
                },
                {
                    "authorId": "8230559",
                    "name": "Yongxin Tong"
                },
                {
                    "authorId": "2193326192",
                    "name": "Xiaofang Zhou"
                },
                {
                    "authorId": "2416851",
                    "name": "Hongzhi Yin"
                }
            ]
        },
        {
            "paperId": "52edefdc0632ce17b193a6f5b0adf1422207fa91",
            "title": "Cross-Domain Disentangled Learning for E-Commerce Live Streaming Recommendation",
            "abstract": "E-commerce live streaming as an increasingly popular sales model has generated a significant amount of gross merchandise value (GMV) for e-commerce platforms. Live streaming recommendation systems (LSRS) of e-commerce aim to recommend the most appropriate live channels for users to motivate them to buy products. Existing LSRS methods focus only on the user\u2019s interaction behaviors on the live channel (live domain) while ignoring the user\u2019s behaviors and intentions on the e-commerce product (product domain). As a result, the user\u2019s consistent purchase intentions in the cross-domain are not being fully captured, especially when user present differentiated purchase intentions in the cross-domain. How to disentangle user\u2019s consistent intentions and domain-specific intentions in the cross-domain poses a challenge to the LSRS of e-commerce platforms. In this paper, we present a live channel recommendation method, named eLiveRec, developed for Taobao, one of the largest e-commerce platform in the world. Specifically, eLiveRec employs the disentangled encoder module to learn user\u2019s cross-domain consistent intentions and domain-specific intentions. Then, an adaptive multi-task learning framework is developed to jointly optimize the multiple objectives (e.g., stay time, click goods bag, and click products after entering channel) related to live streaming recommendation. In this way, the performance of live streaming recommendation can be further improved and con-form to standard industry RS paradigms. Extensive experiments are conducted on a large-scale industry dataset collected from Taobao Live platform have been performed. Both online and offline experimental results indicate that eLiveRec consistently outperforms existing state-of-the-art baseline methods.",
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "authors": [
                {
                    "authorId": "2108248194",
                    "name": "Yixin Zhang"
                },
                {
                    "authorId": "49421468",
                    "name": "Yong Liu"
                },
                {
                    "authorId": "2224892027",
                    "name": "Hao Xiong"
                },
                {
                    "authorId": "2153629224",
                    "name": "Yi Liu"
                },
                {
                    "authorId": "46597961",
                    "name": "Fuqiang Yu"
                },
                {
                    "authorId": "2153476351",
                    "name": "Weiliang He"
                },
                {
                    "authorId": "2146648924",
                    "name": "Yonghui Xu"
                },
                {
                    "authorId": "101457473",
                    "name": "Li-zhen Cui"
                },
                {
                    "authorId": "2158509654",
                    "name": "Chun Miao"
                }
            ]
        },
        {
            "paperId": "5be91daa238b57de082de1d76cff57945686a41e",
            "title": "Modeling Long- and Short-Term User Preferences via Self-Supervised Learning for Next POI Recommendation",
            "abstract": "With the accumulation of check-in data from location-based services, next Point-of-Interest (POI) recommendations are gaining increasing attention. It is well known that the spatio-temporal contextual information of user check-in behavior plays a crucial role in handling vital and inherent challenges in next POI recommendation, including capture of user dynamic preferences and the sparsity problem of check-in data. However, many studies either ignore or simply stack the context features with the embedding of POIs while relying only on POI recommendation loss to optimize the entire model, therefore failing to take full advantage of the potential information in contexts. Additionally, users\u2019 interests are usually unstable and evolve over time, and accordingly recent studies have proposed various approaches to predict users\u2019 next POIs by incorporating contextual information and modeling both their long- and short-term preferences, respectively. Yet many studies overemphasize the final POI recommendation performance, and the association between POI sequences and contextual information is not well embodied in data representations. In this article, we focus on the preceding problems and propose a unified attention framework for next POI recommendation by modeling users\u2019 Long- and Short-term Preferences via Self-supervised Learning (LSPSL). Specifically, based on the self-attention network and two self-supervised optimization objectives, LSPSL first deeply exploits the intrinsic correlations between POI sequences and contextual information through pre-training, which strengthens data representations. Then, supported by pre-trained contextualized embeddings, LSPSL models and fuses users\u2019 complex long- and short-term preferences in a unified way. Extensive experiments on real-world datasets demonstrate the superiority of our model compared with other state-of-the-art approaches.",
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "authors": [
                {
                    "authorId": "2119329340",
                    "name": "Shaowei Jiang"
                },
                {
                    "authorId": "48692318",
                    "name": "W. He"
                },
                {
                    "authorId": "101457473",
                    "name": "Li-zhen Cui"
                },
                {
                    "authorId": "2146648924",
                    "name": "Yonghui Xu"
                },
                {
                    "authorId": "1557267924",
                    "name": "Lei Liu"
                }
            ]
        },
        {
            "paperId": "78125a11b503ff1683c09a2dbfde3dce6fece43d",
            "title": "Explicit Knowledge Graph Reasoning for Conversational Recommendation",
            "abstract": "Traditional recommender systems estimate user preference on items purely based on historical interaction records, thus failing to capture fine-grained yet dynamic user interests and letting users receive recommendation only passively. Recent conversational recommender systems (CRSs) tackle those limitations by enabling recommender systems to interact with the user to obtain her/his current preference through a sequence of clarifying questions. Recently, there has been a rise of using knowledge graphs (KGs) for CRSs, where the core motivation is to incorporate the abundant side information carried by a KG into both the recommendation and conversation processes. However, existing KG-based CRSs are subject to two defects: (1) there is a semantic gap between the learned representations of utterances and KG entities, hindering the retrieval of relevant KG information; (2) the reasoning over KG is mostly performed with the implicitly learned user interests, overlooking the explicit signals from the entities actually mentioned in the conversation. To address these drawbacks, we propose a new CRS framework, namely the Knowledge Enhanced Conversational Reasoning (KECR) model. As a user can reflect her/his preferences via both attribute- and item-level expressions, KECR jointly embeds the structured knowledge from two levels in the KG. A mutual information maximization constraint is further proposed for semantic alignment between the embedding spaces of utterances and KG entities. Meanwhile, KECR utilizes the connectivity within the KG to conduct explicit reasoning of the user demand, making the model less dependent on the user\u2019s feedback to clarifying questions. As such, the semantic alignment and explicit KG reasoning can jointly facilitate accurate recommendation and quality dialogue generation. By comparing with strong baselines on two real-world datasets, we demonstrate that KECR obtains state-of-the-art recommendation effectiveness, as well as competitive dialogue generation performance.",
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "authors": [
                {
                    "authorId": "1994610570",
                    "name": "Xuhui Ren"
                },
                {
                    "authorId": "1490931831",
                    "name": "Tong Chen"
                },
                {
                    "authorId": "144133815",
                    "name": "Q. Nguyen"
                },
                {
                    "authorId": "101457473",
                    "name": "Li-zhen Cui"
                },
                {
                    "authorId": "2129485845",
                    "name": "Zi-Liang Huang"
                },
                {
                    "authorId": "2416851",
                    "name": "Hongzhi Yin"
                }
            ]
        },
        {
            "paperId": "7cb09c77aab947c376df4fbcc4f2d877960f35d6",
            "title": "MMTN: Multi-Modal Memory Transformer Network for Image-Report Consistent Medical Report Generation",
            "abstract": "Automatic medical report generation is an essential task in applying artificial intelligence to the medical domain, which can lighten the workloads of doctors and promote clinical automation. The state-of-the-art approaches employ Transformer-based encoder-decoder architectures to generate reports for medical images. However, they do not fully explore the relationships between multi-modal medical data, and generate inaccurate and inconsistent reports. To address these issues, this paper proposes a Multi-modal Memory Transformer Network (MMTN) to cope with multi-modal medical data for generating image-report consistent medical reports. On the one hand, MMTN reduces the occurrence of image-report inconsistencies by designing a unique encoder to associate and memorize the relationship between medical images and medical terminologies. On the other hand, MMTN utilizes the cross-modal complementarity of the medical vision and language for the word prediction, which further enhances the accuracy of generating medical reports. Extensive experiments on three real datasets show that MMTN achieves significant effectiveness over state-of-the-art approaches on both automatic metrics and human evaluation.",
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "authors": [
                {
                    "authorId": "2112867256",
                    "name": "Yiming Cao"
                },
                {
                    "authorId": "101457473",
                    "name": "Li-zhen Cui"
                },
                {
                    "authorId": "48571012",
                    "name": "L. Zhang"
                },
                {
                    "authorId": "46597961",
                    "name": "Fuqiang Yu"
                },
                {
                    "authorId": "2116506602",
                    "name": "Zhen Li"
                },
                {
                    "authorId": "2146648891",
                    "name": "Yonghui Xu"
                }
            ]
        },
        {
            "paperId": "916bc9ed62113ad7a5bb8096051593df4ebb2061",
            "title": "Unsupervised Representation Learning for Time Series: A Review",
            "abstract": "Unsupervised representation learning approaches aim to learn discriminative feature representations from unlabeled data, without the requirement of annotating every sample. Enabling unsupervised representation learning is extremely crucial for time series data, due to its unique annotation bottleneck caused by its complex characteristics and lack of visual cues compared with other data modalities. In recent years, unsupervised representation learning techniques have advanced rapidly in various domains. However, there is a lack of systematic analysis of unsupervised representation learning approaches for time series. To fill the gap, we conduct a comprehensive literature review of existing rapidly evolving unsupervised representation learning approaches for time series. Moreover, we also develop a unified and standardized library, named ULTS (i.e., Unsupervised Learning for Time Series), to facilitate fast implementations and unified evaluations on various models. With ULTS, we empirically evaluate state-of-the-art approaches, especially the rapidly evolving contrastive learning methods, on 9 diverse real-world datasets. We further discuss practical considerations as well as open research challenges on unsupervised representation learning for time series to facilitate future research in this field.",
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "authors": [
                {
                    "authorId": "103236149",
                    "name": "Qianwen Meng"
                },
                {
                    "authorId": "1732549",
                    "name": "Hangwei Qian"
                },
                {
                    "authorId": "2144384782",
                    "name": "Yong Liu"
                },
                {
                    "authorId": "153018970",
                    "name": "Yonghui Xu"
                },
                {
                    "authorId": "2111639168",
                    "name": "Zhiqi Shen"
                },
                {
                    "authorId": "101457473",
                    "name": "Li-zhen Cui"
                }
            ]
        },
        {
            "paperId": "b48a8c226efb52844c9b97309a654a383f33b823",
            "title": "Interaction-level Membership Inference Attack Against Federated Recommender Systems",
            "abstract": "The marriage of federated learning and recommender system (FedRec) has been widely used to address the growing data privacy concerns in personalized recommendation services. In FedRecs, users\u2019 attribute information and behavior data (i.e., user-item interaction data) are kept locally on their personal devices, therefore, it is considered a fairly secure approach to protect user privacy. As a result, the privacy issue of FedRecs is rarely explored. Unfortunately, several recent studies reveal that FedRecs are vulnerable to user attribute inference attacks, highlighting the privacy concerns of FedRecs. In this paper, we further investigate the privacy problem of user behavior data (i.e., user-item interactions) in FedRecs. Specifically, we perform the first systematic study on interaction-level membership inference attacks on FedRecs. An interaction-level membership inference attacker is first designed, and then the classical privacy protection mechanism, Local Differential Privacy (LDP), is adopted to defend against the membership inference attack. Unfortunately, the empirical analysis shows that LDP is not effective against such new attacks unless the recommendation performance is largely compromised. To mitigate the interaction-level membership attack threats, we design a simple yet effective defense method to significantly reduce the attacker\u2019s inference accuracy without losing recommendation performance. Extensive experiments are conducted with two widely used FedRecs (Fed-NCF and Fed-LightGCN) on three real-world recommendation datasets (MovieLens-100K, Steam-200K, and Amazon Cell Phone), and the experimental results show the effectiveness of our solutions.",
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "authors": [
                {
                    "authorId": "2106755543",
                    "name": "Wei Yuan"
                },
                {
                    "authorId": "2177256804",
                    "name": "Chao-Peng Yang"
                },
                {
                    "authorId": "144133815",
                    "name": "Q. Nguyen"
                },
                {
                    "authorId": "101457473",
                    "name": "Li-zhen Cui"
                },
                {
                    "authorId": "2281761",
                    "name": "Tieke He"
                },
                {
                    "authorId": "2416851",
                    "name": "Hongzhi Yin"
                }
            ]
        }
    ]
}