{
    "authorId": "121300608",
    "papers": [
        {
            "paperId": "6e8627662e66a797be56f473f9bee76451d5eb48",
            "title": "Soft Prompt Decoding for Multilingual Dense Retrieval",
            "abstract": "In this work, we explore a Multilingual Information Retrieval (MLIR) task, where the collection includes documents in multiple languages. We demonstrate that applying state-of-the-art approaches developed for cross-lingual information retrieval to MLIR tasks leads to sub-optimal performance. This is due to the heterogeneous and imbalanced nature of multilingual collections -- some languages are better represented in the collection and some benefit from large-scale training data. To address this issue, we present KD-SPD, a novel soft prompt decoding approach for MLIR that implicitly \"translates'' the representation of documents in different languages into the same embedding space. To address the challenges of data scarcity and imbalance, we introduce a knowledge distillation strategy. The teacher model is trained on rich English retrieval data, and by leveraging bi-text data, our distillation framework transfers its retrieval knowledge to the multilingual document encoder. Therefore, our approach does not require any multilingual retrieval training data. Extensive experiments on three MLIR datasets with a total of 15 languages demonstrate that KD-SPD significantly outperforms competitive baselines in all cases. We conduct extensive analyses to show that our method has less language bias and better zero-shot transfer ability towards new languages.",
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "authors": [
                {
                    "authorId": "2122143",
                    "name": "Zhiqi Huang"
                },
                {
                    "authorId": "2029235362",
                    "name": "Hansi Zeng"
                },
                {
                    "authorId": "2499986",
                    "name": "Hamed Zamani"
                },
                {
                    "authorId": "121300608",
                    "name": "J. Allan"
                }
            ]
        },
        {
            "paperId": "709fb9ddc54f048f255d814738008aab1ae314ba",
            "title": "Cross-lingual Knowledge Transfer via Distillation for Multilingual Information Retrieval",
            "abstract": "In this paper, we introduce the approach behind our submission for the MIRACL challenge, a WSDM 2023 Cup competition that centers on ad-hoc retrieval across 18 diverse languages. Our solution contains two neural-based models. The first model is a bi-encoder re-ranker, on which we apply a cross-lingual distillation technique to transfer ranking knowledge from English to the target language space. The second model is a cross-encoder re-ranker trained on multilingual retrieval data generated using neural machine translation. We further fine-tune both models using MIRACL training data and ensemble multiple rank lists to obtain the final result. According to the MIRACL leaderboard, our approach ranks 8th for the Test-A set and 2nd for the Test-B set among the 16 known languages.",
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "authors": [
                {
                    "authorId": "2122143",
                    "name": "Zhiqi Huang"
                },
                {
                    "authorId": "51029950",
                    "name": "Puxuan Yu"
                },
                {
                    "authorId": "121300608",
                    "name": "J. Allan"
                }
            ]
        },
        {
            "paperId": "91118fd0acdc0876e247e2df455fb9ffd9a1f40b",
            "title": "Cross-Market Product-Related Question Answering",
            "abstract": "Online shops such as Amazon, eBay, and Etsy continue to expand their presence in multiple countries, creating new resource-scarce marketplaces with thousands of items. We consider a marketplace to be resource-scarce when only limited user-generated data is available about the products (e.g., ratings, reviews, and product-related questions). In such a marketplace, an information retrieval system is less likely to help users find answers to their questions about the products. As a result, questions posted online may go unanswered for extended periods. This study investigates the impact of using available data in a resource-rich marketplace to answer new questions in a resource-scarce marketplace, a new problem we call cross-market question answering. To study this problem's potential impact, we collect and annotate a new dataset, XMarket-QA, from Amazon's UK (resource-scarce) and US (resource-rich) local marketplaces. We conduct a data analysis to understand the scope of the cross-market question-answering task. This analysis shows a temporal gap of almost one year between the first question answered in the UK marketplace and the US marketplace. Also, it shows that the first question about a product is posted in the UK marketplace only when 28 questions, on average, have already been answered about the same product in the US marketplace. Human annotations demonstrate that, on average, 65% of the questions in the UK marketplace can be answered within the US marketplace, supporting the concept of cross-market question answering. Inspired by these findings, we develop a new method, CMJim, which utilizes product similarities across marketplaces in the training phase for retrieving answers from the resource-rich marketplace that can be used to answer a question in the resource-scarce marketplace. Our evaluations show CMJim's significant improvement compared to competitive baselines.",
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "authors": [
                {
                    "authorId": "2041844921",
                    "name": "Negin Ghasemi"
                },
                {
                    "authorId": "3390352",
                    "name": "Mohammad Aliannejadi"
                },
                {
                    "authorId": "2131141811",
                    "name": "Hamed Bonab"
                },
                {
                    "authorId": "1713134",
                    "name": "E. Kanoulas"
                },
                {
                    "authorId": "1701063719",
                    "name": "Arjen P. de Vries"
                },
                {
                    "authorId": "121300608",
                    "name": "J. Allan"
                },
                {
                    "authorId": "4021174",
                    "name": "D. Hiemstra"
                }
            ]
        },
        {
            "paperId": "dff9da58041e9bea8e7eecf0de4247a41807e0ae",
            "title": "Evaluating the Robustness of Conversational Recommender Systems by Adversarial Examples",
            "abstract": "Conversational recommender systems (CRSs) are improving rapidly, according to the standard recommendation accuracy metrics. However, it is essential to make sure that these systems are robust in interacting with users including regular and malicious users who want to attack the system by feeding the system modified input data. In this paper, we propose an adversarial evaluation scheme including four scenarios in two categories and automatically generate adversarial examples to evaluate the robustness of these systems in the face of different input data. By executing these adversarial examples we can compare the ability of different conversational recommender systems to satisfy the user's preferences. We evaluate three CRSs by the proposed adversarial examples on two datasets. Our results show that none of these systems are robust and reliable to the adversarial examples.",
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "authors": [
                {
                    "authorId": "3375353",
                    "name": "Ali Montazeralghaem"
                },
                {
                    "authorId": "121300608",
                    "name": "J. Allan"
                }
            ]
        },
        {
            "paperId": "4a1f2360bde7b7ae27359aa019ebbefc36dcfb61",
            "title": "Rank-LIME: Local Model-Agnostic Feature Attribution for Learning to Rank",
            "abstract": "Understanding why a model makes certain predictions is crucial when adapting it for real world decision making. LIME is a popular model-agnostic feature attribution method for the tasks of classification and regression. However, the task of learning to rank in information retrieval is more complex in comparison with either classification or regression. In this work, we extend LIME to propose Rank-LIME, a model-agnostic, local, post-hoc linear feature attribution method for the task of learning to rank that generates explanations for ranked lists. We employ novel correlation-based perturbations, differentiable ranking loss functions and introduce new metrics to evaluate ranking based additive feature attribution models. We compare Rank-LIME with a variety of competing systems, with models trained on the MS MARCO datasets and observe that Rank-LIME outperforms existing explanation algorithms in terms of Model Fidelity and Explain-NDCG. With this we propose one of the first algorithms to generate additive feature attributions for explaining ranked lists.",
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "authors": [
                {
                    "authorId": "40976115",
                    "name": "Tanya Chowdhury"
                },
                {
                    "authorId": "38543401",
                    "name": "Razieh Rahimi"
                },
                {
                    "authorId": "121300608",
                    "name": "J. Allan"
                }
            ]
        },
        {
            "paperId": "7019c562e586210d550b4afb333f89e380b16f1b",
            "title": "Learning Relevant Questions for Conversational Product Search using Deep Reinforcement Learning",
            "abstract": "We propose RelQuest, a conversational product search model based on reinforcement learning to generate questions from product descriptions in each round of the conversation, directly maximizing any desired metrics (i.e., the ultimate goal of the conversation), objectives, or even an arbitrary user satisfaction signal. By enabling systems to ask questions about user needs, conversational product search has gained increasing attention in recent years. Asking the right questions through conversations helps the system collect valuable feedback to create better user experiences and ultimately increase sales. In contrast, existing conversational product search methods are based on an assumption that there is a set of effectively pre-defined candidate questions for each product to be asked. Moreover, they make strong assumptions to estimate the value of questions in each round of the conversation. Estimating the true value of questions in each round of the conversation is not trivial since it is unknown. Experiments on real-world user purchasing data show the effectiveness of RelQuest at generating questions that maximize standard evaluation measures such as NDCG.",
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "authors": [
                {
                    "authorId": "3375353",
                    "name": "Ali Montazeralghaem"
                },
                {
                    "authorId": "121300608",
                    "name": "J. Allan"
                }
            ]
        },
        {
            "paperId": "b181ef29dcab65bfbae7d36fe1a0a5006c890a28",
            "title": "Equi-explanation Maps: Concise and Informative Global Summary Explanations",
            "abstract": "We attempt to summarize the model logic of a black-box classification model in order to generate concise and informative global explanations. We propose equi-explanation maps, a new explanation data-structure that presents the region of interest as a union of equi-explanation subspaces along with their explanation vectors. We then propose E-Map, a method to generate equi-explanation maps. We demonstrate the broad utility of our approach by generating equi-explanation maps for various binary classification models (Logistic Regression, SVM, MLP, and XGBoost) on the UCI Heart disease dataset and the Pima Indians diabetes dataset. Each subspace in our generated map is the union of d-dimensional hyper-cuboids which can be compactly represented for the sake of interpretability. For each of these subspaces, we present linear explanations assigning a weight to each explanation feature. We justify the use of equi-explanation maps in comparison to other global explanation methods by evaluating in terms of interpretability, fidelity, and informativeness. A user study further corroborates the use of equi-explanation maps to generate compact and informative global explanations.",
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "authors": [
                {
                    "authorId": "40976115",
                    "name": "Tanya Chowdhury"
                },
                {
                    "authorId": "38543401",
                    "name": "Razieh Rahimi"
                },
                {
                    "authorId": "121300608",
                    "name": "J. Allan"
                }
            ]
        },
        {
            "paperId": "bae8ea243542daafbdd49831326b0844f464fd2b",
            "title": "Towards Explainable Search Results: A Listwise Explanation Generator",
            "abstract": "It has been shown that the interpretability of search results is enhanced when query aspects covered by documents are explicitly provided. However, existing work on aspect-oriented explanation of search results explains each document independently. These explanations thus cannot describe the differences between documents. This issue is also true for existing models on query aspect generation. Furthermore, these models provide a single query aspect for each document, even though documents often cover multiple query aspects. To overcome these limitations, we propose LiEGe, an approach that jointly explains all documents in a search result list. LiEGe provides semantic representations at two levels of granularity -- documents and their tokens -- using different interaction signals including cross-document interactions. These allow listwise modeling of a search result list as well as the generation of coherent explanations for documents. To appropriately explain documents that cover multiple query aspects, we introduce two settings for search result explanation: comprehensive and novelty explanation generation. LiEGe is trained and evaluated for both settings. We evaluate LiEGe on datasets built from Wikipedia and real query logs of the Bing search engine. Our experimental results demonstrate that LiEGe outperforms all baselines, with improvements that are substantial and statistically significant.",
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "authors": [
                {
                    "authorId": "51029950",
                    "name": "Puxuan Yu"
                },
                {
                    "authorId": "38543401",
                    "name": "Razieh Rahimi"
                },
                {
                    "authorId": "121300608",
                    "name": "J. Allan"
                }
            ]
        },
        {
            "paperId": "d7ec3c66ea0a696168c12460e1421343a66a4473",
            "title": "Alignment Rationale for Query-Document Relevance",
            "abstract": "Deep neural networks are widely used for text pair classification tasks such as as adhoc information retrieval. These deep neural networks are not inherently interpretable and require additional efforts to get rationale behind their decisions. Existing explanation models are not yet capable of inducing alignments between the query terms and the document terms -- which part of the document rationales are responsible for which part of the query? In this paper, we study how the input perturbations can be used to infer or evaluate alignments between the query and document spans, which best explain the black-box ranker's relevance prediction. We use different perturbation strategies and accordingly propose a set of metrics to evaluate the faithfulness of alignment rationales to the model. Our experiments show that the defined metrics based on substitution-based perturbation are more successful in preferring higher-quality alignments, compared to the deletion-based metrics.",
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "authors": [
                {
                    "authorId": "119864658",
                    "name": "Youngwoo Kim"
                },
                {
                    "authorId": "38543401",
                    "name": "Razieh Rahimi"
                },
                {
                    "authorId": "121300608",
                    "name": "J. Allan"
                }
            ]
        },
        {
            "paperId": "1e883502e757b818b2820593882fe4e053547da2",
            "title": "Mixed Attention Transformer for Leveraging Word-Level Knowledge to Neural Cross-Lingual Information Retrieval",
            "abstract": "Pre-trained contextualized representations offer great success for many downstream tasks, including document ranking. The multilingual versions of such pre-trained representations provide a possibility of jointly learning many languages with the same model. Although it is expected to gain big with such joint training, in the case of cross-lingual information retrieval (CLIR), the models under a multilingual setting are not achieving the same level of performance as those under a monolingual setting. We hypothesize that the performance drop is due to thetranslation gap between query and documents. In the monolingual retrieval task, because of the same lexical inputs, it is easier for model to identify the query terms that occurred in documents. However, in the multilingual pre-trained models that the words in different languages are projected into the same hyperspace, the model tends to \"translate\" query terms into related terms - i.e., terms that appear in a similar context - in addition to or sometimes rather than synonyms in the target language. This property is creating difficulties for the model to connect terms that co-occur in both query and document. To address this issue, we propose a novel Mixed Attention Transformer (MAT) that incorporates external word-level knowledge, such as a dictionary or translation table. We design a sandwich-like architecture to embed MAT into the recent transformer-based deep neural models. By encoding the translation knowledge into an attention matrix, the model with MAT is able to focus on the mutually translated words in the input sequence. Experimental results demonstrate the effectiveness of the external knowledge and the significant improvement of MAT-embedded neural reranking model on CLIR task.",
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "authors": [
                {
                    "authorId": "2122143",
                    "name": "Zhiqi Huang"
                },
                {
                    "authorId": "2131141811",
                    "name": "Hamed Bonab"
                },
                {
                    "authorId": "2721029",
                    "name": "Sheikh Muhammad Sarwar"
                },
                {
                    "authorId": "38543401",
                    "name": "Razieh Rahimi"
                },
                {
                    "authorId": "121300608",
                    "name": "J. Allan"
                }
            ]
        }
    ]
}