{
    "authorId": "2112721678",
    "papers": [
        {
            "paperId": "0f84514e42c080efbc94f4aa2b2261e81d08ca24",
            "title": "Curricular Object Manipulation in LiDAR-based Object Detection",
            "abstract": "This paper explores the potential of curriculum learning in LiDAR-based 3D object detection by proposing a curricular object manipulation (COM) framework. The framework embeds the curricular training strategy into both the loss design and the augmentation process. For the loss design, we propose the COMLoss to dynamically predict object-level difficulties and emphasize objects of different difficulties based on training stages. On top of the widely-used augmentation technique called GT-Aug in Li-DAR detection tasks, we propose a novel COMAug strategy which first clusters objects in ground-truth database based on well-designed heuristics. Group-level difficulties rather than individual ones are then predicted and updated during training for stable results. Model performance and generalization capabilities can be improved by sampling and augmenting progressively more difficult objects into the training samples. Extensive experiments and ablation studies reveal the superior and generality of the proposed framework. The code is available at https://github.com/ZZY816/COM.",
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "authors": [
                {
                    "authorId": "2121394809",
                    "name": "Ziyue Zhu"
                },
                {
                    "authorId": "2112721678",
                    "name": "Q. Meng"
                },
                {
                    "authorId": "144129720",
                    "name": "Xiao Wang"
                },
                {
                    "authorId": "2133842786",
                    "name": "Ke Wang"
                },
                {
                    "authorId": "2218779354",
                    "name": "Liujiang Yan"
                },
                {
                    "authorId": "2119197417",
                    "name": "Jian Yang"
                }
            ]
        },
        {
            "paperId": "4b8f3e30d9485896dd58c4c926168ceae0d8ec0f",
            "title": "A Catheterization-Training Simulator Based on a Fast Multigrid Solver",
            "abstract": "A VR-based simulator helps trainees develop skills for catheterization, a fundamental but difficult procedure in vascular interventional radiology. A deformable model simulates the complicated behavior of guide wires and catheters, using the principle of minimum total potential energy. A fast, stable multigrid solver ensures realistic simulation and real-time interaction. In addition, the system employs geometrically and topologically accurate vascular models based on improved parallel-transport frames, and it implements efficient collision detection. Experiments evaluated the method's stability, the solver's execution time, how well the simulation preserved the catheter's curved tip, and the catheter deformation's realism. An empirical study based on a typical selective-catheterization procedure assessed the system's feasibility and effectiveness.",
            "fieldsOfStudy": [
                "Computer Science",
                "Medicine"
            ],
            "authors": [
                {
                    "authorId": "2116621928",
                    "name": "Shun Li"
                },
                {
                    "authorId": "2274805701",
                    "name": "Jixiang Guo"
                },
                {
                    "authorId": "1743616670",
                    "name": "Qiong Wang"
                },
                {
                    "authorId": "2112721678",
                    "name": "Q. Meng"
                },
                {
                    "authorId": "145748447",
                    "name": "Yim-Pan Chui"
                },
                {
                    "authorId": "145947074",
                    "name": "J. Qin"
                },
                {
                    "authorId": "1714602",
                    "name": "P. Heng"
                }
            ]
        },
        {
            "paperId": "327d0b03fe1b8e5246ad2141fe362494bdd6c5ea",
            "title": "CvhSlicer: An Interactive Cross-Sectional Anatomy Navigation System Based on High-Resolution Chinese Visible Human Data",
            "abstract": "We introduce the design and implementation of an interactive system for the navigation of cross-sectional anatomy based on Chinese Visible Human (CVH) data, named CvhSlicer. This system is featured in real-time computation and rendering of high-resolution anatomical images on standard personal computers (PCs) equipped with commodity Graphics Processing Units (GPUs). In order to load the whole-body dataset into the memory of a common PC, several processing steps are first applied to compress the huge CVH data. Thereafter, an adaptive CPU-GPU balancing scheme is performed to dynamically distribute rendering tasks among CPU and GPU based on parameters of computing resources. Experimental results demonstrate that our system can achieve real-time performance and has great potential to be used in anatomy education.",
            "fieldsOfStudy": [
                "Computer Science",
                "Medicine"
            ],
            "authors": [
                {
                    "authorId": "2112721678",
                    "name": "Q. Meng"
                },
                {
                    "authorId": "145748447",
                    "name": "Yim-Pan Chui"
                },
                {
                    "authorId": "145947074",
                    "name": "J. Qin"
                },
                {
                    "authorId": "145168752",
                    "name": "W. H. Kwok"
                },
                {
                    "authorId": "2289670",
                    "name": "M. Karmakar"
                },
                {
                    "authorId": "1714602",
                    "name": "P. Heng"
                }
            ]
        },
        {
            "paperId": "8a8f9aa44aa67cba0b61a8e38ecb59997931da76",
            "title": "WYSIWYF: exploring and annotating volume data with a tangible handheld device",
            "abstract": "Visual exploration of volume data often requires the user to manipulate the orientation and position of a slicing plane in order to observe, annotate or measure its internal structures. Such operations, with its many degrees of freedom in 3D space, map poorly into interaction modalities afforded by mouse-keyboard interfaces or flat multi-touch displays alone. We addressed this problem using a what-you-see-is-what-you-feel (WYSIWYF) approach, which integrates the natural user interface of a multi-touch wall display with the untethered physical dexterity provided by a handheld device with multi-touch and 3D-tilt sensing capabilities. A slicing plane can be directly and intuitively manipulated at any desired position within the displayed volume data using a commonly available mobile device such as the iPod touch. 2D image slices can be transferred wirelessly to this small touch screen device, where a novel fast fat finger annotation technique (F3AT) is proposed to perform accurate and speedy contour drawings. Our user studies support the efficacy of our proposed visual exploration and annotation interaction designs.",
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "authors": [
                {
                    "authorId": "2057359095",
                    "name": "Peng Song"
                },
                {
                    "authorId": "144905858",
                    "name": "Wooi-Boon Goh"
                },
                {
                    "authorId": "144856288",
                    "name": "Chi-Wing Fu"
                },
                {
                    "authorId": "2112721678",
                    "name": "Q. Meng"
                },
                {
                    "authorId": "1714602",
                    "name": "P. Heng"
                }
            ]
        }
    ]
}