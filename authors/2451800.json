{
    "authorId": "2451800",
    "papers": [
        {
            "paperId": "1725ad1d8cc0e539ac5d0a85657d5c95b4538c5e",
            "title": "Self-Supervised Learning for Time Series Analysis: Taxonomy, Progress, and Prospects",
            "abstract": "Self-supervised learning (SSL) has recently achieved impressive performance on various time series tasks. The most prominent advantage of SSL is that it reduces the dependence on labeled data. Based on the pre-training and fine-tuning strategy, even a small amount of labeled data can achieve high performance. Compared with many published self-supervised surveys on computer vision and natural language processing, a comprehensive survey for time series SSL is still missing. To fill this gap, we review current state-of-the-art SSL methods for time series data in this article. To this end, we first comprehensively review existing surveys related to SSL and time series, and then provide a new taxonomy of existing time series SSL methods by summarizing them from three perspectives: generative-based, contrastive-based, and adversarial-based. These methods are further divided into ten subcategories with detailed reviews and discussions about their key intuitions, main frameworks, advantages and disadvantages. To facilitate the experiments and validation of time series SSL methods, we also summarize datasets commonly used in time series forecasting, classification, anomaly detection, and clustering tasks. Finally, we present the future directions of SSL for time series analysis.",
            "fieldsOfStudy": [
                "Computer Science",
                "Medicine",
                "Engineering",
                "Mathematics"
            ],
            "authors": [
                {
                    "authorId": "2119059780",
                    "name": "Kexin Zhang"
                },
                {
                    "authorId": "3308963",
                    "name": "Qingsong Wen"
                },
                {
                    "authorId": "2152737103",
                    "name": "Chaoli Zhang"
                },
                {
                    "authorId": "2136700261",
                    "name": "Rongyao Cai"
                },
                {
                    "authorId": "2072905592",
                    "name": "Ming Jin"
                },
                {
                    "authorId": "2144384782",
                    "name": "Yong Liu"
                },
                {
                    "authorId": "2108020140",
                    "name": "James Zhang"
                },
                {
                    "authorId": "72322304",
                    "name": "Y. Liang"
                },
                {
                    "authorId": "3224619",
                    "name": "Guansong Pang"
                },
                {
                    "authorId": "2451800",
                    "name": "Dongjin Song"
                },
                {
                    "authorId": "2585415",
                    "name": "Shirui Pan"
                }
            ]
        },
        {
            "paperId": "39cb0e25acce48e6833941718b982cf5ed68887a",
            "title": "HiT-MDP: Learning the SMDP option framework on MDPs with Hidden Temporal Embeddings",
            "abstract": "The standard option framework is developed on the Semi-Markov Decision Process (SMDP) which is unstable to optimize and sample inefficient. To this end, we propose the Hidden Temporal MDP (HiT-MDP) and prove that the option-induced HiT-MDP is homomorphic equivalent to the option-induced SMDP. A novel transformer-based framework is introduced to learn options\u2019 embedding vectors (rather than conventional option tuples) on HiT-MDPs. We then derive a stable and sample efficient option discovering method under the maximum-entropy policy gradient framework. Extensive experiments on challenging Mujoco environments demonstrate HiT-MDP\u2019s efficiency and effectiveness: under widely used configurations, HiT-MDP achieves competitive, if not better, performance compared to the state-of-the-art baselines on all finite horizon and transfer learning environments. Moreover, HiT-MDP significantly outperforms all baselines on infinite horizon environments while exhibiting smaller variance, faster convergence, and better interpretability. Our work potentially sheds light on the theoretical ground of extending the option framework into a large scale foundation model.",
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "authors": [
                {
                    "authorId": "2145421183",
                    "name": "Chang Li"
                },
                {
                    "authorId": "2451800",
                    "name": "Dongjin Song"
                },
                {
                    "authorId": "2135519749",
                    "name": "Dacheng Tao"
                }
            ]
        },
        {
            "paperId": "4bdb8888b106bd45a785d6a3afe6dac222fedb25",
            "title": "The 9th SIGKDD International Workshop on Mining and Learning from Time Series",
            "abstract": "Time series data has become pervasive across domains such as finance, transportation, retail, entertainment, and healthcare. This shift towards continuous monitoring and recording, fueled by advancements in sensing technologies, necessitates the development of new tools and solutions. Despite extensive study, the importance of time series analysis continues to increase. However, modern time series data present challenges to existing techniques, including irregular sampling and spatiotemporal structures. Time series mining research is both challenging and rewarding as it connects diverse disciplines and requires interdisciplinary solutions. The goals of this workshop are to (1) highlight the significant challenges that underpin learning and mining from time series data (e.g., irregular sampling, spatiotemporal structure, uncertainty quantification), (2) discuss recent algorithmic, theoretical, statistical, or systems-based developments for tackling these problems, and (3) to synergize the research activities and discuss both new and open problems in time series analysis and mining. In summary, our workshop will focus on both the theoretical and practical aspects of time series data analysis and will provide a platform for researchers and practitioners from academia and industry to discuss potential research directions and critical technical issues and present solutions to tackle related issues in practical applications. We will invite researchers and practitioners from the related areas of AI, machine learning, data science, statistics, and many others to contribute to this workshop.",
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "authors": [
                {
                    "authorId": "144735626",
                    "name": "S. Purushotham"
                },
                {
                    "authorId": "2451800",
                    "name": "Dongjin Song"
                },
                {
                    "authorId": "3308963",
                    "name": "Qingsong Wen"
                },
                {
                    "authorId": "2181310178",
                    "name": "Jun Huan"
                },
                {
                    "authorId": "2113392954",
                    "name": "Cong Shen"
                },
                {
                    "authorId": "2246897295",
                    "name": "Yuriy Nevmyvaka"
                }
            ]
        },
        {
            "paperId": "57611c1415d5d3b37ed2e244fc4df7ba591014e6",
            "title": "Interpretable Skill Learning for Dynamic Treatment Regimes through Imitation",
            "abstract": "Imitation learning that mimics experts' skills from their demonstrations has shown great success in discovering dynamic treatment regimes, i.e., the optimal decision rules to treat an individual patient based on related evolving treatment and covariate history. Existing imitation learning methods, however, still lack the capability to interpret the underlying rationales of the learned policy in a faithful way. Moreover, since dynamic treatment regimes for patients often exhibit varying patterns, i.e., symptoms that transit from one to another, the flat policy learned by a vanilla imitation learning method is typically undesired. To this end, we propose an Interpretable Skill Learning (ISL) framework to resolve the aforementioned challenges for dynamic treatment regimes through imitation. The key idea is to model each segment of experts' demonstrations with a prototype layer and integrate it with the imitation learning layer to enhance the interpretation capability. On one hand, the ISL framework is able to provide interpretable explanations by matching the prototype to exemplar segments during the inference stage, which enables doctors to perform reasoning of the learned demonstrations based on human-understandable patient symptoms and lab results. On the other hand, the obtained skill embedding consisting of prototypes serves as conditional information to the imitation learning layer, which implicitly guides the policy network to provide a more accurate demonstration when the patients' state switches from one stage to another. Thoroughly empirical studies demonstrate that our proposed ISL technique can achieve better performance than state-of-the-art methods. Moreover, the proposed ISL framework also exhibits good interpretability which cannot be observed in existing methods.",
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "authors": [
                {
                    "authorId": "2214140574",
                    "name": "Yushan Jiang"
                },
                {
                    "authorId": "3007026",
                    "name": "Wenchao Yu"
                },
                {
                    "authorId": "2451800",
                    "name": "Dongjin Song"
                },
                {
                    "authorId": "145859270",
                    "name": "Wei Cheng"
                },
                {
                    "authorId": "2145225543",
                    "name": "Haifeng Chen"
                }
            ]
        },
        {
            "paperId": "6d18dcd4b562ea15f3270551b71596b2a1980b07",
            "title": "Tutorials at The Web Conference 2023",
            "abstract": "This paper summarizes the content of the 28 tutorials that have been given at The Web Conference 2023.",
            "fieldsOfStudy": [
                "Computer Science",
                "Physics"
            ],
            "authors": [
                {
                    "authorId": "1705291",
                    "name": "Valeria Fionda"
                },
                {
                    "authorId": "2215622430",
                    "name": "Olaf Hartig"
                },
                {
                    "authorId": "1805958417",
                    "name": "Reyhaneh Abdolazimi"
                },
                {
                    "authorId": "1403657578",
                    "name": "S. Amer-Yahia"
                },
                {
                    "authorId": "2215690996",
                    "name": "Hongzhi Chen"
                },
                {
                    "authorId": "2117027107",
                    "name": "Xiao Chen"
                },
                {
                    "authorId": "2052469774",
                    "name": "P. Cui"
                },
                {
                    "authorId": "145269114",
                    "name": "Jeffrey Dalton"
                },
                {
                    "authorId": "2215596266",
                    "name": "Xin Luna Dong"
                },
                {
                    "authorId": "2957808",
                    "name": "Lisette Espin Noboa"
                },
                {
                    "authorId": "41031455",
                    "name": "Wenqi Fan"
                },
                {
                    "authorId": "2132398392",
                    "name": "Manuela Fritz"
                },
                {
                    "authorId": "47594426",
                    "name": "Quan Gan"
                },
                {
                    "authorId": "2161309826",
                    "name": "Jingtong Gao"
                },
                {
                    "authorId": "46909769",
                    "name": "Xiaojie Guo"
                },
                {
                    "authorId": "2215622544",
                    "name": "Torsten Hahmann"
                },
                {
                    "authorId": "145325584",
                    "name": "Jiawei Han"
                },
                {
                    "authorId": "2046142",
                    "name": "S. Han"
                },
                {
                    "authorId": "1842532",
                    "name": "Estevam Hruschka"
                },
                {
                    "authorId": "2118850040",
                    "name": "Liang Hu"
                },
                {
                    "authorId": "2139299903",
                    "name": "Jiaxin Huang"
                },
                {
                    "authorId": "47247243",
                    "name": "Utkarshani Jaimini"
                },
                {
                    "authorId": "2299944027",
                    "name": "Olivier Jeunen"
                },
                {
                    "authorId": "2214140574",
                    "name": "Yushan Jiang"
                },
                {
                    "authorId": "51118506",
                    "name": "F. Karimi"
                },
                {
                    "authorId": "50877490",
                    "name": "G. Karypis"
                },
                {
                    "authorId": "1769861",
                    "name": "K. Kenthapadi"
                },
                {
                    "authorId": "1892673",
                    "name": "Himabindu Lakkaraju"
                },
                {
                    "authorId": "3309003",
                    "name": "Hady W. Lauw"
                },
                {
                    "authorId": "145535348",
                    "name": "Thai Le"
                },
                {
                    "authorId": "1808423005",
                    "name": "Trung-Hoang Le"
                },
                {
                    "authorId": "2158951945",
                    "name": "Dongwon Lee"
                },
                {
                    "authorId": "2110855835",
                    "name": "Geon Lee"
                },
                {
                    "authorId": "19326298",
                    "name": "Liat Levontin"
                },
                {
                    "authorId": "2144231489",
                    "name": "Cheng-Te Li"
                },
                {
                    "authorId": "144911687",
                    "name": "Haoyang Li"
                },
                {
                    "authorId": "2110471246",
                    "name": "Ying Li"
                },
                {
                    "authorId": "2030126978",
                    "name": "Jay Chiehen Liao"
                },
                {
                    "authorId": "2157067900",
                    "name": "Qidong Liu"
                },
                {
                    "authorId": "46189109",
                    "name": "Usha Lokala"
                },
                {
                    "authorId": "2085850",
                    "name": "Ben London"
                },
                {
                    "authorId": "32545338",
                    "name": "Siqu Long"
                },
                {
                    "authorId": "153612944",
                    "name": "H. Mcginty"
                },
                {
                    "authorId": "145391513",
                    "name": "Yu Meng"
                },
                {
                    "authorId": "29072828",
                    "name": "Seungwhan Moon"
                },
                {
                    "authorId": "1394609613",
                    "name": "Usman Naseem"
                },
                {
                    "authorId": "49824581",
                    "name": "P. Natarajan"
                },
                {
                    "authorId": "1403851743",
                    "name": "Behrooz Omidvar-Tehrani"
                },
                {
                    "authorId": "2069543964",
                    "name": "Zijie Pan"
                },
                {
                    "authorId": "48331451",
                    "name": "Devesh Parekh"
                },
                {
                    "authorId": "2188744953",
                    "name": "Jian Pei"
                },
                {
                    "authorId": "2101664",
                    "name": "Tiago P. Peixoto"
                },
                {
                    "authorId": "144615425",
                    "name": "S. Pemberton"
                },
                {
                    "authorId": "144179461",
                    "name": "Josiah Poon"
                },
                {
                    "authorId": "2065812052",
                    "name": "Filip Radlinski"
                },
                {
                    "authorId": "48890086",
                    "name": "Federico Rossetto"
                },
                {
                    "authorId": "2091913080",
                    "name": "Kaushik Roy"
                },
                {
                    "authorId": "2911888",
                    "name": "Aghiles Salah"
                },
                {
                    "authorId": "2128305",
                    "name": "M. Sameki"
                },
                {
                    "authorId": "2064342729",
                    "name": "Amit P. Sheth"
                },
                {
                    "authorId": "28908689",
                    "name": "C. Shimizu"
                },
                {
                    "authorId": "40553270",
                    "name": "Kijung Shin"
                },
                {
                    "authorId": "2451800",
                    "name": "Dongjin Song"
                },
                {
                    "authorId": "1682824",
                    "name": "Julia Stoyanovich"
                },
                {
                    "authorId": "2064266862",
                    "name": "Dacheng Tao"
                },
                {
                    "authorId": "2528063",
                    "name": "Johanne R. Trippas"
                },
                {
                    "authorId": "39603708",
                    "name": "Quoc-Tuan Truong"
                },
                {
                    "authorId": "1896151979",
                    "name": "Yu-Che Tsai"
                },
                {
                    "authorId": "150035131",
                    "name": "Adaku Uchendu"
                },
                {
                    "authorId": "2215624802",
                    "name": "Bram Van Den Akker"
                },
                {
                    "authorId": "3265905",
                    "name": "Linshan Wang"
                },
                {
                    "authorId": "2144295736",
                    "name": "Minjie Wang"
                },
                {
                    "authorId": "2116951322",
                    "name": "Shoujin Wang"
                },
                {
                    "authorId": "2153691630",
                    "name": "Xin Wang"
                },
                {
                    "authorId": "1684687",
                    "name": "Ingmar Weber"
                },
                {
                    "authorId": "69047048",
                    "name": "H. Weld"
                },
                {
                    "authorId": "2116666963",
                    "name": "Lingfei Wu"
                },
                {
                    "authorId": "2181385841",
                    "name": "D. Xu"
                },
                {
                    "authorId": "2138609128",
                    "name": "E. Xu"
                },
                {
                    "authorId": "2111044480",
                    "name": "Shuyuan Xu"
                },
                {
                    "authorId": "2156653838",
                    "name": "Bo Yang"
                },
                {
                    "authorId": "2125559318",
                    "name": "Keyue Yang"
                },
                {
                    "authorId": "1388775854",
                    "name": "E. Yom-Tov"
                },
                {
                    "authorId": "31888223",
                    "name": "Jaemin Yoo"
                },
                {
                    "authorId": "144007938",
                    "name": "Zhou Yu"
                },
                {
                    "authorId": "2281410",
                    "name": "R. Zafarani"
                },
                {
                    "authorId": "2499986",
                    "name": "Hamed Zamani"
                },
                {
                    "authorId": "41154657",
                    "name": "Meike Zehlike"
                },
                {
                    "authorId": "2145906426",
                    "name": "Qi Zhang"
                },
                {
                    "authorId": "3358065",
                    "name": "Xikun Zhang"
                },
                {
                    "authorId": "1739818",
                    "name": "Yongfeng Zhang"
                },
                {
                    "authorId": "49891156",
                    "name": "Yu Zhang"
                },
                {
                    "authorId": "2148904413",
                    "name": "Zhengqi Zhang"
                },
                {
                    "authorId": "144010790",
                    "name": "Liang Zhao"
                },
                {
                    "authorId": "2116710405",
                    "name": "Xiangyu Zhao"
                },
                {
                    "authorId": "2156154955",
                    "name": "Wenwu Zhu"
                }
            ]
        },
        {
            "paperId": "9e761f4ac57239d68958c817858f5b6627c01e54",
            "title": "FedSkill: Privacy Preserved Interpretable Skill Learning via Imitation",
            "abstract": "Imitation learning that replicates experts' skills via their demonstrations has shown significant success in various decision-making tasks. However, two critical challenges still hinder the deployment of imitation learning techniques in real-world application scenarios. First, existing methods lack the intrinsic interpretability to explicitly explain the underlying rationale of the learned skill and thus making learned policy untrustworthy. Second, due to the scarcity of expert demonstrations from each end user (client), learning a policy based on different data silos is necessary but challenging in privacy-sensitive applications such as finance and healthcare. To this end, we present a privacy-preserved interpretable skill learning framework (FedSkill) that enables global policy learning to incorporate data from different sources and provides explainable interpretations to each local user without violating privacy and data sovereignty. Specifically, our proposed interpretable skill learning model can capture the varying patterns in the trajectories of expert demonstrations, and extract prototypical information as skills that provide implicit guidance for policy learning and explicit explanations in the reasoning process. Moreover, we design a novel aggregation mechanism coupled with the based skill learning model to preserve global information utilization and maintain local interpretability under the federated framework. Thoroughly experiments on three datasets and empirical studies demonstrate that our proposed FedSkill framework not only outperforms state-of-the-art imitation learning methods but also exhibits good interpretability under a federated setting. Our proposed FedSkill framework is the first attempt to bridge the gaps among federated learning, interpretable machine learning, and imitation learning.",
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "authors": [
                {
                    "authorId": "2214140574",
                    "name": "Yushan Jiang"
                },
                {
                    "authorId": "3007026",
                    "name": "Wenchao Yu"
                },
                {
                    "authorId": "2451800",
                    "name": "Dongjin Song"
                },
                {
                    "authorId": "2153516978",
                    "name": "Lu Wang"
                },
                {
                    "authorId": "145859270",
                    "name": "Wei Cheng"
                },
                {
                    "authorId": "2145225646",
                    "name": "Haifeng Chen"
                }
            ]
        },
        {
            "paperId": "e4b0579d9d52a947033d85ea54e034cb7355a129",
            "title": "Privacy-Preserving and Uncertainty-Aware Federated Trajectory Prediction for Connected Autonomous Vehicles",
            "abstract": "Deep learning is the method of choice for trajectory prediction for autonomous vehicles. Unfortunately, its data-hungry nature implicitly requires the availability of sufficiently rich and high-quality centralized datasets, which easily leads to privacy leakage. Besides, uncertainty-awareness becomes increasingly important for safety-crucial cyber physical systems whose prediction module heavily relies on machine learning tools. In this paper, we relax the data collection requirement and enhance uncertainty-awareness by using Federated Learning on Connected Autonomous Vehicles with an uncertainty-aware global objective. We name our algorithm as FLTP. We further introduce ALFLTP which boosts FLTP via using active learning techniques in adaptatively selecting participating clients. We consider two different metrics negative log-likelihood (NLL) and aleatoric uncertainty (AU) for client selection. Experiments on Argoverse dataset show that FLTP significantly outperforms the model trained on local data. In addition, ALFLTP-AU converges faster in training regression loss and performs better in terms of Miss Rate (MR) than FLTP in most rounds, and has more stable round-wise performance than ALFLTP-NLL.",
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "authors": [
                {
                    "authorId": "2210984484",
                    "name": "Muzi Peng"
                },
                {
                    "authorId": "2184291210",
                    "name": "Jiangwei Wang"
                },
                {
                    "authorId": "2451800",
                    "name": "Dongjin Song"
                },
                {
                    "authorId": "2064423453",
                    "name": "Fei Miao"
                },
                {
                    "authorId": "2255869",
                    "name": "Lili Su"
                }
            ]
        },
        {
            "paperId": "f81ea4626d83adcdaa9c1a9955d0be962457e0f4",
            "title": "Federated Distributionally Robust Optimization with Non-Convex Objectives: Algorithm and Analysis",
            "abstract": "Distributionally Robust Optimization (DRO), which aims to find an optimal decision that minimizes the worst case cost over the ambiguity set of probability distribution, has been widely applied in diverse applications, e.g., network behavior analysis, risk management, etc. However, existing DRO techniques face three key challenges: 1) how to deal with the asynchronous updating in a distributed environment; 2) how to leverage the prior distribution effectively; 3) how to properly adjust the degree of robustness according to different scenarios. To this end, we propose an asynchronous distributed algorithm, named Asynchronous Single-looP alternatIve gRadient projEction (ASPIRE) algorithm with the itErative Active SEt method (EASE) to tackle the federated distributionally robust optimization (FDRO) problem. Furthermore, a new uncertainty set, i.e., constrained D-norm uncertainty set, is developed to effectively leverage the prior distribution and flexibly control the degree of robustness. Finally, our theoretical analysis elucidates that the proposed algorithm is guaranteed to converge and the iteration complexity is also analyzed. Extensive empirical studies on real-world datasets demonstrate that the proposed method can not only achieve fast convergence, and remain robust against data heterogeneity as well as malicious attacks, but also tradeoff robustness with performance.",
            "fieldsOfStudy": [
                "Mathematics",
                "Computer Science"
            ],
            "authors": [
                {
                    "authorId": "2055181125",
                    "name": "Yang Jiao"
                },
                {
                    "authorId": "2163436495",
                    "name": "Kai Yang"
                },
                {
                    "authorId": "2451800",
                    "name": "Dongjin Song"
                }
            ]
        },
        {
            "paperId": "065f9775101218665b4baaa2833c91480ec25ccd",
            "title": "TimeAutoAD: Autonomous Anomaly Detection With Self-Supervised Contrastive Loss for Multivariate Time Series",
            "abstract": "Multivariate time series (MTS) data are becoming increasingly ubiquitous in networked systems, e.g., IoT systems and 5G networks. Anomaly detection in MTS refers to identifying time series which exhibit different behaviors from normal status. Building such a system, however, is challenging due to a few reasons: i) labels for anomaly cases are usually unavailable or very rare; ii) most existing approaches rely on manual model-design and hyperparameter tuning, which may cost a huge amount of labor effort. To this end, we propose an autonomous anomaly detection technique for multivariate time series data (TimeAutoAD) based on a novel self-supervised contrastive loss. Specifically, we first present an automatic anomaly detection pipeline to optimize the model configuration and hyperparameters automatically. Next, we introduce three different strategies to augment the training data for generating pseudo negative time series and employ a self-supervised contrastive loss to distinguish the original time series and the generated time series. In this way, the representation learning capability of TimeAutoAD can be greatly enhanced and the anomaly detection performance can thus be improved. Extensive empirical studies on real-world datasets demonstrate that the proposed TimeAutoAD not only outperforms state-of-the-art anomaly detection approaches but also exhibits robustness when training data are contaminated.",
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "authors": [
                {
                    "authorId": "2055181125",
                    "name": "Yang Jiao"
                },
                {
                    "authorId": "2118049422",
                    "name": "Kai Yang"
                },
                {
                    "authorId": "2451800",
                    "name": "Dongjin Song"
                },
                {
                    "authorId": "2082545536",
                    "name": "Dacheng Tao"
                }
            ]
        },
        {
            "paperId": "2c5f6080a69efe76cf56d225808324fb5b692c1b",
            "title": "Asynchronous Distributed Bilevel Optimization",
            "abstract": "Bilevel optimization plays an essential role in many machine learning tasks, ranging from hyperparameter optimization to meta-learning. Existing studies on bilevel optimization, however, focus on either centralized or synchronous distributed setting. The centralized bilevel optimization approaches require collecting massive amount of data to a single server, which inevitably incur significant communication expenses and may give rise to data privacy risks. Synchronous distributed bilevel optimization algorithms, on the other hand, often face the straggler problem and will immediately stop working if a few workers fail to respond. As a remedy, we propose Asynchronous Distributed Bilevel Optimization (ADBO) algorithm. The proposed ADBO can tackle bilevel optimization problems with both nonconvex upper-level and lower-level objective functions, and its convergence is theoretically guaranteed. Furthermore, it is revealed through theoretic analysis that the iteration complexity of ADBO to obtain the $\\epsilon$-stationary point is upper bounded by $\\mathcal{O}(\\frac{1}{{{\\epsilon ^2}}})$. Thorough empirical studies on public datasets have been conducted to elucidate the effectiveness and efficiency of the proposed ADBO.",
            "fieldsOfStudy": [
                "Computer Science",
                "Mathematics"
            ],
            "authors": [
                {
                    "authorId": "2055181125",
                    "name": "Yang Jiao"
                },
                {
                    "authorId": "2163436495",
                    "name": "Kai Yang"
                },
                {
                    "authorId": "2116518438",
                    "name": "Tiancheng Wu"
                },
                {
                    "authorId": "2451800",
                    "name": "Dongjin Song"
                },
                {
                    "authorId": "2142035704",
                    "name": "Chen Jian"
                }
            ]
        }
    ]
}