{
    "authorId": "2066327465",
    "papers": [
        {
            "paperId": "5fa3b8a364d4845ffed5f4cfcdc5b61dd6282ec7",
            "title": "CardiO: Predicting Cardinality from Online Sources",
            "abstract": "Count questions are an important type of information need, though often present in noisy, contradictory, or semantically not fully aligned form on the Web. In this work, we propose CardiO, a lightweight and modular framework for searching entity counts on the Web. CardiO extracts all counts from a set of relevant Web snippets, and infers the most central count based on semantic and numeric distances from other candidates. In the absence of supporting evidence, the system relies on peer sets of similar size, to provide an estimate. Experiments show that CardiO can produce accurate and traceable counts better than small LLM-only methods. Although larger models have higher precision, when used to enhance CardiO components, they do not contribute to the final precision or recall.",
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "authors": [
                {
                    "authorId": "2135976772",
                    "name": "Shrestha Ghosh"
                },
                {
                    "authorId": "2066327465",
                    "name": "S. Razniewski"
                },
                {
                    "authorId": "2301210406",
                    "name": "Damien Graux"
                },
                {
                    "authorId": "1751591",
                    "name": "G. Weikum"
                }
            ]
        },
        {
            "paperId": "81e1ec6b6155523655772826dd39f32a44d59cbd",
            "title": "Cultural Commonsense Knowledge for Intercultural Dialogues",
            "abstract": "Despite recent progress, large language models (LLMs) still face the challenge of appropriately reacting to the intricacies of social and cultural conventions. This paper presents MANGO, a methodology for distilling high-accuracy, high-recall assertions of cultural knowledge. We judiciously and iteratively prompt LLMs for this purpose from two entry points, concepts and cultures. Outputs are consolidated via clustering and generative summarization. Running the MANGO method with GPT-3.5 as underlying LLM yields 167K high-accuracy assertions for 30K concepts and 11K cultures, surpassing prior resources by a large margin in quality and size. In an extrinsic evaluation for intercultural dialogues, we explore augmenting dialogue systems with cultural knowledge assertions. Notably, despite LLMs inherently possessing cultural knowledge, we find that adding knowledge from MANGO improves the overall quality, specificity, and cultural sensitivity of dialogue responses, as judged by human annotators. Data and code are available for download.",
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "authors": [
                {
                    "authorId": "8615485",
                    "name": "Tuan-Phong Nguyen"
                },
                {
                    "authorId": "2066327465",
                    "name": "S. Razniewski"
                },
                {
                    "authorId": "1751591",
                    "name": "G. Weikum"
                }
            ]
        },
        {
            "paperId": "9b4b67f9c26ed5aa316f439dab7b3709ba06fad6",
            "title": "Recall Them All: Retrieval-Augmented Language Models for Long Object List Extraction from Long Documents",
            "abstract": "Methods for relation extraction from text mostly focus on high precision, at the cost of limited recall. High recall is crucial, though, to populate long lists of object entities that stand in a specific relation with a given subject. Cues for relevant objects can be spread across many passages in long texts. This poses the challenge of extracting long lists from long texts. We present the L3X method which tackles the problem in two stages: (1) recall-oriented generation using a large language model (LLM) with judicious techniques for retrieval augmentation, and (2) precision-oriented scrutinization to validate or prune candidates. Our L3X method outperforms LLM-only generations by a substantial margin.",
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "authors": [
                {
                    "authorId": "29001552",
                    "name": "Sneha Singhania"
                },
                {
                    "authorId": "2066327465",
                    "name": "S. Razniewski"
                },
                {
                    "authorId": "1751591",
                    "name": "G. Weikum"
                }
            ]
        },
        {
            "paperId": "ee0fe15afaedbe6752379fe15fb0d715369386cd",
            "title": "FASETS: Discovering Faceted Sets of Entities",
            "abstract": "Computing related entities for a given seed entity is an important task in exploratory search and comparative data analysis.Prior works, using the seed-based set expansion paradigm, have focused on the single aspect of identifying homogeneous sets with high pairwise relatedness. A few recent works discuss cluster-based approaches to tackle multi-faceted set expansion, however, they fail in harnessing the specificity of the clusters and generating an explanation for them. This paper poses the multi-faceted set expansion as an optimization problem, where the goal is to compute multiple groups of entities that convey different aspects in an explainable manner, with high similarity within each group and diversity across groups. To extend a seed entity, we collect a large pool of candidate entities and facets (e.g., categories)from Wikipedia and knowledge bases, and construct a candidate graph. We propose FASETS, an efficient algorithm for computing faceted groups of bounded size, based on random walks over the candidate graph. Our extensive evaluation shows the superiority of FASETS against prior baselines, with regard to ground-truth collected from crowdsourcing.",
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "authors": [
                {
                    "authorId": "2514979",
                    "name": "K. Pal"
                },
                {
                    "authorId": "40434178",
                    "name": "Hiba Arnaout"
                },
                {
                    "authorId": "2066327465",
                    "name": "S. Razniewski"
                },
                {
                    "authorId": "1751591",
                    "name": "G. Weikum"
                }
            ]
        },
        {
            "paperId": "1c86c5793c150a62d5f6581af2f79454f26faa20",
            "title": "UnCommonSense in Action! Informative Negations for Commonsense Knowledge Bases",
            "abstract": "Knowledge bases about commonsense knowledge i.e., CSKBs, are crucial in applications such as search and question answering. Prominent CSKBs mostly focus on positive statements. In this paper we show that materializing important negations increases the usability of CSKBs. We present Uncommonsense, a web portal to explore informative negations about everyday concepts: (i) in a research-focused interface, users get a glimpse into results-per-steps of the methodology; (ii) in a trivia interface, users can browse fun negative trivia about concepts of their choice; and (iii) in a query interface, users can submit triple-pattern queries with explicit negated relations and compare results with significantly less relevant answers from the positive-only baseline. It can be accessed at:https://uncommonsense.mpi-inf.mpg.de/.",
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "authors": [
                {
                    "authorId": "40434178",
                    "name": "Hiba Arnaout"
                },
                {
                    "authorId": "8615485",
                    "name": "Tuan-Phong Nguyen"
                },
                {
                    "authorId": "2066327465",
                    "name": "S. Razniewski"
                },
                {
                    "authorId": "1751591",
                    "name": "G. Weikum"
                }
            ]
        },
        {
            "paperId": "219e69f683f56cf2534a283c8d5647d0cb47045e",
            "title": "BoschAI @ PLABA 2023: Leveraging Edit Operations in End-to-End Neural Sentence Simplification",
            "abstract": "Automatic simplification can help laypeople to comprehend complex scientific text. Language models are frequently applied to this task by translating from complex to simple language. In this paper, we describe our system based on Llama 2, which ranked first in the PLABA shared task addressing the simplification of biomedical text. We find that the large portion of shared tokens between input and output leads to weak training signals and conservatively editing models. To mitigate these issues, we propose sentence-level and token-level loss weights. They give higher weight to modified tokens, indicated by edit distance and edit operations, respectively. We conduct an empirical evaluation on the PLABA dataset and find that both approaches lead to simplifications closer to those created by human annotators (+1.8% / +3.5% SARI), simpler language (-1 / -1.1 FKGL) and more edits (1.6x / 1.8x edit distance) compared to the same model fine-tuned with standard cross entropy. We furthermore show that the hyperparameter $\\lambda$ in token-level loss weights can be used to control the edit distance and the simplicity level (FKGL).",
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "authors": [
                {
                    "authorId": "2265381943",
                    "name": "Valentin Knappich"
                },
                {
                    "authorId": "2066327465",
                    "name": "S. Razniewski"
                },
                {
                    "authorId": "2265381978",
                    "name": "Annemarie Friedrich"
                }
            ]
        },
        {
            "paperId": "4b99e8273227fd05f2be20248050d81e97ab4f4e",
            "title": "Extracting Multi-valued Relations from Language Models",
            "abstract": "The widespread usage of latent language representations via pre-trained language models (LMs) suggests that they are a promising source of structured knowledge. However, existing methods focus only on a single object per subject-relation pair, even though often multiple objects are correct. To overcome this limitation, we analyze these representations for their potential to yield materialized multi-object relational knowledge. We formulate the problem as a rank-then-select task. For ranking candidate objects, we evaluate existing prompting techniques and propose new ones incorporating domain knowledge. Among the selection methods, we find that choosing objects with a likelihood above a learned relation-specific threshold gives a 49.5% F1 score. Our results highlight the difficulty of employing LMs for the multi-valued slot-filling task, and pave the way for further research on extracting relational knowledge from latent language representations.",
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "authors": [
                {
                    "authorId": "29001552",
                    "name": "Sneha Singhania"
                },
                {
                    "authorId": "2066327465",
                    "name": "S. Razniewski"
                },
                {
                    "authorId": "1751591",
                    "name": "G. Weikum"
                }
            ]
        },
        {
            "paperId": "524a781fba2fc08fbfcd58262064ad9f37164b40",
            "title": "Can large language models generate salient negative statements?",
            "abstract": "We examine the ability of large language models (LLMs) to generate salient (interesting) negative statements about real-world entities; an emerging research topic of the last few years. We probe the LLMs using zero- and k-shot unconstrained probes, and compare with traditional methods for negation generation, i.e., pattern-based textual extractions and knowledge-graph-based inferences, as well as crowdsourced gold statements. We measure the correctness and salience of the generated lists about subjects from different domains. Our evaluation shows that guided probes do in fact improve the quality of generated negatives, compared to the zero-shot variant. Nevertheless, using both prompts, LLMs still struggle with the notion of factuality of negatives, frequently generating many ambiguous statements, or statements with negative keywords but a positive meaning.",
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "authors": [
                {
                    "authorId": "40434178",
                    "name": "Hiba Arnaout"
                },
                {
                    "authorId": "2066327465",
                    "name": "S. Razniewski"
                }
            ]
        },
        {
            "paperId": "6778fbc38179f3f79afd36f7ac091bcb3ad111f6",
            "title": "Evaluating the Knowledge Base Completion Potential of GPT",
            "abstract": "Structured knowledge bases (KBs) are an asset for search engines and other applications, but are inevitably incomplete. Language models (LMs) have been proposed for unsupervised knowledge base completion (KBC), yet, their ability to do this at scale and with high accuracy remains an open question. Prior experimental studies mostly fall short because they only evaluate on popular subjects, or sample already existing facts from KBs. In this work, we perform a careful evaluation of GPT's potential to complete the largest public KB: Wikidata. We find that, despite their size and capabilities, models like GPT-3, ChatGPT and GPT-4 do not achieve fully convincing results on this task. Nonetheless, they provide solid improvements over earlier approaches with smaller LMs. In particular, we show that, with proper thresholding, GPT-3 enables to extend Wikidata by 27M facts at 90% precision.",
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "authors": [
                {
                    "authorId": "1738685382",
                    "name": "Blerta Veseli"
                },
                {
                    "authorId": "2066327465",
                    "name": "S. Razniewski"
                },
                {
                    "authorId": "3245041",
                    "name": "Jan-Christoph Kalo"
                },
                {
                    "authorId": "1751591",
                    "name": "G. Weikum"
                }
            ]
        },
        {
            "paperId": "726100be441858f538b45751bb3a57a9b232e1fe",
            "title": "CoQEx: Entity Counts Explained",
            "abstract": "For open-domain question answering, queries on entity counts, such ashow many languages are spoken in Indonesia, are challenging. Such queries can be answered through succinct contexts with counts:estimated 700 languages, and instances:Javanese and Sundanese. Answer candidates naturally give rise to a distribution, where count contexts denoting the queried entity counts and their semantic subgroups often coexist, while the instances ground the counts in their constituting entities. In this demo we showcase the CoQEx methodology (Count Queries Explained) [5,6], which aggregates and structures explanatory evidence across search snippets, for answering user queries related to entity counts [4]. Given a entity count query, our system CoQEx retrieves search-snippets and provides the user with a distribution-aware prediction prediction, categorizes the count contexts into semantic groups and ranks instances grounding the counts, all in real-time. Our demo can be accessed athttps://nlcounqer.mpi-inf.mpg.de/.",
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "authors": [
                {
                    "authorId": "2135976772",
                    "name": "Shrestha Ghosh"
                },
                {
                    "authorId": "2066327465",
                    "name": "S. Razniewski"
                },
                {
                    "authorId": "1751591",
                    "name": "G. Weikum"
                }
            ]
        }
    ]
}