{
    "authorId": "8626045",
    "papers": [
        {
            "paperId": "1d493b2d2407222ab20742889b4a0a79ba958a1d",
            "title": "Image Reconstruction Using Variable Exponential Function Regularization for Wide-Field Polarization Modulation Imaging",
            "abstract": "Polarization modulation imaging technology plays an important role in microscopic super-resolution imaging. However, the specimen medium contains retardancy, while charge-coupled devices may provide discrete under-sampling, and the coupled wavefronts consisting of the polarization state of the light and the anisotropic distribution of the specimen can lead to vectorial phase fitting degradation. Considering that the point spread function (PSF) of the main degradation parts can be regarded as an asymmetric generalized Gaussian distribution with uncertain parameters, an adaptive image reconstruction method is proposed based on variable exponential function regularization. The proposed method concentrates on the diversity of the PSF and uses a variable exponent regularization to improve flexibility of the kernel. Moreover, it can balance image edge preservation and provide staircase artifact suppression, which reduces the over- and under-reconstruction of the microscopic images effectively. By optimizing the Split\u2013Bregman algorithm, we create an efficient method that minimizes the iterative loss function under the premise of achieving high estimation accuracy. Compared with other methods, the experimental results reveal better effectiveness and robustness of the proposed method, with improvements of 18% in the peak signal-to-noise ratio, 21% in the structural similarity index measurement, and 337% in the mean structural similarity index measurement.",
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "authors": [
                {
                    "authorId": "2112259345",
                    "name": "Qiong Wu"
                },
                {
                    "authorId": "46812189",
                    "name": "Kun Gao"
                },
                {
                    "authorId": "2112144548",
                    "name": "Mu Li"
                },
                {
                    "authorId": "2109262818",
                    "name": "Zhenzhou Zhang"
                },
                {
                    "authorId": "40693214",
                    "name": "Zizheng Hua"
                },
                {
                    "authorId": "70159791",
                    "name": "Hanwen Zhao"
                },
                {
                    "authorId": "14988841",
                    "name": "Jichuan Xiong"
                },
                {
                    "authorId": "8626045",
                    "name": "Zeyang Dou"
                },
                {
                    "authorId": "2144273636",
                    "name": "Hong Wang"
                },
                {
                    "authorId": "2027169833",
                    "name": "Peilin Yu"
                }
            ]
        },
        {
            "paperId": "bfdd1515f9f19810efcc1a6984b3175522b50064",
            "title": "Band Selection of Hyperspectral Images Using Attention-Based Autoencoders",
            "abstract": "Band selection is an effective method to reduce redundancy in a hyperspectral image (HSI) without compromising the original contents. Popular band selection methods usually use strong assumptions, such as linear or nonlinear assumptions with simple predefined Kernel functions, to model the correlations between bands. However, this kind of strong assumption may not valid in the real environment due to the complex interactions between bands. In this letter, we treat hyperspectral band selection as a spectral reconstruction task. By assuming that an HSI can be sparsely reconstructed from a few informative bands, we propose an attention-based autoencoder to model the underlying nonlinear interdependencies between bands. The proposed model consists of two parts: an attention module and an autoencoder. The attention module is used to produce the attention mask which selects the most informative bands for every pixel. The autoencoder uses these informative bands to reconstruct the raw HSI. The final band selection is conducted via clustering column vectors of the attention mask and exploring the most representative band for each cluster. Different from most of the existing band selection methods, the proposed method directly learns global nonlinear correlations between bands without strong assumptions. The proposed model is easy to implement and all the parameters can be jointly optimized using the stochastic gradient descend algorithm. Experiments on three open public data sets show that the proposed method offers the promising results.",
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "authors": [
                {
                    "authorId": "8626045",
                    "name": "Zeyang Dou"
                },
                {
                    "authorId": "46812189",
                    "name": "Kun Gao"
                },
                {
                    "authorId": "51161322",
                    "name": "Xiaodian Zhang"
                },
                {
                    "authorId": "2144273636",
                    "name": "Hong Wang"
                },
                {
                    "authorId": "2112708387",
                    "name": "Lu Han"
                }
            ]
        },
        {
            "paperId": "106b3c5a6023b6ebd40b4c2c019385f61714087e",
            "title": "Hyperspectral Unmixing Using Orthogonal Sparse Prior-Based Autoencoder With Hyper-Laplacian Loss and Data-Driven Outlier Detection",
            "abstract": "Hyperspectral unmixing, which estimates end-members and their corresponding abundance fractions simultaneously, is an important task for hyperspectral applications. In this article, we propose a new autoencoder-based hyperspectral unmixing model with three novel components. First, we propose a new sparse prior to abundance maps. The proposed prior, called orthogonal sparse prior (OSP), is based on the observations that different abundance maps are close to orthogonal because, generally, no more than two end-members are mixed within one pixel. As opposed to the conventional norm-based sparse prior that assumes the abundance maps are independent, the proposed OSP explores the orthogonality between the abundance maps. Second, we propose the hyper-Laplacian loss to model the reconstruction error. The key observation is that the reconstruction error distribution usually has a heavy-tailed shape, which is better modeled by the hyper-Laplacian distribution rather than the commonly used Gaussian distribution. Third, to ease the side effect of outliers for end-member initializations, we develop a data-driven approach to detect outliers from the raw hyperspectral images. Extensive experiments on both synthetic and real-world data sets show that the proposed method significantly and consistently outperforms the compared state-of-the-art methods, with up to more than 50% improvements.",
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "authors": [
                {
                    "authorId": "8626045",
                    "name": "Zeyang Dou"
                },
                {
                    "authorId": "46812189",
                    "name": "Kun Gao"
                },
                {
                    "authorId": "51161322",
                    "name": "Xiaodian Zhang"
                },
                {
                    "authorId": "2144273636",
                    "name": "Hong Wang"
                },
                {
                    "authorId": "2110276903",
                    "name": "Junwei Wang"
                }
            ]
        },
        {
            "paperId": "7bf6ce7b4d5af6038dae94ae3fa37fe9b4ee3909",
            "title": "Deep Learning-Based Hyperspectral Target Detection without Extra Labeled Data",
            "abstract": "Target detection from hyperspectral images is an important problem. Recently, several deep learning-based target detection algorithms have been proposed. However, most of them require extra well-labeled data to train detectors. In this paper, we propose a deep learning-based target detection algorithm that doesn't require any extra labeled data. The proposed detector is based on the siamese network and the low-rank-sparse autoencoder. The autoencoder separates the test spectrum into a low-rank component and a sparse component, based on the assumption that the normal spectrum space has a low-rank structure while outliers sparsely spread in the image. The low-rank output of the autoencoder and the target spectrum are then separately fed into the Siamese network to get two high level features, and the final cosine similarity score is computed based on two features. To properly train the proposed detector, we develop a data creation method that creates numerous simulative training data. Extensive experiments show that the proposed method achieves state-of-the-art results.",
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "authors": [
                {
                    "authorId": "8626045",
                    "name": "Zeyang Dou"
                },
                {
                    "authorId": "46812189",
                    "name": "Kun Gao"
                },
                {
                    "authorId": "51161322",
                    "name": "Xiaodian Zhang"
                },
                {
                    "authorId": "2110276903",
                    "name": "Junwei Wang"
                },
                {
                    "authorId": "48016237",
                    "name": "Hong Wang"
                }
            ]
        },
        {
            "paperId": "bdfe91877a17ec1f14a38de8c578798e5cb72b8f",
            "title": "Blind Hyperspectral Unmixing using Dual Branch Deep Autoencoder with Orthogonal Sparse Prior",
            "abstract": "Blind hyperspectral unmixing has become an important task for hyperspectral applications. In this paper, we propose a dual branch autoencoder with a novel sparse prior to simultaneously extract endmembers and abundances from the raw HSI. The dual branch structure extends the linear mixing model by only modeling linear mixtures of the endmembers and treating the bilinear interactions as error. In this way, the proposed model doesn\u2019t require the assumptions of explicit forms of bilinear interactions. The proposed sparse prior, named as orthogonal sparse prior, is based on the key observation that the abundance vector of one pixel is very sparse, there are often no more than two non-zero elements. Different from the conventional norm-based sparse prior which assumes the abundance maps are independent, the orthogonal sparse prior explores the orthogonality between the abundance maps. Extensive experiments on two real datasets show that the proposed method significantly and consistently outperforms the compared state-of-the-art methods, with up to 50% improvements.",
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "authors": [
                {
                    "authorId": "8626045",
                    "name": "Zeyang Dou"
                },
                {
                    "authorId": "46812189",
                    "name": "Kun Gao"
                },
                {
                    "authorId": "51161322",
                    "name": "Xiaodian Zhang"
                },
                {
                    "authorId": "2144273636",
                    "name": "Hong Wang"
                },
                {
                    "authorId": "2110276903",
                    "name": "Junwei Wang"
                }
            ]
        },
        {
            "paperId": "dca358b94fa108df53863f61bd97f36a32278572",
            "title": "Improving Performance and Adaptivity of Anchor-Based Detector Using Differentiable Anchoring With Efficient Target Generation",
            "abstract": "Most anchor-based object detection methods have adopted predefined anchor boxes as regression references. However, the proper setting of anchor boxes may vary significantly across different datasets, improperly designed anchors severely limit the performances and adaptabilities of detectors. Recently, some works have tackled this problem by learning anchor shapes from datasets. However, all of these works explicitly or implicitly rely on predefined anchors, limiting universalities of detectors. In this paper, we propose a simple learning anchoring scheme with an effective target generation method to cast off predefined anchor dependencies. The proposed anchoring scheme, named as differentiable anchoring, simplifies learning anchor shape process by adding only one branch in parallel with the existing classification and bounding box regression branches. The proposed target generation method, including the $L_{p}$ norm ball approximation and the optimization difficulty-based pyramid level assignment approach, generates positive samples for the new branch. Compared with existing learning anchoring-based approaches, the proposed method doesn\u2019t require any predefined anchors, while tremendously improving performances and adaptiveness of detectors. The proposed method can be seamlessly integrated to Faster RCNN, RetinaNet, and SSD, improving the detection mAP by 2.8%, 2.1% and 2.3% respectively on MS COCO 2017 test-dev set. Moreover, the differentiable anchoring-based detectors can be directly applied to specific scenarios without any modification of the hyperparameters or using a specialized optimization. Specifically, the differentiable anchoring-based RetinaNet achieves very competitive performances on tiny face detection and text detection tasks, which are not well handled by the conventional and guided anchoring based RetinaNets for the MS COCO dataset.",
            "fieldsOfStudy": [
                "Computer Science",
                "Medicine"
            ],
            "authors": [
                {
                    "authorId": "8626045",
                    "name": "Zeyang Dou"
                },
                {
                    "authorId": "46812189",
                    "name": "Kun Gao"
                },
                {
                    "authorId": "51161322",
                    "name": "Xiaodian Zhang"
                },
                {
                    "authorId": "48016237",
                    "name": "Hong Wang"
                },
                {
                    "authorId": "2110276903",
                    "name": "Junwei Wang"
                }
            ]
        },
        {
            "paperId": "fc7932f46cd757b235df223815847db195fe5a54",
            "title": "On-Orbit MTF Estimation for GF-4 Satellite Using Spatial Multisampling on a New Target",
            "abstract": "GF-(Gaofen- means high resolution in Chinese) satellite launched in 2015 is the first geosynchronous orbit remote sensing satellite in China. To evaluate the on-orbit modulation transfer function (MTF) of the space-borne panchromatic camera in GF-4, a modified pulse target is proposed. This new type target is laid in the uniform low-reflection background region whose center region is a high-reflection square with the size of 3 ~ 4 ground sampled distance (GSD), and then two low-reflection rectangle stripes are extended along the center square toward both ends with the length over 4 GSD. In consideration of the staring imaging mechanism of GF-4, the target image sequences are accessed with relative random distance taken by the space-borne camera in a short period to reduce accidental error of one sampling and enhance the accuracy of estimation. Based on the multi-sampling calibrating images, maximum a posteriori estimation model and gradient descent solution with grid searching method are used to fit the pulse response function (PRF) when taking the target center positions as references. MTF is then calculated from PRF via Fourier transformation. Numerical simulation results reveal our method can keep the accuracy stable despite of different kinds of noise. Actual calibration result using this method shows that on-orbit MTF of GF-4 camera at Nyquist frequency is 0.1473.",
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "authors": [
                {
                    "authorId": "2112708387",
                    "name": "Lu Han"
                },
                {
                    "authorId": "46812189",
                    "name": "Kun Gao"
                },
                {
                    "authorId": "8626045",
                    "name": "Zeyang Dou"
                },
                {
                    "authorId": "48148052",
                    "name": "Zhenyu Zhu"
                },
                {
                    "authorId": "2144273636",
                    "name": "Hong Wang"
                },
                {
                    "authorId": "25476043",
                    "name": "Xingke Fu"
                }
            ]
        },
        {
            "paperId": "d21da6d85bda9b5b414ccbedcc3b13e73d3e47e5",
            "title": "Fast Blind Image Deblurring Using Smoothing-Enhancing Regularizer",
            "abstract": "Blind deconvolution is a highly ill-posed problem for the restoration of degraded images and requires prior knowledge or regularization. Recently, various priors have been proposed and the models based on these priors have achieved state-of-the-art performances. In this paper, we present a blind image deblurring method based on a computationally efficient and effective image regularizer. The proposed regularizer is motivated by the fact that the success of recent priors mainly stems from their properties, which implicitly generate an unnatural latent image suppressing insignificant structures and preserving only salient edges. These salient edges guide the models to estimate an accurate kernel. In this paper, the proposed regularizer termed smoothing-enhancing regularizer, not only assures that only salient structures in the image are preserved but also enhances these salient structures to help the model estimate the more accurate kernel. To efficiently solve the proposed model, we develop an efficient numerical approach based on the half-quadratic splitting algorithm and the lagged-fixed-point iteration scheme. The optimization scheme only requires a few additional shrinkage operations compared with the original half-quadratic splitting algorithm, making our method much faster than recent leading methods. The qualitative and quantitative experimental results show that our algorithm achieves the state-of-the-art results and can be extended to other challenging deblurring tasks, such as those involving text, face, and low-illuminated images. Furthermore, the proposed method is much more computationally efficient than the recent state-of-the-art algorithms with up to more than $10\\times $ faster execution time.",
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "authors": [
                {
                    "authorId": "8626045",
                    "name": "Zeyang Dou"
                },
                {
                    "authorId": "46812189",
                    "name": "Kun Gao"
                },
                {
                    "authorId": "51161322",
                    "name": "Xiaodian Zhang"
                },
                {
                    "authorId": "2144273636",
                    "name": "Hong Wang"
                }
            ]
        },
        {
            "paperId": "26f85dd6494eef0f58be3d93cc8db8da523705ea",
            "title": "Target-Aware Fusion of Infrared and Visible Images",
            "abstract": "Image fusion technology involves the use of complementary information from multiple sensors to generate a composite image that can highlight the details in the region of interest. Some recent methods have tackled the problem of characterization of different source image features that are lacking in conventional methods. However, during fusion processing, these methods may lose some information of interest such as smoke. This paper proposes a method called target-aware decomposition and parallel gradient fusion (TAD-PGF) that fuses infrared and visible images to maintain the high brightness characteristics of infrared targets while transferring the appearance of both source images to the fused image, where \u201cappearance\u201d means the details pertaining to the environment and \u201cinfrared target\u201d often means hot objects such as human body. The target layer is extracted from the infrared image and used as a guide to extract appearance-related information from the visible image. Given that the background of the infrared image contains useful background information, a parallel gradient fusion scheme is proposed to fuse the relevant features with appearance-related information in the visible image. The final blended image is obtained by adding a target layer and a fused appearance layer directly to the fused image. Numerous experiments using publicly available databases were conducted to provide qualitative and quantitative comparisons between the state-of-the-art methods and the proposed TAD-PGF. The results reveal that the TAD-PGF can attain good visual effect in various scenarios and maintain useful information from source images to enhance the details of interest.",
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "authors": [
                {
                    "authorId": "2118860967",
                    "name": "Yingjie Zhou"
                },
                {
                    "authorId": "46812189",
                    "name": "Kun Gao"
                },
                {
                    "authorId": "8626045",
                    "name": "Zeyang Dou"
                },
                {
                    "authorId": "40693214",
                    "name": "Zizheng Hua"
                },
                {
                    "authorId": "49528487",
                    "name": "Hong Wang"
                }
            ]
        },
        {
            "paperId": "999068350d03edea05ac5a9300bf00040d131d8e",
            "title": "Variable Exponent Regularization Approach for Blur Kernel Estimation of Remote Sensing Image Blind Restoration",
            "abstract": "Spatial remote sensing images are usually degraded during image capturing procedures mainly due to the mixed factors of atmospheric turbulence, spacecraft motion, and out of focus lenses. The real point spread function (PSF) of the whole imaging system is the convolution of all factors contributing to degradation. The exact degradation PSF model estimation is important for the image restoration result. In this paper, we considered the properties of the mixed degradation factors and proposed a new blind deconvolution model to simultaneously estimate and remove blurs from remote sensing images. Inconsistent with existing models, which mainly focus on only one degradation type and estimate blur kernel parameters using the fixed regularizer, we concentrated on the diversity of different PSF types and used the variable exponent regularizer to improve kernel flexibility. The proposed model could estimate not only single PSF types, such as motion, uniform, and Gaussian, but also composite PSFs of different types. Following the split Bregman method, we employed an efficient computational method, which did not require PSF initial values, to minimize the proposed cost function iteratively. Experimental results demonstrated the effectiveness and robustness of the proposed method for simulated and real remote sensing images with different PSFs\u2019 types.",
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "authors": [
                {
                    "authorId": "46812189",
                    "name": "Kun Gao"
                },
                {
                    "authorId": "48148052",
                    "name": "Zhenyu Zhu"
                },
                {
                    "authorId": "8626045",
                    "name": "Zeyang Dou"
                },
                {
                    "authorId": "2112708387",
                    "name": "Lu Han"
                }
            ]
        }
    ]
}