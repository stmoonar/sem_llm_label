{
    "authorId": "40434674",
    "papers": [
        {
            "paperId": "13581a46d32822e44cbeb1acdba4a59cef2b2ec1",
            "title": "On Efficient Training of Large-Scale Deep Learning Models: A Literature Review",
            "abstract": "The field of deep learning has witnessed significant progress, particularly in computer vision (CV), natural language processing (NLP), and speech. The use of large-scale models trained on vast amounts of data holds immense promise for practical applications, enhancing industrial productivity and facilitating social development. With the increasing demands on computational capacity, though numerous studies have explored the efficient training, a comprehensive summarization on acceleration techniques of training deep learning models is still much anticipated. In this survey, we present a detailed review for training acceleration. We consider the fundamental update formulation and split its basic components into five main perspectives: (1) data-centric: including dataset regularization, data sampling, and data-centric curriculum learning techniques, which can significantly reduce the computational complexity of the data samples; (2) model-centric, including acceleration of basic modules, compression training, model initialization and model-centric curriculum learning techniques, which focus on accelerating the training via reducing the calculations on parameters; (3) optimization-centric, including the selection of learning rate, the employment of large batchsize, the designs of efficient objectives, and model average techniques, which pay attention to the training policy and improving the generality for the large-scale models; (4) budgeted training, including some distinctive acceleration methods on source-constrained situations; (5) system-centric, including some efficient open-source distributed libraries/systems which provide adequate hardware support for the implementation of acceleration algorithms. By presenting this comprehensive taxonomy, our survey presents a comprehensive review to understand the general mechanisms within each component and their joint interaction.",
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "authors": [
                {
                    "authorId": "2144035454",
                    "name": "Li Shen"
                },
                {
                    "authorId": "2204964085",
                    "name": "Yan Sun"
                },
                {
                    "authorId": "2216987575",
                    "name": "Zhiyuan Yu"
                },
                {
                    "authorId": "46573238",
                    "name": "Liang Ding"
                },
                {
                    "authorId": "40434674",
                    "name": "Xinmei Tian"
                },
                {
                    "authorId": "2135519749",
                    "name": "Dacheng Tao"
                }
            ]
        },
        {
            "paperId": "a62c5d2654d9fa339ca087daedd6085367621efa",
            "title": "An Active Service Recommendation Model for Multi-Source Remote Sensing Information Using Fusion of Attention and Multi-Perspective",
            "abstract": "With the development and popularization of remote sensing earth observation technology and the remote sensing satellite system, the problems of insufficient proactiveness, relevance and timeliness of large-scale remote sensing supporting services are increasingly prominent, which seriously restricts the application of remote sensing resources in multi-domain and cross-disciplinary. It is urgent to help terminal users make appropriate decisions according to real-time network environment and domain requirements, and obtain the optimal resources efficiently from the massive remote sensing resources. In this paper, we propose a recommendation algorithm using fusion of attention and multi-perspective (MRS_AMRA). Based on MRS_AMRA, we further implement an active service recommendation model (MRS_ASRM) for massive multi-source remote sensing resources by combining streaming pushing technology. Firstly, we construct value evaluation functions from multi-perspective in terms of remote sensing users, data and services to enable the adaptive provision of remote sensing resources. Then, we define multi-perspective heuristic policies to support resource discovery, and fusion these policies through the attention network, to achieve the accurate pushing of remote sensing resources. Finally, we implement comparative experiments to simulate accurate recommendation scenarios, compared with state-of-the-art algorithms, such as DIN and Geoportal. Furthermore, MRS_AMRA achieves an average improvement of 10.5% in the recommendation accuracy NDCG@K, and in addition, we developed a prototype system to verify the effectiveness and timeliness of MRS_ASRM.",
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "authors": [
                {
                    "authorId": "2108595407",
                    "name": "Lilu Zhu"
                },
                {
                    "authorId": "2308737394",
                    "name": "Feng Wu"
                },
                {
                    "authorId": "2266415",
                    "name": "Kun Fu"
                },
                {
                    "authorId": "2113664072",
                    "name": "Yanfeng Hu"
                },
                {
                    "authorId": null,
                    "name": "Yang Wang"
                },
                {
                    "authorId": "40434674",
                    "name": "Xinmei Tian"
                },
                {
                    "authorId": "2112768821",
                    "name": "Kai Huang"
                }
            ]
        },
        {
            "paperId": "e76e96fdd23f5dfc86a795b668683a721423d2df",
            "title": "Structured Cooperative Learning with Graphical Model Priors",
            "abstract": "We study how to train personalized models for different tasks on decentralized devices with limited local data. We propose\"Structured Cooperative Learning (SCooL)\", in which a cooperation graph across devices is generated by a graphical model prior to automatically coordinate mutual learning between devices. By choosing graphical models enforcing different structures, we can derive a rich class of existing and novel decentralized learning algorithms via variational inference. In particular, we show three instantiations of SCooL that adopt Dirac distribution, stochastic block model (SBM), and attention as the prior generating cooperation graphs. These EM-type algorithms alternate between updating the cooperation graph and cooperative learning of local models. They can automatically capture the cross-task correlations among devices by only monitoring their model updating in order to optimize the cooperation graph. We evaluate SCooL and compare it with existing decentralized learning methods on an extensive set of benchmarks, on which SCooL always achieves the highest accuracy of personalized models and significantly outperforms other baselines on communication efficiency. Our code is available at https://github.com/ShuangtongLi/SCooL.",
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "authors": [
                {
                    "authorId": "2032816161",
                    "name": "Shuang-Yang Li"
                },
                {
                    "authorId": "1805655",
                    "name": "Tianyi Zhou"
                },
                {
                    "authorId": "40434674",
                    "name": "Xinmei Tian"
                },
                {
                    "authorId": "2135519749",
                    "name": "Dacheng Tao"
                }
            ]
        },
        {
            "paperId": "edd21525d02b5f3bd9464f069f8ab0e99244cf77",
            "title": "Sharper Bounds for Uniformly Stable Algorithms with Stationary Mixing Process",
            "abstract": "Generalization analysis of learning algorithms often builds on a critical assumption that training examples are independently and identically distributed, which is often violated in practical problems such as time series prediction. In this paper, we use algorithmic stability to study the generalization performance of learning algorithms with \u03c8 -mixing data, where the dependency between observations weakens over time. We show uniformly stable algorithms guarantee high-probability generalization bounds of the order O (1 / \u221a n ) (within a logarithmic factor), where n is the sample size. We apply our general result to speci\ufb01c algorithms including regularization schemes, stochastic gradient descent and localized iterative regularization, and develop excess population risk bounds for learning with \u03c8 -mixing data. Our analysis builds on a novel moment bound for weakly-dependent random variables on a \u03d5 -mixing sequence and a novel error decomposition of generalization error",
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "authors": [
                {
                    "authorId": "2489252",
                    "name": "S. Fu"
                },
                {
                    "authorId": "2365013",
                    "name": "Yunwen Lei"
                },
                {
                    "authorId": "2176189708",
                    "name": "Qiong Cao"
                },
                {
                    "authorId": "40434674",
                    "name": "Xinmei Tian"
                },
                {
                    "authorId": "2186146273",
                    "name": "Dacheng Tao"
                }
            ]
        },
        {
            "paperId": "ee9bc1ed5141f5384b106e8f7879918751c8b801",
            "title": "Semantic-Aware Mixup for Domain Generalization",
            "abstract": "Deep neural networks (DNNs) have shown exciting performance in various tasks, yet suffer generalization failures when meeting unknown target domains. One of the most promising approaches to achieve domain generalization (DG) is generating unseen data, e.g., mixup, to cover the unknown target data. However, existing works overlook the challenges induced by the simultaneous appearance of changes in both the semantic and distribution space. Accordingly, such a challenge makes source distributions hard to fit for DNNs. To mitigate the hard-fitting issue, we propose to perform a semantic-aware mixup (SAM) for domain generalization, where whether to perform mixup depends on the semantic and domain information. The feasibility of SAM shares the same spirits with the Fourier-based mixup. Namely, the Fourier phase spectrum is expected to contain semantics information (relating to labels), while the Fourier amplitude retains other information (relating to style information). Built upon the insight, SAM applies different mixup strategies to the Fourier phase spectrum and amplitude information. For instance, SAM merely performs mixup on the amplitude spectrum when both the semantic and domain information changes. Consequently, the overwhelmingly large change can be avoided. We validate the effectiveness of SAM using image classification tasks on several DG benchmarks.",
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "authors": [
                {
                    "authorId": "2708397",
                    "name": "C. Xu"
                },
                {
                    "authorId": "40434674",
                    "name": "Xinmei Tian"
                }
            ]
        },
        {
            "paperId": "f87d1379fdca3c2af8239f441f21a6e2ff90bf45",
            "title": "Moderately Distributional Exploration for Domain Generalization",
            "abstract": "Domain generalization (DG) aims to tackle the distribution shift between training domains and unknown target domains. Generating new domains is one of the most effective approaches, yet its performance gain depends on the distribution discrepancy between the generated and target domains. Distributionally robust optimization is promising to tackle distribution discrepancy by exploring domains in an uncertainty set. However, the uncertainty set may be overwhelmingly large, leading to low-confidence prediction in DG. It is because a large uncertainty set could introduce domains containing semantically different factors from training domains. To address this issue, we propose to perform a $\\textbf{mo}$derately $\\textbf{d}$istributional $\\textbf{e}$xploration (MODE) for domain generalization. Specifically, MODE performs distribution exploration in an uncertainty $\\textit{subset}$ that shares the same semantic factors with the training domains. We show that MODE can endow models with provable generalization performance on unknown target domains. The experimental results show that MODE achieves competitive performance compared to state-of-the-art baselines.",
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "authors": [
                {
                    "authorId": "2143299123",
                    "name": "Ruiqi Dai"
                },
                {
                    "authorId": "2109116068",
                    "name": "Yonggang Zhang"
                },
                {
                    "authorId": "1382582313",
                    "name": "Zhen Fang"
                },
                {
                    "authorId": "2153287285",
                    "name": "Bo Han"
                },
                {
                    "authorId": "40434674",
                    "name": "Xinmei Tian"
                }
            ]
        },
        {
            "paperId": "03a035710dee42de540978f6e0f1d4dbd35aa719",
            "title": "Toward Real-world Single Image Deraining: A New Benchmark and Beyond",
            "abstract": "\u2014Single image deraining (SID) in real scenarios at- tracts increasing attention in recent years. Due to the dif\ufb01culty in obtaining real-world rainy/clean image pairs, previous real datasets suffer from low-resolution images, homogeneous rain streaks, limited background variation, and even misalignment of image pairs, resulting in incomprehensive evaluation of SID methods. To address these issues, we establish a new high-quality dataset named RealRain-1k, consisting of 1 , 120 high-resolution paired clean and rainy images with low- and high-density rain streaks, respectively. Images in RealRain-1k are automatically generated from a large number of real-world rainy video clips through a simple yet effective rain density-controllable \ufb01ltering method, and have good properties of high image resolution, background diversity, rain streaks variety, and strict spatial alignment. RealRain-1k also provides abundant rain streak layers as a byproduct, enabling us to build a large-scale synthetic dataset named SynRain-13k by pasting the rain streak layers on abundant natural images. Based on them and existing datasets, we benchmark more than 10 representative SID methods on three tracks: (1) fully supervised learning on RealRain-1k, (2) domain generalization to real datasets, and (3) syn-to-real transfer learning. The experimental results (1) show the difference of representative methods in image restoration performance and model complexity, (2) validate the signi\ufb01cance of the proposed datasets for model generalization, and (3) provide useful insights on the superiority of learning from diverse domains and shed lights on the future research on real-world SID. The datasets have been released at https://github.com/hiker-lw/RealRain-1k.",
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "authors": [
                {
                    "authorId": "2157336376",
                    "name": "Wei Li"
                },
                {
                    "authorId": "151714237",
                    "name": "Qiming Zhang"
                },
                {
                    "authorId": "1519070643",
                    "name": "Jing Zhang"
                },
                {
                    "authorId": "2151324863",
                    "name": "Zhen Huang"
                },
                {
                    "authorId": "40434674",
                    "name": "Xinmei Tian"
                },
                {
                    "authorId": "2075330732",
                    "name": "Dacheng Tao"
                }
            ]
        },
        {
            "paperId": "32ff43704a04191cf0b90a1dac7cbbc8f5df12a3",
            "title": "Self-Supervision Can Be a Good Few-Shot Learner",
            "abstract": "Existing few-shot learning (FSL) methods rely on training with a large labeled dataset, which prevents them from leveraging abundant unlabeled data. From an information-theoretic perspective, we propose an effective unsupervised FSL method, learning representations with self-supervision. Following the InfoMax principle, our method learns comprehensive representations by capturing the intrinsic structure of the data. Specifically, we maximize the mutual information (MI) of instances and their representations with a low-bias MI estimator to perform self-supervised pre-training. Rather than supervised pre-training focusing on the discriminable features of the seen classes, our self-supervised model has less bias toward the seen classes, resulting in better generalization for unseen classes. We explain that supervised pre-training and self-supervised pre-training are actually maximizing different MI objectives. Extensive experiments are further conducted to analyze their FSL performance with various training settings. Surprisingly, the results show that self-supervised pre-training can outperform supervised pre-training under the appropriate conditions. Compared with state-of-the-art FSL methods, our approach achieves comparable performance on widely used FSL benchmarks without any labels of the base classes.",
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "authors": [
                {
                    "authorId": "2159316456",
                    "name": "Yuning Lu"
                },
                {
                    "authorId": "147383784",
                    "name": "Liangjiang Wen"
                },
                {
                    "authorId": "2144167531",
                    "name": "Jianzhuang Liu"
                },
                {
                    "authorId": "2144470300",
                    "name": "Yajing Liu"
                },
                {
                    "authorId": "40434674",
                    "name": "Xinmei Tian"
                }
            ]
        },
        {
            "paperId": "3d6849cba47d68a3126eefca04604e13f69b5cfb",
            "title": "Prompt Distribution Learning",
            "abstract": "We present prompt distribution learning for effectively adapting a pre-trained vision-language model to address downstream recognition tasks. Our method not only learns low-bias prompts from a few samples but also captures the distribution of diverse prompts to handle the varying visual representations. In this way, we provide high-quality task-related content for facilitating recognition. This prompt distribution learning is realized by an efficient approach that learns the output embeddings of prompts instead of the input embeddings. Thus, we can employ a Gaussian distribution to model them effectively and derive a surrogate loss for efficient training. Extensive experiments on 12 datasets demonstrate that our method consistently and significantly outperforms existing methods. For example, with 1 sample per category, it relatively improves the average result by 9.1% compared to human-crafted prompts.",
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "authors": [
                {
                    "authorId": "2159316456",
                    "name": "Yuning Lu"
                },
                {
                    "authorId": "2144167531",
                    "name": "Jianzhuang Liu"
                },
                {
                    "authorId": "2109116068",
                    "name": "Yonggang Zhang"
                },
                {
                    "authorId": "2144470300",
                    "name": "Yajing Liu"
                },
                {
                    "authorId": "40434674",
                    "name": "Xinmei Tian"
                }
            ]
        },
        {
            "paperId": "4aad61372bb2eb54147798f84596e55b0dbd04b8",
            "title": "Learning to Collaborate in Decentralized Learning of Personalized Models",
            "abstract": "Learning personalized models for user-customized computer-vision tasks is challenging due to the limited private-data and computation available on each edge device. Decentralized learning (DL) can exploit the images distributed over devices on a network topology to train a global model but is not designed to train personalized models for different tasks or optimize the topology. Moreover, the mixing weights used to aggregate neighbors' gradient messages in DL can be suboptimal for personalization since they are not adaptive to different nodes/tasks and learning stages. In this paper, we dynamically update the mixing-weights to improve the personalized model for each node's task and meanwhile learn a sparse topology to reduce communication costs. Our first approach, \u201clearning to collaborate (L2C) \u201d, directly optimizes the mixing weights to minimize the local validation loss per node for a predefined set of nodes/tasks. In order to produce mixing weights for new nodes or tasks, we further develop \u201cmeta-L2C\u2018, which learns an attention mechanism to automatically assign mixing weights by comparing two nodes' model updates. We evaluate both methods on diverse benchmarks and experimental settings for image classification. Thorough comparisons to both classical and recent methods for IID/non-IID decentralized and federated learning demonstrate our method's advantages in identifying collaborators among nodes, learning sparse topology, and producing better personalized models with low communication and computational cost.",
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "authors": [
                {
                    "authorId": "2032816161",
                    "name": "Shuang-Yang Li"
                },
                {
                    "authorId": "1805655",
                    "name": "Tianyi Zhou"
                },
                {
                    "authorId": "40434674",
                    "name": "Xinmei Tian"
                },
                {
                    "authorId": "2135519749",
                    "name": "Dacheng Tao"
                }
            ]
        }
    ]
}