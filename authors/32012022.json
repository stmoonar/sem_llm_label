{
    "authorId": "32012022",
    "papers": [
        {
            "paperId": "53eb363fde536c7d6cb96f4f4fef194094917192",
            "title": "Investigating Content Planning for Navigating Trade-offs in Knowledge-Grounded Dialogue",
            "abstract": "Knowledge-grounded dialogue generation is a challenging task because it requires satisfying two fundamental, yet often competing constraints: being responsive in a manner that is specific to what the conversation partner has said while also being attributable to an underlying source document. In this work, we bring this trade-off between these two objectives (specificity and attribution) to light, and ask the question: Can explicit content planning before the response generation help the model to address this challenge? To answer this question, we design a framework called PLEDGE, which allows us to experiment with various plan variables explored in prior work supporting both metric-agnostic and metric-aware approaches. While content planning shows promise, our results on whether it can actually help to navigate this trade-off are mixed \u2013 planning mechanisms that are metric-aware (use automatic metrics during training) are better at automatic evaluations but underperform in human judgment compared to metric-agnostic mechanisms. We discuss how this may be caused by over-fitting to automatic metrics, and the need for future work to better calibrate these metrics towards human judgment. We hope the observations from our analysis will inform future work that aims to apply content planning in this context.",
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "authors": [
                {
                    "authorId": "2282539587",
                    "name": "Kushal Chawla"
                },
                {
                    "authorId": "2516777",
                    "name": "Hannah Rashkin"
                },
                {
                    "authorId": "32012022",
                    "name": "Gaurav Singh Tomar"
                },
                {
                    "authorId": "2257286979",
                    "name": "David Reitter"
                }
            ]
        },
        {
            "paperId": "22d34b881d64523da54f13d01fc3c6d93a8412e3",
            "title": "Dungeons and Dragons as a Dialog Challenge for Artificial Intelligence",
            "abstract": "AI researchers have posited Dungeons and Dragons (D&D) as a challenge problem to test systems on various language-related capabilities. In this paper, we frame D&D specifically as a dialogue system challenge, where the tasks are to both generate the next conversational turn in the game and predict the state of the game given the dialogue history. We create a gameplay dataset consisting of nearly 900 games, with a total of 7,000 players, 800,000 dialogue turns, 500,000 dice rolls, and 58 million words. We automatically annotate the data with partial state information about the game play. We train a large language model (LM) to generate the next game turn, conditioning it on different information. The LM can respond as a particular character or as the player who runs the game\u2014i.e., the Dungeon Master (DM). It is trained to produce dialogue that is either in-character (roleplaying in the fictional world) or out-of-character (discussing rules or strategy). We perform a human evaluation to determine what factors make the generated output plausible and interesting. We further perform an automatic evaluation to determine how well the model can predict the game state given the history and examine how well tracking the game state improves its ability to produce plausible conversational output.",
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "authors": [
                {
                    "authorId": "1763608",
                    "name": "Chris Callison-Burch"
                },
                {
                    "authorId": "32012022",
                    "name": "Gaurav Singh Tomar"
                },
                {
                    "authorId": "145262322",
                    "name": "Lara J. Martin"
                },
                {
                    "authorId": "7975935",
                    "name": "Daphne Ippolito"
                },
                {
                    "authorId": "2187686249",
                    "name": "Suma Bailis"
                },
                {
                    "authorId": "1781409",
                    "name": "D. Reitter"
                }
            ]
        },
        {
            "paperId": "07283e1578a50e15ac66efcc35b4ae0cbf2159ef",
            "title": "Measuring Attribution in Natural Language Generation Models",
            "abstract": "Abstract Large neural models have brought a new challenge to natural language generation (NLG): It has become imperative to ensure the safety and reliability of the output of models that generate freely. To this end, we present an evaluation framework, Attributable to Identified Sources (AIS), stipulating that NLG output pertaining to the external world is to be verified against an independent, provided source. We define AIS and a two-stage annotation pipeline for allowing annotators to evaluate model output according to annotation guidelines. We successfully validate this approach on generation datasets spanning three tasks (two conversational QA datasets, a summarization dataset, and a table-to-text dataset). We provide full annotation guidelines in the appendices and publicly release the annotated data at https://github.com/google-research-datasets/AIS.",
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "authors": [
                {
                    "authorId": "2516777",
                    "name": "Hannah Rashkin"
                },
                {
                    "authorId": "48942032",
                    "name": "Vitaly Nikolaev"
                },
                {
                    "authorId": "48024953",
                    "name": "Matthew Lamm"
                },
                {
                    "authorId": "123052390",
                    "name": "Michael Collins"
                },
                {
                    "authorId": "143790066",
                    "name": "Dipanjan Das"
                },
                {
                    "authorId": "1754497",
                    "name": "Slav Petrov"
                },
                {
                    "authorId": "32012022",
                    "name": "Gaurav Singh Tomar"
                },
                {
                    "authorId": "1388156275",
                    "name": "Iulia Turc"
                },
                {
                    "authorId": "1781409",
                    "name": "D. Reitter"
                }
            ]
        },
        {
            "paperId": "946d51acd20d9acc649d0238628261b093ec572b",
            "title": "CONQRR: Conversational Query Rewriting for Retrieval with Reinforcement Learning",
            "abstract": "Compared to standard retrieval tasks, passage retrieval for conversational question answering (CQA) poses new challenges in understanding the current user question, as each question needs to be interpreted within the dialogue context. Moreover, it can be expensive to re-train well-established retrievers such as search engines that are originally developed for non-conversational queries. To facilitate their use, we develop a query rewriting model CONQRR that rewrites a conversational question in the context into a standalone question. It is trained with a novel reward function to directly optimize towards retrieval using reinforcement learning and can be adapted to any off-the-shelf retriever. CONQRR achieves state-of-the-art results on a recent open-domain CQA dataset containing conversations from three different sources, and is effective for two different off-the-shelf retrievers. Our extensive analysis also shows the robustness of CONQRR to out-of-domain dialogues as well as to zero query rewriting supervision.",
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "authors": [
                {
                    "authorId": "7806955",
                    "name": "Zeqiu Wu"
                },
                {
                    "authorId": "116300663",
                    "name": "Yi Luan"
                },
                {
                    "authorId": "2516777",
                    "name": "Hannah Rashkin"
                },
                {
                    "authorId": "1781409",
                    "name": "D. Reitter"
                },
                {
                    "authorId": "32012022",
                    "name": "Gaurav Singh Tomar"
                }
            ]
        },
        {
            "paperId": "ad219f774290a128a3c2150fa93ed9b39b5b2a65",
            "title": "Increasing Faithfulness in Knowledge-Grounded Dialogue with Controllable Features",
            "abstract": "Knowledge-grounded dialogue systems are intended to convey information that is based on evidence provided in a given source text. We discuss the challenges of training a generative neural dialogue model for such systems that is controlled to stay faithful to the evidence. Existing datasets contain a mix of conversational responses that are faithful to selected evidence as well as more subjective or chit-chat style responses. We propose different evaluation measures to disentangle these different styles of responses by quantifying the informativeness and objectivity. At training time, additional inputs based on these evaluation measures are given to the dialogue model. At generation time, these additional inputs act as stylistic controls that encourage the model to generate responses that are faithful to the provided evidence. We also investigate the usage of additional controls at decoding time using resampling techniques. In addition to automatic metrics, we perform a human evaluation study where raters judge the output of these controlled generation models to be generally more objective and faithful to the evidence compared to baseline dialogue systems.",
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "authors": [
                {
                    "authorId": "2516777",
                    "name": "Hannah Rashkin"
                },
                {
                    "authorId": "1781409",
                    "name": "D. Reitter"
                },
                {
                    "authorId": "32012022",
                    "name": "Gaurav Singh Tomar"
                },
                {
                    "authorId": "143790066",
                    "name": "Dipanjan Das"
                }
            ]
        },
        {
            "paperId": "24433d65fb2b3df2bfc500861fa801ba04622028",
            "title": "Improving Semantic Parsing with Neural Generator-Reranker Architecture",
            "abstract": "Semantic parsing is the problem of deriving machine interpretable meaning representations from natural language utterances. Neural models with encoder-decoder architectures have recently achieved substantial improvements over traditional methods. Although neural semantic parsers appear to have relatively high recall using large beam sizes, there is room for improvement with respect to one-best precision. In this work, we propose a generator-reranker architecture for semantic parsing. The generator produces a list of potential candidates and the reranker, which consists of a pre-processing step for the candidates followed by a novel critic network, reranks these candidates based on the similarity between each candidate and the input sentence. We show the advantages of this approach along with how it improves the parsing performance through extensive analysis. We experiment our model on three semantic parsing datasets (GEO, ATIS, and OVERNIGHT). The overall architecture achieves the state-of-the-art results in all three datasets.",
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "authors": [
                {
                    "authorId": "3058104",
                    "name": "Huseyin A. Inan"
                },
                {
                    "authorId": "32012022",
                    "name": "Gaurav Singh Tomar"
                },
                {
                    "authorId": "2113793910",
                    "name": "Huapu Pan"
                }
            ]
        },
        {
            "paperId": "3d4dfbdcb11d7b495e066435a9a98f02eb0cb369",
            "title": "Attention Interpretability Across NLP Tasks",
            "abstract": "The attention layer in a neural network model provides insights into the model's reasoning behind its prediction, which are usually criticized for being opaque. Recently, seemingly contradictory viewpoints have emerged about the interpretability of attention weights (Jain & Wallace, 2019; Vig & Belinkov, 2019). Amid such confusion arises the need to understand attention mechanism more systematically. In this work, we attempt to fill this gap by giving a comprehensive explanation which justifies both kinds of observations (i.e., when is attention interpretable and when it is not). Through a series of experiments on diverse NLP tasks, we validate our observations and reinforce our claim of interpretability of attention through manual evaluation.",
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "authors": [
                {
                    "authorId": "3404827",
                    "name": "Shikhar Vashishth"
                },
                {
                    "authorId": "33145619",
                    "name": "Shyam Upadhyay"
                },
                {
                    "authorId": "32012022",
                    "name": "Gaurav Singh Tomar"
                },
                {
                    "authorId": "1779225",
                    "name": "Manaal Faruqui"
                }
            ]
        },
        {
            "paperId": "ac713aebdcc06f15f8ea61e1140bb360341fdf27",
            "title": "Thieves on Sesame Street! Model Extraction of BERT-based APIs",
            "abstract": "We study the problem of model extraction in natural language processing, in which an adversary with only query access to a victim model attempts to reconstruct a local copy of that model. Assuming that both the adversary and victim model fine-tune a large pretrained language model such as BERT (Devlin et al. 2019), we show that the adversary does not need any real training data to successfully mount the attack. In fact, the attacker need not even use grammatical or semantically meaningful queries: we show that random sequences of words coupled with task-specific heuristics form effective queries for model extraction on a diverse set of NLP tasks, including natural language inference and question answering. Our work thus highlights an exploit only made feasible by the shift towards transfer learning methods within the NLP community: for a query budget of a few hundred dollars, an attacker can extract a model that performs only slightly worse than the victim model. Finally, we study two defense strategies against model extraction---membership classification and API watermarking---which while successful against naive adversaries, are ineffective against more sophisticated ones.",
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "authors": [
                {
                    "authorId": "26161085",
                    "name": "Kalpesh Krishna"
                },
                {
                    "authorId": "32012022",
                    "name": "Gaurav Singh Tomar"
                },
                {
                    "authorId": "144729897",
                    "name": "Ankur P. Parikh"
                },
                {
                    "authorId": "1967156",
                    "name": "Nicolas Papernot"
                },
                {
                    "authorId": "2136562",
                    "name": "Mohit Iyyer"
                }
            ]
        },
        {
            "paperId": "5f486a757893e7761482294227ff91808f15432c",
            "title": "End-to-End Retrieval in Continuous Space",
            "abstract": "Most text-based information retrieval (IR) systems index objects by words or phrases. These discrete systems have been augmented by models that use embeddings to measure similarity in continuous space. But continuous-space models are typically used just to re-rank the top candidates. We consider the problem of end-to-end continuous retrieval, where standard approximate nearest neighbor (ANN) search replaces the usual discrete inverted index, and rely entirely on distances between learned embeddings. By training simple models specifically for retrieval, with an appropriate model architecture, we improve on a discrete baseline by 8% and 26% (MAP) on two similar-question retrieval tasks. We also discuss the problem of evaluation for retrieval systems, and show how to modify existing pairwise similarity datasets for this purpose.",
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "authors": [
                {
                    "authorId": "2396669",
                    "name": "D. Gillick"
                },
                {
                    "authorId": "3377551",
                    "name": "Alessandro Presta"
                },
                {
                    "authorId": "32012022",
                    "name": "Gaurav Singh Tomar"
                }
            ]
        },
        {
            "paperId": "c337d5316b28fa6e502fb98f9bee5c020e372313",
            "title": "Coordinating Collaborative Chat in Massive Open Online Courses",
            "abstract": "An earlier study of a collaborative chat intervention in a Massive Open Online Course (MOOC) identified negative effects on attrition stemming from a requirement for students to be matched with exactly one partner prior to beginning the activity. That study raised questions about how to orchestrate a collaborative chat intervention in a MOOC context in order to provide the benefit of synchronous social engagement without the coordination difficulties. In this paper we present a careful analysis of an intervention designed to overcome coordination difficulties by welcoming students into the chat on a rolling basis as they arrive rather than requiring them to be matched with a partner before beginning. The results suggest the most positive impact when experiencing a chat with exactly one partner rather than more or less. A qualitative analysis of the chat data reveals differential experiences between these configurations that suggests a potential explanation for the effect and raises questions for future research.",
            "fieldsOfStudy": [
                "Computer Science",
                "Psychology"
            ],
            "authors": [
                {
                    "authorId": "32012022",
                    "name": "Gaurav Singh Tomar"
                },
                {
                    "authorId": "3069162",
                    "name": "Sreecharan Sankaranarayanan"
                },
                {
                    "authorId": "2108599909",
                    "name": "Xu Wang"
                },
                {
                    "authorId": "35959897",
                    "name": "C. Ros\u00e9"
                }
            ]
        }
    ]
}